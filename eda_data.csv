,Job Description,Rating,Company Name,Location,Headquarters,Size,Founded,Type of ownership,Industry,Sector,Revenue,Competitors,avg_salary,age_of_company,Job_title_simplified,seniority,R,python,power_bi,tableau,ms_excel,sql,spark,aws,azure,google_cloud,scraping,api_development,machine_learning,deep_learning,statistics,job_description_len,num_comp
0,"Coffee Meets Bagel
Coffee Meets Bagel's mission is to give everyone a chance at love. The app curates quality matches with fuller profiles that result in real conversations. Globally, CMB has generated millions of real dates and thousands of lasting relationships. Coffee Meets Bagel was named one of the Top 10 Dating apps by Time Magazine and the Best Dating App for Women by Refinery29. It has also been voted the #1 recommended dating app for singles looking for relationships.

Job description
Each day, our users visit our app with the hope of connecting with someone. These interactions generate millions of data points that can be used to help us better understand our customers’ experiences. We need you to ask and answer the questions that will transform this data into a better understanding of what our customers find delightful and what they find painful so that you can help drive changes that further our vision of helping singles form meaningful connections with other amazing singles!

The Product Data Scientist will be responsible for partnering with our product and growth teams to provide the facts needed to make better decisions and to help push our products and services to better serve our customers. You will be responsible for building a strong understanding of our ecosystem, working with the product team to determine which projects are the most important, and being willing to use the right tool (a scripted model, a dashboard, a presentation) to find and explain relevant information and insight that will help the company operate better.


Responsibilities
Work cross-functionally with product, design, finance, and engineering teams to provide data-driven insights that will help define the product & marketing roadmap and drive significant increase in core business KPIs (growth, revenue, engagement).
Create internal dashboards to monitor the health of the product and business KPIs (growth, revenue, engagement).
Deliver ad-hoc analyses and reports to support business needs, investigate, triage and resolve metrics-based issues without heavy guidance.
Assist in feature development from ideation to execution, including helping with user research, determining the best way to test new product features, and running deep analysis of feature performance post launch.
Create and share compelling presentations that motivates and inspires the team to build with conviction.
When necessary, build models in R, Python, or other systems that help us better measure and understand the results of experiments or user flows.
Qualifications
Bachelors in a quantitative field and 3+ years post-collegiate work experience as an analyst or data scientist; or a Masters/PhD in a quantitative field with 1+ years relevant experience.
Experience applying statistics to rigorously analyze data and derive insights to solve ambiguous problems.
Expertise designing and evaluating randomized controlled experiments. Familiarity with quasi-experiments is a plus.
High proficiency in SQL & business intelligence tools (e.g., Mode, Tableau, etc).
Capable of condensing data and telling a persuasive story to technical and non-technical audiences.
Self-starter, with ability to thrive in a dynamic, fast-paced environment, drive change through influence, and collaborate effectively with a variety of cross-functional stakeholders. Excited and hungry to try new tools and processes to achieve results.
Passionate about building delightful products for our customers.
Competency in R, Python, or another scripting language is a plus.

This role is only for candidates in Ontario, Canada .",4.4,Coffee Meets Bagel,Toronto,"San Francisco, CA",51 to 200 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,$1 to $5 million (CAD),-1,111.5,8,data scientist,na,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,3599,0
1,"Wanted: A Data visualisation expert who will help us transform customer data into actionable insight

PN is looking for an ambitious, persuasive data visualization guru who’s passionate about health, fitness and helping people live their best life.

Precision Nutrition is growing, and we need a results-driven business intelligence analyst to mine our customer data, develop analysis and deliver recommendations to product and digital marketing groups. As one of the largest nutrition coaching companies in the world, PN is bigger than it’s ever been — and it’s about to get bigger.

To help us scale, we need a data visualization specialist who knows how to synthesize data into plain English so we can help millions more people live healthier, happier lives.

Join our Adventure

We’re embarking on a new adventure, and we need a multi-talented data scientist to drive the analysis that strengthens our product offers

We’ve got an exciting journey ahead of us… Over the next 10 years, Precision Nutrition will be expanding its world-class education and coaching services into a wide range of new fields, including yoga, group exercise, sports coaching, athletics, manual therapy and more.

To help us reach our goals and keep us moving forward, we need a data scientist who knows how to distill complex data into actionable steps—and communicate it to the right people.

Who we’re looking for

A shrewd data hound with the ability to communicate clearly

You’re naturally curious. You have an inquisitive mind, and you’re always looking for hard numbers to uncover patterns and insights in the way people think and work. You want to know what makes people tick, and gaining a deep understanding of your customers drives you to develop innovative solutions to solve their problems.

You’re self-motivated. Once you are confident in what you need to do, you can run with it and don’t need a lot of direction. You have strong self-structure and discipline and have worked remotely either currently or in the past so you know the benefits and the challenges. At the same time, you don’t silo yourself, and are always eager to learn more and share with the team.

You’re results-driven and have a strong bias for action. You get energized by developing recommendations that improve our product, and you excel at understanding and optimizing the journey our customers go through. You excel at knowing how to prioritize, adapt quickly when the scope changes—because it often will—and juggle lots of moving parts.

You’re a confident decision maker. Since you’ll be collaborating with people across the organization, you’ll be taking in a lot of competing input and synthesizing that into a specific course of action. You aren’t afraid to take on the authority and accountability needed to make a decision and drive the plan forward in the way you think will have the biggest effect. You don’t water down the plan to please everyone.

You’re an excellent communicator. You know how to say it, write it and present it in both layman’s terms and a bit more formally if needed. You know how to be heard and energize people around you, even when you’re “managing up” and presenting recommendations to the board.

You’re a motivating, team-oriented, people person. Let’s face it, in order to get other people to execute on your projects, you must be able to easily build relationships and credibility. You earn and give respect so that you can collaborate with the team and persuade the right people of your recommendations. Oh, and since you get to do all of this remotely, from the comfort of your home, and you won’t be going into an office every day to wrangle the team—so your people and leadership skills are truly first class.

What you’ll be doing

Seeking constant opportunities to make our product offerings better

You’re the navigator, deciphering the map and telling the captains the best course to their destination.

Your mission is simple: comb through customer data to find the best areas for improvement, and relay that to the business side of the company. That means:
Building and monitoring metrics. You’ll work through requirements for surveys and dashboards, and monitor KPIs over time to identify trends and build models that explain how our customers interact with our organization and use our product.
Collaborating with the data and analytics group. On the other end of things, you’ll also help set up and automate data collection and aggregation to support analytical needs.
Presenting to stakeholders. Once you identify areas for improvement, you’ll need to present your case to the marketing or product team, explaining what the data tells us and how to make that campaign or product feature better (or discussing possible areas we need to dig deeper).
A few important caveats

This is a dream job, if you’re the right person for it.

Must-Have #1: You must be experienced. We’re looking for someone with 3-5 years of experience in a data scientist position, ideally with a degree in math, stats, or computer science. You must have a demonstrated track record of going from data exploration to analysis and presentation of recommended actions that resulted in a business improvement.

Must-Have #2: You must know the tools of the trade. You have a solid understanding of data manipulation and visualization, statistical analysis, predictive analytics, and customer segmentation—and the tools that go along with those. You can develop visualization dashboards in reporting tools such as Tableau like a pro, and you have experience with data science tools like Heap, Panda, SciKit, and others, as well as manipulate and analyze data in SQL and Python.

Must-Have #3: You must be comfortable collaborating and communicating. Your job extends beyond analyzing the numbers, so you’ll need to be just as comfortable presenting recommendations to others as you are digging through data on your own. In particular, you excel at translating technical concepts into business-driven advice.

Wondering if this is the right path for you?

Every year, professionals at the top of their field choose to join Precision Nutrition.

Here are some reasons why.

Reason #1: We give you the freedom to “do you.”

Unlike most companies, we don’t have rigid rules about how and when to do things. You’ll always be free to work independently, whenever, wherever, and however you want -- without the bureaucracy and office politics.

Reason #2: You can work from anywhere.

We’re a 100% remote company, and have been working remote for 17 years. We’re ideally looking for candidates in Canada, but will consider the US as well. When you join our team, you’re no longer shackled to one desk in one office!

Reason #3: Meetings are optional. (No, really.)

You’re an adult. You’re capable of deciding how your time should be spent. If you don’t think you need to attend a meeting, you don’t. Simple as that.

Reason #4: You’ll always feel supported.

In a regular office, it’s easy to feel like a hamster in a wheel, powerless to change things. At Precision Nutrition, we work as a team to overcome issues & barriers that stand in each other’s way, and we treat each other with enthusiasm, compassion, and care.

Reason #5: You’ll never be bored.

People often come to Precision Nutrition after hitting a plateau in their old jobs. At PN, you’ll get the chance to chart new territories in your space, conquer new challenges, learn from the best, and reach thrilling new heights of personal and professional growth.

Reason #6: You’re free to be you.

At Precision Nutrition, we want everyone to live healthier, happier lives—no matter your race, age, gender, religion, or sexual orientation. That's why diversity is a key ingredient of our workforce, so we can best represent the people we serve. Everyone is welcome—as an inclusive workplace, we want our employees to bring their authentic whole selves to work. Be you.

Reason #7: You’ll have autonomy.

Not every data scientist job allows you time in the driver’s seat, but with this position, you’ll be taking charge of the analytical projects related to our product, and even make up your own projects that help make us better. You’ll never be bored by the range of tasks you get to work on.

Plus: no commute ... and no 9-to-5 grind.

Sound like we might just be the perfect company for you? Then you might just be the perfect fit for us. Click Apply for this Job below to get started!",5.0,Precision Nutrition,Toronto,"Toronto, Canada",51 to 200 employees,2001,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1,111.5,19,data scientist,na,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,8435,0
2,"About ApplyBoard
ApplyBoard is an online platform that empowers students around the world to access the best education. Founded in 2015, ApplyBoard has grown to become the world’s largest online platform for international student recruitment, assisting more than 100,000 students with their educational journey. By connecting international students, recruitment partners, and educational institutions, we simplify the study abroad search, application, and acceptance process through our platform and services. To date, we have built partnerships with 1,200+ educational institutions in Canada, the United States, and the United Kingdom, and 4,000+ recruitment partners around the world. In 2019, ApplyBoard was named the fastest-growing technology company in Canada by Deloitte, ranking #1 on the Technology Fast 50™ list.
In May 2020, the company announced it successfully raised C$100M Series C funding on a C$2B valuation, reaching a ‘Unicorn’ valuation, allowing us to invest heavily in our technology, growing our team, and serving more customers.

Our Team
Our team of over 500+ ApplyBoardians (and growing!) is just as diverse as the customers we support. Comprising 27 nationalities, 53 languages spoken, and 50/50 gender parity, diversity is fostered and celebrated on our team. The ApplyBoard headquarters is located in Kitchener, ON Canada, with representatives in 20 countries including India, Bangladesh, Nepal, Pakistan, Vietnam, the Philippines, the United Kingdom, Mexico, Brazil, and China.


The Role:
ApplyBoard is looking for a Data Scientist that values collaboration and nurtures innovation while working in an energetic team. The ideal candidate will have a strong foundation in statistics, data science, and/or pattern recognition who will be valuable to organize, interpret and transform large datasets into actionable intelligence. In this role, it is expected to use best practices to identify data-driven opportunities for innovation, build analytics, and create machine learning models for deployment across the company.
Responsibilities
Create machine learning models to build a world-class data driven product
Guide data strategies to interpret and predict human behaviour
Work with an innovative team to shape the future using objective data-driven decisions
Identify and qualify new data sources, techniques, and datasets to enhance insight
Facilitate and support the use of sound analytical practices across the organization
Analyze large, raw, and potentially noisy datasets to derive actionable intelligence
Interpret relevant insights from diverse datasets including time-series data
Validate results using best practices in math and statistics
Visualize and present insights and models clearly and effectively to diverse audiences
Required Skills
Degree in mathematics, statistics, engineering, computer science, finance, or similar
2+ years of experience in Data Science and/or Machine Learning
Demonstrated ability to learn, adapt, and solve tough problems
Strong analytical skills, strong model and software development skills and an open mind
Experience and passion for applying statistical and data mining techniques to overcome real world challenges - deriving intelligence from data
Experience writing complete, clear, and concise designs, data models, and algorithms
Highly proficient at disseminating complex technical concepts in both written and oral forms with the ability to communicate this across all levels of the business
Experience building data-driven software solutions with Python
Experience querying and analyzing data using SQL
Experience with visualization tools ( Tableau, Plot.ly/Dash, Pentaho, PowerBI)
Driven, passionate and creative, and thrives in a fast-paced environment
What We Offer


The opportunity to have an impact on a product that is positively affecting change to thousands of students lives every dayWorking alongside a brilliant and globally diverse team that is the fastest growing in the Waterloo regionGreat compensation and benefits package to keep you healthy and happy!
Thank you for your interest in ApplyBoard, however, only those applicants that have been selected for an interview will be contacted.

At ApplyBoard, we understand the value of having a diverse team. That’s why we believe in providing equal opportunity regardless of race, national or ethnic origin, colour, religion, age, sex, sexual orientation, gender identity or expression, marital status, family status, genetic characteristics, disability, and conviction. Please let us know if you require accommodation during the recruitment process.",4.1,ApplyBoard,Kitchener,"Kitchener, Canada",501 to 1000 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,111.5,5,data scientist,na,0,1,1,1,0,1,0,0,0,0,0,0,1,0,1,4599,0
3,"You will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally.

You will influence many of the recommendations our clients need to positively change their businesses and enhance performance.

Role responsibilities
Work on complex and extremely varied data sets from some of the world’s largest organisations to solve real world problems
Develop data science products and solutions for clients as well as for our data science team
Write highly optimized code to advance our internal Data Science Toolbox
Work in a multi-disciplinary environment with specialists in machine learning, engineering and design
Add real-world impact to your academic expertise, as you are encouraged to write ‘black’ papers and present at meetings and conferences should you wish
Attend conferences such as NIPS and ICML as one global team as well as Data Science retrospectives where you will have the opportunity to share and learn from your co-workers.
Work within one of the largest and most advanced data science teams in London, support the Lead Data Scientists to develop data science products
What you’ll learn
How successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines
Build products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations
Be able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.
Best practices in software development and productionise machine learning by working with our Machine Learning Engineering teams which optimise code for model development and scale it
Work with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualisations
Using new technologies and problem-solving skills in a multicultural and creative environment
You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.
Real-World Impact– No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership– We work with the latest technologies and methodologies and offer first class learning programmes at all levels.
Multidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture– Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity– With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.
Our projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimising a Formula1 car’s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture:
Healthcare Efficiency– We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.
Environmental Impact– We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.
Product Development– We worked with the CEO of an elite automotive organisation to reduce the 18-month car development timeframe by improving processes, designs and team structures.
Please submit your CV in English

Visit our Careers site to watch our video and read about our interview processes and benefits

As an equal opportunity employer, QuantumBlack encourages applications from all backgrounds regardless of gender, race, disability, pregnancy, marital status, age, sexual orientation, gender reassignment, religion or belief. We maintain a sense of community rooted in respect and consideration for all employees where any evaluation is based simply upon individual work and team performance.",4.4,McKinsey & Company,Montreal,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&",111.5,94,data scientist,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4674,3
4,"About Assurance
At Assurance we are disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosystem. We are rapidly growing as we expand our product offerings and global footprint, and this growth continues to present new and exciting challenges as we push our industry into its future. We eliminate waste throughout the industry and calculate the complex into simple, valuable solutions to improve people's lives. We are humble, driven, and committed to improving the lives of millions.

About the Position
As we build the future of consumer insurance in a modern age, data is at the core of everything that we do. The role requires team members who are adept at using large data sets to find opportunities for optimization and can leverage appropriate models to test the effectiveness of different courses of action. Our team uses a variety of data mining and analysis methods, a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Team members must be very comfortable writing production-ready code to include testing and maintenance infrastructure, and able to put models and analysis into production with no support from engineering (we own our stack end to end). At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise.

About You
You have a proven ability to drive business results with data-based insights and are comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. You’re capable of getting data for analysis on your own, without reliance on engineering, and you can build professional dashboards as standalone software products and tools. We’re growing at a rapid pace, so it’s important that you embrace the opportunity to blaze your own trail. You thrive in a fast-paced environment where priorities can shift rapidly as we corner opportunity. You can work independently, with little oversight or guidance.
To be successful in this role, you must possess the following:
Proficiency in either Python or R, and expertise in SQL.
Experience working with AWS or another cloud-based computing platform.
Experience and working knowledge of data infrastructure, pipelines, and advanced data manipulation.
Experience with BI tools like Tableau or Looker (preferred), or any other industry tool such Qlik, PowerBI, Spotfire, etc.
Excellent communication ability – you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.
Business Acumen – you are always eager to understand how the business works, and more specifically, how your work impacts the business.
Enthusiastic yet humble – you are excited about the work you do, but you are also humble enough to embrace feedback – you don’t need to be the smartest person in the room.
Bachelors degree in mathematics, statistics, data science or related field of study.
The following additional experience is desired:
Experience retraining a model within a few days or update a model within one day.
Capable of performing an in-depth analysis and summarizing findings in one day.
Comfortable having conversations with our executive team and non-technical team members to distill down their needs and to deliver actionable insights.



Please review our CCPA policies here.",3.4,Assurance Careers,Toronto,"Bellevue, WA",51 to 200 employees,2016,Company - Private,Insurance Agencies & Brokerages,Insurance,Unknown / Non-Applicable,-1,111.5,4,data scientist,na,0,1,1,1,0,1,0,1,0,0,0,0,0,0,1,3731,0
5,"Do you want to join a team of talented professionals at an agriculture technology (#ag-tech) company on the verge of explosive international growth? Our company has designed and developed an AI robotics platform which detects crop health in commercial greenhouses internationally, eliminating the need for mass chemical pesticide usage. With exciting products hitting the market in the coming months, we are looking for candidates who are passionate about high technology, food, innovation, and sustainability.

We support our customers completely, we accomplish great things as a team, we are passionate about enabling a cleaner future for everyone, we act like an owner, diversity in all that we do is our strength, success comes because we are great learners, we are persistent and forthright and realistic, and our optimistic nature allows us to take on any challenge.

The candidate should have a background in machine-learning, data mining, statistical learning, computer science or similar. Experience or interest in fields such as agriculture, agronomy, or biology is a definite plus! The intern candidate should also have good software development skills and be a great team player. Your focus is on solving the problem - whether that involves developing a new algorithm or putting on your muddy boots to walk the field. Bring passion, dedication, and creativity to your work and you will have a chance to change the future of agriculture around the world!

Duties & Responsibilities

Your role will involve assisting senior data scientists and data engineers:
Monitor, test, and debug the data pipeline
Develop machine learning procedures and algorithms
Construct classification models using developed machine learning tools
Document developed features in the application
Understand, support, test, and troubleshoot production machine learning applications
Education, Skills & Experience
Ecoation Inc. is looking for an 8 or 12 month commitment
Meeting SWILP eligibility criteria is also preferred: https://www.eco.ca/swilp/studentquiz.aspx",4.3,Ecoation,Vancouver,"North Vancouver, Canada",1 to 50 employees,2010,Company - Private,Farm Support Services,Agriculture & Forestry,Unknown / Non-Applicable,-1,111.5,10,data scientist,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,2050,0
6,"People.ai accelerates enterprise growth through the power of AI. With the industry’s only Revenue Intelligence System, People.ai frees all customer-facing teams, including sales, marketing, and customer success, from manual data entry by automatically capturing all contact and customer activity data, dynamically updating CRM and other systems of record, and providing actionable intelligence across management tools to realize the full selling capacity of the enterprise. Some of the world’s best brands are leveraging People.ai to transform their business, including Lyft, New Relic, Okta, Tanium, and Zoom.

At People.ai, we believe that people enrich the world around them in countless ways. We believe that the more time they spend applying their creativity, resourcefulness and critical thinking to activities that matter most in their professional life, the more effective a professional they become. We're developing a deep understanding of the professional world, mapping people, companies, and the information that flows between them through natural language processing and machine learning. Our team is a diverse, outspoken group of creatives and critical thinkers, hyper-focused on driving enterprise growth. We embrace different. We applaud non-traditional career paths. We're inspired by people who have made processes their own.


As a Data Scientist on the Success Services team, you will be responsible for the technical design, implementation, and delivery of our customers’ data for use cases that are not served directly through the product. You will be responsible for managing existing data services, as well as driving all net-new data deliverables owned by Success Services. In addition to the engineering work, you will consult directly with customers, enabling them to build use cases with People.ai data on top of their own infrastructure. This role reports to the Director of Business Value & Insights.
Responsibilities
Serve as the most technically advanced member of the Success Services team as it pertains to data ingestion and manipulation skills and coordinate internally with appropriate technical teams to provide a seamless experience to our customers
Work across Product, Technical Success, and Services to simplify and scale the entire portfolio of Services offerings
Lead logical architecture design in collaboration with Product and Technical Success to enable scalable data models that support value delivery to customers
Assist customers with API configuration and ingesting People.ai data into their analytics infrastructure
Enable customers on People.ai activity data to support their own use cases
Build custom dashboards leveraging our Executive Analytics Platform (embedded BI in web app) along with Product
Create customer-facing documentation for our top dashboards
Optimize refresh schedules for data pipelines and dashboards, both internally and externally
Own the delivery and development of the Historical Contacts Service in coordination with Technical Success
Conduct a backend data design audit of top 5 use cases to ensure scalability moving forward
Requirements
Extensive (5+ years) of coding (e.g. Python, Java, Scala) and data modeling experience
Strong (3+ years) experience with enterprise data analytics architecture, developing data pipelines, and using various ETL libraries/tools
Strong (2+ years) experience building reports in BI tools (e.g. Tableau, Looker, Power BI, Sisense) on top of data warehouses (e.g. Redshift, Snowflake, BigQuery)
Expert at extracting and manipulating data from multiple sources, including relational databases and REST APIs
Working knowledge of cloud-based big data technologies (e.g. Spark, Hive, Hadoop)
Comfortable consulting with customers to enable them to leverage People.ai data within their infrastructure
Must be very organized and know how to accurately and thoroughly document all solutions produced
Values teamwork and good at building partnership cross-functionally
Open to feedback and ideas from others
Creative and innovative
Analytical, data-driven and high-level problem solver
Founded in 2016 and based in San Francisco, the company is backed by ICONIQ Capital, Andreessen Horowitz, Lightspeed Venture Partners, Y Combinator and others. In 2019, People.ai was recognized as a winner of the 2019 Bay Area Best Places To Work, an awards program presented by the San Francisco Business Times and the Silicon Valley Business Journal.",4.4,People.ai,Toronto,"San Francisco, CA",51 to 200 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Clari, Outreach",111.5,4,data scientist,na,0,1,1,1,0,0,1,0,0,0,0,1,1,0,0,4446,2
7,"Data Scientist

INVISTA Canada's Kingston Nylon manufacturing
site located in Kingston, Ontario is looking for a Data Scientist to support INVISTA’s
manufacturing plants around the world. A
successful candidate will be responsible for leveraging INVISTA’s data assets -
thousands of sources and billions of records from across our operations – to
improve the company’s business performance.

It is an exciting phase in INVISTA’s
continued evolution through
growth and transformation projects. This
position will be a key strategic addition in growing the capability of our global
operations to make data driven decisions.

We are looking for motivated and talented people who will help us
meet the challenge of leading rapid experimentation, pursuing continuous
innovation and creating long-term value for customers and society. INVISTA is an
independently managed but wholly owned subsidiary of Koch Industries, Inc.
Why Work for INVISTA?
A culture that
places top priority on integrity and compliance
Supported by
INVISTA’s Data Engineering team so the scientist can focus on
experimentation and validation
An opportunity to
learn from analytics experts at INVISTA and collaborate in solving
challenges across other companies at Koch Industries
Leading
implementation of advanced analytics to transform INVISTA operations towards
the factory of the future

Position Responsibilities:

As a member of the INVISTA team, you will
have the opportunity to work in a fast-paced manufacturing environment with an
aim to drive data oriented solutions to operations and commercial needs . You
will:
Work with operations and
commercial stakeholders to identify opportunities for leveraging data and
analytics to drive business solutions across the entire Performance
Solutions business.
Explore and analyze data to
drive optimization and improvement of data informed decisions
Assess the effectiveness and
accuracy of new data sources and data gathering techniques.
Develop data models and Machine
Learning algorithms and implement these capabilities at scale.
Coordinate with different
functional teams to implement models and monitor outcomes.
Develop processes and tools to
monitor and analyze model performance and data accuracy.
Coaching and mentorship for
developing analytics capability across the organization.
To generate the greatest contribution to our
company, you must be results driven, thrive in team-oriented work environment, an
economic thinker, and have excellent communication skills to be able to work
with all areas of the organization.

Above all you must ensure that all your
activities are carried out with integrity and in a safe and efficient manner.
Skill Requirements:

A degree in engineering, computer science, mathematics
or similar field with a focus on Data Science/Data Mining/Data Analytics
Experience with a Programming Language (Python, R,
Scala, Julia, Java)
Experience or education working with the various data
storage mechanisms (Hadoop ecosystem, Microsoft SQL, Oracle)
Exposure to predictive analytics tools (R, TensorFlow,
PyTorch, SAS, Knime, Apache Spark) and concepts (classification,
regression, clustering, neural networks)
Previous work experience in the field is an
asset but not required

Compensation:

Competitive salary commensurate with skills
and experience.


We provide:

Competitive salary
Flexible benefits
package
Defined benefit
pension plan
Optional pension
enhancements
Performance bonus
program
Additional
vacation purchase program
Additional
floating holidays
Education
Assistance Program for job related training

About INVISTA

From the fibers in your carpet to the plastic
in your automobiles, INVISTA’s commitment to continuous improvement has
led its employees to develop some of the most durable, versatile polymers and
fibers in the world. A subsidiary of Koch Industries since 2004, INVISTA
brings to market the proprietary ingredients for nylon 6,6 and recognized
brands including STAINMASTER®, CORDURA® and ANTRON®.

INVISTA also offers specialty chemical
intermediates and process technologies. See the bigger picture at INVISTA.com

Want to learn more about the INVISTA
experience? Watch this!

To find out more about working at INVISTA’s
Kingston Site: Watch this!

To find out about working and living in
Kingston, please visit: https://possiblemadehere.org/

How to apply?

Interested applicants should submit a
detailed resume along with a covering letter to www.invistacareers.com

If you
have the above qualifications, we would like to hear from you. We thank all
applicants, in advance, and advise that only those selected for an interview
will be contacted.

Successful
candidates will be required to complete a criminal background check.

We are an
equal opportunity employer. If you require accommodation or assistance at any
time during the application or selection processes, please submit a request by
following the directions located at the bottom of kochcareers.com webpage.",3.5,INVISTA,Kingston,"Wichita, KS",10000+ employees,-1,Subsidiary or Business Segment,Chemical Manufacturing,Manufacturing,Unknown / Non-Applicable,-1,111.5,-1,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,4961,0
8,"ABOUT MOBSQUAD

We are a well-funded, hyper-growth, scale-up looking for an experienced Data Scientist. If you've ever dreamed of working with a top tier technology company scale-up, on leading edge technologies, backed by the very best venture capitalists in the world, then this is your chance.

Some details about MobSquad:
MobSquad solves the significant and growing technology talent shortage faced by US-based start-ups and scale-ups by enabling our clients to quickly have a turnkey ""virtual"" Canadian subsidiary, where Canadian-based software engineers serve our clients individually on an exclusive basis
We've been featured on the front page of The Washington Post , on NPR multiple times, The Financial Times (UK), The Globe and Mail, the Calgary Herald, BetaKit, CBC, Global News, and many other places. other media outlets
We're a Certified B Corporation, were recognized as the third Best Place to Work in Canada in 2020, and have made numerous contributions to charitable organizations as well as a financial commitment to the Upside Foundation. We believe we are playing a key role in enhancing Canada's innovation economy, and have received financial support from the Government of Canada, Province of Alberta, Province of Nova Scotia, and City of Calgary, to support this ambition
You can learn more about us on our website

ABOUT THE ROLE

As a Data Scientist, you will be part of a Canada-based team working remotely for a leading US start-up. Your team will operate alongside many other talented developers and data scientists in Canada, and you will be an integral part of the tech community that MobSquad has built.

This role requires someone who has demonstrated an ability to bridge the gap between the theoretical and the practical. The ideal candidate has deployed or attempted to execute Artificial Intelligence theories from various Machine Learning (ML) models and algorithms, and also has some experience in data engineering. MobSquad is looking for proven researchers with a track record of publishing in impactful journals and conferences, or those with years of hands-on industry experience.

This role offers the opportunity to apply your knowledge of statistics and your analytical skills to mine data at scale and develop large-scale ML models to reveal the value in data. You will support feature prototyping and utilize best practices to write production-grade code. You will build data pipelines, implement ML-based analytical algorithms, and work closely with the software development team to set up back-end systems and interfaces that will deliver next-generation analytics.

ABOUT YOU

You have an advanced degree (M.S. or PhD) in Data Science, Computer Science, Engineering, or a comparable analytical field from an accredited institution
You are expert in data mining, machine learning, deep learning, statistical modeling, and data visualization techniques using data-oriented tools and languages such as Python, R, and MATLAB
You have over three years of experience or demonstrated fluency in relevant programming languages (Python, R, Scala, Java, C/C++, C#)
You have over three years of experience working with SQL (MySQL, SQL Server) as well as NoSQL (Cassandra, Hbase) databases
You have experience setting up and using large-scale distributed data-processing frameworks such as Apache Spark and Hadoop MapReduce
You have experience working with enterprise-grade cloud computing platforms such as Microsoft Azure, Amazon Web Services, or Google Cloud
You have demonstrated ability to develop high-quality code adhering to industry best practices (e.g., code review, unit testing, revision control)
You are familiar with designing experiments and collecting data for the purpose of deriving data analytics insights and solutions
You have experiencing creating and deploying recommendation and/or predictive models
You have work/project history reflective of a self-motivated professional who excels when given open-ended problems and broadly-defined goals, having an innate desire to discover the patterns and relationships in data that can be leveraged to provide business value

WHAT YOU'LL GET @MOBSQUAD

A full-time position that offers competitive compensation
A benefits program delivered through our bespoke digital platform, giving you control, choice, and flexibility. We give you the ability to build your package of benefits covering health (e.g., medical, dental, vision), wellness (e.g., gym, workout gear, massage, transit), and RRSP (retirement savings)
A downtown office location with first-rate amenities, surrounded by great restaurants and easily-accessible transit
For international candidates, sponsorship for an immediate work permit, expedited permanent residency, and Canadian citizenship within four years

At MobSquad, we support and encourage building a work environment that is diverse, inclusive, and safe for all. We invite and welcome applicants of all backgrounds, regardless of race, religion, sexual orientation, gender identity, national origin, or disability.",4.4,MobSquad,Calgary,"Calgary, Canada",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,111.5,-1,data scientist,na,0,1,0,0,0,1,1,1,1,1,0,0,1,1,1,5047,0
9,"Guavus, a Thales company, is seeking a Data Scientist Intern. This is an exciting, technical role based in our Montreal office. It is focused on enabling our customers to create real, practical value through advanced analytics on their streaming data. Our customers – primarily large telecom service providers – use Guavus’ analytics to increase revenues or reduce costs by better network optimization, customer experience optimization, churn management, marketing, etc.

We offer 4 months internship with a possibility to extend to 8 months. We have full time position available for interns that stand out after the end of their internship & classes.

About Guavus


Guavus solves the world’s most complex data problems. Proven across Tier 1 service providers, Guavus provides a new generation of analytically powered big data applications to address specific business problems for next-generation service assurance, next-generation customer experience management and the Internet of Things. The Company uniquely breaksdown the barriers between Operational Support Systems and Business Support Systems to enable customers to deliver a better customer experience, improve service operations and more efficiently plan network capacity. Guavus’ operational intelligence applications correlate and analyze massive amounts of streaming and stored business, operational and sensor data from multiple, disparate source systems in real time. Guavus’ products currently process more than two trillion transactions per day.

Skills & Qualifications:
Bachelor’s or master’s degree in an Engineering or Science field with coursework in Linear Algebra and Statistics
Analytical skills – ability to quickly analyze data to identify and visualize key insights – as evidenced by coursework or research requiring the analysis of large datasets applying machine learning (regression, clustering, decision trees, neural networks, etc.)
Algorithmic understanding of standard machine learning methods
Good understanding of CS fundamentals such as data structures and algorithms, functional programming, cluster computing, etc. and the ability to quickly translate ideas to efficient, elegant code
Working knowledge of at least one program: Java, Scala, Python
Experience in high volume data scenarios and hands on knowledge of distributed systems such as Hadoop and Spark will be a big plus
Excellent oral and written communication skills, including the ability to present effectively to both business and technical audiences
Excellent attention to detail, organizational and time-management skills
Roles & Responsibilities:


Implement ETL & machine learning algorithms and benchmark their performances
Perform data validation exercises, tracing data from source to applications to confirm
implementation designs
Analyze data and present insights
Document data analysis work and results",2.7,Guavus,Montreal,"San Jose, CA",201 to 500 employees,2006,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (CAD),-1,111.5,14,data scientist,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,1,2867,0
10,"LOCATION: Calgary, Alberta (CA-AB)
JOB NUMBER: 41297

Why you should join us:

We are living in an era of transformation – as a company, as an industry and as a global community. Suncor is evolving and we’re calling it Suncor 4.0. Technology and digital solutions are a big part of this, but unleashing the full potential of our people is what will get us where we need to be.

An essential part of our evolution is creating value through data and becoming a data-informed enterprise where employees can apply their knowledge, draw insights and make the best possible decisions. Hiring specialists like yourself will help us implement our Advanced Analytics strategy and transform our business. It’s all about strengthening our future through digital technology, unleashing the full potential of our people, and creating an engaging and productive workplace.

Working as part of our Advanced Analytics (AA) team in our Transformation Management Office you will work across our organization to identify and apply advanced analytics practices including machine learning, deep learning techniques and artificial intelligence to transform the way we do business.

If you’re passionate about data, and thirsty for new approaches that provide insights into the most complex challenges through the architecting of data for advanced analytics, this role is for you!

Are you ready to help us solve problems we’ve never been able to address before? Join us and be part of transforming Suncor’s future!

You will use your expertise to:
Act as a key contributing team member for advanced analytics products focused on analytics product and insight development and sustainment
Design, create, test and implements models through algorithms that drive analytical products throughout the organization
Apply Suncor Use Case Delivery Model and Suncor Model Management practices for analytics product development and operations
Work with Data Engineers and SME’s to understand the raw data and/or create engineered features that improve model performance
Collaborate with cross-functional team members to deliver high-impact scalable and sustainable products in a Minimum Viable Product (MVP) approach through product releases
Use data science techniques to find data patterns, anomalies, and optimization opportunities
Provide expertise on mathematical concepts for the broader applied analytics team and inspire the adoption of advanced analytics and data science across the entire organization
Interpret, translate and communicate analytical findings to business stakeholders through visualizations
Identify and implement continuous improvement to standards, processes and techniques within the AA Centre of Excellence (CoE)
We’d like to review your application if you have…

Must-haves (minimum requirements):
Three to 10 years of progressive experience in advanced analytics or a quantitative field
A Bachelor or Master’s degree with a focus in data science, computer science, analytics, actuarial science, statistics, operations research, mathematics, data mining, economics or a related quantitative field (e.g. epidemiology/public health, geomatics)
Proven proficiency developing analytics products in Python and/or R MATLAB or statistical analysis environments such as SPSS or SAS
A deep understanding of predictive modeling and statistical concepts, machine learning approaches, clustering and classification techniques, and recommendation and optimization algorithms
Strong communication, dynamic and critical thinking, and story-telling ability (through data) to influence and propose analytics strategies and solutions that challenge and expand the thinking of everyone around you
Alignment with our values: safety above all else, stronger together, operational discipline, curiosity and lifelong learning, and act with integrity
Preference for:
Experience in mining, In Situ, refineries, cyber security, geology, and/or a corporate/functional business background
Experience with unstructured data (e.g. image recognition, audio analytics, text mining)
An accredited professional statistician (PStat)
Where you’ll be working, your work schedule, and other important information:
You will work out of our Calgary head office, located in the Suncor Energy Centre at 150 – 6th Ave S.W.
This role can also be supported from one of our hub locations (e.g. Mississauga, Fort McMurray, Edmonton, Sarnia, Montreal)
One of our values is curiosity and lifelong learning – we challenge the status quo and learn from and support each other to make the world a better place
We are so invested in building advanced analytics skills within our organization that we've created the Analytics Academy to provide training to employees through instructor-led courses, e-learning, communities of practice, etc.
Why Suncor?

Supporting our people. Caring for our communities. Living our purpose.

With our operations declared an essential service, we are continuing to operate and are looking to fill business-critical roles at this time. We require qualified and safety-focused employees to help keep things running. In terms of our current recruitment process, we’re doing things a bit differently to adjust to our new ‘normal.’ We are using technology to conduct virtual interviews to adhere to physical distancing recommendations and we are well set up for remote onboarding and orientation.

We are bolstered by the unity across our community and the solidarity across the world. We continue to encourage you to support global efforts to limit the impact of COVID-19 with good hygience practices, physical distancing, and with care and consideration for the people around you. For more information on how we’re responding to COVID-19, click here. #StrongerTogether

We are Canada's leading integrated energy company with a business portfolio that includes oil sands development and upgrading, offshore oil and gas production, petroleum refining, and product marketing under the Petro-Canada brand. Our global presence offers rewarding opportunities for you to learn, contribute, and grow in a variety of career-building positions. We live by the value of safety above all else – if it isn't safe, we don't do it. Our strong track record of growth and a focus on sustainability mean tremendous potential for the future. Learn about our purpose and values.

In addition to rewarding job opportunities, we offer an attractive employee package, including:
Competitive base salary, compensation programs, and an annual incentive program
Flexible benefits package
Rewarding pension and savings plans
Stay connected to us:
Follow us on LinkedIn, Facebook and Twitter for the latest job postings and news
Visit our Report on Sustainability to see our progress on a number of environmental, social and economic topics and what we’re doing to position our company for the future
Join our Talent Community and sign up to receive customized job alerts
Read our Suncor Connections newsletter to see what we’re doing in the communities we live and work in
We are an equal opportunity employer and encourage applications from all qualified individuals. We are committed to providing a diverse and inclusive work environment where every employee feels valued and respected. We will consider accessibility accommodations to applicants upon request. Check out our social goal to learn how we are working to build greater mutual trust and respect with the Indigenous Peoples in Canada.

Please note that our job postings are typically open for two weeks, so don't delay, apply now.

JOB CATEGORY: Business Professionals",4.0,Suncor Energy Services,Calgary,"Calgary, Canada",10000+ employees,1967,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$10+ billion (CAD),"Imperial Oil, Husky Energy",111.5,53,data scientist,na,1,1,0,0,0,0,0,0,0,0,0,0,1,1,1,7578,2
11,"Who is Geotab:

Geotab, a global leader in IoT and connected transportation, is one of the fastest-growing technology companies in North America and a certified “Great Place to Work.” Each day, Geotab processes billions of data points from over 2 million connected vehicles, extracting actionable insights to help empower businesses to better manage their fleets. Recognized as the world’s #1 commercial telematics provider, Geotab’s solutions are used by more than 40,000 customers in over 130 countries around the globe. Geotab understands that telematics is critical to helping create safer and more sustainable drivers, businesses and communities and actively works to help businesses improve driver behavior, reduce greenhouse gas emissions and create safer roads for all. Global demand for telematics is increasing and Geotab is leading the way. Are you ready to join us? To see what it’s like to be a Geotabber, follow us @InsideGeotab on Instagram, Twitter or Facebook today!

Who are we looking for:

We are looking for amazing talent who can contribute to our efforts and deliver results! Geotab is seeking a Data Scientist Intern who will immediately contribute to the organization and to the Data and Analytics team. If you love technology and analysis, are well organized, and are keen to join an industry leader — we would love to hear from you!

What are the details of this position:

As a Data Scientist Intern, you will work alongside a team of fellow Data Scientists on Geotab’s Data & Analytics team. This technical department is responsible for producing insight from Geotab’s big data environment, which streams and ingests over 3.5 billion data records per day from over 1.3 million vehicles in 85 countries across the globe. You will work closely with Data Scientists and Data Engineers to mine data and build models to support the development of new data-driven solutions. To be a successful Data Scientist, you must be a big-picture thinker who is also interested in the details. The results of your analysis will be developed into Customer-facing data products, so you will need to understand how our Partners and Customers can benefit directly from your analysis. The successful candidate must also be able to manage projects to completion and deliver effective solutions.
Duties and Tasks/Essential Functions:
Use SQL and Python to interact with Geotab’s big data infrastructure
Leverage learning packages like Scikit-Learn and Tensorflow to develop Machine Learning models
Develop new features for Machine Learning models and visualize features
Own the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions
Use data mining, model building, and other analytical techniques to develop new datasets and data driven solutions
Make recommendations for new metrics, techniques and strategies to improve Geotab’s product suite

Experience/Skills Required:

Within final two years of a university degree in Engineering, Computer Science, Math or a related field
Strong communication, organization and time management skills, as well as a willingness to learn and strong work ethic
Experience using SQL
Experience using Python
Experience working with Machine Learning algorithms and big data tools is an asset
Previous industry work experience preferred
Ping Pong and Foosball skills always a plus
What makes our staff passionate about Geotab?

Table Tennis at the office - bring your own bat!
Great accommodation (brand new office building, height-adjustable desks)
Light breakfast served daily
Hot lunches or fresh sandwiches served every Friday
Geotab-sponsored sports teams and social events
Full medical benefits and 4% company matching RSP (full-time employees only)

Our Core Values:

Geotab is shaping the future of telematics. Using leading technology, we embrace change and challenge the status quo. To stay ahead of the curve, we keep Geotabbers energized with data bootcamps, course subsidies, Friday lunches, and more. We believe collaboration leads to innovation; our teams stretch across floors, cities and continents. All employees, from the CEO to the summer students, maintain an open-door policy. Whether we’re fine-tuning our products, or boosting our office culture, we’re building a foundation for long-term success. To us, this means safer roads, more efficient fleets and a team of dynamic Geotabbers!

Geotab encourages applications from all qualified candidates. Geotab is committed to accommodating persons with disabilities throughout the interview, selection and employment process. If you require accommodation at any stage of the application process or want more information about our accommodation policies and practices, please contact us at (416) - 434 4309.",4.3,Geotab,Oakville,"Oakville, Canada",1001 to 5000 employees,2000,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (CAD),-1,111.5,20,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,4784,0
12,"Fujitsu

Named again in 2019 as one of FORTUNE’s ‘World’s Most Admired Companies’, Fujitsu is a leading multinational information and communication technology (ICT) company at the forefront of driving enterprise-scale digital transformation initiatives in organizations and communities around the world. Offering a full range of technology products, solutions and services, Fujitsu’s commitment to R&D continues to deliver cutting-edge technologies, particularly in the fields of artificial intelligence, quantum-inspired computing, IoT, blockchain, and supercomputing. Combined with its core offerings in IT infrastructure and cloud transformation, this has enabled Fujitsu to develop vast international business operations employing over 132,000 people in 100 countries worldwide in all business sectors at the heart of the global economy. Additionally, Fujitsu’s strong orientation towards the environment, sustainability, and social/societal impact, has ensured it continues to be named to the Dow Jones Sustainability World (DJSI World), the world’s leading Socially Responsible Investment (SRI) index, year after year.

Fujitsu Intelligence Technology

Fujitsu Intelligence Technology Limited (FITL) is an emerging center of excellence and forward-looking innovation center in Fujitsu’s global operations for data science, artificial intelligence, quantum-inspired computing, and digital transformation. Located in Vancouver, Canada, and operating as a gateway to Fujitsu’s profound global engineering and innovation ecosystem, FITL is positioned as a digital transformation catalyst, working to grow Fujitsu’s AI and Digital Annealer-powered quantum-inspired computing business in North America and globally.

Learn more:
1) • http://www.fujitsu.com/global/about/corporate/info/
2) • http://www.fujitsu.com/global/about/resources/news/press-releases/2018/1106-01.html
3) • http://www.fujitsu.com/global/digitalannealer/
4) • http://www.fujitsu.com/global/solutions/business-technology/ai/
Comprised of a diverse and talented team of professionals committed to helping Fujitsu’s customers navigate an increasingly digital world, FITL believes that employee development, health and wellbeing, work-life balance, and diversity and inclusion are as important to them as being leaders in digital innovation. FITL’s goal is to create an environment where employees feel free to be their authentic selves at work and realize their full potential all while working collaboratively together to co-create transformative solutions at the heart of reimagining how businesses and society can thrive in this millenium.

We are looking for a Data Scientist in our Vancouver BC office.

Position Summary
We're looking for a seasoned Data Scientist to join Fujitsu's AI and optimization team in Vancouver to help us solve real-world challenges to the society and businesses across different industries, including manufacturing, healthcare, drug discovery, oil and gas, and financial services.

Fujitsu Intelligence Technology aims to shape the nation into a global AI and Operations Research leader, and to become a central player in the North American and global ecosystems. We are operating as a cutting-edge startup tech company, with access to resources and technologies that only a global leader can provide, such as Fujitsu’s Next Generation Quantum-Inspired Digital Annealer, a dedicated architecture for solving complex combinatorial optimization problems.

As a Data Scientist in our team you will play a crucial role in identifying and developing innovative advanced analytics solutions and services. In this position, you will be working with clients to solve business problems through data, using best-of-breed open source and proprietary technologies.

About the position
A successful candidate will perform the following:
Collaborate with our internal and external clients to understand business processes, identify opportunities, and propose approaches to challenges in a consultative manner
Design, develop and lead the implementation of cloud or on-premises analytics solutions
Acquire, explore, analyze, visualize, cleanse, and transform large sets of data from various external or internal sources
Select and apply appropriate algorithms, methods, and tools
Create scalable data pipelines and machine learning systems
Clearly and objectively communicate progress, results and insights to clients
Investigate, define, select, and promote the use of processes, tools, frameworks, and best practices
Provide mentorship to other team members in Data Science

- - Master’s or PhD Degree in a quantitative field such as Data Science, Computer Science, Operations Research, Quantitative Finance, Math, Physics or a related Engineering degree
Minimum three (3) years of work experience and five (5) years of experience in Data Science (industry or academia)
Strong knowledge and experience in statistics, data mining, machine learning, and deep learning
Expert skills in a data and analytics programming language, preferably Python
Experience with analytics, machine learning frameworks and packages such as Numpy, Scipy, Pandas, Scikit-learn, Keras, PyTorch, TensorFlow
Proven ability to communicate complex concepts and insights verbally and in writing to colleagues and clients with varying degrees of data science knowledge
Proven ability to efficiently work in a team
Excellent analytical and problem-solving skills
Ability to articulate complex technical concepts to non-technical stakeholders
Ability to work gracefully and effectively in high pressure situations
Organized, articulate, team player, open to collaborative workstyles
Familiarity working in cross-cultural and geo-diverse teams
Preferred Qualifications
Experience in designing and building production analytics solutions
Experience in Operations Research such as linear programming, metaheuristics, heuristics, quadratic programming, discrete event simulation
Consulting or experience in a client-facing role
Experience with Big Data technologies such as Hadoop and Spark
Experience with visualization platforms such as Tableau and PowerBI
Experience with relational databases, SQL and data modeling",3.3,Fujitsu,Vancouver,"MINATO-KU, Japan",10000+ employees,1935,Company - Public,-1,-1,$10+ billion (CAD),"Atos, Hewlett Packard Enterprise | HPE, IBM",111.5,85,data scientist,na,0,1,1,1,0,1,1,0,0,0,0,0,1,1,1,6172,3
13,"Prodigy Education connects students, parents, teachers and school districts with resources that promote a lifelong love of learning. Anyone with an internet connection is welcome to create a free account and try the most effective and engaging K-8 math platform in the world. Our business model helps us connect with youth around the world, with over 90 million students now voluntarily practicing math every single day — and enjoying it!

At Prodigy Education, we have an incredible team that works tirelessly to turn our goal of making education a human right into a reality. We are immensely grateful for our amazing team and all they do every day. We welcome people who share our passion to join our team, where you will have the opportunity to help an entire generation of students to LOVE learning.

Our passion is our mission - to help every student in the world love learning!

Please note: During the Covid-19 pandemic, in order to keep all our candidates safe, Prodigy is hiring and on-boarding 100% remotely for the time being.
Overview:
What makes an educational product engaging for children? Is there a way to genuinely make learning fun, finding a balance between an immersive gaming experience and improving your grasp of an academic topic? How do we identify moments of frustration and failure in a student's learning progression through their in-game behavior, and select the most effective gamified intervention for levelling up a student's abilities? Here at Prodigy, our Game team is busy trying to answer these and other similar questions about how to best gamify math. We are working on new and interesting approaches to model our players (i.e., students), specifically in the intersection of learning and gaming. Your work will help us to improve our game and by extension how our students learn. The work we do at Prodigy can help shape a student's learning path early in life, and we take that very seriously and hope you will too.
Your Impact:
Help our Game team better understand how users engage with our product
Evaluate the quality and impact of game features for current and upcoming products
Develop and evaluate models related to our game, improving user engagement and the quality of our product
Help design, execute, and evaluate experiments (e.g., A/A, A/B, multivariate tests) to assist our Product teams in developing our game
Who You Are:
Graduate degree in Educational Data Mining, Mathematics, Computer Science, Engineering, Neuroscience, Psychology, Behavioural Sciences, or related fields
Research-level expertise in analyzing how games and / or how children learn
At least 2 years of data analytics experience
Proficiency in Python and SQL (bonus points for R)
Experience working with machine learning algorithms and / or cloud platforms like AWS
Ability to oversee and work simultaneously on different projects with a variety of timelines
Ability to translate data insights into actionable steps
Love for our mission of helping kids everywhere enjoy learning
Bonus Points for:
Experience in cloud ecosystems and their data tooling (AWS, GCP)
Experience with Spark
Demonstrated ability to solve hard mathematical, algorithmic, and statistical problems
Significant accomplishments that required both technical and strategic capabilities, such as research projects, open-source software contributions, and entrepreneurship
What We Offer:
The opportunity to build a career of value and witness first hand the impact Prodigy has as the most engaging math platform in the world!
A culture of transparency, where team members are involved in important conversations
No micromanaging here! We believe in our employees skills and abilities, we encourage you to bring new innovative ideas to your team
Full health benefits from day one (1) for you and your family, fully covered! Nothing is ever taken off your pay cheque
We are a profitable company, with eligibility to participate in stock options for all employees
Late or early riser? We understand! We offer flexible working hours that allow you to schedule your 8 hour day with a bit more flexibility. We do have core office hours, This is to ensure team members can be present for important meetings and department needs. Here are our core office hours (core office hours of 10:30am - 3:00pm)
Feel like a different work environment? Work from home 1x a week!
Team building events that not only include you as a Prodigy employee, but your significant other and children as well
Company pizza lunch every second week for ‘All Hands’, where we discuss important Prodigy milestones
Do you need some fun to help break up your day? We have that covered! Join in some Ping Pong games, Smash Bros competitions or board games!
We are an equal opportunity employer and are committed to providing employment accommodation in accordance with the Ontario Human Rights Code and the Accessibility for Ontarians with Disabilities Act, 2005 (AODA). Prodigy Game will provide accommodations to job applicants with disabilities throughout the recruitment process. If you require an accommodation, please notify us and we will work with you to meet your needs.",4.4,Prodigy Game,Toronto,"Oakville, Canada",201 to 500 employees,2011,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,111.5,9,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,5133,0
14,"Minimum qualifications:
3 years of experience in an analyst or Data Science role.
Experience using SQL to work with multiple datasets.
Experience designing data models and building data structures.
Experience in a language for statistical computing (R, Python/pandas, Stata, etc.).
Preferred qualifications:
PhD in Statistics, Engineering, Data Science, or related field (e.g. Mathematics, Physics, etc.).
Experience with statistical data analysis (a/b tests, hypothesis testing, experiment setting, etc.), and creating models to answer business questions.
Experience designing databases, and defining and implementing system requirements for data collection.
Knowledge of Machine Learning libraries (such as TensorFlow, Scikit-learn, Keras).
Excellent oral and written communication skills, including the ability to communicate findings in a structured and clear manner to a non-technical audience.
About the job


The Cloud Support Data and Analytics team provides data solutions that power the Cloud Support organization.

In this role, you will work on projects in a growing organization with opportunities to address problems needing creative solutions and models. You will be working on bringing together different data sets from across Google Cloud and modeling data to unlock actionable insights that help stakeholders formulate and answer business questions. You will collaborate closely with stakeholders from technical solutions engineering, product programs, vendor operations, support operations, and support experience teams.

Google Cloud provides organizations with leading infrastructure, platform capabilities and industry solutions. We deliver enterprise-grade cloud solutions that leverage Google’s cutting-edge technology to help companies operate more efficiently and adapt to changing needs, giving customers a foundation for the future. Customers in more than 150 countries turn to Google Cloud as their trusted partner to solve their most critical business problems.
Responsibilities
Provide decision-making support for key projects, and research new ways of modeling data to unlock actionable insights or improve processes. Contribute to the development of the frameworks, tools, skills, and culture for the team and wider organization.
Use predictive analytics and/or machine learning to facilitate forecasting for a growing and global support operation.
Write and review technical documents, including requirements and design documents for existing and future data systems, as well as data standards and policies.
Partner with non-technical stakeholders to understand their needs, help frame the problem by asking the right questions, and document and prioritize requirements. Communicate results of technical work.
Design, write, and support extract, transform, and load (ETL) processes to automate data collection and manage pipelines.

Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form.",4.4,Google,Waterloo,"Mountain View, CA",10000+ employees,1998,Company - Public,Internet,Information Technology,$10+ billion (CAD),"Microsoft, Apple, Facebook",111.5,22,data scientist,na,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,3448,3
15,"Req Id: 256936

At Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content – we’re revolutionizing how Canadians communicate.

If you’re ready to bring game-changing ideas to life and join a community that values bold ideas, professional growth and employee wellness, we want you on the Bell team.

Bell’s forward-thinking Customer Operations team is creating the ultimate service experience for our residential, wireless and small business consumers. We lead strategic development and execution of day-to-day operations, develop tools and processes to drive service enhancements, manage customer loyalty and retention, and leverage big data and artificial intelligence to create intellectual property.

Bell’s Business Intelligence team is responsible for the management and optimization of BI systems used to analyze customer behavior, automate business insight processes, target marketing & contact strategy opportunities and provide insight to drive optimal business decisions.

This is a terrific opportunity to help transform the organization, and achieve one of the most significant strategic mandates within Bell, leveraging machine learning and AI algorithms to drive business decisions. As part of this team, you will have opportunities to build your analytics skills, shape the next generation of BI and drive important business decisions working with new, cutting-edge technologies.

What our Team members have to say:
“We work in a fast-paced environment, which allows us to learn about many unique parts of the business in short periods of time. I have the ability and freedom to continually leverage my ideas and research to help solve business problems.”
“To me, the best thing about working for Bell is the amazing people. I am surrounded by a very supportive team and on a daily basis I collaborate with highly talented individuals throughout the company to solve complex business problems.”
We are looking for a data scientist who is highly logical, passionate, and can communicate effectively to all levels within the organization.

Key responsibilities may include:
Lead the development of machine learning products and models from inception to production
Explore new data sources to uncover new business opportunities at all levels of the business (strategic to operational)
Identify areas for ML/AI opportunities and demonstrate to internal clients how ML/AI can improve their business
Build and implement strategies for ML-driven projects
Work with partners within Customer Operations and across Bell to make data-driven business decisions
Work with and present to all management levels
Maintain and expand your knowledge of ML/AI and current technology through training opportunities, conferences, etc.
Critical Qualifications/Competencies:
Bachelors degree, or Masters in a discipline such as Mathematics, Statistics, Machine Learning, Business analytics/Business Intelligence, Computer Science or related area
Algorithms
Advanced knowledge of ML models: deep learning, reinforcement learning, NLP, and others
Hands-on experience and expertise with different AI/ML frameworks such as Keras, Pytorch, TensorFlow, SparkML, Scikit-Learn
Stay abreast of new technology and techniques in the ML/AI space
Coding
Advanced Python development skills
Experience in other programming languages Scala, C, C++, Java, Shell
Excellent code design (OOP, Algorithms, and Data Structures)
Experience with CI/CD pipelines
Data
Understanding RDBMS, Distributed, and NoSQL databases
Proficiency in SQL
Understanding of Spark and MapReduce
Quick learner with ability to think out of the box
#Li-ML1

Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.

Additional Information:

Position Type: Management
Job Status: Regular - Full Time
Job Location: Canada : Ontario : Don Mills || Canada : Ontario : Toronto
Application Deadline: 08/12/2020

Please apply directly online to be considered for this role. Applications through email will not be accepted.

At Bell, we don’t just accept difference - we celebrate it. We’re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.

Accommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.

Created: Canada, ON, Toronto

Bell, one of Canada's Top 100 Employers.",3.6,Bell Canada,Toronto,"Montreal, Canada",10000+ employees,1880,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (CAD),"Rogers Communications, TELUS, IBM",111.5,140,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,1,1,1,4834,3
16,"Do you want a meaningful role in a company that is making a difference in the world? Do you want to be involved in one of the most important environmental resource areas today? Do you want to learn what's involved in developing and deploying machine learning and predictive analytics solutions from colleagues with years of research and development experience? Then join our energetic and growing team and help revolutionize an industry.

About our company


Founded in 2003, Aquatic Informatics provides software solutions that address critical water data management, analytics and compliance challenges for the rapidly growing water industry. Aquatic Informatics is the trusted provider of water management solutions to over 1,000 municipal, federal, state/provincial, hydropower, mining, academic, and consulting organizations in over 60 countries that collect, manage, and process large volumes of water data.

Aquatic Informatics' platforms include AQUARIUS analytics software for natural environments, WaterTrax compliance and electronic reporting tools for municipalities, Linko software for the management of industrial pretreatment and hauled waste records and Tokay for backflow prevention. From source water through to the receiving environment, our interconnected data management platforms drive the efficient management of water information across the water cycle to protect human health and reduce environmental impact.

Aquatic Informatics is headquartered in Vancouver, Canada and has offices in the US and Australia. We are one of the fastest-growing clean technology companies in Canada. We value independent thinking, initiative, teamwork, a relentless pursuit of quality, a playful spirit, and a sense of humour. We like smart people – IQ and EQ – who care about the environment and want to do good in the world.

About the opportunity


You will become an integral member of the team researching and operationalizing algorithms and models for processing water and other environmental data. Working in an Agile scrum team, you will be exposed to the breadth of data science activities, including hypothesis definition, data wrangling and exploratory data analysis, model development and validation, and production deployment and debugging test and customer-reported issues.

Qualifications
Masters or PhD in data science, computer science/engineering, statistics, or a related quantitative discipline.
2+ years of hands-on experience in applied machine learning, predictive modeling and data analysis.
Solid understanding of mathematical concepts and techniques including: time series analysis, regression modeling, forecasting, and machine-learning.
Experience with at least one scientific language (Python, R, Matlab) and knowledge of software design principles.
Passion for data - thrive on using data to solve challenging real-world problems.
Life long learner - incessantly inquisitive about emerging research and technology.
Excellent English communication skills, both verbal and written.
Assets
Experience with python packages and frameworks including pandas, NumPy, scikit-learn, TensorFlow, and PyTorch.
Background in environmental science.
Experience with data visualization.
Experience deploying data science solutions in production.
Experience with AWS or other cloud services and cloud technologies.",4.0,Aquatic Informatics,Vancouver,"Vancouver, Canada",51 to 200 employees,-1,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (CAD),-1,111.5,-1,data scientist,na,0,1,0,0,0,0,0,1,0,0,0,0,1,0,1,3333,0
17,"Important


Do not discuss your application with others (including on social media) besides your partner, or close family members - who should also be reminded about the need to be discreet.

Closing Date 2020-08-26
Reference Number 20-968-09-029
Job Category Subject Matter Expert

Who Can Apply Canadian Citizens

Location Ottawa, Ontario

Salary Range $89,400 - $108,820

Status Indeterminate (permanent)

Language Requirement Various

Job Summary

Define, develop and lead a data science program which identifies exploitation opportunities, and provides solutions and capabilities to address them.
Conduct research and recommend potential initiatives to analysts, and branch management and senior executive staff.
Autonomously find, enrich, transform, interpret, and exploit data to create intelligence products.
Act as a Service representative on joint projects related to data science and participate in collaborative efforts where applicable.
Provide mentorship and guidance to fellow Data Scientists and Data Exploitation Analysts, regarding intelligence analysis and associated activities pursued in response to the mandate.
Recommend new data exploitation projects in annual work plans by identifying analytical gaps and suitable solutions.
Regularly update knowledge of academic and industry data science practices and standards.
Effectively communicate and present findings to specialists, management and non-technical audiences. Clearly document methodologies employed in research and data exploitation solutions.

Education

Undergraduate degree in:
Mathematics
Statistics
Computer Science
Computer Engineering
Field of study related to data analytics
The educational program must be from an accredited learning institution recognized in Canada.
If you completed a program outside of Canada you will be required to obtain proof of a Canadian equivalency at your expense through a recognized credential assessment service.

Note: Any higher level of education (Masters or PhD) in Data Science or a related field of study could be recognized as experience.

Experience

Undergraduate degree and seven (7) years of experience
The candidate must possess seven (7) years of experience in data science, data analytics or data mining. Please note that out of the seven (7) years of relevant experience required, at least four (4) years must have been gained in data science specifically.
The candidate must possess recent and significant experience in the following:
Experience performing complex data exploitation on large volumes of data to provide tactical and strategic insights directly to analysts, business owners, and decision makers.
Experience gathering requirements and identifying opportunities to apply data science towards business objectives.
Experience prototyping and developing data exploitation capabilities using Python, R, and other technologies.
Experience visualizing analytics, writing reports, producing functional notebooks, and designing and delivering presentations.
Experience working with various Big Data technologies.
Candidates must also possess recent and significant experience in at least two (2) of the following:
Experience with supervised and unsupervised machine learning.
Experience in the creation and implementation of algorithms and statistical techniques to resolve data science problems.
Experience with text analytics and natural language processing (NLP).
Experience in the design, creation, and implementation of graph analytics.
Experience with complex data processing for time series and patterns of life analyses.
Recent experience is defined as experience acquired within the last five (5) years.

Significant experience is defined as the depth and breadth of experience that would normally be acquired by a person in a position where the performance of these duties constitutes his or her main functions over that period of time.

Competencies

Communication
Initiative
Innovation
Creativity
Ingenuity
Analytical skills
Coaching

Conditions of Employment

Not Applicable

Notes

A written exam will be administered. If successful, you will be invited to an interview. The exam will serve to evaluate your technical knowledge as it pertains to the position.

Reference Links

Salary Grade Breakdown

Security Requirements

Candidates must be eligible to receive an Enhanced Top Secret security clearance. The process involves a security interview, a polygraph, and a background investigation that includes credit and financial verifications. The use of illegal drugs is a criminal offense. Drug use is an important factor considered in your reliability and suitability assessment during the selection process. Therefore it is important not to use any illegal drugs from the time you submit your application.

Others

Important


Applicants must clearly demonstrate in their application how they meet each Education and Experience criteria. Failure to do so will result in the applicant being screened out of the career opportunity.

CSIS is a separate employer and is not subject to the Public Service Employment Act (PSEA). CSIS has its own classification, compensation system, and a different staffing regime. As such, we use a different staffing process and terminology.

CSIS is committed to diversity and inclusion and the equitable participation of all Canadians. Should you require accommodation in relation to a disability, please tell us at the beginning of the selection process. This information will be kept confidential.

The personal information provided in your application is protected under the Privacy Act and will be held in Personal Information Bank SIS/P-PU-025.

We thank all applicants for their interest in CSIS. However, only those who are selected for further consideration will be contacted.",2.6,Canadian Security Intelligence Service,Ottawa,"Ottawa, Canada",1 to 50 employees,1984,Government,Government Agencies,Government,Less than $1 million (CAD),-1,111.5,36,data scientist,na,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,5778,0
18,"Data Scientist

Overview

You might not have heard of us yet but we’re growing. Fast. Clipwire is one of Canada's fastest growing mobile video game companies. Founded in Toronto 10 years ago, the company is built on strong values, work ethic and intelligent growth. We work hard, have fun, innovate and level-up every day. As for the development of our games, we have built a highly profitable suite of games and continue to refine and improve them for our users each and every day. We like to think we’re making our moms proud.

To work at Clipwire means becoming part of the future right now. We have reached our current growth rate because we support, promote and develop our team so that they can make great games. Come find out what all the buzz is about!

Interested in joining Clipwire Games, but don’t see the right job posting? We want you to speak up! Tell us your story, write your job description, and let us know how you would spend your first 90 days by answering the questions below. (Given that we’re not actively searching for your position, we encourage you to be convincing.)

Qualifications

We are seeking a passionate Data Scientist who is adept at cultivating key insights and analytics to influence our development and marketing decisions allowing us to best engage and delight our avid gaming community.

The Data Scientist will work alongside key game developers and artists to create unique and alluring game experiences for millions of our players worldwide. The ideal candidate must be highly analytical and obsessive about cultivating and identifying key insights to fuel strategic decision making around our design and development of our gaming creative. This data guru must offer a proactive approach to understanding the trends of the mobile gaming industry and the people that play them. The individual must be more than just a ‘number cruncher’. As an analytical genius, you must be capable of visualizing and analyzing the big picture using big data, machine learning tools and visualization techniques to tie together information and make big decisions for big games.

Responsibilities:

As the ‘chosen one’, you will have the responsibility to:
Drive innovation by building predictive models, tools and processes that support production goals of user acquisition and player retention
Analyze large data sets to identify player behavior trends using statistical, quantitative and machine learning techniques
Build end-user lifetime value (LTV) projections and new data models for user acquisition strategy and games’ growth projections
Define KPIs and build comprehensive dashboards and reports on chosen platforms (e.g. Tableau)
Devise, conduct and analyze A/B tests to directly and indirectly drive KPI improvements
Manage and own user data and act as a subject matter expert on relevant KPIs
Serve as a lead in communicating and presenting data analytics and insights, related strategic recommendations and status of game tool systems development to key stakeholders
Own the analysis and reporting on all machine learning output
Continuously learning new technologies that advance analytic function and initiatives at Clipwire
Requirements:
Bachelor’s degree in Computer Science, Math, Statistics, Economics, or other quantitative field
4+ years of work experience in data science, analytics or related quantitative roles
Experience with a diverse set of technologies and predictive modelling tools (Tableau, SQL, Mode, Spark) to deliver insights for creating dashboards, reports, and visualizations
Proficiency in (statistical) programming languages like R, Python and proven mastery with SQL (or other related database technologies)
Economic modelling experience and expertise a must have
Good understanding of A/B testing methodologies
Experience in social or freemium game economies or SAS equivalent
Proven ability to work in a fast-paced team environment, and to meet changing deadlines on multiple projects simultaneously
Nice-to-Haves, but not required:
M.Sc./Ph.D. in a quantitative discipline (i.e. Mathematics, Physics, Operations Research, Computer Science, Statistics)
Familiarity with free-to-play game design concepts and industry-standard KPIs used to measure game performance
Knowledge of freemium mobile game economies
2+ years of work experience in data science/analytics – specifically in the gaming industry
Perks
Build games and work on projects that you’ll be proud of!
Competitive salary, bonus, and benefits package and a wellness spending account
Work in a fun, collaborative, feedback-focused, no-BS environment
Regular paid team lunches, events, and other fun outings
Additional Information

Please note before submitting an application: as a company, we take hiring very seriously. Interviewing with Clipwire may include phone and video interviews, written evaluations, technical tests and/or on-site interviews. Although we are unable to follow-up with each and every applicant, we do our best to run a thorough process for candidates with whom we identify a potential fit.

Please send your application with Data Scientist 2020 in the subject line. Please be sure to include a cover letter explaining in a concise and organized manner, the points above.

Job Types: Full-time, Permanent

Job Types: Full-time, Permanent

Benefits:
Extended Health Care
Schedule:
8 Hour Shift
Work remotely:
Temporarily due to COVID-19",4.4,Clipwire Games,Toronto,"Toronto, Canada",1 to 50 employees,2016,Company - Private,Video Games,Media,$100 to $500 million (CAD),-1,111.5,4,data scientist,na,0,1,0,1,0,1,1,0,0,0,0,0,1,0,1,5388,0
19,"At Ingrooves Music Group, we are committed to powering creativity in today’s dynamic music marketplace by providing the best distribution, marketing, and rights management tools and services to content creators and owners. We develop state-of-the-art, cost-efficient, and scalable technology platforms. Our partners benefit from our experienced, knowledgeable people, unparalleled commitment to customer service, and thoughtful marketing solutions that drive results. We aspire to be the most transparent and solution-driven partner for all of the labels and artists we work with.

How we LEAD:

This is an execution and delivery-oriented, highly visible role in the Insights & Analytics team with primary responsibility for building, testing, and validating scalable machine learning models that drive business-relevant insight generation. This includes development of project plans, handling of potential issues and risks, collaborating constructively with project team members, providing effective cross-functional communication, and advancing multiple projects at once.

The successful candidate will ideally be based in Victoria, BC and their reporting line will be to the Chief Analytics Officer. Although the Insights and Analytics team is primarily based in Victoria, BC, exceptionally strong candidates who wish to work remotely within British Columbia or out of the Ingrooves Los Angeles office are especially encouraged to apply and will be given equal consideration.

Success at Ingrooves

Business Acumen

The successful candidate aligns with the Ingrooves culture by being solution-oriented, collaborative, leveraging best practices, and possessing a passion for both technology and music.

Interpersonal/Communication Skills

The successful candidate will be open minded with a natural curiosity of the internal and external customer, will be delivery oriented with an understanding of the product development process and will build and foster strong relationships and effective partnerships with cross-functional teams.

Executing for Results

The successful candidate will demonstrate the ability to generate and translate strategic plans into actions with timely execution and accountability.

Leadership/Collaboration

The successful candidate establishes and maintains positive working relationships, operates with integrity, influences and supports others, and remains open to ideas.

Problem Solving

The successful candidate will be tenacious and self-motivated and have a demonstrable record of resolving issues and providing effective solutions. They demonstrate eagerness and an ability to learn quickly and leverage a flexible mindset in response to shifting dynamics, adversity and/or change.

How you’ll CREATE:
Design, build, and deploy machine learning models at scale
Collaborate closely with product teams to provide high-level AI-driven services for music content owners
Integrate with external and internal APIs and data sources to augment music consumption data to uncover shifting market trends, new opportunities, operational efficiencies and revenue streams
Create data-rich informative visuals and documents to articulate and convey complex concepts to executive leadership team and label partners
Contribute to and enable a positive work environment which highly encourages creative input and constructive criticism from all team members
Other duties as determined by the Chief Analytics Officer
Bring your VIBE:
Earned graduate degree (PhD/MS) in a highly quantitative discipline (e.g., machine learning, statistics, computer science, applied mathematics, theoretical physics, physical chemistry, econometrics)
2+ years of corporate experience (at the PhD level) / 4+ years of corporate experience (at the MS level) working in a data scientist or equivalent role
Demonstrated experience developing machine learning models (e.g. distributed model training with SparkML, PyTorch, Tensorflow, etc.) to deliver robust predictions and inferences in a production scale environment
Strong software development skills, with demonstrated ability to implement inferential and predictive models in a production environment.
Expert knowledge of at least one data science programming language (e.g. Python, R, Julia, etc.) and relevant data science and visualization libraries (scikit-learn, pandas, ggplot, etc.)
Experience with AWS (i.e., EC2, S3, RDS, Redshift, EMR) or similar cloud computing services
Knowledge and experience of writing and tuning SQL
Excellent communication and exposition skills with the ability to explain and present complex analyses and machine learning concepts to a broad audience, both technical and non-technical, in English
Demonstrated ability to work creatively and deliver within highly collaborative work environments while remaining product focused.",3.5,Ingrooves,Victoria,"Los Angeles, CA",51 to 200 employees,2002,Company - Private,Music Production & Distribution,Media,$100 to $500 million (CAD),-1,111.5,18,data scientist,na,0,1,0,0,0,1,1,1,0,0,0,0,1,0,1,4815,0
20,"Excited by using massive amounts of data to create sophisticated security analytics? Does pushing the envelope with user and entity behavior analytics (UEBA) including developing statistical, stochastic and machine learning models for security excite you? Want to help the largest global enterprises operate safely & securely in the cloud at an unprecedented scale?

You will enhance real-time proactive and preemptive systems using data driven techniques. The analytic techniques are applied at each stage from detection to response mitigation. This job will challenge you to dive deep and understand the unique challenges in operating this platform at a scale unrivaled in the industry. Our scale provides unique opportunities that simply dont exist elsewhere, but these opportunities can only be revealed by a scientific thinker with a curious mind, who is committed to improving every single day.

This is an opportunity to operate in a truly groundbreaking manner given the sheer scale, breadth, and fast pace of the AWS environment. Data scientists are collaborative and highly determined, working backward from threats to create new and innovative ways to detect, assess and react to malicious activity.

Your job is distilling meaningful insights from large volumes of data to address the constantly evolving threat and attack space from sophisticated adversaries. This role will give you an opportunity to use and grow a broad range of skills in data science, analytic development, and information security all using and creating cloud services in large scale computing environments. Considering the scale and the magnitude of the technical challenge, this role is a great opportunity to make a meaningful contribution to an extremely important area. Operating in the cloud at our scale enables activities that have never before been possible, providing new advantages and opportunities for innovative work.

We are hiring technical specialists at the convergence of the four hottest areas in tech: Data Science, Security, Software Development and Cloud Services. Worried that you do not have hands-on experience in all four areas? We are looking for solid base and expertise in two areas - you will grow expertise in the remaining areas to round out your background in all four key areas. Alongside your team, you will work directly with the biggest internal and external Amazon customers leveraging data and analytics to create innovative ways to work securely in the cloud.







Basic Qualifications

· MS + 8 yrs experience or BS + 10 yrs experience in predictive modeling, data science, machine learning, or user and entity behavior analytic development.
· At least 4 years focused on applications of Data Science/Analytics
· A minimum of two years experience in applying Data Science/ Analytics to security related problems.
· A minimum of 4 years experience introducing automation and operating within a fast paced prototyping environment.




Preferred Qualifications

· An M.S. or Ph.D. in Mathematics, Computer Science, Electrical and Computer Engineering, or equivalent degree.
· A post graduate degree in a scientific field is preferred but successful development and deployment of security analytics count. The right candidate has a background in probability and statistics, applied mathematics, or computational science and a history of solving difficult problems using a scientific approach.
· Experience with analytic development for endpoint and network security
· Experience with one or more cloud services
· Analytic development - streaming and a Hadoop ecosystem (Hive, Spark, etc.)
· Analytic development - SQL, NoSQL, graph-based, Key/Value stores, document stores, Python and/or R
· Experience applying machine learning to real-world production systems, analytic development based on SparkML and other ML libraries such as scikit-learn, caret, mlr, MLlib
· Excellent written and oral communication skills, strong sense of ownership, urgency, and drive
· Meets/exceeds Amazons leadership principles requirements for this role
· Meets/exceeds Amazons functional/technical depth and complexity for this role",3.9,Amazon,Ottawa,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (CAD),"Google, Microsoft, Walmart",111.5,26,data scientist,na,0,1,0,0,0,1,1,1,0,0,0,0,1,0,1,4138,3
21,"Design, develop, test, advocate, evangelize and build data-driven products that help our customers improve business decisions. You will provide insight into analytic practices, design and lead iterative learning and development cycles.
Responsibilities
Understanding and worked with database systems.
Understanding and worked with machine learning algorithms.
Perform feature analysis.
Develop ontology for key market segments.
Develop outcome/event taxonomy for key business models.
Build utility code and handle miscellaneous support tasks.
Documenting software projects and maintaining project documentation.
Working in a team environment as well as working alone.
Qualifications
Experience with Big Data, artificial intelligence, natural language processing, machine learning and/or deep learning.
Python programming skills with two (2) years or more of Python experience.
Good verbal and written communication skills.
Knowledge of professional software engineering practices and best practices for the full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations.
Master's degree or six (6) years related work experience delivering quality code on time.
Tools we use...
Confluence
JIRA
Spark
Azure
Python
Keras
Scikit-learn
Bit bucket
Jupyter Notebook
Scala
MonetdB
OrientDB
Nice to haves...
Experience in some subset of the following: Java, R, Python, SQL, Scala, Spark.
Ph.D. in operations research, applied statistics, data mining, machine learning, physics or a related quantitative discipline.
Deep understanding of statistical and predictive modeling concepts, machine-learning approaches, clustering and classification techniques, supervised learning, recommendation and optimization algorithms.",3.9,Cerebri AI,Toronto,"Austin, TX",51 to 200 employees,2016,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,111.5,4,data scientist,na,0,1,0,0,0,1,1,0,1,0,0,0,1,1,1,1794,0
22,"Events in recent years have made us all too familiar with the havoc that natural disasters can wreak, and the increasing frequency and intensity with which they are occurring. Despite record levels of losses, conventional methods of risk modeling continue to paint at best an incomplete picture of these threats.

Zesty.ai uses novel data gathering and data science methods to produce higher quality information about the risks to property from catastrophes like floods and wildfires. While AI alone may not be able to thwart these disasters, it can help us become more prepared for them, and ultimately that will lead to better outcomes.

As a Data Scientist, you are comfortable and excited to work closely with the engineering team to build the best AI tech possible. You will develop top tier models from unique and diverse data sources to provide strong insights and maximize the impact of our company efforts. You thrive in a collaborative, creative environment that moves fast and are comfortable setting in place structures and processes to help the company scale.

The Opportunity:
Exploring data sets and developing new InsureTech models with data science (Machine learning, Deep learning).
Develop computer vision algorithms that extract insights from aerial imagery and geospatial data
Research and model aspects of the built environment utilizing satellite imagery, LiDAR and other datasets
Help develop training and cross­-validation data sets for machine learning algorithms
Translate product management, engineering, and business constraints and queries into tractable data science questions
Iterate rapidly on everything; all of the above happens in a fast paced business driven environment that you must be comfortable with
What You Bring to the Zesty.ai Lab Team:
BA / BS degree in Math, Physics, Computer Science, and Economics
MS or Ph.D. is certainly a bonus
1 - 2 years of experience working with computer vision and building and testing computer vision systems
2 - 3 years experience deploying machine learning models in production environments
2 - 3 years experience working with deep learning / neural network models (using TensorFlow, PyTorch, Keras, Caffe)
Ability to develop new models based on physics and AI sciences
Strong organizational and management skills with past experiences implementing best practices and processes
Experience working with large image datasets (great if you've already worked with satellite imagery) and related tools OpenCV, Pillow, etc.)
Proficient in SQL
Experience working with cloud platforms (AWS, Google Cloud, etc)
Must be legally eligible to work in Canada
Why Zesty.ai Lab:
Be part of a well-funded growth-stage start-up
Market competitive comp and equity incentives to give you a stake in our future
Comprehensive health care plan
Flexible Time Off
An upbeat and collaborative work culture
Company-sponsored outings and offsites
All your information will be kept confidential according to EEO guidelines.",5.0,Zesty.ai,Montreal,"Oakland, CA",1 to 50 employees,2015,Company - Private,Insurance Agencies & Brokerages,Insurance,Unknown / Non-Applicable,-1,111.5,5,data scientist,na,0,0,0,0,0,1,0,0,0,1,0,0,1,1,0,2972,0
23,"Data Scientists


Eagle is currently seeking a Data Scientist for a six (6) month contract opportunity, scheduled to begin immediately.

Key Responsibilities

The successful candidate will be responsible for:
Advising product owners on everything from use case development to solution design to performance measurement;
Working independently and as a team member to research and develop data trends;
Consulting with internal stakeholders on their research needs;
Creating predictive models and machine learning algorithms to anticipate customer needs;
Using your background and experience in machine learning and information retrieval to build and optimize classifiers;
Utilizing dataset experience in document, graph, log data and semi-structured data to extend company’s data with third party sources of information when needed;
Employing your knowledge of distributed computing solutions and leverage them towards gaining faster insights from data;
Exploring and examining data from multiple disparate sources with the goal of discovering previously hidden insights; and,
Building end-end solutions using cloud computing tools such as AWS.
Skills and Qualifications

The qualified candidate must have:
Strong understanding of Data and past experience in a Data scientist role;
Openness and willingness to learn new technologies; and,
Some AWS experience would be a nice to have.
Don’t miss out on this opportunity, apply online today!

Eagle is an equal opportunity employer and will provide accommodations during the recruitment process upon request. We thank all applicants for their interest; however, only candidates under consideration will be contacted. Please note that your application does not signify the beginning of employment with Eagle and that employment with Eagle will only commence when placed on an assignment as a temporary employee of Eagle.

JOB#67261",4.0,Eagle Professional Resources,Calgary,"Ottawa, Canada",51 to 200 employees,1996,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (CAD),"S.i. Systems, Procom, Veritaaq",111.5,24,data scientist,na,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,1876,3
24,"Replicon is looking to hire someone for our Time Intelligence platform who is passionate about taking data and transforming it into information and insights that can help our customers make the right decisions. Our SaaS application is used by thousands of customers, collecting data for millions of users, and we model business capabilities across many different industries.

Objectives
Work within our product engineering team to enhance our data analytics platform by identifying solutions to business problems using data analytics
Gain an understanding of our product and business domain to be able to drive our data model to be able to provide more analytical insights
Design and build our platform for solving time intelligence problems which needs to allow our customers to find meaningful insights in their uniquely modeled business
Evolve data analytics from a static model to a learning model, and not just analyzing a provided set of data
Keep current with industry trends
Responsibilities
Work with product managers to understand business objectives and to deliver results based on that context
Think about our data strategically, identifying new datasets for our product and work with the engineering team to integrate those datasets to create new data products
Execute analytical experiments and interpret the results to provide guidance on how to use or enhance our data platform
Identify relevant datasets to use for analytical experiments
Implement analytical models into production by taking product requirements and collaborating with software developers and machine learning engineers.
Own and continuously improve launched analytical models.
Evangelize analytics best practices and provide technical guidance and options to the team
Managing work on multiple concurrent analytics projects
Iterate and improve your work until the business objective is met, even if there are very challenging technical constraints to overcome
Openness to using many different tools and approaches as necessary - the right tool for the job
Take ownership and pride in everything you do and stand by what you deliver
Skills and Qualifications
Bachelors degree in statistics, applied mathematics, or related discipline
Proficiency with data mining, mathematics, and statistical analysis
Advanced pattern recognition and predictive modeling experience
Programming experience (Python, R, etc.)
Preferred Qualifications
2+ years experience in data science
Professional certifications
Experience with visualization tools such as PowerBI and Tableau
Experience with NLP/NLU technologies (Amazon Lex, Google DialogFlow, etc)
Experience with AI/ML technologies (Tensorflow, Amazon Sagemaker, etc)
Experience with SQL
Experience working in an Agile environment
A portfolio of relevant work to share",4.0,Replicon,Calgary,"Calgary, Canada",201 to 500 employees,1996,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (CAD),"Kronos Incorporated, Workday",111.5,24,data scientist,na,0,1,1,1,0,1,0,0,0,0,0,0,1,0,1,2789,2
25,"Data Scientist 4-20000K8Z Applicants are required to read, write, and speak the following languages: English
Preferred Qualifications


Utilize your statistical programming skills to collect, analyze, interpret, and visualize large data sets to develop data-driven solutions to difficult business challenges. Preferred applicants have a wide range of technical competencies including: statistics and machine learning, coding languages, databases, machine learning, and reporting technologies. Ability to visualize large amounts of information in ways that are universally understandable and spot patterns, trends, and correlations.

Data Scientists commonly have a master’s degree in statistics, math, computer science, or economics.
Detailed Description and Job Requirements
Designs, develops and programs methods, processes, and systems to consolidate and analyze unstructured, diverse “big data” sources to generate actionable insights and solutions for client services and product enhancement.

Interacts with product and service teams to identify questions and issues for data analysis and experiments. Develops and codes software programs, algorithms and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources. Identifies meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.

Leading contributor individually and as a team member, providing direction and mentoring to others. Work is non-routine and very complex, involving the application of advanced technical/business skills in area of specialization. 8 years relevant work experience. BS/BA preferred.
Job
: Business Operations
Travel
: Yes, 25 % of the Time
Location
: Canada
Job Type
: Regular Employee Hire
Organization
: Oracle",3.6,Oracle,Canada,"Redwood City, CA",10000+ employees,1977,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (CAD),"SAP, Salesforce, Microsoft",111.5,43,data scientist,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,1867,3
26,"Job Description
Status: Permanent – Full-time
Location: Montréal – Griffintown

At Brainfinance, we pride ourselves in offering the highest possible quality of customer experience. We are looking for a person who thrives in a team environment, who is passionate, driven and who yearns to grow personally and professionally. This person will become part of a team that thrives on the new challenges presented by a fast-paced and constantly evolving environment. The chosen candidate will possess a keen eye for detail and will come up with innovative ideas that will contribute to the success of both the company and the customer experience.

As a Data Scientist, you will be working with teammates who are passionate, helpful, and strive to get the best out of Big Data .

Responsibilities
Participating in daily and bi-weekly scrum activities (Daily scrum, sprint planning, sprint review, and sprint retrospective).
Working with Business Analysts and Business Units to understand the business and requirements.
Working with DevOps Engineers and Software Engineers (Mobile and Web) to integrate Big Data Science solutions.
Developing data analysis and science solutions with Python.
Leveraging NumPy, SciPy, Pandas, MLlib, Scikit-Learn, NLTK, Scrapy, and Keras.
Utilizing Apache Spark, Apache Kafka, and Apache Cassandra to develop scalable real-time and data-driven applications
Advantages
A cutting edge technology stack: https://stackshare.io/brainfinance/
Competitive salary.
Fun and relaxed work environment.
Full health benefits - Medical.
Free healthy snacks and refreshments.
Advancement opportunities.
Great office location.
Providing opportunities to attend trainings and conferences
Requirements
A bachelor degree in software engineering or related fields ( A Ph.D. degree is a plus ).
Software engineers experienced with Python programming language.
3+ years of experience with Python Machine Learning and Optimization.
2+ years of experience with Apache Cassandra.
2+ years of experience with Apache Spark.
Familiarity with Apache Kafka and Apache Mesos.
Familiarity with Deep Learning libraries such as TensorFlow or Theano or CNTK.
Experience with GIT and Continuous Integration.
Being open to learn and explore new technologies.
Experience working in an agile environment (preferably, Scrum).",5.0,Brain Finance,Montreal,"Montreal, Canada",51 to 200 employees,-1,Private Practice / Firm,-1,-1,Unknown / Non-Applicable,-1,111.5,-1,data scientist,na,0,1,0,0,0,0,1,0,0,0,0,0,1,1,0,2308,0
27,"About Mila

Founded by Professor Yoshua Bengio of the Université de Montréal, Mila rallies researchers specializing in the field of artificial intelligence. Recognized globally for its significant contributions to the field of deep learning, Mila has distinguished itself in the areas of natural language processing, machine translation, object recognition and generative models. Since 2017, Mila is the result of a partnership between the Université de Montréal, McGill University, École Polytechnique de Montréal and HEC Montréal.

Job description

In addition to its academic training and fundamental research focus, Mila’s mission is to contribute to Quebec and Canada’s economic development through technology transfer and business innovation.

As part of the technology transfer team, the candidate will be involved in helping companies innovate by integrating AI into their products or improving their existing AI-based solutions. The candidate will also contribute to building and fostering long-term relationships with Mila’s partners and players in the AI ecosystem. Finally, the candidate will be involved in professional training programs.

Multidisciplinarity is desired. In addition to expertise in machine learning, we favor candidates with expertise in areas of application of AI such as biomedical, medical, neuroscience, law, insurance, ethics, finance, cybersecurity, transportation, agriculture, robotics, chemistry, computer vision, natural language understanding.

Main responsibilities
Support companies through consulting / coaching to introduce AI into their products or improve their AI-based solutions.
Participate in applied research projects with companies, academic or research institutes.
Develop machine learning training programs for industry.
Supervise interns from the Professional MSc in Machine Learning program.
Dedicate one day per week to own research projects.
Benefits
Stimulating and cutting-edge workplace.
Participation in conferences.
Competitive salary.
Comprehensive benefits.
Generous annual vacation policy.
Flexible work schedule.
Located at the heart of Little Italy, in the trendy Mile-Ex neighborhood.
Easy access to public transit.
Mila is a fair employer that cares about diversity. We value the development of ideas in teams and cultivate an open and respectful working environment. The masculine gender is used only to simplify the text. We encourage all candidates to apply for this position, however only selected candidates will be contacted. Thank you for your interest in Mila!

Requirements

Required skills
Expertise in machine or deep learning (MSc, PhD, post-doc in the field, or equivalent work experience).
Expertise in PyTorch or TensorFlow.
Excellent oral and written communication skills.
Ability to multitask.
Ability to lead a project and to work well as part of a team.
Preferred skills
Industry experience in machine / deep learning.
Industry experience in fields of application of machine / deep learning.
Proficiency in English and French.
Benefits
Stimulating and cutting-edge workplace.
Participation in conferences.
Competitive salary.
Comprehensive benefits.
Generous annual vacation policy.
Flexible work schedule.
Located at the heart of Little Italy, in the trendy Mile-Ex neighborhood.
Easy access to public transit.",4.5,Mila,Montreal,"Montreal, Canada",51 to 200 employees,-1,College / University,-1,-1,Unknown / Non-Applicable,-1,111.5,-1,machine learning engineer,na,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,3302,0
28,"Let’s define the future of digital assets, together!

NDAX is a Calgary-based digital asset exchange that offers a world-class experience for individuals and institutions to buy and sell cryptocurrency in the fastest, safest and most compliant manner possible. As Canada’s most advanced cryptocurrency exchange, NDAX has set the bar high for the country’s crypto industry and is consistently leading the way in terms of security and innovation.

To address the various needs in the Canadian cryptocurrency space, NDAX has assembled a multi-disciplinary team with diverse backgrounds including banking, investment advisory, compliance, engineering, information technology, marketing, public relations and accounting.

As a Data Scientist you will utilize your experience and education to support our development team to improve our current products and add to our new products currently in development.

Our team is currently working remotely, so being a self-starter and having the ability to work unsupervised is essential to the success of any applicant.

Requirements
Strong familiarity with Python.
Can demonstrate ability to work individually and on a team.
Experience with Block-chain technology is an asset.
Strong data analytical skills.
Familiarity with technology development project management is an asset.
As this is a summer internship, current students in a related field, or recent graduates are encouraged to apply.
Experience with Trading/ Trading bots would a bonus
Benefits
NDAX benefits include professional development, and if the internship becomes a full-time position comprehensive health benefits.
Employees local to Calgary can also take advantage of a free gym membership.",5.0,NDAX INC,Calgary,"Calgary, Canada",1 to 50 employees,2017,Company - Public,Stock Exchanges,Finance,Unknown / Non-Applicable,-1,111.5,3,data scientist,na,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1699,0
29,"We're on a mission to ensure that all our players have fun, dream big and play responsibly one player experience at a time and we're looking for team members who share that same passion. Our culture is built on a shared commitment to do what's right for our customers, our people, and our communities. If this sounds like you this may be a perfect fit. Atlantic Lottery (AL) is looking for a Data Scientist to lead in the mining of large data sets and generate meaningful insights to better service our players and grow our business based in Moncton, NB, Halifax, NS or St. John's, NL or work remotely.

The primary focus of this role will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our existing and future products. As the ideal candidate you are well adept at using large data sets to identify opportunities for product and process optimization and using models to test the effectiveness of different courses of action. You have strong experience using a variety of data mining/data analysis methods, using a variety of data tools, building and implementing models, using/creating algorithms and creating/running simulations. You have a proven ability to drive business results through data-based insights. This is the perfect opportunity for the you to become part of an innovative and energetic team that develops solutions which will influence AL's products, its clients, and its business overall.

Responsibilities

Data mine large amounts of information to discover trends and patterns

Identify valuable data sources, automate collection processes and develop custom data models and algorithms to apply to data sets.

Process, cleanse, and verify the integrity of data used for analysis.

Build predictive models and machine-learning algorithms to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.

Develop processes and tools to monitor and analyze model performance and data accuracy.

Work with business stakeholders to identify opportunities for leveraging data to drive business solutions

Coordinate with different functional teams to implement models and monitor outcomes

Collaborate with Enterprise Data Solutions team for data governance and maintenance

Qualifications

What we can expect from you:
Experience in statistical and data mining techniques, including generalized linear model/regression, random forest, boosting, trees, text mining, social network analysis, etc.
Experience using statistical computer languages (R, Python, SQL etc.) to manipulate data and draw insights from large data sets
Experience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modeling, clustering, decision trees, neural networks, etc.
Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.
Experience using web services: Redshift, S3, Spark, DigitalOcean, etc.
Experience analyzing data from third-party providers, including Google Analytics, Site Catalyst, Coremetrics, AdWords, Crimson Hexagon, Facebook Insights, etc.
Experience with distributed data/computing tools: Map/Reduce, Hadoop, Hive, Spark, Gurobi, MySQL, etc.
Experience visualizing/presenting data for stakeholders using tools such as Periscope, Business Objects, D3, ggplot, etc.
Experience working with and creating data architectures
Who's a good fit for this team:
Ability to multi-task, problem-solve, prioritize and competently handle a variety of activities with a high degree of accuracy in a fast-paced, customer-driven environment;
A self-starter and an independent thinker who follow-up on responsibilities in a timely manner while also a strong team player;
Your decisions are always made with the player in mind and;
You can adapt to change in a nimble & agile fashion.
You should apply if you have the following:
3-5 years of relevant experience manipulating data sets and building statistical models.
Master's or Ph.D. in statistics, mathematics, or computer science.
Awesome if you had:
Experience in lottery and/or gaming industry.
Skills
Data Architecture
Data Mining
Statistics
About Atlantic Lottery

Our players have been having fun and ""dreaming big"" since 1976 when Atlantic Lottery started offering lottery games on behalf of the governments of Nova Scotia, New Brunswick, Newfoundland and Labrador and Prince Edward Island.

The game options have grown and changed over the years and so has our workforce! Today's Atlantic Lottery has more than 600 employees, who are the heart and soul of our business. We offer everything from dare-to-dream draw games to online bingo; breakopen tickets to sports wagering; and games in social settings and on the internet.

With games come winners - big and small wins every day - but the best thing about lottery games is that when you choose to play with us, everyone benefits. 100% of our profits go back into our communities. That feels good! #ProudToBeAL

Are you interested?

What you can expect from us:

Our Mission is to offer great gaming experiences for the benefit of all Atlantic Canadians. Everyone at Atlantic Lottery embraces our Core Values of Integrity & Social Responsibility. #ProudtobeAL

Our Operating Principles help guide us to achieve our Vision;
Customers lead our priorities;
Always think differently;
Be fast and nimble;
We are all leaders and;
Team matters.
We are proud, gritty, community-minded, and punch above our weight. Being Atlantic Canadian means that we work hard and we know how to have fun. It also means that we genuinely care for each other as co-workers, neighbours, and friends.

We provide a comprehensive Total Rewards Program including bonuses and flexible benefits/pension and competitive compensation with plenty of training.

We are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodations), please let us know and we will work with you to meet your needs.

What Is Next?
Love what you see so far? For the best chance to hear from us, apply before August 24, 2020.
Not the right fit this time? Follow us on our careers page at www.alc.ca!
We thank all applicants for their interest, however, only those selected for an interview will be contacted. Please note that the successful candidate will be subject to reference and criminal background checks prior to employment.

Please note - Must be 19 years of age or older to apply.",3.9,Atlantic Lottery,Moncton,"Moncton, Canada",501 to 1000 employees,-1,Government,Gambling,"Arts, Entertainment & Recreation",$1 to $2 billion (CAD),-1,111.5,-1,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,1,0,1,6903,0
30,"Analytics
Data Scientist - QuantumBlack

Montreal

Apply Now

Qualifications

Masters or PhD level in the field of computer science, machine learning, applied statistics, mathematics or a related field
Experience in statistical modelling and machine learning techniques
Programming experience in Python. Some experience with R, Scala and SQL is preferable though not essential.
Good presentation and communication skills, with the ability to explain complex analytical concepts to people from other fields

Who You'll Work With


As a Data Scientist at QuantumBlack in Montreal (based in the MILA)...

You will work with other Data Scientists, Data Engineers, Machine Learning Engineers, Designers and Project Managers on interdisciplinary projects, using Maths, Stats and Machine Learning to derive structure and knowledge from raw data across various industry sectors.

Who you are

You are a highly collaborative individual who is capable of laying aside your own agenda, listening to and learning from colleagues, challenging thoughtfully and prioritising impact. You search for ways to improve things and work collaboratively with colleagues. You believe in iterative change, experimenting with new approaches, learning and improving to move forward quickly.

What You'll Do


You will work in multi-disciplinary environments harnessing data to provide real-world impact for organisations globally.

You will influence many of the recommendations our clients need to positively change their businesses and enhance performance.

Role responsibilities
Work on complex and extremely varied data sets from some of the world’s largest organisations to solve real world problems
Develop data science products and solutions for clients as well as for our data science team
Write highly optimized code to advance our internal Data Science Toolbox
Work in a multi-disciplinary environment with specialists in machine learning, engineering and design
Add real-world impact to your academic expertise, as you are encouraged to write ‘black’ papers and present at meetings and conferences should you wish
Attend conferences such as NIPS and ICML as one global team as well as Data Science retrospectives where you will have the opportunity to share and learn from your co-workers.
Work within one of the largest and most advanced data science teams in London, support the Lead Data Scientists to develop data science products
What you’ll learn
How successful projections on real world problems across a variety of industries are completed through referencing past deliveries of end to end machine learning pipelines
Build products alongside the Core engineering team and evolve the engineering process to scale with data, handling complex problems and advanced client situations
Be able to focus on modelling by working alongside the Data Engineering team which focuses on the wrangling, clean-up and transformation of data.
Best practices in software development and productionise machine learning by working with our Machine Learning Engineering teams which optimise code for model development and scale it
Work with our UX and Visual Design teams to interpret your complex models into stunning and user-focused visualisations
Using new technologies and problem-solving skills in a multicultural and creative environment
You will work on the frameworks and libraries that our teams of Data Scientists and Data Engineers use to progress from data to impact. You will guide global companies through data science solutions to transform their businesses and enhance performance across industries including healthcare, automotive, energy and elite sport.
Real-World Impact– No project is ever the same; we work across multiple sectors, providing unique learning and development opportunities internationally.
Fusing Tech & Leadership– We work with the latest technologies and methodologies and offer first class learning programmes at all levels.
Multidisciplinary Teamwork- Our teams include data scientists, engineers, project managers, UX and visual designers who work collaboratively to enhance performance.
Innovative Work Culture– Creativity, insight and passion come from being balanced. We cultivate a modern work environment through an emphasis on wellness, insightful talks and training sessions.
Striving for Diversity– With colleagues from over 40 nationalities, we recognise the benefits of working with people from all walks of life.
Our projects range from helping pharmaceutical companies bring lifesaving drugs to market quicker to optimising a Formula1 car’s performance. At QuantumBlack you have the best of both worlds; all the benefits of being part of one of the leading management consultancies globally and the autonomy to thrive in a fast growth tech culture:
Healthcare Efficiency– We helped a healthcare provider improve their clinical trial practices by identifying congestion in diagnostic testing as a key indicator of admissions breaches.
Environmental Impact– We designed and built the first data-driven application for a state of the art centre of excellence in urban innovation by collecting real-time data from environmental sensors across London and deploying proprietary analytics to find unexpected patterns in air pollution.
Product Development– We worked with the CEO of an elite automotive organisation to reduce the 18-month car development timeframe by improving processes, designs and team structures.
Please submit your CV in English

Visit our Careers site to watch our video and read about our interview processes and benefits

As an equal opportunity employer, QuantumBlack encourages applications from all backgrounds regardless of gender, race, disability, pregnancy, marital status, age, sexual orientation, gender reassignment, religion or belief. We maintain a sense of community rooted in respect and consideration for all employees where any evaluation is based simply upon individual work and team performance.

Industries
High Tech

Functions
Technology

Apply Now
FOR U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity/Affirmative Action employer.
All qualified applicants will receive consideration for employment without regard to sex, gender
identity, sexual orientation, race, color, religion, national origin, disability, protected Veteran
status, age, or any other characteristic protected by applicable law.

FOR NON-U.S. APPLICANTS: McKinsey & Company is an Equal Opportunity employer. For additional details
regarding our global EEO policy and diversity initiatives, please visit our
McKinsey Careers and
Diversity & Inclusion sites.",4.5,QuantumBlack,Montreal,"London, United Kingdom",501 to 1000 employees,2009,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Palantir Technologies, Google, Microsoft",139.0,11,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,1,0,1,6599,3
31,"Do you want to be a part of a team that proudly serves and supports customers across the world? Do you enjoy flexibility and gain exposure to the latest business innovations? Join us today!

Camfil Power Systems is a leading supplier of air filtration and acoustic treatment systems for gas turbines with its headquarters for the Americas in Laval.

When you visit our vibrant office in Laval, you will find a team that is intellectual, collaborative, relaxed and playful, with a strong focus on results. You will also be able to quickly and clearly see the impact of your work.

As a key member of our R&D team, you take the lead in analysing the performance of both gas turbines and their air filtration systems around the world, while building models to accurately predict future performance of various sub-systems.

Your primary function would consist of the following activities:
Analyze real-time data stored in a data historian
Ingest data from new sources
Predict gas turbine and air filter performance using time series analysis and machine learning algorithms (regression, SVM, KNN, neural networks etc.), for datasets with various levels of completeness
Implement production code for anomaly detection, as well as for the prediction of equipment performance
Maintain and optimize existing algorithms in development and production environments
Develop effective visualizations to present findings with the goal of improving the operation and maintenance of gas turbines, including through the use of PI Vision dashboards
Do you have the required qualifications?
Background in engineering, mathematics, statistics with hands-on experience in data analysis
Experience in working with external databases and APIs
Proficient in time series analysis, regression analysis, KNN, machine learning, neural networks
Skilled in R or Python with good grasp of data visualization (ggplot2, seaborn, Plotly, Shiny, Dash) and reporting
Knowledge of gas turbine and/or air filtration performance a plus
Camfil Power Systems does not discriminate. Hiring is subject to interview and qualification review. We thank all applicants for their interest but only those under consideration will be contacted.

Job Type: Full-time

Benefits:
Casual Dress
Company Events
Company Pension
Dental Care
Disability Insurance
Discounted or Free Food
Employee Assistance Program
Extended Health Care
Flexible Schedule
Life Insurance
On-site Gym
On-site Parking
RRSP Match
Vision Care
Wellness Program
Work From Home
Schedule:
8 Hour Shift
Monday to Friday
Experience:
time series analysis: 1 year (Required)
R and/or Python: 2 years (Required)
external database: 1 year (Required)
Education:
Bachelor's Degree (Required)
Language:
English (Required)
Work remotely:
Temporarily due to COVID-19",3.6,Camfil Power Systems,Laval,"Stockholm, Sweden",1001 to 5000 employees,-1,Company - Private,Industrial Manufacturing,Manufacturing,Unknown / Non-Applicable,-1,139.0,-1,data scientist,na,1,1,0,0,0,0,0,0,0,0,0,0,1,0,1,2769,0
32,"Title: Data Scientist
Job ID: DM74515678

Our client is looking for a Data Scientist to collect, store, clean, visualize, analyze, interpret, and model data relevant to Sports Betting markets in order to recognize patterns and trends in betting markets.

Responsibilities:
Acquire and store data from various sources related to Sports Betting markets including: sports data, betting market data, twitter data, etc.
Visualize, Analyze, and Interpret data.
Build and maintain data products and user interfaces for business users.
Interact with public API’s, such as Twitter, to collect relevant sports data.
Organize data products into API’s used to build internal data products and share data resources with business partners.
Develop unique approaches to solving complex modelling and inference problems, which combines the market and trading knowledge with a mathematical approach.
Other duties as assigned.
Qualifications:
Strong passion for working with data and Data Science.
Strong background in statistics, modelling, and algorithms. (Machine Learning or other)
Ability to convey complex information through Data Visualization.
Understanding of software and ability to write code to solve problems.
Exceptional analytical, conceptual, and problem-solving abilities with attention to detail.
Strong written and oral communication skills – Fluency in English.
Ability to communicate results to engineers and non-engineers.
Thorough understanding and passion for sports and sports betting markets preferable.
Expertise in R and other statistical programming languages. (3+ years)
Experience in Frequentist and Bayesian Statistical methods. (2+ years)
Experience working with Machine Learning algorithms, Probabilistic Models, and/or other statistical modelling approaches. (2+ year)
Experience with modern R packages such as dplyr, ggplot2, data.table, etc.
Experience in front-end R technologies for data products such as ShinyR, FlexDashboards.
Ability to write complex SQL queries.
Cloud Computing Experience desirable.
Some Python Experience desirable.
Good Software Engineering Design Principles, such as Design Patterns.
For more information about TEEMA and to consider other career opportunities, please visit our website at www.teemagroup.com.",4.7,TEEMA,North York,"Litchfield Park, AZ",201 to 500 employees,2008,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (CAD),-1,139.0,12,data scientist,na,1,1,0,0,0,1,0,0,0,0,0,0,1,0,1,2254,0
33,"Job Description


SUMMARY OF POSITION

As an Environmental Data Scientist, you will support numerous multi-disciplinary Environmental Engineering project teams with managing environmental quality and laboratory analytical data used in the assessment and remediation of contaminated sites. You will interface with digital solution specialists, project managers, laboratories, data technicians and GIS/drafting technicians to assure the reporting quality of environmental data. Using the environmental database EQuIS(TM) and other digital solutions, you will review sampling programs and analytical data, compile and update regulatory standards, support the preparation of report-quality results, trouble-shoot and provide solutions, and conduct quality control so that data management, reporting and visualization is completed in an efficient and timely manner.

In this role, you will contribute to critical path work which will be relied upon to make fundamental engineering decisions that affect clients, the public and SNC-Lavalin.

The successful candidate for this entry level position will have a strong understanding of organic and inorganic chemistry coupled with technical knowledge of database and data interpretation.

QUALIFICATIONS
B.Sc. in Chemistry or related field;
Experience or specialized training in the use of databases such as MS Access, SQL or equivalent;
1 to 2 years of related work experience;
English speaking;
Bilingual preferred (English and French)
PREFERRED SKILLS
Self-motivated, independent worker with strong organizational skills and the ability to manage time and multiple tasks;
Analytical thinker with problem solving skills;
Strong commitment to teamwork and multi-disciplinary communication skills;
Commitment to excellence;
Focus on quality control, quality management and attention to detail.
We are an equal opportunity employer.
Appropriate accommodations will be provided upon request throughout the recruitment and hiring process as required by Company policy and the Accessibility for Ontarians with Disabilities Act (AODA).Successful applicants will be notified about SNC-Lavalin’s accommodation policies at the time the employment offer is extended, and the information will be shared with new personnel during the onboarding process.

Founded in 1911, SNC-Lavalin is a global fully integrated professional services and project management company and a major player in the ownership of infrastructure. From offices around the world, SNC-Lavalin's employees are proud to build what matters. Our teams provide comprehensive end-to-end project solutions – including capital investment, consulting, design, engineering, construction, sustaining capital and operations and maintenance – to clients in oil and gas, mining and metallurgy, infrastructure and power. On July 3, 2017, SNC-Lavalin acquired Atkins, one of the world's most respected design, engineering and project management consultancies. http://www.snclavalin.com

At SNC-Lavalin, we seek to hire individuals with diverse characteristics, backgrounds and perspectives. We strongly believe that world-class talent makes no distinctions based on gender, ethnic or national origin, sexual identity and orientation, age, religion or disability, but enriches itself through these differences.

Worker Type
Employee
Job Type
Regular

At SNC-Lavalin, we seek to hire individuals with diverse characteristics, backgrounds and perspectives. We strongly believe that world-class talent makes no distinctions based on gender, ethnic or national origin, sexual identity and orientation, age, religion or disability, but enriches itself through these differences.

SNC-Lavalin cares about your privacy. SNC-Lavalin and other subsidiary or affiliated companies of SNC-Lavalin (referred to throughout as “SNC-Lavalin”) are committed to protecting your privacy. Please consult our Privacy Notice on our Careers site to know more about how we collect, use and transfer your Personal Data.

By submitting your personal information to SNC-Lavalin, you confirm that you have read and accept our Privacy Notice.",3.3,SNC-Lavalin,Ottawa,"Montreal, Canada",10000+ employees,1911,Company - Public,Building & Construction,"Building, Repair & Maintenance",$10+ billion (CAD),"Bechtel, Fluor, Amec Foster Wheeler",139.0,109,data scientist,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,4097,3
34,"Détails du poste
Data Scientist
Date 2020-02-21
Numéro 2729
Secteur Technologie
Durée Permanent
Expertises Rôle et Responsabilités:
Extraire et analyser les données se trouvant dans les bases de données de l’entreprise afin d’optimiser et d’améliorer le développement des produits, les techniques de marketing et les stratégies commerciales.
Évaluer l’efficacité et l’exactitude des nouvelles sources de données et techniques de collecte de données.
Élaborer des algorithmes et des modèles de données personnalisées à appliquer aux ensembles de données.
Utiliser une modélisation prédictive pour accroître et optimiser l’expérience des clients, les revenus générés, le ciblage publicitaire et d’autres résultats opérationnels.
Élaborer un cadre de tests A/B pour l’entreprise et mettre à l’essai la qualité du modèle.
Coordonner différentes équipes fonctionnelles pour mettre en œuvre des modèles et surveiller les résultats.
Élaborer des processus et des outils pour le contrôle et l’analyse du rendement des modèles et de l’exactitude des données.

Exigences et requis:
Titulaire d’une maîtrise ou d’un doctorat en statistique, informatique, analyse des systèmes de gestion ou autre domaine connexe.
Au moins 6 ans d’expérience en science des données ou en statistiques appliquées.
Solides aptitudes pour le développement de produits et la résolution de problèmes.
Expérience dans l’utilisation de langages informatiques statistiques (R, Python, SLQ, etc.) pour manipuler les données et extraire des renseignements de grands ensembles de données.
Expérience dans la manipulation d’ensembles de données et l’élaboration de modèles statistiques.
Expérience avec diverses techniques d’apprentissage automatique (Forêt d'arbres décisionnels, gradient boosting, machines à vecteur de support, réseaux de neurones, réseaux bayésiens, etc.) et de leurs avantages et inconvénients dans le monde réel.
Expérience avec les techniques et concepts statistiques sophistiqués (MLG/régression, séries chronologiques, propriétés des distributions, tests statistiques et utilisation conforme, etc.).
Expérience dans l’utilisation et la création d’architectures de données.
Expérience dans l’utilisation de services Web : Redshift, S3, Azure, Spark, DigitalOcean, etc.
Expérience dans l’analyse de données provenant de: Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Expérience dans la visualisation et la présentation de données pour des intervenants, à l’aide de : Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc.
Expérience de direction d’initiatives axées sur le service client.
Excellentes aptitudes pour la communication verbale et écrite en vue de la coordination des équipes.",-1.0,Services Conseils IntelliS,Montreal,"Montreal, Canada",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,139.0,-1,data scientist,na,0,1,1,0,0,0,1,0,1,0,0,0,0,0,0,2765,0
35,"DATA SCIENTIST


Headquartered in Dieppe, New Brunswick, the J.D. Irving, Limited Moncton-based companies have plants, terminals, operations and sales office throughout Canada and in the United States. We are a dynamic, rapidly growing and successful group with diverse interests. Our companies operate in Canada and the United States. We're proud to be part of the larger Irving Group of Companies, a family owned business whose commitment to quality products and services dates back over 135 years.

Based in Dieppe, New Brunswick, the Data Scientist will
create mathematical models that enable the business to make better faster
decisions. Will collaborate with other members of the strategy and business
performance group to enable sustainable, profitable growth through the
development and implementation of analytical solutions.

Successful candidate will possess the following Qualifications:
A post-secondary degree in science, mathematics, computer science or engineering
Minimum 5 years of analytical related experience
Highly enthusiastic and ambitious
Strong analytical and critical thinking skills
Experience in machine learning, simulation
Strong communication and presentation skills
Demonstrated ability to work well in a team environment
Proficiency in R, Python
Key Responsibilities:
Develop
and implement analytical solutions by working with the business on key projects.
Techniques involved in solutions will include: statistical analysis, machine
learning, financial analysis, simulation (stochastic modeling) and artificial
intelligence. Will take projects from the initial collection of data (working
with data steward if available) to the delivery of solution to the end-user.
Identify
opportunities to improve analytical processes within business and work
with continuous improvement to implement changes.
Work
with corporate analytics on research and development of new techniques.
To Apply for this Career Opportunity:

Please apply online with an up-to-date resume of past experience and education by Friday, July 31.

We thank all candidates for their interest, however, only those selected for interviews will be contacted.

To learn more about our products and services, click here.

J.D. Irving, Limited is committed to the principle of equal opportunity in its employment practices and to providing an environment free from discrimination and harassment for all employees.

We thank all candidates for their interest, however, only those selected for interviews will be contacted.
Additional Information



Posting Date: Jul 13, 2020",4.3,J.D. Irving,Dieppe,"Saint John, Canada",10000+ employees,1882,Company - Private,Industrial Manufacturing,Manufacturing,Unknown / Non-Applicable,-1,139.0,138,data scientist,na,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,2566,0
36,"At Nylas, our mission is to empower the world to communicate with context and insight. Our hosted sync platform and APIs enable developers to quickly integrate their apps with email, contacts, and calendar across all providers (including Exchange).

We are changing the way companies and developers innovate with email and messaging. Customers like Pipedrive, Salesloft, and Lever use our cloud messaging APIs to power their products and accelerate their ability to innovate.

Nylas has raised over $30M from Spark Capital, 8VC, Data Collective, Fuel Capital, SV Angel and more. Our HQ is in San Francisco with offices in New York, Denver, Toronto, and several of us work remotely. Members have previously worked at Dropbox, Google, Facebook, Microsoft, Oracle, SAP, and VMware.

Want to know more? Check us out on Comparably, Great Place to Work, and read our Employee Handbook!

About the team

The Intelligence team at Nylas is responsible for forward development of various services that built on top of emails, calendars and contacts utilizing natural language processing, machine learning, and integrations with external API's to categorize and contextualize information for developers to build an intelligence layer on top of Nylas' world class communications layer.

About the role

This role will be responsible for designing, developing and deploying various solutions such as rule-based, natural language processing, to deep learning models to categorizer and contextualize emails, calendars, and contacts. You'll be applying ML algorithms to solve real world problems.
You'll be working with on high impact datasets mission critical to the rest of the world from healthcare, operations, and infrastructure
You'll be working with frontend and backend engineers building an intelligence layer on top of email, calendars and contacts
You'll be able to use your models and solutions in real-time and see it in action on the front-end
You'll be independent enough to build and evaluate robust models
You'll be using the latest and greatest tools to build things the way you want with little to no legacy code to stand in your way
You'll be building out machine learning infrastructure for billions of datasets with trillions of connections
Who you are
Strong foundations in Statistics, Data Modeling, and Machine Learning
Strong foundations in Computer Science or Software Engineering
At least 2+ years of experience on developing and deploying to production systems
You've trained models and shipped them to production
Experience with python, scala, golang or java
Experience working with natural language processing packages
Experience working with industry standard machine learning packages and tools
Track record and references from great people
Ability and confidence to pick up any technical concept to get the job done
Comfortable in the dark and exploring ideas never done before
Strong belief that product and design decisions are inextricably linked
Busy creating magic from your code
A power user of the tools of your trade or building your own tools
Never stop learning
Communicate design decisions openly and confidently, regardless of the audienceengineers, PMs, executives, other designers, etc.
Not afraid to change your opinion in the face of new information or understanding of the product goalsyou have strong beliefs, but you're open-minded
Benefits

Tech setup - we'll make sure you have everything you need to work at your best, including laptop, laptop stand, and noise-canceling headphones
Competitive Pay
Meaningful Equity
Medical, Vision, Dental, and Life benefits for you and your family
401k, FSA, HSA, Commuter benefits
$1k yearly Education & Development benefit
Catered lunch & Unlimited snacks
$100 a month health and wellness benefit
Relocation assistance
Unlimited vacation (mandatory 2 week consecutive vacation once per year)
12 weeks caregiver leave
Flexible work hours

Nylas is an Equal Opportunity Employer, and diversity of all kinds is important to us.

Our team is roughly equal by identified gender (including engineering) and focuses on creating an inclusive environment for all people. We welcome people from all different backgrounds and currently employ startup founders, college graduates from all over the country and the world, coding academy graduates and those with no degrees at all.

We are actively and regularly working with the entire team to shape our culture in a conscious way to our ideal of empowerment, transparency, and kindness.",4.9,Nylas,Toronto,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,139.0,7,data scientist,senior,0,1,0,0,0,0,1,0,0,0,0,0,1,1,1,4501,0
37,"Mobile data connectivity drives economic growth and brings vast social benefits to the world, but two-thirds of the world's population is unable to access this valuable resource. Our mission is to make affordable mobile communications available to every human on earth.

We are founded by early Product and Growth team executives from Facebook, and backed by world-leading VCs including Google Ventures, Social Capital, SV Angels, Macquarie Capital, and Compound.

We partner with some of the greatest institutions in the world including Linkedin, Supercell, Twitter, Microsoft, Verizon Wireless, Singtel, and T-Mobile.

SUMMARY

As a Data Scientist / Engineer at LotusFlare, you will play a vital role in redefining connectivity on a global scale. You will work on products bringing connectivity to more than 10 million people across the globe. You will advocate data-fueled products that help our customers to make data-driven decisions. You will provide insight using leading analytics practice and ultimately produce new and creative analytic solutions that will become part of our core products including experimentation platform (Velocity), analytics platform (Periscope), and data platform. You are a strategic thinker who can form hypotheses, synthesize disparate information to validate those hypotheses, and provide actionable insights for the product team to scale user base.

RESPONSIBILITIES
Participate in building models that will scale products with millions of users globally
Partner with cross-functional teams including engineering, UX/UI, sales, marketing, and customer success to build growth strategies and manage complex, cross-functional projects
Analyze diverse sources of data to devise actionable insights
Deep understanding of the B2C consumer markets and core metrics in the markets
Work with Product Managers to develop, execute, and test different growth experiments that have a significant impact on conversion across all funnels (acquisition, activation, retention, engagement, and monetization)
REQUIREMENTS
Undergraduate degree in quantitative fields including Engineering, Math, Statistics from top tier institute or relevant field (MS or PHD is preferred)
Candidate must have the ability to independently build data pipelines, develop data models, and recommend growth strategies to product and executive teams
3 - 5 years of previous experience in building ETLs, analyzing consumer insights, creating metrics
Experience with SQL and/or NoSQL database
Experience with data visualization, dashboards, and reports
Experience with scripting languages such as Python
Candidate must be able to effectively synthesize disparate quantitative and qualitative data sets to make data-driven decisions
Eager to learn new programming languages and tools when needed
Strong desire to work in a fast-paced startup environment
Obsessive around moving critical business metrics and products
Strong communication skills, attention to detail, and ability to manage multiple projects and stakeholders
Great oral and written communication skills in English
Powered by JazzHR",4.2,"LotusFlare, Inc.",Waterloo,"Santa Clara, CA",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,139.0,6,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,3091,0
38,"This position will be accessing/extracting, analyzing and interpreting customer and consumer data across autoTRADER's business to build advanced predictive models leveraging statistics and mathematics to support business objectives such as acquisition and churn management, sales territory and channel optimization, product and price optimization, value-based segmentation as well as ad-hoc strategic and tactical issues.

Key Areas of Responsibility:

Customer Segmentation and Modelling
Develop and maintain models to identify best acquisition targets based on value to autoTRADER, and likelihood to convert. Work with key internal stakeholders in Marketing, Product and Sales to implement and continually back test and refine models as necessary
Develop and maintain models to identify customers at risk of churning from autoTRADER; identify key churn drivers; work with business stakeholders to continually refine model to increase precision and effectiveness
Extract, clean and transform customer data from across autoTRADER's business for the purposes of analysis, modelling
Support Product and Pricing Management
Support/Analyze existing pricing strategies and simulate potential changes to understand impact to customer segments, products, and revenues. Assess current performance against expectations and predict impact of implementing potential changes
Cultivate a data-informed culture and deliver meaningful insights that drive product roadmaps and optimize business strategies
Perform statistical analysis to evaluate critical areas for revenue improvement, while forecasting and optimizing customer penetration levels in order to maximize revenue
Develop predictive models through all stages in the product life cycle
Sales Optimization
Develop and maintain models to identify the optimal frequency of customer contact and best sales/ service channel by customer segment
Work with the Sales and IT team to integrate predictive models within Salesforce and other Trader systems as needed
Analyze data to identify process and people gaps where data is essential for predictive models
Thought Leadership
Develop best practices and standards for data modeling and management that improve the quality of the Marketing Intelligence team’s overall deliverables and increase its efficiency
Develop comprehensive testing and measurement programs that quantify and optimize models developed with each successive execution
Collaborate with BI, ISIT and Sales Operations to identify and secure data needed to increase the effectiveness of Trader’s predictive models
Identify data required to enhance and improve model accuracy; provide input and advice to MI/BI teams as part of data roadmap with IT
Collaborate with peer leaders across the broader Data organization to improve and drive the team-wide Data Science vision
Required Skills
High degree of autonomy – ability to work with internal teams to identify requirements and communicate them effectively
Strong business perspective – ability to understand medium-term (9-12m) implications of business decisions and react accordingly
Strong communication skills – ability to work in both technical and business environments, and can communicate key findings and implications to business leaders
Creative and innovative thinker with strong problem-solving skills\Ability to interact professionally with all levels within and external to the organization
Required Experience
Bachelors or Masters Degree in Mathematics/Statistics, Quantitative Science or Computer Science
Expert level SQL querying skills; fluent in statistical programs (i.e. R, Python)
Working knowledge of Office Suite Applications (Excel, PowerPoint, Word, Access, Outlook)
Experience working and combining data from multiple source systems
Minimum 5 years of related work experience in statistical and mathematical model development, quantitative analysis, interpretation and communication to internal and external stakeholders. Experience in online loyalty businesses is strongly preferred
Development of models include innovative solutions that leverage large data sets focused on customer attributes, business attributes and transactional data. The person should have successfully implemented many analytically advanced models in production for clients/stakeholders with benchmark measurements based on outcome. Experience with pricing models and concepts such as price elasticity is strongly preferred",3.1,autoTrader.ca,Toronto,"Etobicoke, Canada",501 to 1000 employees,1975,Company - Private,Advertising & Marketing,Business Services,$100 to $500 million (CAD),"CarGurus, Kijiji, Flipp",139.0,45,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,4428,3
39,"Join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive decisions at every level of our organization. The insurance industry is undergoing a transformation and you get to be in the driver’s seat of this data-driven, technology revolution.

You will work on impactful projects that range from predicting customer life-time values and optimizing customer journeys to incorporating novel data sources for building cutting-edge pricing algorithms. You will leverage machine-learning algorithms to automate and predict claim outcomes and find new and innovative ways to impact our customers. This team is exploring the frontiers of the insurance business such as how to harness the data from connected homes and cars to deliver new types of products to customers.

As a data-scientist, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. You will propose machine-learning and statistical models for practical applications that impacts millions of customers. You will also mentor and guide your peers in novel approaches and provide peer review for their work. The team has already developed algorithms used in production systems and you will be part of the team that expands the scope of these algorithms. This is your chance to join the InsureTech revolution!

The insurance industry has entered a period of unprecedented change, disruption and rapid technological development. Aviva recognizes that in this rapidly changing environment building a distinctive capability in Data Science is critical - demonstrating this commitment through the development of our Data Science Practice. If you are passionate about Data Science and leveraging your analytical prowess to tackle business challenges, this role could be for you. We are embracing new technology and exploring new ways of working. With our constant advancement, you will be at the forefront of a fast-evolving field. These exciting roles are at the heart of a high-performing Data Science team that is transforming Aviva in the Digital age. Here, we are creating a long-lasting legacy and optimizing every customer’s experience.

What you need to succeed

As a data-scientist, you will need the following skills and experience to succeed in the role:
An educational background in computer-science or engineering, math, statistics, physics or related field. A minimum of MSc is required and Phd preferred.
5+ years of experience with model development and working with large datasets. This can include experience from any industry or academia (post-doc experience).
5+ programming experience in Python or R with good grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.
Python/R /Dataiku
REST/XML/JSON/API ingestion
Spark/Impala/Hive
Expertise in machine learning theory and predictive modelling lifecycle
API configuration
Conformance/Alignment to IT/Enterprise Architecture standards (where applicable)
Relevant experience in P&C (preferred)
Shiny App development

Geo-analytics experience (ESRI/KML/KMZ layer development) with specialization in weather & environmental data ingestion
What sets you apart
A growth mindset with versatile skills and able to work through problems from first-principles.
A portfolio of projects that demonstrate your ability to draw inferences from data. This includes participation within the broader data science community including Kaggle competitions or any personal projects with open data.
A can-do teammate who is willing to roll-up the sleeves and do whatever is needed to move projects forward. That means at times you will wear different hats and be a project manager, developer, modeler and chief communicator of solutions.
Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners.
The best problems in the industry are yet to be articulated. We need someone who is creative, self-motivated and can lead projects independently.
Position Objectives
Provide data support to Claims business inclusive of data mining, automated reporting and modelling.
Transformation of complex data sets into meaningful conclusions & recommendations
Develop innovative solutions for pattern recognition using machine learning and statistical approaches
Maintenance of expanding set of data mining tools, frameworks & approaches
Communicate actionable recommendations based on insights/model results
Deliver proactive analysis on CAT exposure, historical performance and decision making using weather and geo-analytical approaches (CAT Analytics role)
Driving co-ordination/delivery accountability of project and BAU delivery based on timelines & direction (Sr Data Scientist)
Driving conformance/Alignment to IT/Enterprise Architecture standards (where applicable) (Sr Data Scientist)
About you

Highly numerate, you will be educated to post graduate (MSc) in a relevant discipline; Mathematics, Statistics, Computer Science. You will bring solid experience in a related role with a record of accomplishment of solving complex non-routine problems; along with expertise in some, if not all, of the following areas: Statistics, Machine Learning, Deep Learning & AI. You will have experience at all stages of data science; problem definition, data acquisition & wrangling, modelling, feature engineering and deployment. Big Data experience (e.g. Hadoop) would be ideal, but not essential. What is equally important is programming knowledge and a gift for coding using: R, Python or Spark. Your knowledge must also come with the ability to explain technical concepts to non-specialists. You will also need the drive to deliver projects –leading teams and coaching development. With these talents, you will be equipped to provide insights and deployments at scale. If you thrive on complex, non-routine problems, you will be right at home here.",3.5,Aviva,Markham,"London, United Kingdom",10000+ employees,1861,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),Legal & General,139.0,159,data scientist,na,1,1,0,0,0,0,1,0,0,0,0,0,1,1,1,6138,1
40,"We make small businesses more successful through better banking.

Our company is looking for a Data Scientist to join our growing team as we enter a new phase of expansion We are a Toronto and New York-based, venture-backed startup at the heart of the FinTech movement that is shaping the way financial services are delivered.

Our product

NorthOne is a mobile, tech-powered bank account built for startups, freelancers, and small/medium-sized businesses (SMBs). Poor financial literacy has an outsized impact on the costs and failure rates amongst SMBs, and we are on a mission to eliminate these problems. We are more than a banking platform, we are the world-class Finance Department that SMBs could never afford.

Our team

We data. As a Data Scientist you'll work with our world-class Data, Engineer, Growth and Product teams. Our COO has helped build digital products used by companies like Frank And Oak, Supercell, MachineZone, BMO, and Trivago. Oh, and our CEO? 6 years at McKinsey working on digital customer experience in financial services. We're building a product that solves real pain, vs the imagined kind. Feeling it?

REQUIREMENTS

The skills required for this role:
You love using SQL and Python to answer business questions and analyze data
You live and breath report automation
World class data science experience that you can apply to product, operations, and growth marketing
You're delighted by the idea building the foundational elements of a growing data science practice
You're a strong, clear communicator who knows keep the whole team on the same page
BONUS points:
Hands on experience working with tools like Looker and Mixpanel
Financial services experience or good understanding of banking
Experience working in a startup environment or for a SaaS company
Background in management consulting
PhD or Masters degree
BENEFITS

Our mission is big and audacious, but we're assembling a team to take the challenge head-on.

As a Data Scientist you'll be joining a team that prioritizes:
People: Our company is more than just a business. We're a band of brothers and sisters supporting each other on our mission to rebuild business banking. We're really serious about mission, fit, and the people we work with. You'll be part of a rapidly scaling team that reflects these values and keeps this place special.
Diversity: You'll find yourself in an environment that values diversity and inclusivity. Excellence doesn't come in one flavor and neither should we.
Leadership: You're right in the thick of it, making critical decisions that will clear our path forward.
We offer full health/dental benefits, competitive compensation/equity, and one hell of an adventure.

If you recognize yourself in this job description, let's talk.",4.1,NorthOne,Toronto,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,139.0,-1,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,2754,0
41,"We're looking for someone to join our diverse team in Montreal to play a key role for designing, creating, and maintaining client reports, analyzing client data, and communicating insights back to clients. We are looking for individuals from a wide range of backgrounds with demonstrated quantitative and problem-solving skills. We value creativity, hard work and on-the-job excellence.

The ideal candidate is someone who is highly motivated and who seeks to take on a challenging role in a fast growing company. We need someone who can work effectively with members of our data, analytics and digital teams to deliver data-driven products to organizations.

Responsibilities
Interpret client requirements in order to identify solutions
Query, transform and analyze client data in order to generate actionable insights
Draft and maintain automated reporting
Design and coordinate experimental protocols in multiple departments to identify strategic efficiencies
Support analysis projects from start to finish from theoretical, to practical, to execution
Communicate insights clearly and succinctly to internal and external audiences
Special projects, and other duties as required

Requirements
SQL database: 1 year
Analytical programming language: 1 year
Bachelor's degree in a quantitative or technical field

Assets
Advanced degree in a quantitative or technical field, or significant experience
Experience with surveys (drafting, fielding, weighting, analysis, reporting)
Experience with structured data (AWS Redshift, MySQL preferred)
Experience with unstructured data
Fluency with SQL
Familiarity with at least one analytics programming language (Python, R, etc)
Understanding of statistical principles
Understand that data is never perfect and although you may wish for more and better data, this does not deter you in getting to the best possible answer by creatively using available resources
Ability to develop and follow through a structured approach to a complex and novel problem
An ability and eagerness to constantly learn and teach others
Strong communication skills
A persistent mindset
Aptitude for BI and data visualization
Bilingualism (French/English)

What we offer

A thrilling work environment where every day is different
From fundraising for non-profit organizations to improving children's health, you will work on projects that have a real impact on people's lives.
A startup office space and the opportunity to join a growing multidisciplinary team
Competitive health coverage including dental care

About Data Sciences

Data Sciences is a different type of agency. We bring data and digital together to deliver unmatched, measurable results.

Data Sciences is a group of leading experts in the fields of data analytics, research, digital marketing and engagement campaigns that have a common goal to make a difference. Together we help organizations including Canadian and international NGOs, political parties, and major companies leverage data to produce measurable results.

Data Sciences is committed to the principles of diversity, inclusion and employment equity. We believe that the most successful teams are those made up of people from diverse backgrounds with diverse belief systems. Applications from all qualified candidates are welcome. We will contact only those summoned for an interview.


Analyste de données

Nous recherchons quelqu'un pour rejoindre notre équipe diversifiée à Montréal afin de jouer un rôle clé dans la conception, la création et la maintenance de rapports sur les clients, l'analyse des données client et la communication des informations aux clients. Nous recherchons des personnes d'horizons divers ayant des compétences démontrées en matière de résolution de problèmes et de méthodes quantitatives. Nous valorisons la créativité, le travail acharné et l’excellence au travail.

Description d’emploi

Relevant de notre directeur de l'analyse des données, vous serez responsable de la conception, la création et le maintien de rapports aux clients, l'analyse de données des clients, ainsi que de la communication des conclusions aux clients.

Responsabilités

Interpréter les exigences du client afin d'identifier les solutions
Consulter, transformer et analyser les données des clients afin de générer des informations utiles
Conception et maintenance des rapports automatisés
Conception et coordination des protocoles expérimentaux dans plusieurs départements pour identifier les gains d'efficacité stratégiques
Soutenir les projets d'analyse du début à la fin, de la théorie à la pratique, à l'exécution
Communiquer les idées clairement et succinctement aux publics interne et externe
Projets spéciaux et autres tâches requises

Exigences

Base de données SQL: 1 an
Langage de programmation en analyse de données: 1 an
Baccalauréat dans un domaine d’analyse quantitative ou technique

Atouts

Diplôme d'études supérieures dans un domaine d’analyse quantitative ou technique, ou une expérience significative
Expérience avec les enquêtes d’opinion (rédaction, mise en ligne, pondération, analyse, rapport)
Expérience avec des données structurées (AWS Redshift, MySQL sont préférés)
Expérience avec des données non structurées
Maîtrise de SQL
Familiarité avec au moins un langage de programmation en analyse de données (Python, R, etc.)
Compréhension des principes statistiques
Comprendre que les données ne sont jamais parfaites et, bien que vous souhaitiez plus de données, cela ne vous empêche pas d'obtenir la meilleure réponse possible en utilisant de manière créative les ressources disponibles
Capacité à développer et suivre une approche structurée pour résoudre un problème complexe et nouveau
Capacité et désir d'apprendre et d'enseigner constamment aux autres
Solides compétences en communication
Persistance
Aptitude pour l’intelligence d’affaire (BI) et la visualisation de données
Bilinguisme (français / anglais)

Ce que nous offrons
Un environnement de travail palpitant où chaque jour est différent
De la collecte de fonds pour des organismes à but non lucratif, à l’amélioration de la santé des enfants, vous travaillerez sur des projets qui ont un impact réel sur la vie des gens.
Un espace de bureau de type startup et l'opportunité de rejoindre une équipe multidisciplinaire en pleine croissance
Une couverture santé compétitive comprenant les soins dentaires

À propos de Data Sciences
Data Sciences est une agence différente. Nous combinons données et stratégies numériques, pour obtenir des résultats hors pair et surtout… mesurables.

Data Sciences est un groupe d'experts renommés dans les domaines de l'analyse de données, de la recherche, du marketing numérique et des campagnes d'engagement qui ont pour objectif commun de faire la différence. Ensemble, nous aidons des organisations, notamment des ONG canadiennes et internationales, des partis politiques et de grandes entreprises, à tirer parti des données pour obtenir des résultats mesurables.

Data Sciences s'est engagée à respecter les principes de diversité, d'inclusion et d'équité en emploi. Nous pensons que les équipes les plus performantes sont celles composées de personnes d'origines diverses ayant des systèmes de croyances diversifiés. Ce poste est ouvert à tous les candidates et candidats qualifiés.",5.0,Data Sciences Inc.,Montreal,"Vienna, VA",1 to 50 employees,2013,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1,139.0,7,data analyst,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,7266,0
42,"We’re revolutionizing the way humanity eats, and there’s a lot of room for optimization and growth. That’s where you come in. Your ingenuity will help us continue to drive innovation, making an impact on the reliability, performance, and scalability of Skip’s industry-leading technology.

Key Responsibilities
Delivering high-quality data science models as part of a team working on a variety of forecasting, optimization, logistical and routing challenges as a part of an established team of data scientists with experience in these areas.
Work closely with team members across all business units to build and evaluate suitable algorithms to allow us to scale our business.
Interfacing with other Tech teams working to production deadlines.
Taking on board feedback from other data scientists, gathering reviews of your code and models and ensuring they can be effectively deployed by our Tech team.
Use data to visualize and explain hypotheses and models.
Qualifications & Experience
MS degree / Ph.D. degree in a quantitative discipline (eg. CS, CEng, Stats, Physics).
Demonstrable relevant working experience.
Applied experience with machine learning, data science and solving problems at scale.
Ability to communicate business outcomes and recommendations from analysis verbally and written, ability to present results coherently.
Ability to develop confidently in Python, with the capability to read and understand other languages with complicated codebases.
Confident extracting and manipulating data from our various SQL and NoSQL data stores and storage frameworks.
Practical experience with Logistics algorithms, routing algorithms, optimizations, time series analysis or forecasting time-series.
Experience working on projects that employed assignment algorithms, routing algorithms or time series forecasting.
Deep understanding of best practices for Data Conditioning, Model Selection and Testing.
Experience from similar markets to the food-delivery market.
Experience working in agile teams, with code reviews and source control.
Comfortable with big data stores (Google BigQuery, Amazon Datastores) and tools (including dynamoDB, elasticsearch, S3, SQS, Kinesis) or Spark / Storm / Hadoop / Kafka or Neo4
Why work at Skip?

Picture this: you, dressed in your fave casual attire, amongst a team of friendly and passionate colleagues. You feel pride knowing your input and uniqueness is not only embraced, but makes an impact on a major Canadian company, and its satisfied customers. As the company grows, so do you—you meet and surpass new challenges every day.

This is just a taste of what it’s like to work at one of Canada’s leading tech companies. If you’re hungry for opportunity, growth, and something meaningful in a dynamic yet casual environment, we’d love to hear from you.

Note: All employees will be asked to sign a Consent for Disclosure of Personal Information in order to complete a background check. Job offers will be conditional upon results that the Company determines to be satisfactory.",3.3,SkipTheDishes,Winnipeg,"Winnipeg, Canada",201 to 500 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,139.0,7,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,3025,0
43,"Use cutting-edge Data Science techniques to redefine the grocery industry at BC’s fastest growing grocery retailer!

Save-On-Foods is one of Western Canada's largest employers. Our legacy of outstanding value and customer service dates back more than 100 years largely due to our commitment to going the extra mile!

We are driven to meet the specific needs of each community we serve and have grown to become Western Canada’s premier grocer with four banners and more than 175 locations from British Columbia to Manitoba and the Yukon.

We currently have an exciting opportunity for a Data Scientist - Customer to join our team in Langley, BC.

Reporting to the Director, Enterprise Analytics, you will use all aspects of data & analytics, perform root cause analysis, and create machine learning and statistical workflows for end-user manipulation.

You will be responsible for:
Working with stakeholders to understand marketing programs and information needed to support analysis, insight and model development
Working with IT and the Data Analytics Specialists to identify technical and data requirements to deploy analytic solutions catered to the business
Finding unique and creative insights to identify new opportunities to drive business value
In order to qualify for this role, you will have a minimum of a graduate degree in a STEM discipline PLUS 1 year of relevant experience in data science and machine learning.

You have:
Knowledge of experimental design principles such as AB and multivariate testing, as well as experience working with business stakeholders to formulate testable hypotheses
Experience in Linux-based cloud computing infrastructures such as Azure, AWS or GCP
Experience developing ML workflows with distributed systems and file structures including Hadoop, Spark, and Databricks
Experience integrating data from various data sources including enterprise databases such as Azure SQL Server, Oracle, Snowflake, etc. leveraging advanced SQL
Experience in machine learning and statistical model development related to turnover modelling, survival analysis, and attribution modelling
Extensive experience in building and developing machine learning models using Python and packages such as Tensorflow, Scikit-Learn, Pandas, etc.
Experience collaborating with a team of data scientists leveraging version control, such as git
Strong knowledge in data management concepts
You are:
A strong communicator
A strong problem solver
Collaborative
Entrepreneurial
Someone who enjoys mentoring others
What we offer

In addition to a highly competitive salary, we offer a great range of benefits, a company pension plan, free access to our onsite gym, free parking, team member offers, and opportunities for development and career progression.

Save-On-Foods is an inclusive team-oriented environment where we recognize achievements and celebrate them.

If you want to be part of an organization that makes an impact every day in our local communities, apply online today!

PLEASE NOTE: If you are using Microsoft Explorer, please open this page in another browser such as Chrome or Edge to apply.

Job Types: Full-time, Permanent

Benefits:
Company Events
Dental Care
Employee Assistance Program
Extended Health Care
Life Insurance
On-site Gym
On-site Parking
Paid Time Off
Store Discount
Tuition Reimbursement
Vision Care
Work remotely:
Temporarily due to COVID-19",3.5,Save-On-Foods,Langley,"Langley, Canada",51 to 200 employees,-1,Company - Private,Grocery Shops & Supermarkets,Retail,Unknown / Non-Applicable,-1,139.0,-1,data scientist,na,0,1,0,0,0,1,1,1,1,0,0,0,1,0,0,3384,0
44,"About SurveyMonkey

SurveyMonkey (NASDAQ: SVMK) is a leading global survey software company on a mission to power the curious. The company's People Powered Data platform empowers over 17 million active users to measure and understand feedback from employees, customers, website and app users, and the market. SurveyMonkey's products, enterprise solutions and integrations enable 335,000+ organizations to solve daily challenges, from delivering better customer experiences to increasing employee retention. With SurveyMonkey, organizations around the world can transform feedback into business intelligence that drives growth and innovation.

SurveyMonkey is a place where the curious come to grow. By embedding inclusion into our processes, policies, and culture, we are building a workplace for our 1,000+ employees across North America, Europe, and APAC where people of every background can thrive. We've won multiple awards and received recognition for our forward-looking policies, including extended parental and bereavement leave, vendor benefits standards, and Take 4 sabbaticals. SurveyMonkey was recognized by Great Place to Work® and FORTUNE as a top workplace in 2018 and 2019, and the company has also won numerous awards as a leader in global survey software, including being named among CNBC's Disruptor 50 and the Forbes Cloud 100.

Over the past two years we've become a public company and expanded our platform with enterprise-grade features in privacy, security and compliance, putting SurveyMonkey on the path to rapidly expand our presence within the Fortune 500. We have ambitious goals to grow our international footprint as well, and every member of our troop plays a critical role in driving this growth and transformation. It's an incredible time to join the company and be a part of our next chapter!

The Role


We are looking for a seasoned machine learning and data mining expert to join our data science team to lead the execution of Business strategy setting projects.

As a senior member of the Data Science team, the successful candidate will play a leading role in deriving key insights from large amounts of our people-powered data, suggest and implement new product features, and make improvements in existing models for better user experience. They will work on developing machine learning algorithms and systems, and need to be capable of implementing and utilizing intelligent tools and technologies. They will help internal constituents to achieve extraordinary value for our customers. This role also involves technical leadership and mentorship of data scientists and machine learning engineers.

Requirements
Industrial data-mining including applied techniques in data mining and machine learning, especially in the domain of natural language processing and fraud detection
Expertise in machine learning model development, including data preprocessing, feature engineering, classification and prediction model development, and model deployment.
Strong programming skills, expert knowledge of algorithms, and data structures (Python preferred).
AWS knowledge is must
Prior experience and continued interest in mentorship and technical development of junior data scientists.
Excellent problem-solving, critical thinking, creativity, organizational, design, and interpersonal skills.
Ability to work well with all levels of engineers.
Confirmed ability to handle multiple projects with strict deadlines.
Prior experience in partnering with business teams to solve problems and identify trends and opportunities.
Developing solutions that improve business performance through advanced statistical analysis, data mining, and data visualization technologies.
Excellent customer experience intuition; demonstrate success in inventing innovative and user-friendly products.
Preferred Qualifications
Master's or PhD in Computer Science or a data-driven physical science, or equivalent, plus 4 or more years of relevant industry experience.
Experience in computer vision is a plus.
Expert knowledge of Airflow, Pytorch/Tensorflow, Scikit-learn and Pandas is a plus
Must be able to obtain and hold government security clearance at the Reliability level.

At SurveyMonkey, we offer competitive salaries, medical/dental benefits, PTO, RRSP matching, and equity compensation.

SurveyMonkey is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.

Accommodations are available for applicants with disabilities.",4.6,SurveyMonkey,Ottawa,"San Mateo, CA",1001 to 5000 employees,1999,Company - Public,Internet,Information Technology,$100 to $500 million (CAD),-1,139.0,21,data scientist,senior,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,4514,0
45,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

A data science all rounder role. The core purpose of the role is to build models to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Conceive, devise, create, implement and fine tune data science models to solve a range of business problems, from customer churn through to
Set up, run and analyse A/B experiments for the website and email marketing campaigns
Help devise and layout a high quality infrastructure, upon which future data science can flourish
Help up skill other analytical team members into advanced data science techniques
Produce ad hoc analyses
And let's be honest, a whole load of data wrangling!
Skills and experience

Non negotiables:
SQL
Python or R
Data science models (K-means, random Forrest, neural nets etc.)
Strong foundational knowledge in stats and maths
Experience in actually productionising models and exposing to real customers
Business acumen
Strong communication skills, both written and verbal
Nice to haves:
Experience in working with developers, especially on experimentation
Some kind of cloud based experience (AWS preferred)
Some basic knowledge of source control with Git
Our application process consists of some online testing with Alooba, video call interview and then a case study. We expect the process to take about 10 business days end to end.

Job Type: Full-time

Salary: $80,000.00-$120,000.00 per year

Work remotely:
Temporarily due to COVID-19",-1.0,GradTests (gradtests.c,Ottawa,-1,-1,-1,-1,-1,-1,-1,-1,139.0,-1,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1734,0
46,"Open up to the Possibilities!
At Purolator, you’ll be proud knowing you’re working for a Canadian company that truly values its employees. And it’s community. This is an exciting and evolving industry and we’re leading the change as we strive to deliver the future. Here you will be empowered to help move the business forward. Each and every day. Are you open to the possibilities?

Job Description

We are looking for a seasoned Data Scientist who is enthusiastically driven to generate actionable insights and create new growth opportunities. You must have proven analytics leadership skills to grow and foster rapid learning and application of insights. You will lead analytics initiatives including advanced statistical modelling and develop data-driven solutions across several lines of business and domains. This is a unique opportunity to apply your analytics skills in a uniquely Canadian organization rich in history and data.

REQUIREMENTS
M.Sc. or Ph.D. in a quantitative field (e.g., Computer Science, Statistics, Financial Economics, Applied Mathematics, Computer Engineering, or other related discipline).
Significant experience solving problems with the required use of advanced statistical modelling techniques.
Proven programming skills including experience conducting modelling and statistical analysis (e.g., R, Matlab), object-oriented software development (e.g., Python, Scala), and massive parallel processing (e.g., Spark, Apache Hadoop).
Professional experience applying statistical analysis, machine learning, analysis and modelling of large scale and complex datasets.Excellent communication skills and ability to describe and present complex technical concepts in clear and concise language across an audience with varying levels of understanding.
Excellent presentation skills to both technical and non-technical people.
Ability to lead teams and create an environment of continuous learning and open communication.
Ability to structure and lead a project from idea to experimentation to prototype to delivery to the customer (internal / external).
A track record of distilling complex and ambiguous problems into actionable recommendations based on sound data analysis and insights
Strong programming fundamentals, and ideally have extensive experience analyzing data using SQL, Pandas, Spark, or similar tools
WHAT WE EXPECT?
Self-starter that is focused and driven with amazing follow-through.
Enthusiastically tackling problems with curiosity and a love of sharing ideas and insight.
Ability to synthesize information, evoke good conversation and consider problems from new perspectives.
Ability to provide clear recommendations in the face of challenges or limitations.Driven to deliver quality solutions and models that are accurate, valid and are supported with reliable data.
Ability to manage time effectively, prioritize tasks, and take ownership for your work
POSTING DETAILS
Location: 530 - Corporate
Working Conditions: Office Environment

Reports to: Manager Enteprise Analytics
--

Purolator is an equal opportunity employer committed to diversity and inclusion. We consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, Aboriginal/Indigenous status or any other factors considered discriminatory. If you require an accommodation during the recruitment process, we will work with you to meet your needs.
We recognize that our employees and their families are key stakeholders. We will only be successful as a business if we provide our employees with a safe and healthy workplace and we have the right people in the right roles with the support they need to succeed. We hire for attitude and train for skills. To learn more about us and our values, go to www.purolator.com.

At Purolator, every day is an opportunity for our employees to connect with one another and with our customers to help make a positive impact in the communities where we live, work and play.",3.4,Purolator,Mississauga,"Mississauga, Canada",10000+ employees,-1,Company - Private,Express Delivery Services,Transportation & Logistics,$2 to $5 billion (CAD),-1,139.0,-1,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,1,0,1,4020,0
47,"Job description:

Le point focal étant les clients, léquipe Accélérateur numérique sengage rehausser lexpérience de formation afin de sassurer que les pilotes soient les meilleurs possible.

Voici quelques raisons pour lesquelles les employés aiment travailler avec nous:
Travail significatif qui favorise le perfectionnement professionnel
Possibilité de travailler dans lindustrie technologique et de sy épanouir
Environnement de travail axé sur la collaboration
Faire partie dune équipe haut rendement
Votre mission

À titre de scientifique des données, votre mission est concevoir, développer et implanter des solutions analytiques et prédictives complètes, dans un environnement infonuagique, qui sont évolutives, répétables et sécuritaires.

Votre rôle et responsabilités principales

Être un contributeur-clé de la stratégie dintelligence artificielle
Concevoir des solutions dIntelligence Artificielle innovatrices permettant de supporter les opérations dentrainement dans les domaines de laviation et de la santé
Extraire et analyser les données des bases de données de l'entreprise pour stimuler l'optimisation et l'amélioration du développement de produits, des techniques de marketing et des stratégies commerciales.
Évaluer l'efficacité et l'exactitude des nouvelles sources de données et techniques de collecte de données.
Développer des solutions et des algorithmes d'IA personnalisés appliquer aux ensembles de données.
Expérimentez des méthodologies de modélisation avancées qui visent augmenter et optimiser l'expérience client, la génération de revenus, le ciblage publicitaire et d'autres résultats commerciaux.
Développer un cadre de test A/B pour l'expérimentation de l'IA et l'analyse des résultats.
Coordonner avec différentes équipes fonctionnelles pour mettre en œuvre des modèles et suivre les résultats.
Développer des processus et des outils pour surveiller et analyser les performances du modèle et la précision des données.
Être un contributeur-clé dans la transformation de lentreprise
Piloter la recherche sur les tendances de l'industrie de l'aviation et des soins de santé et les applications commerciales de l'apprentissage automatique pour être un différenciateur sur le marché
Mener plusieurs projets liés l'apprentissage machine grande échelle et orientés services: du plan fonctionnel au plan de mise en œuvre
Diriger une équipe pour le développement rapide et itératif d'une solution minimale viable validée
Développer et prototyper de nouvelles techniques d'apprentissage automatique, exécuter des expériences pour améliorer la compréhension et modéliser le taux d'efficacité
Être un collègue inspirant et motivant
Partager vos connaissances avec léquipe et initier des activités de partage des connaissances
Être un agent de changement et un promoteur de la mentalité agile
Contribuer au milieu de travail collaboratif et stimulant
Communiquer avec la communauté d'intelligence artificielle de Montréal et d'ailleurs pour trouver de nouvelles possibilités de collaboration et pour injecter de nouvelles idées dans notre pipeline
Vos qualifications
Une volonté d'apprendre et de maîtriser les nouvelles technologies, méthodologies et techniques.
Expérience piloter des initiatives dirigées par le client.
Expérience de travail dans un environnement Agile un atout.
Excellentes compétences en communication écrite et verbale pour la coordination entre les équipes.
Compétences techniques
Avoir une maîtrise ou un doctorat en statistique, informatique, analyse commerciale ou un domaine connexe
Posséder au moins 5 ans d'expérience en science des données ou en statistiques appliquées.
Solides compétences en résolution de problèmes en mettant l'accent sur le développement de produits.
Expérience de l'utilisation de langages informatiques statistiques (R, Python, SLQ, etc.) pour manipuler des données et tirer des enseignements de grands ensembles de données.
Expérience dans la manipulation d'ensembles de données et dans l'élaboration de modèles statistiques.
Connaissance d'une variété de techniques d'apprentissage automatique (forêts aléatoires, machine vecteur de support, amplification de gradient, réseaux de neurones artificiels, réseaux bayésiens, etc.) et leurs avantages / inconvénients réels.
Connaissance des techniques et concepts statistiques avancés (MLG / régression, séries chronologiques, propriétés des distributions, tests statistiques et utilisation appropriée, etc.) et expérience de leurs applications.
Expérience de travail en création et consommation d'architectures de données.
Expérience de l'utilisation des services Web: Redshift, S3, Azure, Spark, DigitalOcean, etc.
Expérience de l'analyse de données de fournisseurs tiers: Microsoft Application Insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Expérience de visualisation / présentation de données pour les parties prenantes en utilisant: Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc.
Ce que nous avons offrir
Avantages sociaux : entièrement flexibles pour que vous puissiez choisir ce qui est important
Retraite : Régime de retraite prestations déterminées et régime enregistré dépargne-retraite (REER) collectif
Avantages financiers : Régime dactionnariat et nombreux rabais dentreprise
Programmes personnels et familiaux : Plan de bien-être physique et prestations de maternité complémentaires
Équilibre travail-vie personnelle : Horaires flexibles et « vendredis californiens » toute lannée
Plaisir au travail : Activités sociales et communautaires tout au long de lannée!
**********************************************************************************

Data Scientist

With its strong customer focus, the Digital Accelerator team is dedicated to elevating the training experience to make pilots the best they can be.

Here are few reasons why folks love working with us:
Meaningful work that drives professional development
Ability to enter and grow within the technology industry
Work in a collaborative environment
Be part of a high-performance team
Your Mission

As a member of the Data Science team, your mission is to design, develop, and implement end-to-end cloud-based analytics production pipelines that are scalable, repeatable and secure.

Your Role & Main Responsibilities

Be a key contributor to the AI Strategy
Design innovative Artificial Intelligence solutions to support aviation and health training operations.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies. ?
Assess the effectiveness and accuracy of new data sources and data gathering techniques. ?
Develop custom AI solutions and algorithms to apply to data sets. ?
Experiment advanced modeling methodologies that aim increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes. ?
Develop company A/B testing framework for AI experimentation and results analysis. ?
Coordinate with different functional teams to implement models and monitor outcomes. ?
Develop processes and tools to monitor and analyze model performance and data accuracy.
Be an active member of the business transformation
Drive research on aviation & healthcare industry trends and the commercial applications of machine learning to be a differentiator in the market
Lead multiple service-oriented large-scale machine learning related projects: from functional to the implementation plan
Lead a team for rapid and iterative development of validated minimum viable solution
Develop and prototype new machine learning techniques, run experiments to improve comprehension and model efficiency rate
Be an inspirational and motivational colleague

Be an inspirational and motivational colleague
Share knowledge with team members & participate in various learning-sharing activities
Contribute to the collaborative and stimulating work environment
Be a change agent & Agile mindset promoter
Be connected to the industry to know tendencies and suggest innovative ideas
Your Qualifications

Softskills
A drive to learn and master new technologies and techniques.
Experience leading customer driven initiatives.
Experience working in an Agile environment an asset.
Excellent written and verbal communication skills for coordinating across teams.
Technical skills
Have a Master or PhD in Statistics, Computer Science, Business Analytics or a related field
Possess at least 5 years experience in Data Science or applied statistics.
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience manipulating data sets and building statistical models.
Knowledge of a variety of machine learning techniques (Random Forests, Support Vector machine, Gradient boosting, artificial neural networks, Bayesian networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (GLM/Regression, Time Series, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Experience working with and creating data architectures.
Experience using web services: Redshift, S3, Azure, Spark, DigitalOcean, etc.
Experience analyzing data from 3rd party providers: Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc.
What we have to offer
Benefits: fully flexible for you to choose what is important
Retirement: Defined Benefits Retirement Plan & Group Registered Retirement Savings Plan (RRSP)
Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts
Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan
Work-Life Balance: Flextime & California Fridays all year
Fun at work: social and community events all-year round!
Job #43536",3.6,Tundra,Montreal,"Toronto, Canada",201 to 500 employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,139.0,16,data scientist,na,0,1,1,0,0,0,1,0,1,0,0,0,1,0,1,10104,0
48,"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.

Principal Accountabilities:

As a Data Scientist Programmer with balanced analytics, technology, and consulting experience, you will provide data analytics expertise to IQVIA R&D Solutions' organizations and related external organizations to drive digital innovations. Embedded in the R&D Solutions’ key business processes, you will work with business stakeholders to identify and prioritize business problems to be addressed with data analytics. You will design, develop and deliver data analytics solutions to address identified business problems, working with other ACOE team members, e.g. GSM (Global Solutions Manager) as needed. This hands-on role is a key analytics interface between stakeholders and Analytics and must have the ability to interpret requests and provide insights to support the overall business needs.

Specific activities include:
Embedded in the R&D Solutions’ key business processes, identify and prioritize business problems to be addressed with data analytics;
Support business partnership and empower data-driven decisions by working with structured and unstructured data sets, building analytics solutions and advising business stakeholders on data solutions development;
Contribute to data innovation task and the development and delivery of high value and differentiating analytic insights to enhance trial strategy and execution;
Leverage large volumes of complex internal and external data using a variety of technologies, including tools like Python, R, SQL, Spark, HDFS;
Integrate custom analytics (e.g. clustering, predictive, prescriptive) to support data-driven decision making using advanced computing tools;
Translate and communicate results, recommendations and opportunities to improve data solutions to internal and external leadership with easily consumable reports and presentations;
Stay updated on IQVIA offerings and newly acquired assets for developing R&D Solutions opportunities and identify new areas of growth, outside the scope of existing solutions, e.g. data exploration, data acquisition, visualization;
Proactively continue to strengthen subject matter expertise within business partnership;
Contribute to analytical methodology research, project execution, streamlining processes and efficiencies.
Qualifications and capabilities:

Our ideal candidate will have:
A Bachelor’s or Master’s degree in Statistics, Economics, Econometrics, and Computer Science or a related field – alternatively, a relevant combination of education, training and work experience;
At least two years of relevant quantitative experience analyzing data;
Experience working with large volumes of complex health / claims data;
A good understanding of data modelling, visualization, e.g. Spotfire, Tableau, Power BI;
Experience with R or Python (Python preferable);
Experience with Spark, SparkR, and PySpark within distributed environment is preferred;
Strong SQL and/or Hive skills;
A good understanding of data science, ML / AI with a sound foundation in statistics;
Ability to bridge the technical expertise of data engineers and data scientists with the operational expertise of business functions and business managers;
Sound understanding of local / regional health sector and data;
Strong communication and presentation skills;
Ability to manage a workstream / project;
Local language skills, to an advanced level (spoken and written), with complete fluency in English.
Join Us

Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.

Forge a career with greater purpose, make an impact, and never stop learning.

Apply Now!",3.6,IQVIA,Montreal,"Durham, NC",10000+ employees,2017,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$2 to $5 billion (CAD),"PPD, INC Research, PRA Health Sciences",139.0,3,data scientist,na,1,1,1,1,0,1,1,0,0,0,0,0,0,0,1,4234,3
49,"Job description:

6+ years experience - Responsible for data analysis, validation, cleansing, collection and reporting. Extract and analyze data from various sources, including databases, manual files, and external websites. Respond to data inquiries from various groups within an organization. Create and publish regularly scheduled and/or ad hoc reports as needed. Document reporting requirements and process and validate data components as required. Experience with relational databases and knowledge of query tools and/or statistical software required. Strong analytical and organizational skills required. Must possess expert level knowledge of MS Excel. 5+ years of prior experience as a Data Analyst is required.

Job #43881",3.6,Tundra,Toronto,"Toronto, Canada",201 to 500 employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,139.0,16,data analyst,na,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,731,0
50,"Job Description:

Data Scientist

Create awesome experiences for our customers.

Are you eager to build and deploy machine learning models to tackle real-world problems? Are you curious about learning new techniques and applying them to large datasets? Are you passionate about using data to understand and improve the customer experience for millions of Canadians?

Join our team

The data products team is an agile team focused on building machine learning applications which enable dynamic experiences that adapt to the behaviour of our customers. Some of the solutions weve worked on include product recommendation, fraud detection, lead scoring and natural language analysis. Our team of data scientists and engineers allows us to build end to end solutions from data ingestion to model serving.

Heres the impact youll make and what well accomplish together

As a data scientist with Client Digital, you will be responsible for developing and operating the machine learning applications that enable innovative digital experiences inside and outside the organization.

You will work as part of a friendly, cross-disciplinary, and agile team who helps each other tackle problems across all functions. As a custodian of customer trust, you will employ the best methodologies in development, security, accessibility and design to achieve the highest quality of service for our customers.

Heres how
Understand business needs and apply data science/machine learning techniques to address real-world problems
Analyze source data (including structured and unstructured data), cleanse data, and support the building of data pipelines
Build models and enable solutions using techniques such as regression, classification, clustering, natural language processing, deep learning, and/or statistical modeling
Help validate, maintain, optimize, and troubleshoot the performance of machine learning models being used in development and production applications
Ensure data privacy is respected
Use visualization techniques to communicate findings and explain models
You're the missing piece of the puzzle
Education in computer science, engineering, mathematics, or a related field
Expertise developing machine learning models in Python and using open source ML libraries such as Scikit-learn, PySpark, Tensorflow, SpaCy, and PyTorch
Ability to communicate technical and complex concepts in a way that is understood by non-technical audiences
Relevant work or research experience delivering substantial data science projects including publications, contributing to packages, deploying applications, building tools and frameworks
Interpersonal and communication skills to enable collaboration with a range of team members with diverse skill sets and backgrounds
The ability to quickly familiarize yourself with new languages, tools, frameworks, and to stay informed on developments in ML techniques and technologies
Dedication to ensuring your work is well documented and version controlled
Experience using Cloud infrastructure like Google Cloud Platform, Amazon Web Services or Microsoft Azure
Experience with agile methodology and team-based software development workflows
Must to have skills: (please at least 3 skills/exp):
Candidate needs one of the following:
-~5 Years of industry experience as a Data Scientist or similar work
-A Masters Degree in Computer Science, Engineering, or Mathematics or a related field with 1-2 years experience as a Data Scientist or similar work
-A PHD in the above academics with course work in Machine Learning and applied knowledge during schooling
Experience in Machine Learning libraries such as Python, Scikit-learn, PySpark, Tensorflow, and PyTorch
Proven demonstrated experience applying Machine Learning practices to Real World scenarios (ie building applications)
Nice to have skills: (please at least 3 skills/exp):
Great Communication Skills
Boot camp experience (Machine Learning or Data Science)
A development background that theyve transitioned to a Data Scientist role (eg Python development)
Job #43410",3.6,Tundra,Toronto,"Toronto, Canada",201 to 500 employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,139.0,16,data scientist,na,0,1,0,0,0,0,1,1,1,1,0,0,1,1,0,4046,0
51,"Health insurance is critical to guaranteeing people's ability to pay for care and be financially protected when sudden, unexpected illness strikes.

We're tackling some of the industry's toughest problems by employing AI-powered predictive analytics on the messiest data. Together, we can make health insurance more effective, reliable and affordable.
This is how we will achieve cost effective care that works for everyone.

Backed by both Canadian and Silicon Valley based venture capital, the Canadian government, and a team of high-profile entrepreneurs, we are proud to be based in Toronto, Canada at the center and birthplace of deep learning.

Top Reasons to Join Knowtions:

Healthcare is the most impactful field in AI. Your work will make sure people can pay for healthcare when they need it most. This is an extraordinary opportunity to transform healthcare from within the behemoth.
We are solving some of the most complicated problems in our industry. Join us if you want to push the frontier of what AI can do and how AI can transform an entire industry.
We have unparalleled size of proprietary datasets. It's the critical raw ingredient to optimizing healthcare and your playground.
We build and deliver, then explore to build more. Work and grow with a diverse team that brings out the collective genius in each other



Who we’re looking for

You are an individual with outstanding analytical abilities, firm understanding of machine learning and creativity to take new approaches in the way they solve problems. Our new ML Data Scientist will focus on maximizing the usability of large healthcare datasets presented in different languages, formats and recorded variables to train machine learning models.

This is an opportunity to use advanced quantitative and statistical analysis techniques to solve some of the most complex challenges facing the machine learning adoption in the global healthcare sector.

Your Role

Develop data collection plans and ensure integrity of data collected through all stages of acquisition and processing (e.g. ground truth generation, normalization, and transformation).
Quantitatively test hypotheses about data used to create models that increase the performance of predictive models.
Combine expert knowledge of statistical methodology and analysis with advanced programming skills to perform exploratory data analysis to uncover patterns in user’s health and activities.



Qualifications

Graduate degree (MS or equivalent) or higher in a quantitative field such as Mathematics, Statistics, Biostatistics, Computational biology or Medical Sciences.
Experience with SQL and NoSQL databases.
Programming experience in Python and/or Java/Scala; knowledge of standard data analysis tools for these languages (for example Pandas in Python); experience with other analytics software (R, SAS, STATA, MATLAB, Mathematica) is a plus.
Experience with Spark is a plus.
Creative in finding new solutions as well as designing innovative methods, systems, and processes.
Broad understanding of health data is an asset.
Ability to conduct independent research.
Good interpersonal and communication skills",-1.0,Knowtions Resea,Toronto,"Toronto, Canada",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,139.0,-1,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,1,1,1,3148,0
52,"Our Telco client in Toronto is in need of a Data Scientist for an initial 6 month contract.

You will work as part of a friendly, cross-disciplinary, and agile team who helps each other tackle problems across all functions.
As a custodian of customer trust, you will employ the best methodologies in development, security, accessibility and design to achieve the highest quality of service for our customers.
Heres how:
Understand business needs and apply data science/machine learning techniques to address real-world problems
Analyze source data (including structured and unstructured data), cleanse data, and support the building of data pipelines
Build models and enable solutions using techniques such as regression, classification, clustering, natural language processing, deep learning, and/or statistical modeling
Help validate, maintain, optimize, and troubleshoot the performance of machine learning models being used in development and production applications
Ensure data privacy is respected
Use visualization techniques to communicate findings and explain models
You're the missing piece of the puzzle
Education in computer science, engineering, mathematics, or a related field
Expertise developing machine learning models in Python and using open source ML libraries such as Scikit-learn, PySpark, Tensorflow, SpaCy, and PyTorch
Ability to communicate technical and complex concepts in a way that is understood by non-technical audiences
Relevant work or research experience delivering substantial data science projects including publications, contributing to packages, deploying applications, building tools and frameworks
Interpersonal and communication skills to enable collaboration with a range of team members with diverse skill sets and backgrounds
The ability to quickly familiarize yourself with new languages, tools, frameworks, and to stay informed on developments in ML techniques and technologies
Dedication to ensuring your work is well documented and version controlled
Experience using Cloud infrastructure like Google Cloud Platform, Amazon Web Services or Microsoft Azure
Experience with agile methodology and team-based software development workflows
Must to have skills:
Candidate needs one of the following:
~5 Years of industry experience as a Data Scientist or similar work
A Masters Degree in Computer Science, Engineering, or Mathematics or a related field with 1-2 years experience as a Data Scientist or similar work
A PHD in the above academics with course work in Machine Learning and applied knowledge during schooling
Experience in Machine Learning libraries such as Python, Scikit-learn, PySpark, Tensorflow, and PyTorch
Proven demonstrated experience applying Machine Learning practices to Real World scenarios (ie building applications)
Nice to have skills:
Great Communication Skills
Boot camp experience (Machine Learning or Data Science)
A development background that theyve transitioned to a Data Scientist role (eg Python development)
Project details: Working on the Data/Analytics team (Machine Learning)

Additional comments: Looking for a candidate with either the industry experience or the educational experience listed above. Not looking for someone who has 10 years of legacy DBA experience who recently transitioned over to a Data Scientist role.
Machine Learning and development/coding experience is very important for this role, will look at a former Python Developer who has bootcamp experience and transitioned over to a Data Scientist role",3.7,emergiTEL Inc.,Toronto,"Richmond Hill, Canada",201 to 500 employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (CAD),"Veritaaq, TEKsystems, Procom",139.0,14,data scientist,na,0,1,0,0,0,0,1,1,1,1,0,0,1,1,0,3505,3
53,"The quantitative research team is looking for an entry/mid level Data Scientist in the field of time series analysis and pattern recognition to help with modelling work related to infrastructure optimization. You will be working with team of data scientists responsible for providing insights into client device management for cost savings and performance management. This is a fantastic opportunity to rapidly learn and advance in a growing company.

REQUIREMENTS
2+ years practical data science or engineering work experience out of school, in quantitative domains.
Strong quantitative background: B.Sc. or M.Sc. preferred.
Familiarity with technical tools for analysis: Python, R, SQL, Spark.
Experience with software design concepts. Previous software engineering background is a plus.
Ability to structure a project from idea to experimentation to prototype to implementation.
WHAT WE EXPECT?
Enthusiastically tackling problems with a love for teaching and celebrating the successes of others.
Ability to synthesize information and consider problems from new perspectives.
Desire to share information with others and contribute to our top notch learning environment.
Self-starter that is focused and driven with amazing follow-through.
Driven to delivery quality solutions.",-1.0,Temet,Ottawa,-1,-1,-1,-1,-1,-1,-1,-1,139.0,-1,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,1278,0
54,"About Fusion Analytics

We believe in a future where analytics takes the lead role in steering organizations, and that Fusion is positioned as the leading consulting firm for this transformation. Founded in 2005, we are now 30 consultants and will be growing to 50 in the next 3 years. To make this happen we are looking for extremely smart people to join us. Our current client list is a who’s who of amazing companies, including Budweiser, Sobey's, Staples, IKEA, Walmart and Canadian Tire. We love what we do and know you will too.

What makes this role unique
You will become a master in data science, statistical modelling & analytics
Exposure to Canada’s largest and most successful companies
Opportunity for aggressive promotion as we build our team
Work with the smartest team of data scientists in the country
Contribution to company success is encouraged from day one
No politics and we work hard for everyone to succeed
Highly supportive work culture (learn more at http://www.fusionanalytics.com/team.html ).
Team builders (e.g. BBQs, board game nights)
Equal opportunity employer
Examples of typical projects
Develop a complex analytical model to help a national home decor retailer optimize their business operation
Build an integrated media mix model for a $20 billion international retailer
Work with a major national retailer to develop a predictive model to measure, monitor and forecast key industry indicators
Requirements
A Masters or undergraduate degree with knowledge in data science (Mathematics, Statistics, Engineering, Finance, Science)
3+ years of professional experience related to data science, modelling and analytics
Strong technical skill in data modelling, machine / deep learning models (R, Python, Power Pivot, Power BI)
Strong sense of curiosity, with advanced critical thinking and analytical skills
Passionate about problem-solving and will rise to any challenge
Track record in doing excellent work in a high pressure and fast paced environment
Compensation
Competitive top-tier data scientist level salary
Health & dental benefits for spouse and dependents
Share options at the management level
Start Date
Flexible start dates through 2019 and 2020
Application Deadline
Ongoing
How to Apply
Apply with a PDF copy of your resume and undergraduate transcript.
Please name all files ((applicant name)) - ((document)) for example John Doe - Transcript.pdf.
Your resume should highlight your education, your overall GPA at each academic level, academic scholarships/awards, analytical experience (labeled as Analytical Experience), and other experience (labeled as Other Experience).
We define analytical experience in its broadest sense (working in a medical lab doing tests, software programming, robotic design, engineering projects, financial modeling, etc.).",4.8,Fusion Analytics,Toronto,"Toronto, Canada",1 to 50 employees,2006,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1,139.0,14,data scientist,senior,0,1,1,0,0,0,0,0,0,0,0,0,0,1,1,2800,0
55,"The Individual Contributor in Business Insights & Analytics (BI&A) is a strategic thought partner to key stakeholders and an integral contributor to Roche's operational planning efforts.

The specific role of Operations Data Analyst requires a mix of Forecasting, Data Analytics and Advanced Data Analytics capabilities. However, all Individual Contributors have the opportunity to blend and extend their expertise on different initiatives to further develop both the breadth and depth of their capabilities.

He/she is responsible for providing strategic operational insights with significant guidance / supervision, leveraging their capabilities in the following areas of expertise:
Forecasting: creating time-series and/or patient-based forecasts; conducting uncertainty analyses
Data Analytics: designing and delivering advanced quantitative data analyses leveraging large/complex datasets
MAIN RESPONSIBILITIES
Work with Team Leads (TLs), Franchise Leads, Study Management & Country Leaders, Study Management Teams, LSPC stakeholders, Lifecycle Teams to understand business needs and priorities, as well as immediate scope of work
Create and manage tools with up-to-date industry information to build accurate short-and long-term forecasts
Work with other team members to pull in insights from primary and secondary data, to continuously improve forecast methods and accuracy
Communicate the effects that trial design elements, country and site selection, competitor activities and new engagement tactics will have on clinical trial recruitment & retention forecasts
Provide technical/analytical expertise to team through secondary data analytics
Apply analytical and statistical methods to answer a variety of business questions using multiple data sources and technical tools
Monitor and assess the effectiveness of enrollment and engagement efforts, projects, and practices and identify opportunities to optimize value of investments
Support the identification of appropriate sites and countries for trial placement
Increase the sophistication and application of advanced analytics methods (including predictive modeling, machine learning, and scalable prototypes) to measure study performance and guide portfolio-level decisions efficiently and at the speed of business
Act as subject matter expert for applicable advanced analytical methodologies, programs and projects
Collaborate within cross-functional teams to develop solutions, gain alignment and deliver impactful business insights; engage necessary stakeholders to enable better decision-making
Openly share perspective and insights to elevate team thinking and drive a balanced, holistic point of view; effectively weigh and communicate trade-off considerations
Take an enterprise and One PDG mindset, linking individual responsibilities with broader organization; focus on outcomes that provide most business value
Demonstrate self-accountability and integrity
Demonstrate strategic agility and an ability to engage stakeholders to understand and diagnose business problems and recommend appropriate courses of action
Look for opportunities for continuous improvement; engage managers and peer group regularly for coaching, assistance, and advocacy
Stay current with and adopt emergent relevant methodologies, tools and applications to ensure fit-for-purpose and impactful approaches.
Act as a thought partner and advisor to all relevant teams and stakeholders; look for and establish opportunities for peer mentorship
Actively participate in cross functional communities, networks and/or knowledge-sharing bodies that enable broader and more effective use of insights and/or analytics that drive and support decisions
Acquire, aggregate and/or curate data and information
WHO YOU ARE

We are looking for people who are nimble, curious, able to effectively collaborate and lend expertise to multi-functional teams and adapt quickly to competing priorities within their Disease Area. We are also looking for people who are committed to continuing to make Roche a great place to work, by seeking opportunities to develop their own and others’ expertise through ongoing mentorship and coaching.
""Self-starter""; strong sense of responsibility with demonstrable comfort in an entrepreneurial environment
Able to work effectively in a fluid, cross-functional, global matrixed environment and stand out as a successful collaborator
Strong interpersonal skills and a consultative mindset, with the ability to develop strong partnerships
Good problem-solving ability, breaking down complex problems into distinct parts, managing uncertainty, understanding, anticipating interdependencies
Able to proactively “connect the dots” by asking thought-provoking questions
Objective when presenting insights and guiding decision-making; demonstrate good presentation skills by pairing sound analytics with storytelling
Motivated to continuously improve performance; outcomes-focused and driven to achieve objectives
Able to lean in and manage through change
PREFERRED QUALIFICATIONS
Bachelor’s Degree (Business, Economics, Statistics, Mathematics, or Physical Sciences or related field is a plus); MBA or Graduate-level Degree is preferred
2+ years of work experience with Bachelors; 1+ year of work experience with Masters; 0+ years of work experience with PhD/JD, preferably within pharmaceutical or biotech industry (commercial or clinical) and/or management consulting
Deep expertise in at least one of the following areas: Patient Insights, Investigator Insights, Forecasting, Competitive Intelligence, Data Analytics, Advanced Data Analytics, Resourcing, Information Visualization and/or Data Science
Experience with various forecasting methods and techniques preferred
Understands the advantages and limits of different analytical approaches
Considerable experience applying exploratory & confirmatory data analysis techniques that inform business decisions
Awareness of scripting, statistical & programming languages and analytical tools a plus (i.e. Python, Metlab, R, SAS, Google/Adobe analytics, SQL)
Autonomous or semi-autonomous examination of data or content
Demonstrated use of sophisticated techniques, tools & languages typically beyond those of traditional data analysis to discover deeper insights, make predictions, or generate recommendations
Experience acting as a strategic thought partner to teams; Entrepreneurial mindset, to transform the way we use data and analytics to enable decisions and hasten our delivery of medicines for our patients
Track record of effectively working in a matrix environment with international team members coming from scientific, business and operational backgrounds, using influence without authority
Expertise in standard analysis and presentation software (Excel, PowerPoint)
Ability to merge together data sets from disparate sources and report findings in a variety of formats and mediums
Persuasive written and verbal communication skills, easily communicating complex ideas.
Strong attention to detail
Experience managing outside vendors preferred
Good luck with your application.

Roche is an equal opportunity employer.

Business Development, Business Development > Strategic Business Development",4.1,Roche,Mississauga,"Basel, Switzerland",10000+ employees,1896,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (CAD),"Novartis, AstraZeneca, Siemens Healthineers",117.0,124,data analyst,na,0,1,0,0,0,1,0,0,0,0,0,0,1,0,1,7213,3
56,"ABOUT HOPPER

At Hopper, were on a mission to make booking travel faster, easier, and more transparent. We are leveraging the power that comes from combining massive amounts of data and machine learning to build the worlds fastest-growing travel app -- one that enables our customers to save money and travel more. With over $235M CAD in funding from leading investors in both Canada and the US, Hopper is primed to continue its path toward becoming the go-to way to book travel as the world continues its shift to mobile.

Recognized as the fastest-growing travel app by Forbes and one of the worlds most innovative companies by Fast Company two years in a row, Hopper has been downloaded over 40 million times and has helped travelers plan over 100 million trips and counting. The app has received high praise in the form of mobile accolades such as the Webby Award for Best Travel App of 2019, the Google Play Award for Standout Startup of 2016 and Apples App Store Best of 2015.

Take off with us!

THE ROLE

Hopper is looking for a data-savvy individual to join our team as a Data Scientist and lead data-centric product development and complex business intelligence projects within our core air travel business unit. Every day you would draw powerful insights from our real-time feed of billions of flight search results and archives of several trillion data points. To succeed at Hopper you need the talent, passion, and experience to thrive in a highly performing company.
IN THIS ROLE YOU WILL:
Frame and conduct complex exploratory analyses needed to deepen our understanding of Hopper users.
Partner with product, business and strategy teams to leverage this user understanding for product improvements and other initiatives
Use machine learning and big data tools on tremendously large and complex data sets to enhance our data-driven, personalized travel advice
Conduct research into various aspects of our business and employ statistical and modeling techniques when appropriate to make recommendations to non-technical stakeholders
Create advanced dashboards for product experiment tracking and business unit performance analysis using Amplitude and Tableau
Find effective ways to simplify and communicate analyses to a non-technical audience.
A PERFECT CANDIDATE HAS:

A degree in Math, Statistics, Computer Science, Engineering or other quantitative disciplines
Extremely strong analytical and problem-solving skills
Proven ability to communicate complex technical work to a non-technical audience
A strong passion for and extensive experience in conducting empirical research and answering hard questions with data
Experience with a data visualization tool (Tableau preferred) and project analysis tool such as Amplitude
Experience with relational databases and SQL, especially Hive
Experience working with extremely large data sets
Experience in Pandas, R, SAS or other tools appropriate for large scale data preparation and analysis
Experience with data mining, machine learning, statistical modeling tools and underlying algorithms
Proficiency with Unix/Linux environments
BENEFITS

• Well-funded and proven startup with large ambitions, competitive salary and stock options
• Dynamic and entrepreneurial team where pushing limits is everyday business
• 100% employer paid medical, dental, vision, disability and life insurance plans
• Access to a 401k (US) or Retirement Savings Plan (Canada)",3.6,Hopper,Montreal,"Montreal, Canada",501 to 1000 employees,2007,Company - Private,Travel Agencies,Travel & Tourism,Unknown / Non-Applicable,-1,117.0,13,data scientist,senior,0,0,0,1,0,1,0,0,0,0,0,0,1,0,1,3414,0
57,"Data Scientist

Local Logic is hiring Data Scientist to join our Development team. As a Data scientist you will be responsible for generating and communicating insights about cities, our users and the real estate market. Our products are used by millions of people on the top real-estate sites across the whole of North America, and by some of the biggest Real Estate investors in the world. As a member of the development team, you will work alongside a group of talented and motivated UI and UX designers, full-stack developers, engineers, and GIS experts to build the most valued tools and change how cities are built!

Local Logic develops vertical AI software to optimize real estate investment for consumers and professionals. We leverage alternative data to create new insights that expose market trends for real estate assets with property level precision. We understand the world, and its cities to better forecast the future and make the real estate market more transparent and efficient.

We believe in diversity of thought and experience and strongly encourage candidates of all backgrounds and identities to apply. Every new hire brings their own perspectives and unique qualities to the team, and Local Logic is committed to fostering an inclusive and supportive environment where everyone is empowered to do their best work.

Join our team in our mission to change the way cities are built and improve the lives of citizens!

About the Job

This role falls under our new Insights team, led by the Head of Insights, and is part of the Development department led by CPO and co-founder Gabriel Damant-Sirois. The Dev team at Local Logic are the urban wizards, the data crunchers, and the product gurus who bring Local Logic products to life. They design, code, research, and are responsible for ensuring that our products are exactly as we envision them to best serve our clients. The Dev team covers the following disciplines at Local Logic:
Data Science
UI/UX Design
Product Management
Front End/Back End Development
Heres some of the day to day work youll be doing as a Data Scientist at Local Logic:
Work with Product Managers, UI/UX and engineers to find the best way to bring our insights into our product and solve the problems experienced by our users
Explore our datasets to uncover hidden patterns
Find the best way to answer questions we have
Communicate new needs or challenges regarding our infrastructure to the engineering team
Communicate to internal stakeholders insights about value we create, our understanding of cities, and KPIs about our products
About You

Were looking for someone with 2-5 years of experience using programming languages (R or Python) in a data-driven startup or company. A keen interest or experience in Machine Learning or other modeling techniques is essential. You should be skilled at communicating data to non-technical audiences, and have an aptitude for asking the right questions with an open mind for answers.

A background in urban planning or experience working with geospatial data is a great asset, as is experience with Natural Language Processing. We certainly wouldnt turn down someone with experience in Business Intelligence, either!

Local Logic is passionate about growth and we dont expect you to know it all right out of the gate. We care that you have mastered the basics and have a keen desire to grow professionally, learn new things, and strive to do your best work always.

*As a result of the COVID-19 pandemic, our team is currently working 100% remotely and will continue to do so until such time as the government regulations indicate it is safe for us to return to any kind of in-person workspace.

In 2020, Local Logic is transitioning to a flexwork model. This means we will be a remote-centric company with access to a physical community hub in our home city of Montreal for in-person interactions. This innovative work structure will offer employees the option to work remotely, while maintaining the flexibility and space that Local Logic has always given employees to be human first, while maintaining the valuable in-person ties to our team and to the Montreal community that are at the core of Local Logic.

The Local Logic team are a group of driven, growth minded individuals - we value people who take initiative, try new things, and live to learn. We like to debate ideas, from the tough decisions to the is it a sandwich? debate that seems to grip us at least once a quarter. We are here to support and inspire one another, and to continue to push our collective work to the next level.

Pay and Benefits

This is a full time, salaried position with full benefits.

Local Logic is proud to offer a comprehensive benefits package to its employees. We offer all full time employees a great health insurance plan, which includes $1500 annual coverage for paramedical services like massage, acupuncture, nutrition, and naturopathy. We care about our employees health, so we cover 100% of premiums for our employees. Additionally, Local Logic covers the cost of membership to Dialogue, a telemedicine service for our employees and their family members.

We also provide employees with a $250 discretionary health and wellness credit. In that past, employees have used this credit to purchase everything from noise cancelling headphones to fitness watches or yoga memberships!

To support our company value of being Growth Oriented, employees are given a $500 annual professional development credit, as well as 8 hours of professional development time per month. Take the time to develop a new skill, read up on the industry, attend a workshop or conference, or take a short course!

How to Apply

Please apply through our website at locallogic.co/careers

We are accepting applications on a rolling basis until the role is filled. After that, well take about two weeks to process applications and get back to you about next steps. We begin our hiring process with a screening call to chat more about the role, your background and experience, and to talk about what its like to work at Local Logic. After that, youll meet a few more team members, complete a practical interview, and eventually meet our executive team!

Please send us a resume tailored to this position. Here at Local Logic, we want to hear about the person behind the resume, so we ask that you answer an application question designed to give us a snapshot of the superstar behind the resume! For us, these snapshot questions are a chance to hear directly from you why you think youd be the best fit for this role. Dont just list off your CV, this is your chance to tell us why that short stint as a performer would make you the perfect salesperson, or how your experience working in a totally different industry would allow you to bring a fresh new perspective to our development team. Your snapshot is a chance to tell us a story - YOUR story - and to convince us that wed be crazy not to talk to you. We accept answers in whatever format you think best represents you - video, written format, photo collage, you name it! Please upload your snapshot submission along with your application.

We look forward to meeting you and hearing how you plan to contribute to Local Logic!

Powered by JazzHR",4.8,Local Logic,Montreal,"Montreal, Canada",1 to 50 employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1,117.0,6,data scientist,na,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,7258,0
58,"Fantuan was founded in Vancouver, Canada in 2014. It is a one-stop life-services platform providing food delivery, reviews (Fantuan Reviews), an errand service (Fantuan Rush), e-commerce and marketing services. Fantuan is one of the top Asian life-services platforms in North America, currently covering Vancouver, Toronto, Edmonton, Calgary, Montreal, Seattle, Los Angeles, New York and other metropolitan areas in Canada and the US.

Fantuan Delivery provides consumers with delivery and self-pickup services of various products such as food, beverages, grocery and supermarket/convenience store items. We provide our partner businesses with distribution resources while helping them improve their profit margins, using our intelligent data analysis. In just 5 years, Fantuan Delivery has accumulated a large number of high-quality businesses, nearly 600,000 users, and has become the largest Asian food delivery platform in North America. In 2019, the company has also officially entered the US market and is continuing to develop rapidly.

Responsibilities:
Interpret, evaluate, and interrelate research data and develop integrated business analyses and projections for incorporation into strategic decision-making.
User Behavioral Analytics. Research and analyze user flows, funnels, activation, retention, and qualitative feedback to derive insights and themes and present opportunities to the Product team
Build data analysis products with user documentation, such as self-serve and on-demand reports, dashboards, and other BI tools
Work closely with business units and Product Managers to understand their analytical needs, and enable stakeholders across the company to use data efficiently and effectively
Requirements:
Bachelor’s degree related to Computer Science, Statistics, Applied Mathematics
Have 2+ years of working experience in a data analysis or similar role
Experience with programming languages such as Python, Java, SQL, etc…
Experience with various BI tools, e.g. Power BI
Strong analytical and problem solving skills
Excellent communication skills, ability to clearly explain technical terms to non-technical audience
Java/JavaScript is an asset
Fluent in Mandarin
饭团是一家北美互联网生活服务公司,主要业务包括饭团外卖、饭团点评、饭团跑腿,结合中式优质服务与北美先进大数据技术,以互联网思维推动生活服务行业变革。 目前,饭团已覆盖温哥华、多伦多、卡尔加里、埃德蒙顿,蒙特利尔,西雅图,洛杉矶,纽约等加拿大及美国主要城市,为海外华人乃至所有海外消费者提供更加便捷、高效、智能的生活服务。

饭团外卖是饭团旗下的外卖送餐平台,为消费者提供餐饮美食、水果生鲜、超市便利等品类的即时配送服务,包括自提和配送两种模式,同时通过智能数据分析帮助合作餐饮商家拓展盈利模式;已积累众多优质商家,拥有超过60万用户,是北美最大的亚洲美食送餐平台。2019年,饭团正式进军美国,上线后发展迅速。

职位描述
业务数据监控及分析:通过数据监控,分析各项影响产品提升与增长的因素,给出建议或产品优化方案,驱动业务快速迭代发展;
平台用户行为数据分析:通过规范化的用户埋点事件,收集并处理用户行为数据,对用户行为挖掘及活跃用户分析,搭建指标体系,以及增长分析模型,并洞悉平台产品的问题,提出改进意见;
与产品/运营/研发等配合,推进优化方案落地执行,带来业务的实际提升增长。

职位要求
本科及以上学历,计算机、数据科学相关专业;
2年+数据分析工作经验;
熟练掌握Python、Java、SQL等;
了解常用的统计和分析方法,掌握 Tableau/Power BI等BI可视化工具;
有相关行业数据分析经验、数据建模分析经验者优先;
掌握Java, JavaScript优先
能快速理解业务,发掘业务细节和数据之间的联系;
沟通交流能力强,工作严谨。

Job Types: Full-time, Permanent

Schedule:
8 Hour Shift
Day shift
Monday to Friday
Experience:
data analysis: 2 years (Required)
Education:
Bachelor's Degree (Required)
Language:
Mandarin (Required)",-1.0,Just Order Enterprises Corp. (,Burnaby,-1,-1,-1,-1,-1,-1,-1,-1,117.0,-1,data scientist,na,0,1,1,1,0,1,0,0,0,0,0,0,0,0,1,3071,0
59,"At Kinaxis, who we are is grounded in our common belief that people matter. Each one of us plays an important part in accomplishing our work, building our culture and making a global impact.

Every day, we're empowered to work together to help our customers make fast, confident planning decisions. This is how we create a better planet for each other, for our customers and for generations to come. Our cloud-based platform RapidResponse ensures that the products we need everything from medicine and cars, to day-to-day items like toothpaste make it to market and into our hands when we need them with minimal ecological footprint.

We make the world better, and you can too.

Senior Data Scientist


Job location: our office in Toronto or Ottawa, Canada

Who We Are Looking For


You have a strong background in math and technology typically (but not exclusively) found in graduate research programs in Computer Science, Engineering or Mathematics. You have a proven track record solving real-world business problems and a practical mindset using the more appropriate technique for the problem, whether that be a simple linear regression, lighGBM or a LSTM. You can comfortably explain the difference between a random forest and gradient boosted trees.

All aspects of building data science products are familiar to you: wrangling with messy or missing data, feature engineering, prototyping statistical/machine learning models, and coding up an appropriate solution that's fit for production. You are always willing to get your hands dirty analyzing the minutiae in the data.

You're fluent in Python, have run more SQL queries than you would like to admit, and have hands-on experience with big data technologies such as Spark and Hadoop.

As an excellent communicator, you'll work with other like-minded individuals to come up with creative solutions to our retail and CPG data science problems interfacing with all aspects of the company from external stakeholders to product to data science to engineering. Your primary focus is on providing value to our clients, which requires asking the right questions, distilling the problem and coming up with creative solutions.

Requirements


· Masters/PhD degree or equivalent in Computer Science, Engineering, Mathematics or related field

· Strong familiarity with various machine learning & statistical techniques

· Self-motivated, strong sense of ownership, and adaptable in a fast paced environment

· Ability to initiate and drive projects to completion with minimal guidance

· Strong written and verbal communication skills to describe results of analyses in a clear and effective manner

· Proficiency in Python

· Experience working with relational data via SQL

· Ability to work in *nix environments

Nice to have


· Experience with big data technologies such as PySpark and Hadoop

· Software development experience

· Experience working with major cloud technologies (AWS, Azure, and GCP)

· Retail and CPG business background

What we have to offer
Challenging Work - We love solving highly complex problems. And as the global leaders in our industry, we never stop innovatingour work is never ""done. That's because across our teams and in all roles, every employee is empowered to bring their best ideas forward and to jump in and solve the problems they're passionate about.
Great People - We take our work seriously, but we don't take ourselves too seriously! It's in our DNA to celebrate, laugh, and have fun. We are stronger, together, when we are open, honest, and above all, real. Every person is valued here and plays an important role in our shared success.
Global Impact - As a global team spanning continents, boundaries, and cultures, every day we are inspired by the impact our work has on our colleagues, our customers, our communities, and the world at large.
For more information, visit the Kinaxis web site at www.kinaxis.com or the company's blog at http://blog.kinaxis.com/.

Kinaxis invites candidates to apply to its welcoming community. Accommodations are available upon request for applications in all aspects of the recruitment process. If you require accommodation, please contact Human Resources at accommodation@kinaxis.com",4.7,Kinaxis,Toronto,"Kanata, Canada",501 to 1000 employees,1984,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (CAD),-1,117.0,36,data scientist,senior,0,1,0,0,0,1,1,0,1,0,0,0,1,0,0,4218,0
60,"Do you have risk management experience and a good knowledge of Retail Credit?
Have you acquired excellent complex data analysis skills, including the use of modelling approaches and various AI techniques?
Are you a born leader who is curious and thorough and has outstanding communication skills?
Working as a Data Scientist (Senior Analyst), Portfolio Management, means you are a recognized expert in identifying, anticipating, performing complex analyses and disclosing risks related to Retail Credit portfolios. You will develop, optimize and upgrade the various risk analysis tools and processes in place. This includes leading special projects, representing the sector in various forums and advising management on their strategic orientations.

This position reports to the Manager, Portfolio Management. Your main responsibilities:
Take part in the analysis and disclosure of Retail Credit portfolio risk and quality by developing risk indicators
Perform complex analyses using various modelling approaches such as AI techniques to identify concentrations and sub-performance that could represent losses for the Bank
Take part in and oversee special projects that impact delinquency, losses, transactions, product profitability, automation of credit decisioning and risk assessment
Make recommendations to increase the quality of information and the efficiency of information production and risk analyses
Play a leadership role and act as the quantitative expert for colleagues and management by rapidly identifying issues and challenges and defending the sectors strategic orientations
Respond to various ad hoc requests associated with risk management by providing relevant and high quality information
Take part in all of the sectors other portfolio management activities as needed
Bachelors degree in a related field (economics, finance, statistics, mathematics) and 7 years of relevant experience OR a masters degree in a related field and 5 years of relevant experience OR university certificate/undergraduate diploma from the National Bank University Program and 9 years of relevant experience
Experience in risk management
Experience with modelling, including the use of AI techniques
Experience with manipulation of large quantities of data
Skilled at carrying out complex portfolio risk analyses
Relevant knowledge of Retail Credit and data warehouses
Knowledge of SAS software and/or SQL, R and/or Python programming languages
Very good knowledge of the Microsoft Office suite (Word, Excel and PowerPoint)
Self-starter with leadership skills and initiative.
Excellent oral and written communication skills
Good analytical skills, intellectual curiosity, thoroughness and ability to summarize
Bilingualism, spoken and written (English/French), essential
We strive to be an inclusive organization where all employees are valued. National Bank stands out for its many initiatives to promote inclusion, making it a Canada-wide leader in diversity. See how we do it: https://jobs.nbc.ca/diversity",4.1,National Bank of Canada,Montreal,"Montreal, Canada",10000+ employees,1859,Company - Public,Banks & Building Societies,Finance,$10+ billion (CAD),-1,117.0,161,data scientist,na,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,3008,0
61,"At Veeva, we build enterprise cloud technology that powers the biggest names in the pharmaceutical, biotech, consumer goods, chemical & cosmetics industries. Our customers make vaccines, life-saving medicines, and life-enhancing products that make a difference in everyday lives. Our technology has transformed these industries; enabling them to get critical products and services to market faster. Our core values, Do the Right Thing, Customer Success, Employee Success, and Speed, guide us as we make our customers more efficient and effective in everything they do.

The Role

As a Data Scientist for the Andi team, you will work with Andi Product Management, Engineering, and fellow Data Scientists to support product development.

Andi is a solution to coordinate data across life science field teams and through different channels to support intelligent customer engagement. Andi’s Next Best Action capabilities will enable reps to make decisions in the field through the generation of suggestions and insights based on dynamic programming engines and AI.

Your role will be to generate and own the mathematical and behavioral models that will help drive the generation of impactful insights and suggestions. You will assist Engineering in “productizing” the code to ensure it can be scalable and repeatable. Our ideal candidate is multi-talented, with the capabilities to develop statistical, machine learning and optimization models to create scalable solutions that can be embedded within Andi.

This is a great opportunity for someone who is excited about using their deep Data Science expertise to help shape the product development from the early stages of Andi and can envision how Andi will enable reps to make smarter decisions in the field.
What You’ll Do
Develop advanced algorithms that solve problems of large dimensionality in a computationally efficient and statistically effective manner
Design, develop and assess highly innovative models for adaptive predictive learning, suggestion ranking, anomaly detection, and more
Collaborate with Engineering to help implement machine learning algorithms and “productize"" data science capabilities
Build and run analysis of models and algorithms in order to assess performance and identify the best algorithms to integrate into Andi
Ensure models and algorithms support our customers and help them drive towards more intelligent and effective engagement with their customers
Execute statistical and data mining techniques (e.g. hypothesis testing, machine learning and retrieval processes) on large data sets to identify trends and figures
Work closely with the data warehouse product team to ensure architecture is effectively developed to support algorithms embedded in Andi
Requirements
M.S. or Ph.D. in Machine Learning, Applied Statistics, Mathematics, Computer Science, or other quantitative disciplines. Ph.D. with at least 2 years of relevant industry experience, M.S. with 3 years of relevant industry experience.
Advanced in-depth specialization and experience in data analysis techniques such as: classification, pattern recognition, clustering, feature analysis, deep learning (NLP), fuzzy matching, sentiment analysis, A/B testing, active/adaptive learning
Expertise in using R or Python to manipulate large data sets and develop statistical models, with the ability to accurately determine cause and effect relationships
Good SQL skills
Intellectual curiosity, along with excellent problem-solving and quantitative skills, including the ability to disaggregate issues, identify root causes and recommend solutions, even in situations with non-standard problems
Excellent oral and written communication skills with the ability to effectively explain complex problems and advocate technical solutions to Engineering
Nice to Have
Experience with commercial aspects of the Life Sciences industry
Experience with Veeva CRM data sets or other commercial Life Sciences data
Experience working in an agile software development environment
Experience working with Software as a Service and/or enterprise products
Experience with AWS
Hands on experience building models with deep learning frameworks (Tensorflow or similar)
Perks & Benefits

· Conveniently located in downtown Toronto
· Snacks, beverages, and weekly lunches from local restaurants
· Team events and rec league sports teams
· Allocations for continuous learning & development
· Health & wellness programs
· Weekly yoga classes
· Ping pong and other games

Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.

Veeva Systems is an equal opportunity employer. Accordingly, we are committed to fair and accessible employment practices. Veeva Systems welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.",3.5,Veeva Systems,Toronto,"Pleasanton, CA",1001 to 5000 employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (CAD),-1,117.0,13,data scientist,na,1,1,0,0,0,1,0,0,0,0,0,0,1,1,1,4924,0
62,"Req Id: 261612

At Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content – we’re revolutionizing how Canadians communicate.

If you’re ready to bring game-changing ideas to life and join a community that values bold ideas, professional growth and employee wellness, we want you on the Bell team.

Bell’s forward-thinking Customer Operations team is creating the ultimate service experience for our residential, wireless and small business consumers. We lead strategic development and execution of day-to-day operations, develop tools and processes to drive service enhancements, manage customer loyalty and retention, and leverage big data and artificial intelligence to create intellectual property.

Name and description of the hiring department:
Under Small Business Markets, the Business Strategy team works on initiatives to drive frontline performance.

Job Duties / Accountabilities:
Evaluate requests from the team, create reports and efficiently analyze required data
Perform data analysis and present the findings in a PowerPoint format
Project expected lift from sales and loyalty initiatives, and monitor and report on their progress
Analyze changes in key performance indicators and identify the potential causes as well as opportunities for improvement
Prepare and control the monthly communication of incentive programs to the Frontline teams and provide progress updates on communication and results
Maintain a calendar of initiatives and liaise with the Marketing team on their initiatives
Manage administration of compensation and recognition programs
Validate and control payouts from the compensation and recognition programs
Essential Qualifications / Competencies:
Strong analytical and communication skills
English, fluent in the language with no significant limitation
MS Excel intermediate level (pivot tables and VLookup)
MS Power Point intermediate level
Able to work autonomously and demonstrate initiative
Ability to work under tight timeframes and manage multiple priorities
Preferred Qualifications / Competencies:
French, working ability to carry out normal business in the language
2+ years’ experience in data analysis
SQL - intermediate level (Oracle, MS SQL)
Experience in a call center environment
Working Condition:
Work Hours: 37, 5 hours per week
Availability: Monday to Friday, between 8h00 am and 6h00pm
Compressed work week not available
Job location address: 1 Alexandre-Graham-Bell, Verdun (QC) and/or 5099 Creekbank Rd, Mississauga (ON)

Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.

Additional Information:

Position Type: Union
Job Status: Regular - Full Time
Job Location: Canada : Ontario : Mississauga || Canada : Quebec : Verdun
Application Deadline: 08/10/2020

Please apply directly online to be considered for this role. Applications through email will not be accepted.

At Bell, we don’t just accept difference - we celebrate it. We’re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.

Accommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.

Created: Canada, QC, Verdun

Bell, one of Canada's Top 100 Employers.",3.6,Bell Canada,Verdun,"Montreal, Canada",10000+ employees,1880,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (CAD),"Rogers Communications, TELUS, IBM",117.0,140,data analyst,na,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,3710,3
63,"Morningstar Research Inc. is a leading provider of independent investment research. Our mission is to create great products that help investors reach their financial goals. We offer an extensive line of Internet, software, and print-based products for individual investors, financial advisors, and institutional clients around the world.

We are currently seeking an Equity Data Analyst (entry level) to join the CPMS product line of our business. The office is located in downtown Toronto, within walking distance of Union Station (subway, GO trains). We provide flexible working hours.

Working with our Equity Data team of Analysts, the successful candidate will maintain financial databases for equities listed on Canadian and American stock exchanges. The successful candidate will possess analytical skills, solid mathematical and database knowledge and have the ability to work in a team environment.

Responsibilities
Reviewing, analyzing and inputting of press releases and financial reports from public companies
Accumulating, monitoring and reviewing estimates supplied by the brokerage community
Increasing the CPMS equity universe coverage
Participating in projects designed to improve the efficiency of internal processes or enhance the CPMS product line
Requirements
Bachelor’s degree with intermediate level financial accounting courses which focused on consolidations and future income taxes
Comprehension of the fundamentals of databases and data flows
Knowledge of SQL is an asset
Ability to analyze issues and determine possible courses of action either in a team or independently
Canadian Securities Course is recommended
To apply, please submit a copy of your resume and cover letter. If you have graduated within the last 3 years, please include a copy of your unofficial transcript.

100_MstarResCanad Morningstar Research, Inc. (Canada) Legal Entity",4.1,Morningstar,Toronto,"Chicago, IL",5001 to 10000 employees,1984,Company - Public,Financial Analytics & Research,Finance,$2 to $5 billion (CAD),"Thomson Reuters, FactSet, Bloomberg L.P.",117.0,36,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1874,3
64,"What is the opportunity?

As Data Analyst, you are a key technical role that supports the National Operations’ Data & Analytics team with enhancing data management, systems and process improvement initiatives. To ensure success in this role, you require critical thinking, problem solving and great attention to detail. RBC Corporate Client Group (CCG) National Operations supports CCG planning, directing, and overseeing their operational policies, rules, initiatives, and goals. The CCG team is responsible for meeting annually established targets for revenues and returns, providing advice to our partners along with broader RBC relationship goals, while the National Operations team helps & supports the group execute long-term and short-term plans.

What will you do?
Commit to the delivery of robust database and reporting systems for the CCG team and senior management
Develop new processes and tools to streamline existing data provisioning processes and reports using VBA, SQL and other programming languages
Assist the CCG Senior Manager, Data & Analytics in data management, project management and ensuring data provisioning is timely, accurate and regulatory compliant
Analyze data for useful insights and utilize Excel and Tableau to create data visualizations
Perform data mining, cleanup and proactively monitor data quality while also supporting database administration activities and troubleshoot user inquiries and data escalations by acting as a liaison between CCG and enterprise IT teams
Document and diagram key system and data management processes
Coordinate project delivery by tracking project progress and facilitate requirement gathering sessions
Fulfill Ad-Hoc data requests and support the creation of periodic reports
Must have:
Undergraduate or equivalent degree in Computer Science, Computer Engineering or Management Information Systems with knowledge and experience in database and data management principals
2- 3 years of professional work experience in a data analytics, business intelligence or data warehousing
Strong verbal and written communication skills
Advanced level of MS Office with a focus on Excel and Access, and intermediate knowledge and practical experience with VBA and SQL
Ability to solve problems through creativity and critical thinking, strong analytical skills and attention to detail
Proven capabilities in effective management of tasks and delivering high quality work while performing well under pressure, meeting time sensitive deadlines, and prioritizing work
Nice to have:
Database Development Experience
Database Administration Experience
Tableau
Python, C programming, Java
What’s in it for you?

We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.
Learn and develop new technical skills in a team that supports creativity and thinking outside of the box
Improve organizational skills including business analysis, project coordination and effective communication
Exposure to fast paced high performing teams and senior management
Work in a dynamic and collaborative organization that supports personal and professional growth
Opportunities to learn and grow through challenging work
Being part of a great organization that values inclusion and diversity
Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers.

JOB SUMMARY
City: Vancouver
Address: 666 Burrard Street
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: Permanent
Career Level: Experienced Hire/Professional
Pay Type: Salary + Variable Bonus
Required Travel (%): 0-25
Exempt/Non-Exempt: N/A
People Manager: No
Application Deadline: 08/19/2020
Platform: Personal & Commercial Banking
Req ID: 262463
Ad Code(s):",4.0,RBC,Vancouver,"Toronto, Canada",10000+ employees,1869,Company - Public,Banks & Building Societies,Finance,$10+ billion (CAD),"Barclays, Morgan Stanley, TD",117.0,151,data analyst,na,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,4224,3
65,"Machine Learning Engineer

Granify is a rapidly evolving technology company at the intersection of e-commerce, machine intelligence and psychology. Our reach is growing exponentially; in the last year we processed more terabytes of data than in the previous five years combined!

We are building an industry-leading personalization and optimization platform for online retailers wanting to create a better online shopping experience for their customers.

We’re searching for a Machine Learning Engineer to join our platform team. While focusing on machine learning development, with our small, agile team you'll get a chance to design, build, and improve each part of our tech stack, while providing guidance and technical direction.

This position is full-time in Edmonton, AB, Canada. We welcome local applicants, as well as any Canadian citizens, permanent residents, or eligible international applicants willing to relocate.

What You'll Work On

As a Machine Learning Engineer with Granify you’ll:
Research, design and prototype intelligent systems with the aim of enhancing online shopper experience.
Productionize research prototypes into fully-fledged AI software that are ready to be delivered to our clients.
Participate in active maintenance and code reviews in a large codebase, suggesting and implementing changes as appropriate.
Keep up-to-date with the latest papers in artificial intelligence and machine learning to propose solutions for real problems in e-commerce.
Build infrastructure to support the evolution of our shopper interaction toolset.
Mentor other engineers, participate in code reviews, and share knowledge.
Troubleshoot, test, and debug to your heart’s content.
You Are…
Passionate about finding elegant solutions to complex technical problems.
Committed to mastery and craftsmanship in your work.
Team-focused and people-centric, able to give feedback as well as receive it.
Curious, constantly looking for better ways to build things and excited to learn about emerging technologies.
Positive and personable - we're all tackling these challenges together!
Able to communicate with clarity and brevity.
Fundamentals:
BSc (MSc or PhD preferred) in Computer Science, Machine Learning, Artificial Intelligence, Statistics, Mathematics, Engineering, Physics, or a related discipline, with (at minimum) graduate-level courses in machine learning, or equivalent practical experience.
Strong research experience in machine learning, preferably in one or more of the following (in no particular order): reinforcement learning, natural language processing, recommendation and/or ranking systems, deep generative models, representation learning, AI interpretability, domain generalization, meta-learning, computer vision, deep neural network architectures.
Proficient in deep learning frameworks like Tensorflow, PyTorch, etc. and scientific computing packages like NumPy. Able to implement an algorithm as described in an academic paper using these frameworks in quality code.
Strong computer science background, with experience in object-oriented programming, systems design, data structures and algorithms. Proficient in Python and/or C/C++, with an interest in learning new languages.
Familiarity with source control (Git) and Unix systems, including shell scripting.
Good intuition for applying AI theory to make business-oriented products with minimal guidance.
Communicate to introduce honesty and clarity (avoiding buzzwords and jargon) to experts in multiple disciplines. Demonstrate a mature understanding of the current possibilities and limitations of AI research.
Bonus points if you have expertise in:
Evidence of academic publications in machine learning and/or computer science research.
Experience in online advertising and/or marketing analytics, behavioural targeting and/or web analytics.
Experience working in an Agile software development environment.
Experience in using cloud solutions, preferably AWS.
Experience in distributed and/or parallel programming.
An active GitHub repository.
Working at Granify:

You’ll work closely with an incredible group of the smartest, most interesting, genuinely good people around. You’ll work hard, learn quickly, and have plenty of excitement. You’ll also get a first hand view into the rapidly evolving, exciting intersection of e-commerce, machine intelligence and psychology.

With our continued growth as a company, you’ll find limitless opportunities for growth, development, and career progression.

Did you know? Granify is backed by early investors in Facebook, Uber, Twitter, Airbnb, Paypal, Pinterest, Palantir and Yelp. Wouldn’t it have been great to get in at one of those companies as they were taking off...",4.2,Granify,Edmonton,"Edmonton, Canada",1 to 50 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1,117.0,10,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,4707,0
66,"Who We Are

Tonal – the world’s most intelligent fitness system – enables you to be your strongest by providing an effective fitness program tailored to you, your goals, and your schedule. Combining cutting-edge, all-in-one equipment and personalized video guidance, it’s like having a personal trainer, on demand, in the convenience of your home.

At Tonal, we are applying our collective knowledge and creativity to reimagine fitness. We know firsthand that too many hurdles stand between each of us and our fitness goals. Drawing on decades of research and a diverse team of experts, we have created the most advanced strength training system available that makes working out more efficient, effective, and engaging.

We're passionate about building products that transform people's lives.

What You Will Do

Provide expert input on architecture of Tonal's data collection, analytics, infrastructure, and learning systems
Architect and build our AI and machine learning systems
Identify innovative opportunities for data-driven features
Improve real-time rep and set detection from time-series data
Develop algorithm to recommended weights to users over time
Use accelerometers and gyroscopes to detect users' weightlifting form
Analyze user behavior and engagement to inform feature roadmap and marketing
Implement algorithms in conjunction with embedded, front-end, and back-end teams

Who You Are

Advanced degree in mathematical field or equivalent experience
5+ years data science experience
Knowledge of machine learning, filtering, and cleansing techniques
Strong knowledge of Python and one of Java, C/C++, Kotlin, or Go
Working knowledge of backend software development, including RESTful APIs and databases
Team player with high integrity
Open to feedback and constantly striving to improve
High degree of self awareness

Extra Credit

Experience with gyros and accelerometers
Experience with computer vision
Experience as a software engineer",4.4,Tonal,Toronto,"San Francisco, CA",51 to 200 employees,2015,Company - Private,"Health, Beauty & Fitness",Consumer Services,Unknown / Non-Applicable,-1,117.0,5,data scientist,senior,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1955,0
67,"At Nylas, our mission is to empower the world to communicate with context and insight. Our hosted sync platform and APIs enable developers to quickly integrate their apps with email, contacts, and calendar across all providers (including Exchange).

We are changing the way companies and developers innovate with email and messaging. Customers like Pipedrive, Salesloft, and Lever use our cloud messaging APIs to power their products and accelerate their ability to innovate.

Nylas has raised over $55M from Spark Capital, 8VC, Data Collective, Fuel Capital, SV Angel and more. Our HQ is in San Francisco with offices in New York, Denver, Toronto, and several of us work remotely. Members have previously worked at Dropbox, Google, Facebook, Microsoft, Oracle, SAP, and VMware.

Want to know more? Check us out on Comparably, Great Place to Work, and read our Employee Handbook!

About the team

The Intelligence team at Nylas is responsible for forward development of various services that built on top of emails, calendars and contacts utilizing natural language processing, machine learning, and integrations with external API's to categorize and contextualize information for developers to build an intelligence layer on top of Nylas' world class communications layer.

About the role

This role will be responsible for designing, developing and deploying various solutions such as rule-based, natural language processing, to deep learning models to categorizer and contextualize emails, calendars, and contacts. You'll be applying ML algorithms to solve real world problems.

You'll be working with on high impact datasets mission critical to the rest of the world from healthcare, operations, and infrastructure
You'll be working with frontend and backend engineers building an intelligence layer on top of email, calendars and contacts
You'll be able to use your models and solutions in real-time and see it in action on the front-end
You'll be independent enough to build and evaluate robust models
You'll be using the latest and greatest tools to build things the way you want with little to no legacy code to stand in your way
You'll be building out machine learning infrastructure for billions of datasets with trillions of connections

Who you are
Strong foundations in Mathematics, Statistics, Data Modeling, and Machine Learning
Strong foundations in Mathematics, Statistics, Computer Science or Software Engineering
At least 0-2 years of experience on developing and deploying to production systems
Experience with python, golang or java
Experience working with R, matlab, or other analytics tools
Experience working with natural language processing packages
Experience working with industry standard machine learning packages and tools
Ability and confidence to pick up any technical concept to get the job done
Looking to become a world class machine learning expert
Comfortable in the dark and exploring ideas never done before
Strong belief that product and design decisions are inextricably linked
Busy creating magic from your code
A power user of the tools of your trade or building your own tools
Never stop learning
Communicate design decisions openly and confidently, regardless of the audienceengineers, PMs, executives, other designers, etc.
Not afraid to change your opinion in the face of new information or understanding of the product goalsyou have strong beliefs, but you're open-minded
Benefits

Tech setup - we'll make sure you have everything you need to work at your best, including laptop, laptop stand, and noise-canceling headphones
Competitive Pay
Meaningful Equity
Medical, Vision, Dental, and Life benefits for you and your family
Retirement benefits
$1k yearly Education & Development benefit
Catered lunch & Unlimited snacks
$100 a month health and wellness benefit
Relocation assistance
Unlimited vacation (mandatory 2 week consecutive vacation once per year)
12 weeks caregiver leave
Flexible work hours

Nylas is an Equal Opportunity Employer, and diversity of all kinds is important to us.

Our team is roughly equal by identified gender (including engineering) and focuses on creating an inclusive environment for all people. We welcome people from all different backgrounds and currently employ startup founders, college graduates from all over the country and the world, coding academy graduates and those with no degrees at all.

We are actively and regularly working with the entire team to shape our culture in a conscious way to our ideal of empowerment, transparency, and kindness.",4.9,Nylas,Toronto,"San Francisco, CA",51 to 200 employees,2013,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,117.0,7,data scientist,na,0,1,0,0,0,0,1,0,0,0,0,0,1,1,1,4538,0
68,"Jarvis Consulting Group identifies high potential individuals and develops them into professional technology consultants working with the hottest technologies in some of Canadas top companies.

The Opportunity

Were looking for individuals with the right attitude and aptitude to become Data Engineers and work with some of Canadas top companies to unlock the value of their data. If you want to become a data engineer working with top companies on high profile projects Jarvis just might be what you're looking for.

Youll be involved in projects of high strategic importance to design, build and integrate data pipelines that provide a consistent flow of high quality data. Also, youll have the opportunity to explore the use of new and emerging data related technologies and pioneer new patterns and practices.

What we offer
Comprehensive training on core Big Data technologies provided by industry experts:
Cloud
DevOps
Java
Hadoop/Spark
Access to the most exciting and innovative projects within some of Canadas top companies
Dedicated support to help you develop your career through coaching, professional networking opportunities and attaining industry recognized certifications
The opportunity to dramatically improve your skills by writing a lot of code
Who we're looking for
Curious - Youre interested in experimenting, learning, innovating and trying new things
Customer Focused You strive to create value for your customers and always deliver with quality
Adaptable - You maintain a focus on results even as plans and priorities change and consistently deliver value
Humble - You recognize your strengths as well as your opportunities and are always willing to learn from others
Collaborative - You value the success of the group and freely share your knowledge, experience and insight
What were looking for


Experience and education
Diploma or degree in computer science, technology, engineering or a mathematical discipline
Aptitude for logical reasoning and quantitative problem solving
Good oral and written communication skills
Good collaboration and teamwork skills
Willing and able to commit to working with Jarvis for at least two years following a training period
Legally permitted to work in Canada (citizen/permanent resident/work permit)
Core Technical Skills
Familiar with one or more programming languages (C++, Java, Python, Scala, etc)
Have completed at least one course related to designing algorithms and data structures
Why you should work with us
The ability to have your potential recognized and rewarded
Practical and relevant training utilizing the newest technologies
Support to help you establish your career and achieve your goals
The opportunity to work on innovative projects within a variety of Canadas top companies
A competitive compensation package with support for continuous learning",4.2,Jarvis Consulting Group,Toronto,"Toronto, Canada",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1,117.0,-1,data engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,2831,0
69,"Who We Are

Tonal – the world’s most intelligent fitness system – enables you to be your strongest by providing an effective fitness program tailored to you, your goals, and your schedule. Combining cutting-edge, all-in-one equipment and personalized video guidance, it’s like having a personal trainer, on demand, in the convenience of your home.

At Tonal, we are applying our collective knowledge and creativity to reimagine fitness. We know firsthand that too many hurdles stand between each of us and our fitness goals. Drawing on decades of research and a diverse team of experts, we have created the most advanced strength training system available that makes working out more efficient, effective, and engaging.

We're passionate about building products that transform people's lives.

What You Will Do

Provide expert input on architecture of Tonal's learning systems
Architect and build our machine learning and computer vision solutions
Identify innovative opportunities for deep learning and computer vision

Who You Are

Advanced degree in mathematical field or equivalent experience
3+ years of research or engineering experience in one or more of the following: generative models (GANs, VAE, Glow), segmentation, object detection, classification, tracking, NLP, or other related applications of machine learning
Deep learning, especially generative models, e.g, GANs, Image-to-Image translation
Industry or project experience with deep learning frameworks (e.g. PyTorch, TensorFlow, Caffe2)
Team player with high integrity
Experience working on a team where feedback is routinely shared as a mechanism for professional development
High degree of self awareness
Have worked on a distributed team across different geographies

Extra Credit

Experience with gyros and accelerometers
Experience with deepfake technology
Experience as a software engineer",4.4,Tonal,Toronto,"San Francisco, CA",51 to 200 employees,2015,Company - Private,"Health, Beauty & Fitness",Consumer Services,Unknown / Non-Applicable,-1,117.0,5,data scientist,senior,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1864,0
70,"Job Description


Job #: 1076413

Role: Data Scientist II

Client: Biotechnology/Pharmaceutical Company

Location: Mississauga

Contract Duration: 7/20/2020 - 12/31/2020

40 hours per week

As an IT Expert - Data Scientist, you will be working as a part of a squad that is designed to respond to the business needs of our organization quickly. The specific role will be to perform Data Modeling analysis, run the Data Analysis, find patterns

primary responsibilities:
Research and implement comprehensive statistical, mathematical and computing science algorithms across business contexts including research, development and quality
Investigate available tools and technologies in machine learning and deep learning
Support collaboration with third parties including academia and industry
Analyzing large amounts of data from several sources
The skills we are searching are amongst others:
Knowledge of classification techniques
Good knowledge of data matching/entity resolution techniques
Superb analytical and conceptual thinking skills, attention to details
Strong problem-solving skills (taking a significant, complex problem and breaking it down into components, involve others as needed, drive resolution)
Excellent communication skills/ability to interact with business stakeholders
Ability to solve problems by using machine learning or deep learning techniques
Quick learner and passionate about continually adapting your skills and knowledge
Ability to work in the interdisciplinary area and can interpret and translate the very abstract and technical approaches to a healthcare and business-relevant solution
Active team player and can work effectively in a collaborative, fast-paced, multi-tasking environment
Excellent communication skills and a demonstrated ability to interact with different teams and parties of the organization, such as business, technical and academic partners
Knowledge of R is essential
Knowledge of Cloud environments (GCP, AWS) would be an asset
Required
DEEP LEARNING
EXCELLENT COMMUNICATION SKILLS
GCP
MACHINE LEARNING
PROBLEM-SOLVING
Additional
TEAM PLAYER
TRANSLATE
ALGORITHMS
DATA ANALYSIS
DATA MODELING
DATABASE
DATABASES
MARKETING ANALYSIS
MODELING ANALYSIS
EEO Employer

Apex Systems is an equal opportunity employer. We do not discriminate or allow discrimination on the basis of race, color, religion, creed, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), age, sexual orientation, gender identity, national origin, ancestry, citizenship, genetic information, registered domestic partner status, marital status, disability, status as a crime victim, protected veteran status, political affiliation, union membership, or any other characteristic protected by law. Apex will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law. If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation in using our website for a search or application, please contact our Employee Services Department at employeeservices@apexsystemsinc.com or 844-463-6178.",3.8,Apex Systems,Mississauga,"Glen Allen, VA",1001 to 5000 employees,1995,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$2 to $5 billion (CAD),"TEKsystems, Insight Global, Accenture",117.0,25,data scientist,na,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,3177,3
71,"How do you imagine life at an insurance company - its people, its culture, its offices? We bet that if you join Intact, you will be in for quite a surprise!

With offices in downtown Toronto and Montreal, the Lab is a digital innovation hub bringing together actuaries, big data scientists, machine learning experts, geomaticians, meteorologists and software engineers who work together to propose and implement innovative solutions to the complex issues facing us.

Merging the speed and culture of a start-up with the resources and means of a large enterprise, the DataLab is a dynamic team offering exciting challenges, inspiring colleagues and great career opportunities (at one of Canadas Top 100 Employers!)

About you:
Are you a machine learning coding expert who believes we are only in the infancy of artificial intelligence? Are you passionate about advanced analytics and Big Data? Do you stay current with the latest trends in analytics and jump at the chance to experiment with new tools? We have the perfect opportunity for you!
Your Job
Hiring Manager: Sébastien Bernard

Workplace: Quebec City (5700, des Galeries)

YOUR CONTRIBUTION:
Develop innovative solutions for trend recognition using machine learning and advanced statistics
Transform complex databases into relevant conclusions and recommendations
Keep pace with new approaches and trends and use them in your own solutions
Help maintain our data mining tools and platforms
Make actionable recommendations based on the findings
Work with other departments to promote the adoption of analytical principles within the organization
Validate the quality of the analytical approach and project outputs of the other team members
Your Skills
YOUR ASSET:
Your Masters degree in a relevant discipline (mathematics, science, engineering, operational research, economics, statistics, AI, computer science or a related field)
Your 5 years of experience in the field of advanced statistics, data mining and text mining
A multi-platform production experience with the following commercial and open-source data mining frameworks:
Open-source frameworks: R, Python, GitHub
Expert-level understanding of the underlying theory of machine learning
Expert-level understanding in either computer image analysis, natural language processing or artificial intelligence
Your great teamworking skills
Your ability to focus on vaguely defined issues requiring the application of a creative approach
Your strong communication, time management and work organization skills
Closing Statement
This opportunity interests you? We look forward to meeting you!

Excellent benefits are offered: competitive salary, flexible benefits, flexible work arrangements, flexible leave, pension plan defined benefit, etc..

As part of Intacts selection process, candidates may be requested to consent to background checks relevant to the role under consideration for, prior to receiving a job offer. These could include: work references, education and credential confirmation, employment verification, identity check, credit report, criminal offence and drivers license record.

Please note we may have identified other internal candidates through our Employee Development Program, and that the selection process may also be opened to external applicants.

#li-qc
Referral Bonus
This role is eligible for employee referral bonus. #RightPeopleRightRole
Eligibility to work in Canada
Its important that you are eligible to work in Canada at the time an offer of employment is made. Proof of eligibility can be a Canadian birth certificate, Canadian passport, Canadian citizenship certificate, permanent residence card or confirmation.

Prior to receiving a job offer, you may be asked to consent to background checks if its a requirement for the role. These checks could include: work references, education and credential confirmation, employment verification, identity check, credit report, criminal offence and drivers license record.
Indeed Sponsored
IN-QCIT
Glassdoor Sponsored
#GD-Quebec",4.1,Intact,Quebec,"Toronto, Canada",10000+ employees,-1,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),"Aviva Canada, RSA Group, Economical Insurance",117.0,-1,data scientist,senior,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,4021,3
72,"Role and Responsibilities

Scientifique des données

(English follows)

Lorsque vous prenez l’avion, peu importe la destination, il y a de fortes chances que le pilote ait été formé par CAE. Le point focal étant les clients, l’équipe Accélérateur numérique s’engage à rehausser l’expérience de formation afin de s’assurer que les pilotes soient les meilleurs possible.

Voici quelques raisons pour lesquelles les employés aiment travailler à CAE!
Travail significatif qui favorise le perfectionnement professionnel
Possibilité de travailler dans l’industrie technologique et de s’y épanouir
Environnement de travail axé sur la collaboration
Faire partie d’une équipe à haut rendement
Votre mission

À titre de scientifique des données, votre mission est concevoir, développer et implanter des solutions analytiques et prédictives complètes, dans un environnement infonuagique, qui sont évolutives, répétables et sécuritaires.

Votre rôle et responsabilités principales

Être un contributeur-clé de la stratégie d’intelligence artificielle
Concevoir des solutions d’Intelligence Artificielle innovatrices permettant de supporter les opérations d’entrainement dans les domaines de l’aviation et de la santé
Extraire et analyser les données des bases de données de l'entreprise pour stimuler l'optimisation et l'amélioration du développement de produits, des techniques de marketing et des stratégies commerciales.
Évaluer l'efficacité et l'exactitude des nouvelles sources de données et techniques de collecte de données.
Développer des solutions et des algorithmes d'IA personnalisés à appliquer aux ensembles de données.
Expérimentez des méthodologies de modélisation avancées qui visent à augmenter et à optimiser l'expérience client, la génération de revenus, le ciblage publicitaire et d'autres résultats commerciaux.
Développer un cadre de test A/B pour l'expérimentation de l'IA et l'analyse des résultats.
Coordonner avec différentes équipes fonctionnelles pour mettre en œuvre des modèles et suivre les résultats.
Développer des processus et des outils pour surveiller et analyser les performances du modèle et la précision des données.
Être un contributeur-clé dans la transformation de l’entreprise
Piloter la recherche sur les tendances de l'industrie de l'aviation et des soins de santé et les applications commerciales de l'apprentissage automatique pour être un différenciateur sur le marché
Mener plusieurs projets liés à l'apprentissage machine à grande échelle et orientés services: du plan fonctionnel au plan de mise en œuvre
Diriger une équipe pour le développement rapide et itératif d'une solution minimale viable validée
Développer et prototyper de nouvelles techniques d'apprentissage automatique, exécuter des expériences pour améliorer la compréhension et modéliser le taux d'efficacité
Être un collègue inspirant et motivant
Partager vos connaissances avec l’équipe et initier des activités de partage des connaissances
Être un agent de changement et un promoteur de la mentalité agile
Contribuer au milieu de travail collaboratif et stimulant
Communiquer avec la communauté d'intelligence artificielle de Montréal et d'ailleurs pour trouver de nouvelles possibilités de collaboration et pour injecter de nouvelles idées dans notre pipeline
Vos qualifications
Une volonté d'apprendre et de maîtriser les nouvelles technologies, méthodologies et techniques.
Expérience à piloter des initiatives dirigées par le client.
Expérience de travail dans un environnement Agile un atout.
Excellentes compétences en communication écrite et verbale pour la coordination entre les équipes.
Compétences techniques
Avoir une maîtrise ou un doctorat en statistique, informatique, analyse commerciale ou un domaine connexe
Posséder au moins 5 ans d'expérience en science des données ou en statistiques appliquées.
Solides compétences en résolution de problèmes en mettant l'accent sur le développement de produits.
Expérience de l'utilisation de langages informatiques statistiques (R, Python, SLQ, etc.) pour manipuler des données et tirer des enseignements de grands ensembles de données.
Expérience dans la manipulation d'ensembles de données et dans l'élaboration de modèles statistiques.
Connaissance d'une variété de techniques d'apprentissage automatique (forêts aléatoires, machine à vecteur de support, amplification de gradient, réseaux de neurones artificiels, réseaux bayésiens, etc.) et leurs avantages / inconvénients réels.
Connaissance des techniques et concepts statistiques avancés (MLG / régression, séries chronologiques, propriétés des distributions, tests statistiques et utilisation appropriée, etc.) et expérience de leurs applications.
Expérience de travail en création et consommation d'architectures de données.
Expérience de l'utilisation des services Web: Redshift, S3, Azure, Spark, DigitalOcean, etc.
Expérience de l'analyse de données de fournisseurs tiers: Microsoft Application Insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Expérience de visualisation / présentation de données pour les parties prenantes en utilisant: Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc.
Ce que nous avons à offrir
Avantages sociaux : entièrement flexibles pour que vous puissiez choisir ce qui est important
Retraite : Régime de retraite à prestations déterminées et régime enregistré d’épargne-retraite (REER) collectif
Avantages financiers : Régime d’actionnariat et nombreux rabais d’entreprise
Programmes personnels et familiaux : Plan de bien-être physique et prestations de maternité complémentaires
Équilibre travail-vie personnelle : Horaires flexibles et « vendredis californiens » toute l’année
Plaisir au travail : Activités sociales et communautaires tout au long de l’année!
À CAE, il est très important de créer des liens avec les gens. Si vous avez des questions au sujet de cette possibilité de carrière, n’hésitez pas à communiquer avec Sawsan Ghamraoui, spécialiste en acquisition de talents (sawsan.ghamraoui@cae.com) ou Arnaud Van de Voorde, vice-président, accélérateur numérique (arnaud.vdv@cae.com).

Joignez-vous au moteur de changement à CAE - notre prochain horizon de croissance passe avant tout par l’innovation numérique afin d’appuyer la réussite de nos clients.

**********************************************************************************

Data Scientist

If you’ve taken a plane to any destination in the world, chances are, your pilot was trained by CAE. With its strong customer focus, the Digital Accelerator team is dedicated to elevating the training experience to make pilots the best they can be.

Here are few reasons why folks love working at CAE!
Meaningful work that drives professional development
Ability to enter and grow within the technology industry
Work in a collaborative environment
Be part of a high-performance team
Your Mission

As a member of the Data Science team, your mission is to design, develop, and implement end-to-end cloud-based analytics production pipelines that are scalable, repeatable and secure.

Your Role & Main Responsibilities

Be a key contributor to the AI Strategy
Design innovative Artificial Intelligence solutions to support aviation and health training operations.
Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Develop custom AI solutions and algorithms to apply to data sets.
Experiment advanced modeling methodologies that aim increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes.
Develop company A/B testing framework for AI experimentation and results analysis.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Be an active member of the business transformation
Drive research on aviation & healthcare industry trends and the commercial applications of machine learning to be a differentiator in the market
Lead multiple service-oriented large-scale machine learning related projects: from functional to the implementation plan
Lead a team for rapid and iterative development of validated minimum viable solution
Develop and prototype new machine learning techniques, run experiments to improve comprehension and model efficiency rate
Be an inspirational and motivational colleague

Be an inspirational and motivational colleague
Share knowledge with team members & participate in various learning-sharing activities
Contribute to the collaborative and stimulating work environment
Be a change agent & Agile mindset promoter
Be connected to the industry to know tendencies and suggest innovative ideas
Your Qualifications

Softskills
A drive to learn and master new technologies and techniques.
Experience leading customer driven initiatives.
Experience working in an Agile environment an asset.
Excellent written and verbal communication skills for coordinating across teams.
Technical skills
Have a Master or PhD in Statistics, Computer Science, Business Analytics or a related field
Possess at least 5 years experience in Data Science or applied statistics.
Strong problem solving skills with an emphasis on product development.
Experience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.
Experience manipulating data sets and building statistical models.
Knowledge of a variety of machine learning techniques (Random Forests, Support Vector machine, Gradient boosting, artificial neural networks, Bayesian networks, etc.) and their real-world advantages/drawbacks.
Knowledge of advanced statistical techniques and concepts (GLM/Regression, Time Series, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.
Experience working with and creating data architectures.
Experience using web services: Redshift, S3, Azure, Spark, DigitalOcean, etc.
Experience analyzing data from 3rd party providers: Microsoft Application insights, Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.
Experience visualizing/presenting data for stakeholders using: Periscope, Microsoft Power BI, Business Objects, D3, ggplot, etc.
What we have to offer
Benefits: fully flexible for you to choose what is important
Retirement: Defined Benefits Retirement Plan & Group Registered Retirement Savings Plan (RRSP)
Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts
Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan
Work-Life Balance: Flextime & California Fridays all year
Fun at work: social and community events all-year round!
At CAE, connecting with people is very important. If you have any questions on this career opportunity, please do not hesitate to contact Sawsan Ghamraoui, Talent Acquisition Specialist (sawsan.ghamraoui@cae.com) or Arnaud Van de Voorde, Vice-President, Digital Accelerator (arnaud.vdv@cae.com).

Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.

Position Type

Regular

CAE thanks all applicants for their interest. However, only those whose background and experience match the requirements of the role will be contacted.

Equal Employment Opportunity

At CAE, everyone is welcome to contribute to our success. With no exception.

As captured in our overarching value ""One CAE"", we’re proud to work as one passionate, boundaryless and inclusive team.

At CAE, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age.

The masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.",3.9,CAE,Montreal,"Montreal, Canada",10000+ employees,1947,Company - Public,Aerospace & Defence,Aerospace & Defence,$2 to $5 billion (CAD),"Pratt & Whitney, Lockheed Martin",117.0,73,data scientist,na,0,1,1,0,0,0,1,0,1,0,0,0,1,0,1,12046,2
73,"Join our evolving team at an exciting time for Hifyre - grow with us!

Lead in the build and execution of the data science vision for Hifyre's retail platform.

To reach our goal, we need the best talent to help us evolve and drive change across the business. You will be responsible for creating consumer knowledge by providing relevant and actionable data that will shape general consumer and customer understanding and influence merchant and marketing activities.

YOU HAVE:
Experience with data pipeline work flow
Intermediate to advanced data manipulation ability via Excel and/or Python/SQL
Data visualization techniques
The ability to devise, conduct and analyze tests to directly and indirectly drive KPI improvements
Design product and marketing tests to support continuous improvement
Improve predictive scoring solutions for marketing stakeholders
YOU WILL:
Drive innovation by building predictive models, tools and processes that support production goals
Translate business requests and questions into SQL logic
Build dashboards and reports for core retail business metrics and performance trends
Develop analysis templates and standards for use across the Analytics Team
Build and maintain standard performance reports on predictive scoring models
Curate datasets from raw sources for analysis, modelling and machine learning
Manage and own user data
Serve as a lead in communicating and presenting data findings & insights, related strategic recommendations and status of systems development to key business stakeholders
Provide insightful information to contribute to the improvement of development strategies and marketing techniques
Strictly adhere to legal and compliance guidelines; regarding access and exposure to sensitive and confidential information
NICE TO HAVE:
Prior experience with Amazon Web Services
Experience with Redshift
Data pipeline and/or database development and engineering experience
Database administration
Knowledge of statistical modelling, predictive analytics or machine learning
Experience with Looker a bonus
Experience in BI, data discovery, and data visualization tools are a great asset
WHY SHOULD YOU WORK HERE?
An equally balanced team of solid, hard-working humans - diverse in talents and actively growing.
Technology Agnostic - if you believe in it, build it.
(No) Dress Code - if you’re comfortable, so are we.
Work/Life Balance - we offer 3 weeks of Vacation Time to all employees - effective in your first year. Plus 3 days off around Christmas.
A People First organization. Truly a family that supports each other in every endeavour.
For your health - Comprehensive Benefits! Dental, health, and more.
* DUE TO COVID WE ARE CURRENTLY WORKING REMOTELY * BELOW WOULD APPLY ONCE WE ARE ABLE TO CONGREGATE IRL.
Cool Digs - a modern, restored historical building as your workspace - located in the newly renovated King James Building - views of James North and Gore Park, exposed brick and beams, and most importantly... not a cubicle in sight.
Endless snacks & coffee on hand - Nibs + Espresso for breakfast? We don’t judge.
Work Local -> No Commute -> Sighs of Relief",1.9,Hifyre,Hamilton,"Hamilton, Canada",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1,117.0,-1,data analyst,na,0,1,0,0,0,1,0,1,0,0,0,0,1,0,0,3123,0
74,"Share this job

Location

Montreal
Department

Data & Analytics
Type

full-time
Requisition ID

6835

Apply now

Role description


Unity Monetization Team, a division of Unity, builds advertising, in game purchases promotions, and other personalized content delivery solutions and technologies used in hundreds of thousands of apps. Our Monetization team builds the technology infrastructure and serving systems that manage the delivery of relevant content to hundreds of millions of users every day. Our platform process massive data sets that feed into machine learning systems that live in the core of various of our products.

Specifically, Unity Monetization is investing to master these methodologies and applying them to real-world problems of game economics and monetization. We want to bring the cutting edge machine learning to help developers in Unity’s vast mobile monetization ecosystem to succeed in build sustainable monetization for their games. Thus, we are looking to add a Data Scientist to our amazing team!

Unity’s vast game monetization ecosystem gives us a unique opportunity to leverage data and innovative machine learning methods to benefit the gaming and game development communities. Unity is continuously striving to build disruptive and powerful solutions to enable game developers to be more successful.

Responsibilities
The team will focus driving Unity’s internal data augmentation for monetization needs, validate and acquire external datasets and create embeddings and representations of different data sets in close collaboration for other monetization data scientist to use for online decision making problems
You will work with the world’s number one content creation platform to drive data integration requirements, building representation learning to help personalization of mobile gaming and mobile advertising experience
You will become a domain expert implementing cutting edge solutions to learn embeddings to further power decision making algorithms
You will help drive the execution of the team build technical expertise and implement machine learning algorithms and model training processes to solve business problems
Requirements
Capability to convey ideas, lead execution and guide more junior members to firm data science and machine learning implementation
Solid understanding and experience of machine learning concepts, scientific thinking and programming
Capability to participate in defining new business opportunities and products actively
Experience in implementing varied data and machine learning based online decision-making systems on a large scale
Bonus points
Experience in the gaming industry, especially mobile f2p world
Experience in mobile advertising
Mathematics, physics, computer science PhD or equivalent degree
Experience in representation learning
About Unity Technologies

Unity is the world’s leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity’s platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company’s 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com.

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this website or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

L'équipe de monétisation de Unity conçoit des publicités, des promotions sur des achats en jeu et d'autres solutions et technologies de contenu personnalisé utilisées par des centaines de milliers d'applications. Notre équipe de monétisation bâtit l'infrastructure technologique et les systèmes de services qui gèrent quotidiennement la livraison de contenu pertinent à des centaines de millions d'utilisateurs. Notre plateforme de traitement des données de masse intègre ce flux de données aux systèmes d'apprentissage machine qui sont au cœur de nombreux de nos produits.

Plus précisément, les investissements du secteur de la monétisation de Unity visent à maîtriser ces technologies et à les appliquer aux problèmes réels liés à l'économie et à la monétisation des jeux vidéo. Nous souhaitons que l'apprentissage machine à la fine pointe puisse aider les développeurs du vaste écosystème de monétisation sur appareils mobiles de Unity à mettre en place avec succès un système de monétisation durable pour leurs jeux. C'est pourquoi nous sommes à la recherche d'une personne pour pourvoir au poste de scientifique des données dans notre formidable équipe!

Le vaste écosystème de monétisation des jeux vidéo de Unity nous offre l'occasion d'exploiter les données et les méthodes novatrices d'apprentissage machine afin d'en faire profiter l'industrie des jeux vidéo et les communautés de développeurs de jeux. Unity met tous les efforts pour bâtir des solutions puissantes et créatrices de marché qui favorisent la réussite des développeurs de jeux.

Responsabilités
L'équipe se concentrera à mener à bien l'augmentation des données internes pour les besoins de la monétisation, à valider et à acquérir des jeux de données externes, et à créer des incorporations et des représentations des différents jeux de données en étroite collaboration, afin qu'un autre scientifique des données en monétisation puisse les utiliser pour des problèmes en ligne de prise de décisions
Vous travaillerez avec la première plateforme mondiale de création de contenu afin de guider les exigences liées à l'intégration des données, et mettrez en place l'apprentissage par représentation afin de contribuer à la personnalisation de l'expérience sur les jeux mobiles et dans le contenu publicitaire
Vous vous spécialiserez dans l'implémentation de solutions à la fine pointe pour l'apprentissage d'incorporations qui serviront à de puissants algorithmes futurs de prise de décisions
Vous aiderez à guider la mise en place de l'expérience technique de l'équipe et implémenterez des algorithmes d'apprentissage machine et des processus de modèles d'entraînement pour résoudre les problèmes commerciaux
Exigences
Aptitude à transmettre des idées, à diriger des tâches et à guider des membres d'équipe moins expérimentés dans la solidification des données scientifiques et l'implémentation de l'apprentissage machine
Solide compréhension et expérience des concepts d'apprentissage machine, de raisonnement scientifique et de programmation
Aptitude à participer activement à l'établissement de nouvelles occasions d'affaires et de nouveaux produits
Expérience dans l'implémentation à grande échelle de différentes données et de systèmes de prise de décisions en ligne fondés sur l'apprentissage machine
Atouts
Expérience dans l'industrie des jeux vidéo, surtout dans les jeux gratuits (F2P) sur appareil mobile
Expérience dans la publicité sur appareil mobile
Doctorat en mathématiques, physique, informatique ou un diplôme équivalent
Expérience dans l'apprentissage par représentation
À propos de Unity Technologies

Unity est la plateforme la plus utilisée au monde pour la création et l'exécution interactive de contenu 3D en temps réel (RT3D). Des créateurs, notamment des développeurs de jeux vidéo, des artistes, architectes, concepteurs automobiles et cinéastes, utilisent Unity pour donner vie à ce qu'ils ont imaginé. La plateforme de Unity offre un ensemble complet de solutions logicielles pour créer, exécuter et monétiser du contenu interactif 2D et 3D en temps réel pour les téléphones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de réalité augmentée et de réalité virtuelle.

Notre équipe de plus de 1400 personnes assignées à la recherche et au développement fait en sorte que Unity soit à l'avant-garde du développement et assure un soutien optimal pour les plus récentes technologies et plateformes. Les applications développées par les créateurs au sein de Unity ont été téléchargées plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d'appareils uniques. Pour en savoir davantage, visitez le site www.unity.com.

Unity est un employeur axé sur l'égalité des chances qui s'engage à favoriser un environnement inclusif et innovateur avec les meilleurs employés. Par conséquent, nous fournissons des opportunités d'emploi sans tenir compte de l'âge, la race, la couleur, l'ascendance, l'origine nationale, la religion, le handicap, le sexe, l'identité sexuelle ou l'expression, l'orientation sexuelle ou tout autre statut protégé. S'il y a des préparatifs que nous pouvons faire pour vous aider à avoir une expérience d'entrevue confortable et positive, veuillez-nous le faire savoir.

Les chasseurs de têtes et les agences de recrutement ne peuvent pas soumettre résumes/CV par ce site Web ou directement aux superviseurs. Unity n’accepte pas des chasseurs de têtes non sollicités et des résumés (CV) d’agence. Unity ne payera pas d’honoraires à aucune agence tierce ou entreprise qui n’a pas signé d’ententes avec Unity.

#LI-DD1 #SEN",4.9,Unity Technologies,Montreal,"San Francisco, CA",1001 to 5000 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Epic Games, Electronic Arts, Zynga",117.0,15,data scientist,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,10096,3
75,"About Assurance
At Assurance we are disrupting the antiquated and inefficient world of insurance and financial services. Our team of world class software engineers, data scientists, and business professionals are modernizing how people obtain and manage their financial life all through our powerful platform ecosystem. We are rapidly growing as we expand our product offerings and global footprint, and this growth continues to present new and exciting challenges as we push our industry into its future. We eliminate waste throughout the industry and calculate the complex into simple, valuable solutions to improve people's lives. We are humble, driven, and committed to improving the lives of millions.

About the Position
As we build the future of consumer insurance in a modern age, data is at the core of everything that we do. The role requires team members who are adept at using large data sets to find opportunities for optimization and can leverage appropriate models to test the effectiveness of different courses of action. Our team uses a variety of data mining and analysis methods, a variety of data tools, builds and implements models, develops algorithms, and creates simulations. Team members must be very comfortable writing production-ready code to include testing and maintenance infrastructure, and able to put models and analysis into production with no support from engineering (we own our stack end to end). At Assurance, we hire experts in their field, and we give them the independence and trust to build based on their expertise.

About You
You have a proven ability to drive business results with data-based insights and are comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes. You’re capable of getting data for analysis on your own, without reliance on engineering, and you can build professional dashboards as standalone software products and tools. We’re growing at a rapid pace, so it’s important that you embrace the opportunity to blaze your own trail. You thrive in a fast-paced environment where priorities can shift rapidly as we corner opportunity. You can work independently, with little oversight or guidance.

To be successful in this role, you must possess the following:
Proficiency in either Python or R, and expertise in SQL.
Experience working with AWS or another cloud-based computing platform.
Experience and working knowledge of data infrastructure, pipelines, and advanced data manipulation.
Experience with BI tools like Tableau or Looker (preferred), or any other industry tool such Qlik, PowerBI, Spotfire, etc.
Excellent communication ability – you can explain your work in a way that anyone on the team can understand, and you can frame problems in a way that ensures the right question is being asked.
Business Acumen – you are always eager to understand how the business works, and more specifically, how your work impacts the business.
Enthusiastic yet humble – you are excited about the work you do, but you are also humble enough to embrace feedback – you don’t need to be the smartest person in the room.
Bachelors degree in mathematics, statistics, data science or related field of study.

The following additional experience is desired:
Experience retraining a model within a few days or update a model within one day.
Capable of performing an in-depth analysis and summarizing findings in one day.
Comfortable having conversations with our executive team and non-technical team members to distill down their needs and to deliver actionable insights.

Please review our CCPA policies here.",1.8,ASSURANCE,Toronto,"Bellevue, WA",501 to 1000 employees,-1,Company - Private,Insurance Agencies & Brokerages,Insurance,Unknown / Non-Applicable,-1,117.0,-1,data scientist,na,0,1,1,1,0,1,0,1,0,0,0,0,0,0,1,3731,0
76,"Company Description

About Us:

American Iron & Metal (AIM) is a family-owned, Canadian-based company founded in 1936 in Montreal, Quebec. Recognized as one of North America’s most sophisticated metal recyclers, AIM has evolved into a successful and multifaceted company with a global footprint.

At AIM, we understand that the well-being of our employees is the key factor for our international success. Accordingly, we promote a safe, fair and dynamic work environment that provides excellent training programs and career advancement plans and maintains the highest safety standards.

If you are looking for career development and an opportunity to work for a company that promotes growth, then keep reading!

Job Description

As a data analyst, you help develop and use tools and methods to collect, compile, model and oversee the quality of transactional data. You will be part of a team whose mandate is to develop business intelligence knowledge to support decision-making and help decisionmakers understand the big picture. Your role covers analyzing and helping diagnose issues related to the data, providing opinions in accordance with the existing data and information, and developing recommendations and implementation plans.

Main responsibilities
Work closely with various technology and project teams to understand business data and provide analysis and requirements to ensure the data design / development initiatives are in line with the management expectations.
Provide support throughout data lifecycle to resolve data issues and support operation users to interpret the data
Develop and maintain knowledge of available data from different IT systems and data sources
Design and implement reports and dashboard to provide insights and meet business requirements
Identify, analyze key performance indicators (KPI) and interpret data to inform management decision-making
Perform data analysis, with a wide variety of statistical methods including cluster, regression, decision tree, random forest, time series and others.
Participate actively in reviewing the dashboard and performance of different operation units
Works closely with IT BI team to ensure that the needed data models are available and meet the expected reports and dashboards
Establish strong relationships with peers and work cross-functionally with Operations, Purchasing, Sales, and Finance teams.
Qualifications
Bachelor’s degree in Business, Engineering, Computer Science, Supply Chain Management, Statistics, Mathematics, or related field
A minimum of two years of relevant experience
Strong interest in data analytics, data transformation and problem-solving skills.
Experience in business intelligence and data management
Advanced Knowledge: Microsoft Excel (Pivot tables), experience with cubes, data analysis tool, hypothesis testing, linear regression, qualitative and quantitative forecasting methods
Specific knowledge
Knowledge of SQL, entity relationship diagrams and dimensional data models
Knowledge of visualization tools such as Cognos or Power BI (an asset)
Knowledge of VBA, R, or Python (an asset);
Facility with databases management
Knowledge of the operation and supply chain",3.1,American Iron and Metal,Montreal,"Montreal, Canada",1001 to 5000 employees,1936,Company - Private,Metal & Mineral Manufacturing,Manufacturing,$2 to $5 billion (CAD),-1,117.0,84,data analyst,na,0,1,1,0,1,1,0,0,0,0,0,0,0,0,1,3181,0
77,"Job Description

As a global market share leader in the high-growth customer engagement market, Verint is focusing to expand our growth as a critical part of its announced plan to create two independent public companies in February 2021. As a part of this exciting growth trajectory, Verint is looking to add additional top talent to our team.

The Senior Data Scientist is a member of Verint’s Data Science team that builds cutting-edge models while digging deep into insights that can drive decisions. The Senior Data Scientist is passionate about building predictive applications and solving critical business problems and enjoys the whole data science lifecycle from ideation, data exploration, model building, results communication, all the way to productization.

Principal Duties and Essential Responsibilities:
Work with data scientists to implement new scoring capabilities.
Collaborate with big data engineers to scale existing solution.
Work on problems and data sets: pattern detection, time series forecasting, pattern recognition, natural language processing.
Help create a test case plan, quality processes and requirements for newly implemented components.
Follow and share with team members cutting-edge machine learning and deep learning research.
Minimum Requirements:
Bachelors Degree in Computer Science, Engineering, Applied Math, Statistics, Operations Research, or related field required
5+ years of experience in stats/machine learning algorithms, such as SVM, logistic regression, boosting, clustering, classifiers, etc.
Proficiency in at least 2 high level programming language such as Python and java or Scala
Mastery of scoring and statistical modeling in Python (NumPy, SciPy, pandas), MLlib, H2O
Expertise in TensorFlow, PyTorch and Keras.
Experience Building and Training NLP models; Sentimental analysis, Persona/product detection…
Experience building scalable ML services in the cloud.
Experience working with EC2 and AWS.
Curiosity in data and a strong desire to continuously improve.
Successful completion of a background screening process including, but not limited to, employment verifications, criminal search, OFAC, SS Verification, as well as credit and drug screening, where applicable and in accordance with federal and local regulations; and
The ability to obtain the necessary credit line required to travel.
Preferred Requirements
Experience with python scientific computational libs (MatplotLib, Statsmodels, Seaborn, Blaze, SymPy).
Experience with big data tools such as ELK/Kafka /Spark SQL/MLib.
Knowledge of Reactive programming.
->
Job Title: Sr. Data Scientist

Location: CA-Vancouver

Job Code: 15130
Job Description

As a global market share leader in the high-growth customer engagement market, Verint is focusing to expand our growth as a critical part of its announced plan to create two independent public companies in February 2021. As a part of this exciting growth trajectory, Verint is looking to add additional top talent to our team.

The Senior Data Scientist is a member of Verint’s Data Science team that builds cutting-edge models while digging deep into insights that can drive decisions. The Senior Data Scientist is passionate about building predictive applications and solving critical business problems and enjoys the whole data science lifecycle from ideation, data exploration, model building, results communication, all the way to productization.

Principal Duties and Essential Responsibilities:
Work with data scientists to implement new scoring capabilities.
Collaborate with big data engineers to scale existing solution.
Work on problems and data sets: pattern detection, time series forecasting, pattern recognition, natural language processing.
Help create a test case plan, quality processes and requirements for newly implemented components.
Follow and share with team members cutting-edge machine learning and deep learning research.
Minimum Requirements:
Bachelors Degree in Computer Science, Engineering, Applied Math, Statistics, Operations Research, or related field required
5+ years of experience in stats/machine learning algorithms, such as SVM, logistic regression, boosting, clustering, classifiers, etc.
Proficiency in at least 2 high level programming language such as Python and java or Scala
Mastery of scoring and statistical modeling in Python (NumPy, SciPy, pandas), MLlib, H2O
Expertise in TensorFlow, PyTorch and Keras.
Experience Building and Training NLP models; Sentimental analysis, Persona/product detection…
Experience building scalable ML services in the cloud.
Experience working with EC2 and AWS.
Curiosity in data and a strong desire to continuously improve.
Successful completion of a background screening process including, but not limited to, employment verifications, criminal search, OFAC, SS Verification, as well as credit and drug screening, where applicable and in accordance with federal and local regulations; and
The ability to obtain the necessary credit line required to travel.
Preferred Requirements
Experience with python scientific computational libs (MatplotLib, Statsmodels, Seaborn, Blaze, SymPy).
Experience with big data tools such as ELK/Kafka /Spark SQL/MLib.
Knowledge of Reactive programming.",3.4,Verint Systems,Vancouver,"Melville, NY",1001 to 5000 employees,1994,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (CAD),-1,117.0,26,data scientist,senior,0,1,0,0,0,1,1,0,0,0,0,0,1,1,1,5235,0
78,"Position Location: Office located in London, ON. Open to candidates with a 2-3 hour radius! Work from anywhere options available.

Voices.com is the #1 Online Marketplace for Sourcing Voice Over Talent.

We are looking to add a Data Analyst to our growing team to provide data-driven analysis that supports strategic decision making. This is a great opportunity to make a direct and significant impact on how Voices operates by providing and communicating valuable data insights.

Responsibilities
Act as an Analytics generalist that effectively translates Voices’ extensive datasets to the rest of the organization
Help solve organizational problems through identification of the right information to analyze, methods to use, and communication of findings to key stakeholders
Select, measure, and visualize metrics that align the organization strategically
Build prototypes of models that can be implemented to improve Voices’ product and/or internal processes
Provide analytical expertise to support departments such as Product, Technology, and Sales, as well as the organization as a whole
Support the development of business plans by forecasting outcomes, creating and governing company targets, and narrowing the knowledge gap between potential actions and results
Skills Required
Analytic, problem-solving, and strategic skills to understand, explain, and resolve complex business issues
Presentation skills demonstrating the ability to convey complex conceptual ideas
Must have experience analyzing data in R or Python
Experience using Tableau, SQL, Excel, Heap, and/or Salesforce is an added benefit
Passion for leveraging analytics to solve business problems, contributing to organizational success, and working hard to complete projects on time
Work Experience & Educational Requirements
1-5 years of experience in an analytical role
BSc or BA in business, math, statistics, analytics or a related discipline
A master’s degree in a related discipline is preferred but not required
Please provide a link to any of your analytics work (ex. Github, LinkedIn) in the portfolio section of the application
How Voices.com is supporting our colleagues through this pandemic:
Voices had all of our colleagues working from home with their laptops, monitor, accessories includes their ergonomic chairs by Monday March 16th
We maintain communication with our colleagues by putting out a good news, fun and informative newsletter type bulletin once per week
We hold virtual huddle every Monday and bi-weekly virtual Town Halls
We care about the mental health of our colleagues through our EFAP program and human connection through our optional virtual social events such as meditation, stretching, games, happy hours, etc.
Equal Employment Opportunities

Voices.com values diversity. We're proud to be an equal opportunity employer and consider qualified applicants without regard to race, color, religion, sex, national origin, ancestry, age, genetic information, sexual orientation, gender identity, marital or family status, veteran status, medical condition or disability.

Accommodation

Voices.com is committed to providing accommodation for applicants with disabilities; please let us know if you require an accommodation during the recruitment process.

Application Process

Interested candidates are encouraged to send their cover letter and resume by completing the online application. By doing so, your resume is guaranteed to be reviewed.

Only those selected for an interview will be contacted.",3.5,Voices.com,London,"London, Canada",51 to 200 employees,2005,Company - Private,Internet,Information Technology,$50 to $100 million (CAD),"Voicebox Technologies, Noble Voice, Voice Media Group",117.0,15,data analyst,na,1,1,0,1,0,1,0,0,0,0,0,0,0,0,1,3504,3
79,"Accelerating the mass adoption of electric vehicles.

GBatteries is pioneering technology which enables ultra-fast charging of Li-ion batteries without compromising battery life, and without changing the batterys chemistry or manufacturing process.

Curious for more? Read more about us in the news (https://www.gbatteries.com/newsroom).

About the role:

The Software Engineering team at GBatteries is responsible for bringing our charging technology to life. As a Data Scientist, your role will involve recognizing patterns in our vast battery database, building sophisticated models, and building the tools and systems necessary to do your work.

The ideal candidate will be extremely curious, and have a strong scientific background in machine learning, math, statistics, and be obsessed with results. You exercise very sound judgment and have the ability to balance sophistication with simplicity, scientific rigor with pragmatism, and agility with quality.

Knowledge and Skill Requirements:
Background in electrical engineering or a related field
3+ years industry experience
Extensive experience developing statistical modeling techniques for pattern recognition problems
Strong mathematics skills
Experience handling large data sets
Experience with a broad selection of machine learning algorithms
Experience architecting enterprise systems and proven ability to design and implement an end to end machine learning process
Strong Python skills required, and at least one of: PyTorch, TensorFlow, Pandas, NumPy, Keras, PySpark, Scikit-learn
What we offer

Our mission is to accelerate the mass adoption of electric vehicles to reduce global greenhouse gas emissions. Since being established in 2014, and with the only demonstrated technology capable of charging off the shelf lithium-ion batteries as quickly as filling a tank of gas, weve grown rapidly and are working with some of the largest manufacturers in the world.

We are working on many exciting projects towards our goal of breaking down the final barrier preventing the adoption of electric vehicles; range anxiety. Were a growing company, and theres still a huge amount to do. Youll be able to see the impact of your work from day one, and have the opportunity to see the final effect on real world products. We encourage unconventional thinking, and seek resilient problem solvers who arent afraid to get their hands dirty.

Of course, we also offer other great benefits:

Inclusive parking, full dental and health coverage, a renovated and spacious office, fridge and pantry filled with drinks and snacks, and regular weekly social events. Were conveniently located near the 417 highway with easy access via major public transit routes, right beside a small park and an assortment of shops and restaurants.

How to apply

Is the idea of enabling the global mass adoption of electric vehicles exciting to you? Wed love to hear from you! If you have any questions, or just want to say hello, feel free to reach out to Tim Sherstyuk on LinkedIn. To apply please include a short message addressed to Henry Rearden within the application below; no cover letter necessary.

We particularly value diversity, and we know that experience comes in many forms. If your unique experience is close to what were looking for, please still consider applying.

Powered by JazzHR",4.4,GBatteries,Ottawa,"Ottawa, Canada",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,117.0,-1,data scientist,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,1,3334,0
80,"Salary Mid-Point: $90,000

Location: Toronto ON

Job Type: Permanent

Position Title: Data Scientist

Position Type: Permanent

Location: Toronto

Our client is looking for a Data Scientist, as a Data Scientist, you will be responsible for leading, designing and developing data solutions and layering it with data science using the new gen tools and technology to support both internal and external client facing business processes. In this role the individual will work with different parts of the organization to understand the data needs and accordingly build the design and implement efficient, reliable, scalable, secure reports and analysis using big data technologies in Cloud Infrastructure to meet the business needs while complying with enterprise governed standards. This role will also be responsible for creating and building custom, re-usable interactive web based data visualizations based on statistical and mathematical modeling and data analysis to be used to solve a variety of problems related to data reporting.

To be successful in the role strong knowledge of computer applications, database management and data science concepts and tools are required. This role will also dedicate time and effort to research and pilot new techniques that will help serve our customers of data more efficiently

You will be accountable for:
Build and support data and machine learning models related to varying business applications, customer, product, sales, etc.
Research, design, and develop dashboards and web applications using data and predictions
Partner with Data Engineering team to determine the best architecture to develop data science applications
Coordinate with different functional teams to implement and automate models and measure outcome and develop processes and tools to provide data and predictions to the end users
Programming and support in writing production ready data science scripts/applications
Your experience includes:
Masters in Computer Science, Mathematics, Engineering
5+ years of experience in building machine learning / data science solutions
Must have 2+ years of experience working with cloud-based services and systems Microsoft Azure, Apache Spark, Databricks
Familiarity with relational or NoSQL database development
Data Visualisation (Plotly ,Tableau, D3.js, GGplot)
Programming languages and frameworks – Python, Scala, Spark, SQL, Java, JavaScript, JQuery, HTML, CSS, Node.js
If you are interested in this opportunity, kindly send your resumes in MS Word format to Toronto.talent@ifgpr.com today!",2.6,IFG Project Resourcing,Toronto,"Toronto, Canada",501 to 1000 employees,2006,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (CAD),-1,117.0,14,data scientist,na,0,1,0,1,0,1,1,0,1,0,0,0,1,0,0,2551,0
81,"About Us:

Established over 30 years ago, Medcan is a global leader in assessing clients' overall well-being and inspiring them to live well. Medcan has a comprehensive range of diagnostic assessments, which, in combination with innovative programs tailored to specific needs, are designed to successfully reach improved health outcomes.

Over 80 physicians and specialists, alongside a broad roster of complementary health care disciplines, provide health and lifestyle management services on site and by video consult for individuals, families and organizations. Our team of 550 staff see clients physically and virtually from our downtown Toronto location.

The Role

The Data Analyst is accountable for supporting Medcan’s data cleansing and data migration efforts. The key outcome is to have reliable data and data integrity to apply to our new infrastructure and systems.

The candidate will play a key role in supporting the development of the newly redesigned data architecture, data validation, ensuring the appropriate data points are available for reporting, and supporting the development team in readying data for system loads.

The Accountabilities
Entering data into system [Salesforce] based off revised data model and new business requests in an accurate and timely manner
Identify and support fixes to structural errors, data parsing, transformation, and duplicate elimination
Entering customer and account data from source documents – referencing legacy systems and new systems for validation and verification as well as identifying areas of missing data
Compiling data, verifying accuracy and sorting information to prepare source data for entry
Ability to validate/ challenge data model and requests. Ability to have conversations focused on verification with key business stakeholders
Support additional data auditing and workflow specifications associated to data integrity
Assist in other data entry, data-cleansing duties as required and requested
Connect and collaborate with Analytics team to ensure data sources for reporting requirements available and accurate
Keep information confidential. Comply with data integrity and security policies
The Requirements
1+ years’ experience as a Data Analyst, Business Analyst, or similar role
Ability to QA data (post-processing and additional cleansing processes), fix structural errors and data integrity issues.
Strong attention to detail
Ability to work in fast-paced environment and on project with tight delivery windows
Well versed in Microsoft Excel and data programs, experience using Salesforce is a plus
Ability to learn new systems quickly
Self-sufficient individual with the ability to work well in cross-functional teams
This is a short-term full-time contract opportunity. Preference will be given to those able to start immediately.

In your cover letter please include why you wish to align yourself with Medcan and how you believe you can add value to our organization.

We thank all applicants for their interest; however only those selected for an initial interview will be contacted. No phone calls and no agencies please.",2.3,Medcan,Toronto,"Toronto, Canada",501 to 1000 employees,1989,Company - Private,Healthcare Services & Hospitals,Healthcare,$100 to $500 million (CAD),-1,117.0,31,data analyst,na,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,3111,0
82,"Job Title
Data Scientist II

20-Jul-2020

TD Description

Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think ""TD"" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.

Stay current and competitive. Carve out a career for yourself. Grow with us. Here's our story: jobs.td.com

Auto req ID
278279BR

Country
Canada

Job Requirements
BREADTH & DEPTH: Work autonomously and accountable for acting as a lead within a specialized business management function and may provide work direction to others
• Provide seasoned specialized knowledge, advice and/or guidance to various stakeholders and team members
• Scope of role may have enterprise impact
• Focus on short to medium - term issues (e.g. 6-12 months)
• Undertake and complete a variety of complex projects and initiatives requiring specialist knowledge and/or the integration of cross functional processes within own area of expertise
• Oversee and/or independently perform tasks from end to end
• Generally reports to a Senior Manager or executive role

EXPERIENCE & EDUCATION: Undergraduate degree or technical certificate
• 7+ years relevant experience

Hours
5
Job Description

Provide technical leadership across the overall Analytics function which may have an enterprise mandate. Role generally provides deep technical knowledge and expertise in client interactions to explain complex data analysis related material

KEY ACCOUNTABILITIES

CUSTOMER: Provide insight into leading analytic practices, designs and leads iterative learning and development cycles, and ultimately produce new and creative analytic solutions that will become core deliverables
• Work closely with business owners to identify opportunities and serve as an ambassador for data science
• Design and deliver enterprise analytic solutions for customers
• Develop powerful business insights from social, marketing and industrial data using advanced machine learning techniques
• Work in a highly interactive, team-oriented environment with Big Data developers, engineers, modelers and Visualization experts

SHAREHOLDER: Build complex statistical models that learn from and scale to petabytes of data.
• Analytical thought leadership and stay current on developments in data mining and the application of data science
• Work independently as a senior lead and may manage and direct activities related to analysis, design and support of technical data management solutions on various projects ranging in complexity and size

EMPLOYEE / TEAM: Act as a technical working lead/resource to others. Work closely with senior leadership on significant projects.
• Provide thought leadership and/or industry knowledge for own area of expertise
• Support a positive work environment that promotes service to the business, quality, innovation, and teamwork; ensure timely communication of issues/ points of interest
• Identify opportunities, leverage data related solutions to drive business productivity, and implement measures to enhance effectiveness and operational efficiency
• Work effectively as a team, supporting other members of the team in achieving business objectives and providing client services
• Participate in knowledge transfer within the team and business units

Inclusiveness

At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

Work Location
TD Centre - TD Tower - 66 Wellington Street West

Business Line
Corporate

Job Category - Primary
Enterprise Data & Analytics

Job Category(s)
Enterprise Data & Analytics

**Province/State (Primary)
Ontario

City (Primary)
Toronto

Job Family
Advanced Analytics & Modelling

Time Type
Full Time

Employment Type
Regular

Apply",3.9,TD Bank,Toronto,"Toronto, Canada",10000+ employees,1855,Company - Public,Banks & Building Societies,Finance,$10+ billion (CAD),"Chase, BB&T, SunTrust",66.5,165,data scientist,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4214,3
83,"Syniti was founded to solve business’ complex data challenges, bringing synergy between data and business, delivering confidence and progress along clients’ business transformation journey. Through a combination of unique data expertise, services, and intelligent software leveraging artificial intelligence and machine learning, we help clients manage their data journey from data conversion to data quality, data archival and replication, master data management, analytics, information governance, and data strategy.

Utilizing the market’s top data specialists, validated industry knowledge and proven methodologies, Syniti has led thousands of successful data journey projects for Forbes Global 2000 organizations. SAP resells Syniti products as part of the Solution Extension Partner program.

Syniti is a purpose-driven company. “We’re embracing the future together as one – with our employees, clients and partners – accelerating global and human progress, one data challenge at a time.”

Headquartered in Boston, MA, Syniti operates in 25 countries around the globe.

Position Summary


As a Data Analyst, you will help our clients address some of their biggest data challenges. You will develop a diverse set of core consulting skills, such as business analysis, process improvement and technical expertise. You will be a key contributor to the consulting team at different phases of the project including discovery, solution generation, design/architecture and the detailing of the overall process. Over time, you’ll play a pivotal role in helping us drive the successful delivery of new solutions to our clients every day.

Primary Responsibilities:
Deliver unique technology and business solutions to clients across industries, including; Financial Services, Pharma & Life Sciences, Manufacturing and Utilities
Work closely with other consultants on customer site as a part of small to large size project teams
Participate in team problem solving efforts and offer ideas to solve client issues
Conduct requirements analysis, data analysis and create reports
Assist in the customization and configuration of the solution
Maintain responsibility for completion and accuracy of work products
Actively expand consulting skills and professional development through training courses, mentoring, and daily interaction with clients
Observe and foster best practices in business process design and implementation
Maintain engagement utilization requirement
Qualifications:


Bachelor’s Degree in Computer Science, Information Systems or related analytical or technical disciplines
1+ years of ERP techno-functional or functional experience, SAP preferred
Proficient in MS SQL (query skills, table structure and relational databases)
Experience with data quality analysis, statistical analysis and/or modeling
Experience mining and analyzing transactional electronic data with competency in one or more of the following: SAS, SQL or other software tools
Advanced proficiency with MS Office Suite, specifically Excel, Office and Word
Experience using collaboration tools such as Skype, Zoom, Hangouts, Slack etc
Proven experience effectively prioritizing workload to meet deadlines and work objectives
Demonstrated ability to present clearly, succinctly and in a manner that appeals to a wide audience
Superior customer service skills, preferably demonstrated by experience working directly with customers
Ability to adapt to changing environments and pick up new skills quickly
Excellent written and verbal communication skills
Self-starter with the ability to self-motivate in fast paced environments
Strong drive for achieving results under pressure
Syniti offers a generous benefits package that includes medical, 401k, long term disability, life insurance and a paid time off program.

If you are interested in this or any one of the exciting career opportunities at Syniti®, please go to www.syniti.com and view our Careers section, where you should complete the on-line application process.",3.6,Syniti,Moncton,"Hyannis, MA",501 to 1000 employees,1996,Company - Private,IT Services,Information Technology,$100 to $500 million (CAD),"Collabera, Commvault, LTI",66.5,24,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,3998,3
84,"Who Are We?

At National Credit Recovery Inc., our primary purpose is to serve Clients and their customers related to debt collection, debt purchasing, business process outsourcing (BPO) and litigation solutions. Our Agents are central to ensuring we are able to collect on outstanding debts effectively. They also provide the best customer service, loyalty, litigation and retention solutions possible too.

We are a global organization with multiple locations in Canada and abroad. Having a Data Analyst is essential for a BPO to improve their business and therefore, this is an integral position to our team. We are excited to provide internal and external growth opportunities as we continue to expand. National Credit Recovery Inc., is proud to offer initial paid training, monthly coaching, performance management support and ongoing learning and development opportunities. We value providing numerous employee engagement and philanthropic initiatives throughout the year also.

Who You Are:

The ideal Data Analyst is someone who has the ability to scrutinize information using various data analysis tools. Normally doing this from raw data to assist us and our clients to make decisions to further support opportunities and success in the business, identify facts and trends. It is important to have a keen understanding of what elements data can provide and have a high level of problem solving skills. It is a necessity for our ideal candidate to have a strong background in algorithm.

What Youll Be Doing:
Interpret data and analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data system
Identify, analyze, and interpret trends or patterns in complex data sets
Filter and clean data by reviewing computer reports, printouts, and performance indicators to locate and correct code problems
Work with management to prioritize business and information needs
Locate and define new process improvement opportunities
Remove corrupted data and review through root cause analysis
What You Bring:
Minimum of 1-3 years of experience as a Data Analyst in a BPO environment
Must be self-motivated and a self starter and able to work with a team
Must have knowledge with the following or similar programs of Microsoft Office, Programming languages, such as SQL, Oracle, Python and Tableau
Solid time management skills, the ability to multitask and work in a fast paced environment
Excellent verbal, written and interpersonal communication skills
Ability to organize, prioritize and adapt to change
Powered by JazzHR",3.2,NCRI,Mississauga,"Mississauga, Canada",1 to 50 employees,-1,Company - Private,Investment Banking & Asset Management,Finance,$1 to $5 million (CAD),-1,66.5,-1,data analyst,na,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,2753,0
85,"Responsibilities:

• Work closely with product owners to understand and maintain focus on their analytical needs, including identifying critical metrics and KPIs, and deliver actionable insights to relevant decision-makers

• Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance, investigating and communicating areas for improvement in efficiency and productivity

• Create and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources

• Define and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution

• Develop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets

Skills and Qualifications:

• Bachelors degree in Mathematics, Computer Science, Economics, or Statistics

• 3+ years experience mining data as a data analyst

• Proven analytic skills, including mining, evaluation, analysis, and visualization

• Technical writing experience in relevant areas, including queries, reports, and presentations

• Strong SQL or Excel skills with the ability to learn other analytic tools

• Strong knowledge on Exadata, Hive and SAS queries optimization

Preferred Qualifications

• Prior experience with database and model design and segmentation techniques

• Practical experience in statistical analysis through the use of statistical packages including Excel, and SAS

• Proven success in a collaborative, team-oriented environment

The Capgemini Freelancer Gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. The software platform leverages Machine Learning and Artificial Intelligence to make sure the right people end up in the right job.

A global leader in consulting, technology services and digital transformation, Capgemini is at the forefront of innovation to address the entire breadth of clients opportunities in the evolving world of cloud, digital and platforms. Building on its strong 50 year heritage and deep industry-specific expertise, Capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. Capgemini is driven by the conviction that the business value of technology comes from and through people. It is a multicultural company of over 200,000 team members in more than 40 countries. The Group reported 2018 global revenues of EUR 13.2 billion.",3.8,Capgemini,Brampton,"Paris, France",10000+ employees,1967,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (CAD),"Accenture, CGI, Sopra Steria",66.5,53,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,1,0,1,2768,3
86,"Educator, Data Science

BrainStation is the global leader in digital skills training and development, offering a 12-week accredited Diploma program in Data Science. BrainStation is currently seeking a full-time Data Science professional (40 hours per week) to lead the delivery of our program through online and in-person teaching. BrainStation Educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education.

Responsibilities
Lead our 12-week Data Science Diploma program
Help build a world class technical team
Deliver lectures and mentor the next wave of Data Science talent
Co-create BrainStation's full-time Data Science Program that will positively impact the lives and careers of hundreds of individuals across our campuses
Actively work on writing and researching new content to teach the most up to date skills in data science to our students
Apply BrainStation's ""Agile Education"" methodologies to the program to continuously improve the educational experience for students
Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material
Define the education experience of the future
Successful candidates will have
4+ years experience as a Data Scientist or Analytics professional and at least a Master's degree relevant to the subject matter
Experience building and leading teams
Strong command of querying and programming languages (SQL, Python, R), and visualization tools (Tableau, Python packages, etc.), as well as experience applying various methods of numerical and categorical modeling and machine learning principles
Practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner
Experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job
An empathetic, friendly, and approachable demeanor
A proven ability to work under pressure and meet deadlines
Ability to teach the entire program in English
Teaching experience in Canada preferred
While not required, a PhD would be preferred.
Perks and Benefits
Flexible Vacation Policy
Health & Wellness Programs
Culture of Learning & Development
New Shiny Device Upgrades
Compensation includes an annual salary commensurate with experience ($85K-110K) full health and medical benefits, and RRSP matching.
About BrainStation

BrainStation is a global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state-of-the-art campuses in New York, Toronto, Chicago, Vancouver, and Boston. Founded in 2012, BrainStation has worked with over 350 instructors from the most innovative companies, developing cutting-edge, real-world digital training for more than 100,000 professionals and some of the largest corporations in the world. By 2025, BrainStation will have innovation hubs around the world, and will be empowering young minds, powerful politicians, fortune 500 CEOs, and the newest wave of disruptive innovators, on campuses and online.

*Have you been to a campus or joined an online learning opportunity? We are actively seeking individuals that believe in lifelong learning and that have taken part in our On Campus or Online offerings.

NOTE: Only those applicants under consideration will be contacted. Please accept our utmost appreciation for your interest.

BrainStation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. All qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. If you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.",4.3,BrainStation,Toronto,"New York, NY",51 to 200 employees,2012,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1,66.5,8,data scientist,na,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,4106,0
87,"About Skillz:

Skillz is driving the future of entertainment by accelerating the convergence of sports, video games and media for an exploding mobile-first audience worldwide. The company's platform empowers mobile game developers and players with democratized access to fun, fair and skill-based competition for real prizes, shifting the paradigm to make eSports accessible to anyone, anywhere with a mobile device.

Skillz helps developers build multi-million dollar game franchises by turning content into competitive social gaming properties for the world's 2.6 billion gamers. The company has already worked with 13,000 game developers, leveraging its patented technology to host over 800 million tournaments for 18 million players worldwide.

This year, Skillz was recognized as one of Fast Company's Most Innovative Companies and CNBC Disruptor 50 (for the second time). In 2018, Skillz was listed as one of Forbes' Next Billion-Dollar Startups and Entrepreneur Magazine's 100 Brilliant Companies. In 2017, Inc. Magazine ranked Skillz the No. 1 fastest-growing private company in America.

The company is backed by leading venture capitalists, media companies, and professional sports luminaries, ranging from Liberty Global, Accomplice, Wildcat Capital, Telstra Ventures, and a founder of Great Hill Partners to the owners of the New England Patriots, Milwaukee Bucks, New York Mets, and Sacramento Kings.

Who we're looking for:

You're ready to take the next step in your Data Engineering career - to a fast-moving, successful company building out their next-generation streaming analytics infrastructure! You love data consistency and integrity. You consider yourself scrappy and a technologist, passionate about data infrastructure... with your attention to detail and insistence on doing things correctly, you know you can make a big impact on a small team! You're an excellent communicator and know that you grow faster from being able to mentor others.

What You'll Do:
Build new systems to provide real-time streaming analytics and event processing pipeline based on fast data architecture
Build enterprise grade data lake to support both business analytical needs and next generation data infrastructure
Building data integration toolkit for backend services
Support our data science team in deploying new algorithms for matchmaking, fraud and cheat detection
Find better ways to move massive amounts of data from a variety of sources to formats consumable by reporting systems and people
Improve monitoring and alarms that impact data integrity replication lag
Support our product development team in creating new events to measure/track
Your Skillz:

Basic Qualifications:
At least 1+ years of experience in Scala/Java or Python programming
AWS data products (Data pipelines, Athena, Pinpoint, S3, etc)
Experience deploying data infrastructure
Experience with recognized industry patterns, methodologies, and techniques
Bonus:
Familiarity with Agile engineering practices
1+ years experience on Kubernete, Helm chart
1+ years of experience with Spark, Scala and/or Akka
1+ years of experience with Spark Streaming, Storm, Flink, or other Stream Processing technologies
1+ years of experience working with Kafka or similar data pipeline backbone
1+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python
1+ years' experience with NoSQL implementation (ElasticSearch, Cassandra, etc. a plus)
At least 1 year of experience with Unix/Linux systems with scripting experience
Familiarity with Alooma, Snowflakes
Familiarity with Kinesis, Lamda
Prior experience in gaming
Prior experience in finance
Skillz embraces diversity and is proud to be an equal opportunity employer. As part of our commitment to diversifying our workforce, we do not discriminate on the basis of age, race, sex, gender, gender identity, color, religion, national origin, sexual orientation, marital status, citizenship, veteran status, or disability status.",4.2,Skillz Inc.,Vancouver,"San Francisco, CA",201 to 500 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,66.5,8,data engineer,junior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,3985,0
88,"We are searching for a talented Data Scientist to join our engineering team as we continue to expand our data science efforts. Our platform is connected to thousands of publishers and advertisers worldwide and as a result, we're dealing with millions of requests each second, making billions of decisions. We utilize the latest technologies to solve challenges in traffic, data storage, machine learning, and scalability.

Learn more about our engineering culture here: https://www.stackadapt.com/artificial-intelligence-in-advertising

Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU

Responsibilities include:

· Develop models and algorithms to maximize ROI and advertising performance
· Implement machine learning models in production, sometimes with the assistance of Data Engineers
· Implement a data analysis framework to analyze and test models effectively
· Generate insights on user behaviour and implement necessary solutions
· Be able to test results using historical data and optimize efficiently in production
We'll be reaching out to candidates who:
Have a Masters degree or PhD in Statistics, Computer Science, Operations Research, or a related field, with dual degrees preferred.
Have relevant experience as a Data Scientist
Have the ability to take an ambiguously defined task, and break it down into an insightful analysis
Are proficient with relevant data science tools such as Spark, Python (scipy, sk-learn) etc.
Have a comprehensive understanding Bayesian modeling, machine learning techniques, and optimization
Have the ability to innovate custom algorithmic solutions to machine learning problems
Understand multivariate regression, and classification
Background in advertising technology or a related field is a plus

StackAdapters enjoy:

Competitive salary with stock options
Full benefits from League on day one of employment
Fully stocked kitchen with healthy (and some not so healthy) snacks
A friendly, welcoming, and supportive culture
An awesome parental leave policy
A weekly $15 lunch credit via Ritual
Our weekly Friday social events (sometimes on our 4000sq. ft. outdoor patio)
Quarterly team events like escape rooms, bubble soccer, indoor skydiving, boat cruises, the list goes on…
About StackAdapt

StackAdapt is a self-serve programmatic advertising platform used by North America’s most exceptional digital marketers. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience. Ad buyers plan, execute, and manage data-driven digital advertising campaigns across all devices, inventory and publisher partners. Ranking a high performer by G2 Crowd in the DSP category for four consecutive years, StackAdapt is also recognized as a LinkedIn Top Startup in 2019.

Our office is located at King and Sherbourne near Toronto's historic Distillery District and the St. Lawrence Market. Our Walk, Bike and Transit Score are all over 90.

We've been recognized for our high performing campaign conversion rates, award winning customer service, and innovation by numerous industry publications including:

6th Fastest on Deloitte Technology's Fast 50 In Canada
StackAdapt’s New Chrome Extension Tackles Recruitment Bias
G2 Crowd's Highest Performing Demand Side Platform
The Globe and Mail 2019 Canada’s Top Growing Companies
Startup 50: The Complete Ranking of Canada’s Top New Growth Companies

StackAdapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. We are an equal opportunity employer and we are happy to work with applicants requesting accommodation at any stage of the hiring process. We welcome and encourage anyone and everyone to apply.",4.1,StackAdapt,Toronto,"Toronto, Canada",51 to 200 employees,2013,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1,66.5,7,data scientist,senior,0,1,0,0,0,0,1,0,0,0,0,0,1,0,1,3750,0
89,"At Ingrooves Music Group, we are committed to powering creativity in today’s dynamic music marketplace by providing the best distribution, marketing, and rights management tools and services to content creators and owners. We develop state-of-the-art, cost-efficient, and scalable technology platforms. Our partners benefit from our experienced, knowledgeable people, unparalleled commitment to customer service, and thoughtful marketing solutions that drive results. We aspire to be the most transparent and solution-driven partner for all of the labels and artists we work with.

How we LEAD:

This is an execution and delivery-oriented, highly visible role in the Insights & Analytics team with primary responsibility for building, testing, and validating scalable machine learning models that drive business-relevant insight generation. This includes development of project plans, handling of potential issues and risks, collaborating constructively with project team members, providing effective cross-functional communication, and advancing multiple projects at once.

The successful candidate will be based in Victoria, BC and their reporting line will be to the Chief Analytics Officer.

Success at Ingrooves

Business Acumen

The successful candidate aligns with the Ingrooves culture by being solution-oriented, collaborative, leveraging best practices, and possessing a passion for both technology and music.

Interpersonal/Communication Skills

The successful candidate will be open-minded with a natural curiosity of internal and external customer, delivery oriented with an understanding of the product development process and will build and foster strong relationships and effective partnerships with cross-functional teams.

Executing for Results

The successful candidate will demonstrate the ability to generate and translate strategic plans into actions with timely execution and accountability.

Leadership/Collaboration

The successful candidate establishes and maintains positive working relationships, operates with integrity, influences and supports others, and remains open to ideas.

Problem Solving

The successful candidate will be tenacious and self-motivated and have a demonstrable record of resolving issues and providing effective solutions. They demonstrate eagerness and an ability to learn quickly and leverage a flexible mindset in response to shifting dynamics, adversity and/or change.

How you’ll CREATE:
Design, build and deploy machine learning models at scale
Collaborate closely with product teams to provide high-level AI-driven services for music content owners
Integrate with external and internal APIs and data sources to augment music consumption data to uncover shifting market trends, new opportunities, operational efficiencies and revenue streams
Create data-rich informative visuals and documents to articulate and convey complex concepts to executive leadership team and label partners
Contribute to and enable a positive work environment which highly encourages creative input and constructive criticism from all team members
Other duties as determined by the Chief Analytics Officer
Bring your VIBE:
Earned degree (MS or BS + 2 years corporate experience) in a highly quantitative discipline (e.g., machine learning, statistics, computer science, applied mathematics, theoretical physics, physical chemistry, econometrics)
Demonstrated experience developing or applying machine learning algorithms to deliver robust predictions and inferences in a production scale environment
Strong software development skills, with demonstrated ability to implement inferential and predictive models in a production environment.
Knowledge of at least one data science programming language (e.g. Python, R, Julia, etc.) and relevant data science and visualization libraries (scikit-learn, pandas, ggplot, etc.)
Experience with AWS (i.e., EC2, S3, RDS, Redshift, EMR) or similar cloud computing services is a plus
Knowledge and experience of writing and tuning SQL
Excellent communication and exposition skills with the ability to explain and present complex analyses and machine learning concepts to a broad audience, both technical and non-technical, in EnglishDemonstrated ability to work creatively and deliver within highly collaborative work environments while remaining product-focused",3.5,Ingrooves,Victoria,"Los Angeles, CA",51 to 200 employees,2002,Company - Private,Music Production & Distribution,Media,$100 to $500 million (CAD),-1,66.5,18,data analyst,na,0,1,0,0,0,1,0,1,0,0,0,0,1,0,1,4333,0
90,"Closing Date: August 31, 2020

With a strong history of innovation for over 100+ years, we are Canada’s largest diversified natural resource company looking to embark on our next chapter.

Being part of the RACE21™ team, you’ll be leading the charge of a company-wide renewal of technology and infrastructure – a high-tech transformation of mining into the next generation.

With the financial backing and commitment from our leadership, we envision a fully-integrated agile digital platform that will:

• Renew, Automate, and Connect material, processes, equipment flows, and data systems to expand and enable a broad application of advanced analytics, robotics, and artificial intelligence

• Empower our employees by investing in digital skills and capabilities to enhance creativity and innovation – increasing sustainability, safety, and performance in real time, unlocking resource base knowledge and improving planning for optimal resource extraction

We are world-class leaders in sustainability and safety – and we are building a better world for the next generation with lasting competitive advantages, from 2021 and beyond.

Reporting to the Manager of Technology, the Data Scientist, RACE21 brings deep understanding of big data to the teams, and helps in building and enabling big data analytics solutions. They apply complex and most current modelling techniques to existing data sets in order to find optimization and or improvement opportunities relevant to the context of the product being developed.

Responsibilities:
Be a courageous safety leader, adhere to and sponsor safety and environmental rules and procedures
Designs, develops, and implements end-to-end cloud based machine learning production pipelines (data exploration, sampling, training data generation, feature engineering, model building, and performance evaluation)
Ensures that data pipelines are scalable, repeatable, and secure, and can serve multiple users within the company
Enables big data and batch/real-time analytical solutions that leverage emerging technologies
Collects, parses, manages, analyzes and visualizes large sets of data using multiple platforms
Translates complex functional and technical requirements into detailed architecture, design, and high performing software
Codes, tests, and documents new or modified data systems to create robust and scalable applications for data analytics
Implements security and recovery tools and techniques as required
Works with fellow Data Scientists and Engineers to ensure that all data solutions are consistent
Ensures all automated processes preserve data by managing the alignment of data availability and integration processes
Develops standards and processes for integration projects and initiatives
Qualifications:
Master’s or PhD Degree in Information Technology, Computer Science, or a related quantitative discipline
Minimum five years of experience in data science
Understanding of high performance algorithms and R statistical software
Experience in industry data science (e.g., machine learning, predictive maintenance) preferred
Capability to architect highly scalable distributed systems, using different tools
Demonstrated experience with object oriented design, coding and testing patterns as well as experience in engineering software platforms and largescale data
Expert knowledge of data modeling and understanding of different data structures
Strong understanding of Agile methodologies
Experience as a Data Scientist on an agile team or other rapid development methods preferred
Excellent problem solving, critical thinking, and communication skills
Experience in developing presentations and communications to be shared with internal and external stakeholders
Brings a high energy and passionate outlook to the job and can influence those around them
Able to build a sense of trust and rapport that creates a comfortable & effective workplace
Passion for innovation and “can do” attitude
A valid driver's licence might be required
Ability to travel to our sites in British Columbia 20-40% of the time
At Teck, we value diversity. Our teams work collaboratively and respect each person’s unique perspective and contribution.

Qualified applicants interested in joining a dynamic team are encouraged to submit a resume and cover letter electronically.

We wish to thank all applicants for their interest and effort in applying for the position; however, only candidates selected for interviews will be contacted. Your application to this posting is deemed to be your consent to the collection, use and necessary disclosure of personal information for the purposes of recruitment. Teck respects the privacy of all applicants and the confidentiality of personal information.

Teck is a diversified resource company committed to responsible mining and mineral development with major business units focused on copper, steelmaking coal, zinc and energy. Headquartered in Vancouver, Canada, its shares are listed on the Toronto Stock Exchange under the symbols TECK.A and TECK.B and the New York Stock Exchange under the symbol TECK.

The pursuit of sustainability guides Teck’s approach to business. Teck is building partnerships and capacity to confront sustainability challenges within the regions in which it operates and at the global level. In 2019, Teck was named to the Dow Jones Sustainability World Index (DJSI) for the tenth straight year, indicating that Teck’s sustainability practices rank in the top 10 per cent of the world’s 2,500 largest public companies in the S&P Global Broad Market Index.

Learn more about Teck at www.teck.com or follow @TeckResources

#LI-AMN",3.7,Teck Resources Limited,Vancouver,"Vancouver, Canada",5001 to 10000 employees,-1,Company - Public,Mining,Mining & Metals,$10+ billion (CAD),-1,66.5,-1,data scientist,na,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,5643,0
91,"The Career Opportunity:

Data Scientist & Marketing Cloud

rickis.com is the established and expanding online channel of Ricki’s fashions Inc.

cleo.ca is the established and expanding online channel of cleo fashions Inc.

We are looking for an experienced and innovative Data Scientist & Marketing Cloud to represent both Ricki’s and cleo. This position is based in Ricki’s Home Office located in Winnipeg, MB.

The Data Scientist & Marketing Cloud will consult and partner with internal and external stakeholders to review, analyze, provide recommendations and execute changes in order to improve and further enhance product data. The successful candidate is self-motivated and focused technical services enthusiast with a passion for cutting edge digital marketing technology. Must possess exceptional written and verbal communication skills and a thirst for knowledge with a sharp eye for detail.

Main Responsibilities:
Collaborate with internal and external stakeholders to develop and support overall digital transformation of the Ricki’s and cleo brands through the use of technology.
Collaborate closely with Marketing and E-commerce team members on development of the web user experience, delivery and maintenance
Effectively communicate using data storytelling
Proactively identify opportunities and make recommendations to improve product data
Troubleshoot and solve product data issues
Identify and resolve product listing issues: product details, descriptions, performance, measurements, images
Discern which problems are important to solve for the business and identify new ways the business should be leveraging its data.
Work with product specialists and suppliers to enrich product data from various data sources
Optimize existing product listings using basic knowledge of keyword research, image enhancement, copy-write and product search rankings
Design and build journeys like welcome series, cart reminders, promotions, and reactivation/retention campaigns.
Create and review dashboards and reports to help analyze performance and discover where improvements to performance can be made.
Monitor and maintain data quality for both brands’ marketing databases.
Prepare, test and deploy campaigns utilizing emails, workflows, landing pages, and forms.
Help drive business decision-making by educating and informing teams on digital metrics
Use a variety of software tools, such as spreadsheets, databases, reporting and analytical software to assemble and format data and reports
Develop end to end process documentation for product data management
Establish regular reporting activities for internal and external stakeholders
Work with IT and technical teams to define and automate regular tasks and reporting
Educate team members through training and individual support.
Design solutions to address business needs using Salesforce Marketing Cloud.
Other duties as assigned.
Qualifications:
3-5+ years-experience in product information management
Secondary education in Computer science, Social sciences, Physical sciences, or Statistics.
Have a working knowledge of SQL, CSS, HTML;
Exposure to Salesforce Marketing Cloud (and/or other cloud marketing technology) a plus
Knowledge of mobile, social, and ecommerce marketing;
Experience with various templating languages such as PHP, ASP.NET, and Jinja;
Knowledge of various mobile, social, and ecommerce platforms..
Salesforce Certified Email Specialist or Marketing Cloud consultant certification a plus.
Must be a motivated self-starter with strong interpersonal skills.
Strong communication skills, verbal and written.
Strong organizational skills, attention to detail, and ability to multi-task and shift between projects on a time-sensitive basis.
Strong understanding working with Unstructured Data
Knowledge of Electrical, Comm/Data and Automation products an asset
Advanced Excel skills
Experience working as a member of an e-commerce team a plus.
Understanding of digital technologies as they relate to analytics on an ecommerce site
Knowledge of SEO tools
Strong Project management skills
Experience working with Business Intelligence Tools
We thank all applicants for their interest however, only those selected for an interview will be contacted. Ricki’s/cleo is an equal opportunity employer. If chosen to participate in the selection process, accommodations are available upon request. We will consult with the applicant to provide or arrange suitable accommodation in a manner that takes into account the applicant’s accessibility needs",3.7,Ricki's,Winnipeg,"Trail, Canada",1001 to 5000 employees,-1,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1,66.5,-1,data scientist,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,4521,0
92,"Terms of employment: Full time, permanent


Job location: 510 West Georgia Street, Vancouver, V6B 0M3

The Smart Home team is focused on making Alexa the user interface for the home. From the simplest voice commands (turn on the lights, turn down the heat) to use cases spanning home security, home entertainment, and the home environment, we are evolving Alexa into intelligent, indispensable companion that automates daily routines, simplifies interaction with appliances and electronics, and alerts when something unusual is detected.

You will be part of a team delivering features that are highly anticipated by media and well received by our customers. Here are a few links that highlight working with Alexa.
Meet the Alexa Software Team:
https://www.youtube.com/watch?v=KpXEsrjcj6Y
Charlie Kindel, Director, Alexa Smart Home, CEDIA Keynote:
https://www.youtube.com/watch?v=tatp2M5hG-M
Amazon Echo Emerges as a Surprise Leader in Smart Home Platform War:
[url=https://www.forbes.com/sites/aarontilley/
You can make your Amazon Alexa Smarter:
[url=http://fortune.com/video/
How to make the Amazon Echo the Center of Your Smart Home:
[url=http://www.wired.com/


As a Machine Learning Scientist, you will work with software developers and other teams to design and implement NLU models for how customers use and interact with smart devices in their homes. You will help lay the foundation to move from directed device interactions to learned behaviors that enable Alexa to proactively take action on behalf of the customer. And, you will have the satisfaction of working on a product your friends and family can relate to, and want to use every day. Like the world of smart phones less than 10 years ago, this is a rare opportunity to have a giant impact on the way people live.

Salary $97,800 to 163,800/yr, commensurate with experience


Basic Qualifications

· Master or PhD in Computer Science, Machine Learning, Statistics or a related quantitative field.
· 4+ years of hands-on experience in applied machine learning, and predictive modeling and analysis.
· Algorithm and model development experience for large-scale applications
· Experience using Python, or other programming or scripting language, as well as with R, MATLAB.
· Solid understanding of foundational statistics concepts, NLU and ML algorithms: linear/logistic regression, random forest, boosting, GBM, NNs, etc.
Language required for job: English



Preferred Qualifications

All applicants must meet qualifications above.


Benefits: Amazon provides a full range of benefits for our global employees and their eligible family members. Eligible employees may also receive signing bonuses and Amazon Restricted Stock Units. This position is eligible for further pay increases and bonuses at the company's discretion. While they might vary from location to location, Amazon benefits for Canada may include:


· Health Care
· Savings Plans
· Income Protection
· Paid Time Off
· Employee Stock
· Signing Bonuses

Amazon offers competitive packages, growth potential and a challenging and exciting work environment. Amazon and its affiliates are Equal Opportunity Employers. Visit www.Amazon.com/careers for more information.",3.9,Amazon,Vancouver,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (CAD),"Google, Microsoft, Walmart",66.5,26,data scientist,na,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,3197,3
93,"About Us

We are changing the way utilities and industry manage our most precious resource: water. We provide water facilities with an Artificial Intelligence driven platform to help their staff make smarter decisions in real-time when operating their critical processes (i.e. water treatment, pumping etc). In doing so, we are able to help facilities drive down their costs, enhance reliability and reduce risks to public safety.

We are thinking about the future, too: by using AI we are reimagining how the operational staff of the 21st century will interact with critical infrastructure.

The Right Candidate

We are looking for impact-minded people who are passionate about making the world a better place through Artificial Intelligence. As a Data Engineer in EMAGIN, you will be responsible for building data pipelines behind billions of dollars in critical water infrastructure for Fortune 500 companies. We are looking for ambitious, energetic, and talented individuals to join our purpose-driven community bridging the technical and business worlds to deliver products for the global water sector. You will have the opportunity to lead teams in building mission-critical systems and services for high profile clients globally using cutting-edge cloud technologies in an agile environment.

What You Will Do
Work with back-end developers and data scientists to develop, deploy, and test scalable, fault-tolerant, machine learning pipelines
Deploy and test robust, computationally intensive technologies enabling real-time responses from machine learning models
What You Will Need
3+ years experience with Python
Experience with Python Data science libraries (numpy, pandas, tensorflow/pytorch, scikit-learn, etc)
Experience with SQL and NoSQL databases
Proficiency in a statically typed language (Java, C, Julia) and Bash shell scripting
Experience working with CI/CD and containerization tools such as GitLab, Jenkins, Kubernetes, and Docker
Knowledge of optimization, classification, clustering, and other machine learning concepts
Nice to Have
Experience with cloud technologies, specifically AWS
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Demonstrated experience developing production level code
Strong project management and organizational skills
Experience supporting and working with cross-functional teams in a dynamic environment
Why we think you will love working with us

Build something that makes a difference in the world. Have a big impact at an early-stage, VC-backed software startup. Work with a tight-knit community of experienced entrepreneurs and technologists creating socially-mindful technology. Learn and apply cutting-edge technology to meaningful problems.

Other perks include:
Employee Stock Option Plan
Competitive Salary
Regular social events
Flexible hours
Centrally located at the Tannery District in Ontario's start-up city alongside Google, D2L, Shopify.
If this sounds like your kind of challenge and you have the relevant experience to take them on, get in touch! Please apply with your résumé/CV and any links (GitHub)/attachments about relevant projects and related work.",4.0,EMAGIN,Kitchener,"Kitchener, Canada",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,66.5,4,data engineer,na,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,3180,0
94,"IT/IQ Tech Recruiters is seeking a Data Scientist to Work Remotely for our client.

Why work with our client?
100% Remote
Competitive rates
Possible extensions
Responsibilities
Build machine-learning models
Create regression, classification models; Work with engineering teams to deploy robust, highly available decisioning pipelines based on your models.
Analyze large amounts of information to discover trends and patterns
Combine models through ensemble modeling
Present information using data visualization techniques
Processing, cleansing, and verifying the integrity of data used for analysis. Undertake pre-processing of structured and unstructured data
Top Skills Required
Business acumen and communication skills to gather the data requirement from the business
3+ years of related professional work experience
Theoretical and execution background of Data Science with specific focus on Machine Learning
Experience testing and validating models and assessing the trade-offs between different modeling techniques and specifications
Comfort manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources
Strong analytics and problem-solving skills needed. Can take the data and come up with a solution specific to the use case
Experience in applying statistical learning methods to solve business problems
Experience working with complex and/or large data sets
Practical ability to visualize data, communicate the data, and utilize it effectively
Programming skills – 2 years (In-depth knowledge of Python, Pandas, and its open-source ecosystem or similar)
Proficiency in using query languages such as SQL, Hive, Pig, Sqoop.
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase and SQL databases and unstructured data stores
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naïve Bayes, SVM, Random Forests, etc.
NLP / NLU experience preferred.
Must be legally eligible to work in Canada
Why work with us?
Build a long-term relationship with an experienced recruitment expert
Access to the ‘hidden’ job market – opportunities across Canada that aren’t posted on job boards
Get a high-level understanding of market dynamics affecting your industry
Gain insight into the culture of the company you’re applying for before submitting your profile
About Us

IT/IQ Tech Recruiters provides contract and permanent IT recruitment services to employers across Canada. We have a specialized approach to recruiting, segmenting our recruitment teams into specialty practice areas focusing on Development, PMO, Infrastructure and BI/CRM/ERP skill sets.

This approach enables our recruiters to become specialists; they know the market and work hard to understand each candidates’ capabilities, goals, career ambitions and quickly present them with the best possible opportunities. We are committed to helping candidates develop their careers and to helping our clients grow their business and complete important projects successfully.

We create opportunities for IT Professionals to empower business.",2.8,IT IQ TECH RECRUITERS LTD,Vancouver,"Vancouver, Canada",1 to 50 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (CAD),"Randstad, TEKsystems, TEEMA Solutions Group",66.5,18,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,3077,3
95,"As a Senior Data Scientist at Vendasta you will ask questions and discover meaningful answers that drive Vendasta’s growth and success. You will work closely with the leadership team in sales, success, product, and more to develop robust research questions and contribute to all steps of the data analysis process, including: hypothesis generation, exploring and cleaning data, modelling/interpreting/communicating results, and measuring their implementation. Finally, you will leverage the interdepartmental analyst group to review, develop, and share information or analyses that help one another learn and grow in data & business intelligence, as well as help the company grow and evolve. The selected candidate must enjoy coordinating with interdisciplinary teams, learn quickly, and be comfortable working independently!

Responsibilities
Respond to ad hoc requests from various stakeholders
Follow Vendasta’s analysis workflow
Hypothesis Generation: Work with stakeholders to refine and transform questions into hypotheses
Exploratory Data Analysis: Gather, clean, and explore large data sets
Model Building: Create a visual and/or mathematical representation of the real world
Interpret Results: Understand the conclusions that can be reached and know the implications
Communicate Results: Deliver findings to stakeholders
Follow-up: Ensure that the data was effectively implemented and measure results
Build, maintain & monitor internal dashboards for each department to track productivity, revenue, quality, staffing patterns, expenses, efficiency metrics and more
Provide prompt reports on monthly, quarterly, and yearly information
Provide analytical support and identify business trends that require action
Review and critique other’s analysis
Develop and foster a working relationship with other analysts, software developers, product managers, sales, marketing, and executive
Become the expert in multiple data sources and create/implement innovative and sustainable solutions
Participate in process improvement initiatives and assist in automating processes currently requiring manual efforts

Skills & Qualifications
3-5 years experience in data analysis
Demonstrated expertise with databases and various querying techniques (SQL, NoSQL, API)
Strong understanding of statistical inference and descriptive statistics
Demonstrated ability to retrieve and clean data by whatever means is necessary
Proven ability to analyze and report information
Well developed communication and presentation skills
Ability to engage in multiple initiatives simultaneously while working in a dynamic environment subject to impromptu changes in schedules and priorities
Strong initiative – establish goals and take responsibility for meeting them within defined timelines",4.3,Vendasta Technologies,Saskatoon,"Saskatoon, Canada",201 to 500 employees,2008,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (CAD),-1,66.5,12,data scientist,senior,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,2767,0
96,"About Us

We are changing the way water utilities and heavy industry manage our most precious resource: water. We provide water facilities with an Artificial Intelligence-driven platform to help their operational staff make smarter decisions in real-time when operating their critical processes (i.e. water treatment, pumping etc). In doing so, we are able to help facilities drive down their costs, enhance reliability and reduce risks to public safety.

The Right Candidate

We are looking for impact-minded software engineers – those who are passionate about making the world a better place through Artificial Intelligence. As a Machine Learning Engineer at EMAGIN, you will be responsible for deploying the data architecture behind billions of dollars in critical water infrastructure for Fortune 500 companies. We are looking for ambitious, energetic, and talented individuals to join our purpose-driven community as you bridge the technical and business worlds to deliver products for the global water industry. You will have the opportunity to build mission-critical systems for global high profile clients using cutting-edge cloud technologies in an agile environment.

What You Will Do

As a Machine Learning Engineer, you play a major role in a team of developers and engineers in deploying and supporting EMAGIN’s Hybrid Adaptive Real-time Intelligence (HARVI) application.

Work with domain experts to analyze and manage time-series data from the global water industry.
Work with data engineers, data scientists and domain experts to build, evaluate, deploy and maintain high-performance machine-learning models.
Work with back-end developers to design and build scalable and robust, computationally intensive technologies for near real-time execution.


What You’ll Need

Bachelors or advanced degree in Computer Science, Software Engineering, Data Science, Statistics/Mathematics or equivalent is required.
Masters level degree in Data Science (nice to have).
3+ years of experience with for data science and/or software engineering
Experience with Python Data science libraries (numpy, pandas, scipy, tensorflow/pytorch, scikit-learn, etc)
Proficiency in Python, Java, Scala, R, or equivalent
Extensive experience connecting to various data sources and structures: APIs, SQL, NoSQL, Blob Storage, etc.
Experience in the end to end modelling process (data analysis, data cleaning, feature engineering, modelling, testing/validation)
Experience building a time-series model using ML algorithms (preferred)
Strong knowledge of optimization, classification, clustering and other machine learning technologies
Experience supporting and working with cross-functional teams in a dynamic environment

Why we think you will love working with us.

Build something that makes a difference in the world. Have a big impact at an early-stage, VC-backed software startup. Work with a tight-knit community of experienced entrepreneurs creating socially-mindful technology.

Other perks include:

Employee Stock Option Plan
Competitive Salary
Monthly social events
Flexible hours
Centrally located at the Tannery District in Ontario's Start-up city alongside Google, D2L, Shopify.

If this sounds like your kind of challenge and you have the relevant experience to take them on, get in touch! Please apply with your résumé/CV and any links (Github)/attachments about relevant projects and related work.",4.0,EMAGIN,Kitchener,"Kitchener, Canada",1 to 50 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,66.5,4,machine learning engineer,na,0,1,0,0,0,1,0,0,0,0,0,0,1,0,1,3400,0
97,"RESPONSIBILITIES:
Develop state-of-the-art computer vision algorithms for object detection, classification, and face recognition.
Prototype hardware and software solutions for object detection, classification, and face recognition.
Develop and implement scalable and efficient modeling algorithms that can work with large-scale data in production systems.
Collaborate with product management and engineering groups to develop new products and features.

SKILLS AND QUALIFICATIONS:
PhD or MS degree in Computer Science, Electrical Engineering, Statistics, Applied Math, or other related fields.
Expertise in deep learning, deep neural networks, convolutional neural networks, Artificial Intelligence and/or related techniques.
Proficient in one or more programming languages such as Python and Java.
Familiarity with one or more neural network frameworks such as TensorFlow, Caffe or MXNet.
Strong analytical and quantitative problem solving ability.
Excellent communication, relationship skills and a strong team player.
Preferred Qualifications
Experience with big data techniques (Hadoop, MapReduce, Spark).
Experience with relational (SQL) and NoSQl Databases.

compensation:
TBD

How to apply:
Please send your resume to hr@awakedata.com",-1.0,Awaked,Canada,"Burnaby, Canada",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,66.5,-1,data scientist,na,0,1,0,0,0,1,1,0,0,0,0,0,0,1,1,1241,0
98,"Data Analyst
Full-Time | Engineering | Regina, SK

**In light of recent developments surrounding the COVID-19 pandemic, our hiring team has temporarily placed this role on hold. During this time, our hiring team will not be scheduling phone screens, conducting interviews, or extending employment offers - however, we still encourage you to apply! We are monitoring the situation very closely, and have plans to reach out to candidates once the situation regarding COVID-19 becomes more clear.**

At GasBuddy, we take pride in helping people by building innovative and comprehensive products for millions of gas station owners, fuel retailers, and drivers every day - our world-class team is always up to the challenge. GasBuddy is a place that empowers employees to grow, build, and thrive. Whether we’re pulling data from our database of 5 terabits of data or competing in ping pong tournaments, you’ll be a part of a team that puts in 110%.

As a Data Analyst at GasBuddy, you will be working directly with Data Developers and Data Scientists in collecting, maintaining, and analyzing data that can be translated into insights to guide our business strategy as well as inform product development efforts. You’ll be tasked with answering data-related questions in the form of charts, graphs, tables, and dashboards that can be presented to the company. In addition to technical skills, we’re looking for analysts who can communicate clearly and express ideas in verbal discussion, client communication, technical documentation, and architectural reviews. The ideal candidate will have a data-orientated personality and an excellent eye for details.

What You’ll Do:
Interpret data, analyze results using statistical techniques and provide ongoing reports.
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.
Use data to answer key questions about the business.
Identify, analyze, and interpret trends or patterns in complex data sets
Work with management to prioritize business and information needs.
Own and maintain dashboards, ongoing reports, and ad hoc requests from the organization.
Identify key business levers, establish cause & effect, perform analyses, and communicate key findings to various stakeholders to facilitate data driven decision-making
What You Need:
2+ years of experience in data, analytics, or a related function involving quantitative data analysis to solve problems.
Technical expertise regarding data models, database design development, data mining and segmentation techniques.
Strong knowledge of and experience with business intelligence and data visualization tools (DOMO, Tableau etc), databases (Amazon Redshift, Postgres etc), and programming (SQL, Python, R etc).
Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, SPSS, SAS etc).
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
About GasBuddy
For budget-minded drivers, GasBuddy is the travel and navigation app that is used by more North American drivers to save money on gas than any other. Unlike fuel retailer apps, as well as newer apps focused on fuel savings, GasBuddy covers 150,000+ gas stations in North America, giving drivers 27 ways to save on fuel. That’s why GasBuddy has been downloaded nearly 90mm times – more than any other travel and navigation app focused on gas savings. GasBuddy’s publishing and software businesses enable the world’s leading fuel, convenience, QSR and CPG companies to shorten the distance between the North American fueling public and their brands.

GasBuddy is proud to be an Equal Opportunity Employer. We don’t just accept difference – we celebrate it and thrive on it. We endeavour to be a diverse workforce that is representative, at all job levels, of the consumers we serve. Qualified applicants will receive consideration for employment without regards to race, colour, religion, sex, age, disability, military status, national origin, or any other characteristic protected under federal, provincial, or applicable local law.",3.4,GasBuddy.com,Regina,"Boston, MA",51 to 200 employees,2000,Company - Private,Oil & Gas Services,"Oil, Gas, Energy & Utilities",Unknown / Non-Applicable,-1,66.5,20,data analyst,na,1,1,0,1,0,1,0,0,0,0,0,0,0,0,1,4218,0
99,"The role is responsible for designing, developing, manipulating and maintaining financial reporting systems, as well as interpreting data that influence and drive decisions. This includes identifying needs, creating process improvement solutions, working with multiple stakeholders and maintaining collaborative relationships with business partners.

To be successful in the role, the candidate brings a solid working knowledge of SQL, Tableau, Python and process automation. In addition, the candidate is a self-starter with a passion for providing various ways to improve effectiveness within the business.

You will be accountable to:
• Meet with various business units to understand their needs, identify the business problem, determine, define and deploy predictive/prescriptive analytic solutions to meet business objectives.
• Prepare, extract data and perform data manipulation by using various programming language (SQL, Python etc.).
• Use machine learning methods or other data mining techniques to get insights from massive datasets.
• Work closely with data analysts, data engineers, data scientist and other team members on projects and ad-hoc requests.
• Communicate approaches, findings and recommendations to business stakeholders.
• Strictly adhere to legal and compliance guidelines regarding access and exposure to sensitive and confidential information.

Your experience includes:
• Bachelor or Masters’ degree in an analytical field of study e.g. Engineering, Mathematics, Business Analytics, Finance, Computer Science.
• 3 - 5 years of work experience directly related to quantitative analysis, with proven results.
• Familiar with tools such as SQL/Python/Data Bricks or other tools for large scale data analysis.
• Solid knowledge and some hands-on experience with various machine learning algorithms e.g. time series analysis, anomaly detection, cluster analysis, decision trees, random forest, SVM.
• Superb analytical and conceptual thinking skills to not only manipulate but also derive meaningful interpretations from data.
• Ability to take initiative, multi-task, and is a good team player in a fast-paced environment.
• Strong detail orientation is essential in this role.",3.2,Moneris Solutions Corporation,Etobicoke,"Etobicoke, Canada",1001 to 5000 employees,2000,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1,66.5,20,data analyst,na,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,2205,0
100,"ABOUT MOBSQUAD

We are a well-funded, hyper-growth, scale-up looking for an experienced Machine Learning Engineer. If you've ever dreamed of working with a top tier technology company scale-up, on leading edge technologies, backed by the very best venture capitalists in the world, then this is your chance.

Some details about MobSquad:
MobSquad solves the significant and growing technology talent shortage faced by US-based start-ups and scale-ups by enabling our clients to quickly have a turnkey ""virtual"" Canadian subsidiary, where Canadian-based software engineers serve our clients individually on an exclusive basis
We've been featured on the front page of The Washington Post, on NPR multiple times, The Financial Times (UK), The Globe and Mail, the Calgary Herald, BetaKit, CBC, Global News, and many other places. other media outlets
We're a Certified B Corporation, were recognized as the third Best Place to Work in Canada in 2020, and have made numerous contributions to charitable organizations as well as a financial commitment to the Upside Foundation. We believe we are playing a key role in enhancing Canada's innovation economy, and have received financial support from the Government of Canada, Province of Alberta, Province of Nova Scotia, and City of Calgary, to support this ambition
You can learn more about us on our website
ABOUT THE ROLE

As a Machine Learning Engineer, you will be part of a Canada-based team working remotely for a leading US start-up. Your team will operate alongside many other talented developers and data scientists in Canada, and you will be an integral part of the tech community that MobSquad has built.

This role requires someone who has demonstrated an ability to use data to train models which can be used to automate processes such as image classification, speech recognition, and forecasting. The ideal candidate has deployed or attempted to execute Artificial Intelligence theories from various Machine Learning (ML) models and algorithms, and they also have familiarity with data science engineering. The candidate should be able to apply their analytical skills to develop large-scale ML models that reveal the value in data. They are able to understand business objectives from a broader team and build customized models and processes to enable delivery of the business objectives.

ABOUT YOU
You have an advanced degree (M.S. or PhD) in Computer Science, Engineering, Mathematics, Physics, or a comparable analytical field from an accredited institution
You have over five years of experience working with deep learning frameworks (TensorFlow, Keras)
You have over five years of experience with relevant languages (Python, Java) and libraries (scikit-learn, Pandas)
You have over five years of experience developing unique algorithms
You have strong experience creating and deploying machine learning models
You have demonstrated knowledge of relevant libraries and operating systems (OpenCV, Linux)
You have knowledge of SQL (MySQL, PostgreSQL) and NoSQL (MongoDB, Cassandra, HBase) databases
You have strong attention to detail, translating to strength in data quality verification to enable clean data at all times
You have work/project history reflective of a self-motivated professional who excels when given open-ended problems and broadly-defined goals, having an innate desire to build models and algorithms that reveal the patterns and relationships in data that can be leveraged to provide business value
WHAT YOU'LL GET @MOBSQUAD
A full-time position that offers competitive compensation
A benefits program delivered through our bespoke digital platform, giving you control, choice, and flexibility. We give you the ability to build your package of benefits covering health (e.g., medical, dental, vision), wellness (e.g., gym, workout gear, massage, transit), and RRSP (retirement savings)
A downtown office location with first-rate amenities, surrounded by great restaurants and easily-accessible transit
For international candidates, sponsorship for an immediate work permit, expedited permanent residency, and Canadian citizenship within four years
At MobSquad, we support and encourage building a work environment that is diverse, inclusive, and safe for all. We invite and welcome applicants of all backgrounds, regardless of race, religion, sexual orientation, gender identity, national origin, or disability.",4.4,MobSquad,Vancouver,"Calgary, Canada",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,66.5,-1,machine learning engineer,na,0,1,0,0,0,1,0,0,0,0,0,0,1,1,0,4393,0
101,"August 12, 2020 - 23:59 EST

Diversity and Inclusion
As one of Canada’s Top 100 Employers, we offer you a superior work environment that allows you to reach your full potential both professionally and personally. We make career growth and professional development a priority. We are committed to developing inclusive, barrier-free recruitment and selection processes, and a work environment that supports our diverse workforce.

Let our team know if you need accommodation or support during the recruitment process due to a disability or other reason. We can provide support in multiple ways, from using this site and submitting your application, right through to the interview process. If you are the successful candidate, you can also discuss accommodation needs when you receive your offer.

Contact accessiblecareers@bankofcanada.ca to discuss how.

Data Engineer

Take a central role
The Bank of Canada has a vision to be “a leading central bank—dynamic, engaged and trusted—committed to a better Canada.” No other employer in the country offers you the unique opportunity to work at the very center of Canada’s economy, in a diverse and inclusive organization with significant impact on the economic and financial well-being of all Canadians. You will be challenged, energized and motivated to excel in an environment where we are reinventing central banking, renewing ways of doing business and reinforcing a culture of innovation.

Find out more about the next steps in our Recruitment process.

Did you know?
The Bank is undertaking an evolution of its data management infrastructure and exploring new data and analytics technologies (i.e. machine learning, AI, RPA) to empower the next generation of economic analysis and insight. This role will be present as our current data and analytic infrastructure is enhanced to meet the demands of a modern data-centric Central Bank.

What you will do
The Bank of Canada’s Information Technology Services (ITS) Analytics Environment and Currency Portfolio provides the applications, software and hardware to support the business functions of the Bank’s Currency and Economic departments.
As a data engineer (DE) within the Analytics Environment and Currency Portfolio you are part of a dedicated and innovative team that maintains, integrates and builds solutions key to our internal and external stakeholders.

As part of the evolution of the workforce, “Data” is a critical skill area that is increasingly and broadly required at the Bank. The DE role will bridge the gap between the infrastructure Database administrators (DBA), the Application Architects and the Developers. The focuses are on obtaining data from a variety of different sources, in the right formats and data quality standards, resolving any information flow or content issues and ensuring data transformation using various types of data processing pipelines.

You will collaborate with architects, scrum masters, product owners, and other team members in an Agile environment to deliver maintenance support, testing services, bug fixes, and optimizations of existing application integrations, and to engineer and support data pipelines from acquisition to discovery. You will write automated tests for new and existing software systems and report to your team daily by participating in scrums and stand-ups. You will also take an active role in performing code reviews and feature analysis as well as participate in product feature discovery and technical experiments. Finally, you will support and develop APIs to enable the simple sharing of data internally and externally.

You will:
Work closely with architects and take ownership of the development and implementation of data processing solutions that support high performing and scalable data pipelines
Provide input on infrastructural decisions pertinent to data and database systems
Develop, maintain and troubleshoot complex data ETL / ELT processes, jobs, schedules etc. (including writing scripts, calling APIs, write SQL queries, etc.) and build ETL processes ingesting data into BI stores
Identify, design, and implement internal process improvements – optimize the delivery/quality/reliability of our data and automating manual processes
Collaborate with wider IT teams to make sure that data engineering solutions fit into IT infrastructure and support corporate standards and practices
Work closely with data scientists, data analysts and other data consumers to help resolve their data needs
Analyze data-related system integration challenges and design and implement appropriate solutions
Design databases key and indexing schemes and designs partitioning
Participate in the implementation of operational data stores, data lakes. and data marts
Document and Translate user requirements into technical designs and implementations
Create quality ERD’s (entity-relationship diagrams) and system documentation
Implement security and recovery tools and techniques as required
Work with other development teams to review and approve database changes according to database design standards and principles
Resolve conflicts between models, ensuring that data models are consistent with the Bank’s enterprise
Integrate data from one or more source systems into data repositories that are optimized for reporting and analytics
What you need to succeed
You are a curious, rational and critical thinker who by nature loves to dig deeper on problems and always questions the “why”. As an effective communicator, you have the ability to articulate your thoughts in a clear and concise manner. You have a team and security first mentality and can naturally step in to support your co-workers. You prefer to utilize best practices when building integrations to third party systems.
Advanced knowledge of data modeling and understanding of different data structures and their benefits and limitations under particular use cases
Data modeling experience with different tools (Dimensional and 3rd Normal Form, Erwin, ER Studio, Enterprise Architect etc.)
Strong background in Database administration or design
Experience with at least one visual ETL tool
Experience in using Enterprise BI tool such as Cognos, Power BI, Tableau, Qlik client-side report authoring and/or server-side administration
Experience developing Data Quality processes: data profiling, unit-testing etc.
Experience in the DevOps best practices such as GIT source control, continuous integration lifecycle such as Jenkins, Bamboo and such
Experience with deploying and maintaining data infrastructure in the cloud
Experience implementing / administering continuous integration/delivery process
Experience with deploying and maintaining data infrastructure in the cloud
Experience implementing / administering continuous integration/delivery process
Your education and experience
The position requires a bachelor’s degree in Computer Science, Information Systems, or other related field and a minimum of 5 years of experience in data engineering, data science, or software engineering, including knowledge of Big Data ecosystem.

What you need to know
Language requirement: English or French essential
Priority will be given to Canadian citizens and permanent residents
Security level required: Reliability
Relocation assistance may be provided, if required
Please save a copy of the job poster. Once the closing date has passed, it will no longer be available.
In response to the COVID-19 pandemic and further to public health guidelines, preventative measures are being taken to ensure health and safety during the recruitment process. All interviews are conducted via Skype.
We wish to thank all applicants for their interest and effort in applying for this position. Only candidates selected for interviews will be contacted.

What you can expect from us
This is a great opportunity to join a leading organization and be part of a high-performing team. We offer a competitive compensation and benefits package designed to meet your needs at every stage of your life and career. For more information on key benefits please visit A great deal to consider.
Salaries are based on qualifications and experience and typically range from $79,100 to $93,000 (job grade 16)
Depending on performance, you may be eligible for performance pay for successfully meeting (5 to 7% of your base salary) or for exceeding expectations (10% of your base salary). Exceptional performers who far exceed expectations may be eligible for higher performance pay.
Flexible and comprehensive benefits so you can choose the level of health and dental coverage that meets your needs
Extra vacation days (up to five each year) that you can purchase to add to your vacation entitlement
Option to join the indexed, defined-benefit pension plan after 24 consecutive months of service
We strive to make our policies, programs and workplace more inclusive, respectful and barrier-free. We encourage applications from women, Indigenous peoples, veterans, persons with disabilities, members of visible minorities and persons of all races, ethnic origins, religions, abilities, sexual orientations, and gender identities and expressions.",4.2,Bank of Canada,Ottawa,"Ottawa, Canada",1001 to 5000 employees,1935,Government,Government Agencies,Government,$1 to $2 billion (CAD),-1,66.5,85,data engineer,na,1,0,1,1,0,1,0,0,0,0,0,0,1,0,0,9147,0
102,"Title: Geospatial Data Analyst

Term: 4- 6-month temporary contract, full time (negotiable)

Compensation: $6580 -$9380/month (negotiable)

Department and program: KBA Conservation Program

Project: Key Biodiversity Area Program Support

Location: Remote

Date written/revised: July 28, 2020

Reports to: Dr. Justina Ray, President and Senior Scientist

Supervises: Not applicable

Project:

Accounting for Resource Roads and other Linear Disturbances in Analyses related to Key Biodiversity Areas, Human Footprints, and Connectivity

Background:

Available resource road network data for Canada at large is incomplete and inconsistent. For example, comparison of national and provincial road network data reveals substantial gaps in the national road network data, which is reflected in global datasets such as OpenStreetMap. National-scale industrial linear disturbance remote sensing efforts are consistent across jurisdictions, but our ability to detect narrow linear features using low-cost widely available remotely sensed data products is limited. Higher resolution data products yield better maps but costs are prohibitive at national or international scales.

The objective of this project is to assemble, assess, and make better use of existing data, and help identify priority areas for additional remote sensing effort, as well as distinguish ecologically intact areas from rapidly changing industrial landscapes. This will help with the broader goal of identifying key biodiversity areas based on the ecological integrity criterion, the characterization of Canada’s national human footprint and areas of highest ecological integrity, and enhanced understanding of connectivity of protected areas and other natural areas.

Responsibilities:

1) Compile existing information on resource roads and other industrial disturbances across Canada, addressing data sharing issues with individual jurisdictions.

2) Assess geographic variation in the quality and completeness of available data.

3) Develop recommendations for resolving data gaps.

4) Research and analyze the relative impact weighting of various linear feature categories.

5) Work with project teams to incorporate this information into ongoing conservation-related analytical processes, including assessment of key biodiversity areas (kbacanada.org), a national metric of human disturbance (Venter et al 2016), and analysis of the connectivity of Canadian protected areas.

Qualifications:
Graduate degree in ecology, conservation biology or a related field
Experience with handling publicly available geospatial data in Canada
Experience and skill managing, collating and analyzing large geospatial datasets
Experience with open source scientific computing tools (e.g. R, Python, git) is an asset
Supervision:

The consultant/employee will be under the supervision of Dr. Justina Ray (Wildlife Conservation Society Canada) and Dr. Richard Schuster (Carleton University).

Timeline/Remuneration:

The project term is September 2020. – March 2021. Remuneration will be commensurate with experience. We have designed the contract to work full time for approximately 4-6 months, but welcome other proposals for completing the work within the defined time frame.

How to apply:

Please send us your CV with a cover letter explaining your qualifications related to the responsibilities listed above, motivation to work on this project, and details regarding your availability and compensation rates through the Fitzii application link.

For questions regarding the job description, please contact richard.schuster@ glel.carleton.ca

Requests for accommodation can be made at any stage of the recruitment process. Applicants need to make their requirements known when contacted. For questions regarding the application process please contact tdias@ wcs.org

Deadline for applications: August 10, 2020.

About WCS Canada:

WCS Canada (www.wcscanada.org) was established as a Canadian conservation organization in July 2004. We are committed to championing accessibility, diversity, and equal opportunity. Our mission is to conserve wildlife and wild places by improving our understanding of and seeking solutions to critical problems that threaten key species and large wild ecosystems throughout Canada. We implement and support comprehensive field studies that gather information on wildlife needs and then seek to resolve key conservation problems by working with a broad array of stakeholders. We also provide technical assistance and biological expertise to local groups and agencies that lack the resources to tackle conservation concerns. WCS Canada is independently registered and managed, while retaining a strong collaborative working relationship with sister Wildlife Conservation Society (WCS) programs in more than 60 countries.",3.4,Wildlife Conservation Society Canada,Toronto,"Bronx, NY",1001 to 5000 employees,1895,Non-profit Organisation,Social Services,Non-Profits,$100 to $500 million (CAD),-1,66.5,125,data analyst,na,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,4807,0
103,"ABOUT MEGAZEBRA

At MegaZebra we have successfully crafted category-leading games for more than 10 years. We develop our own original titles, and develop games based on “Hollywood”-IP such as Desperate Housewives - The Game. By combining technology, game-design, art, analytics, and bringing together passionate people from around the globe we have repeatedly been able to produce hit games. We are based in Munich/Germany and Montréal/Canada.

We develop all our games in small and vibrant teams. Each team has a high degree of responsibility and creative freedom for their game and is committed to creating something outstanding. For our studio in the heart of Montréal’s gaming scene, we are now looking for an experienced Data Scientist - Marketing.

YOUR RESPONSIBILITIES
Leading our Business Intelligence and Analytics efforts, and working with our marketing team to create data-driven strategies for all games
Working with large volumes of data; extract and manipulate large data sets through scripting in SQL. Use this data to gain insight into the user journey, user behavior, or understand root causes of user performance
Usage of big data analytics to monitor the performance across our game portfolio, leverage analytics to tune mechanics, modify existing features, and identify new ones to increase user conversion, retention, and monetization
Providing data-driven insights, recommendations and optimizations based on SQL databases
Responsibility for identifying opportunities for maximizing revenue of our games based on insights gathered from data analysis
Responsibility for monitoring and identifying actionable plans for improving marketing campaign KPIs, incl. player actions, installs and reactivation
Driving the innovative use of data to optimize overall game revenues and ROI
Main driver of using new and innovative methodology, tools, and technology to analyze and display data, as well as looking to automate marketing functions.
YOUR PROFILE
Bachelor’s or Master's degree (advanced degree preferred) in a quantitative discipline such as economics, statistics, mathematics, operations research mathematics, computer science, or engineering
3+ years experience in the games industry resulting in general understanding of video-games, turning insights from data into actionable improvement plans for games, and collaboration with game-designers
Comprehensive understanding of statistical and data mining concepts and techniques as well as experience with data management
Pragmatic and insight-driven approach to quantitative analytics/statistics and ability to determine what data-sets validate or invalidate your hypotheses
Experience with analytics platforms and technologies such as Google and Facebook Analytics
Experience working with database technologies, SQL, and basic scripting capabilities
Ability to communicate complex concepts to all stakeholders
Ability to pick up and adapt to new concepts and technologies
Inquisitive and analytical mindset
YOUR BENEFITS
Become part of the company which develops category-leading, casual games on mobile and social platforms
Work in a highly creative environment with a super-flat hierarchy
Join our office in Montréal. Work with a very experienced and talented group of game-designers and developers at our centrally located office. Experience start-up spirit and the ability to have significant impact
At the same time, you will be able to plug into our capabilities as a fully-fledged video-game development studio. MegaZebra has a ten-year track-record developing and publishing our own games. So, you get the best of both worlds
If you’re a game changer and would like to join MegaZebra, please apply in English with your current CV and a cover letter.",3.0,MegaZebra GmbH,Montreal,"Munich, Germany",1 to 50 employees,2008,Other Organisation,Video Games,Media,Unknown / Non-Applicable,-1,66.5,12,data scientist,na,1,0,0,0,0,1,0,0,0,0,0,0,0,0,1,3732,0
104,"Tartan Energy Group is a multifaceted engineering and manufacturing company that provides drilling and completion equipment and services to the oil and gas industry. For more than 20 years, Tartan has followed the philosophy of engineering our products for simplicity, reliability, and ultimate performance. Our field service personnel are well trained and certified and are able to perform safe and flawless services. Tartan’s knowledge and execution of service, add value to our customers’ operation. At Tartan, we continue to innovate, expand service offerings and grow; which ultimately allows Tartan to be a leader in the oilfield service and supply industry.

Tartan Energy Group is proud to be an equal opportunity employer. We are committed to fostering an inclusive work environment where the different strengths and perspectives of each employee are both recognized and valued.

Duties and responsibilities:

· Bring deep functional expertise to shape data structures and algorithms in a distinctive way to ensure large-scale business impact of the digital products being built and drive competitive advantage for Tartan Energy Group Inc. as a whole.

· Develop/apply new methods/methodologies to all Artificial Intelligence (AI) related projects within company, such as big-data/machine learning analysis models

· You’ll use Machine Learning and Artificial Intelligence to increase revenue generation, and other business outcomes.

· Collaborate with Technical advisors and developers to find opportunities to use company and industry shareable data to drive business solutions.

· As an assistant Project Manager (PM), help PM design/plan the specific project, including project scope, contents, workflows, etc.

· Applying timely new technologies from industry to our products of both Petroleum Engineering and Statistics Analysis

· You’ll code, test, and document new or modified data systems to create robust and scalable applications for data analytics, and need closely work with other programmers to develop other software modules designed

· Work with sales personals and customers for optimizing customer experiences

· Train/help/supervise junior engineers

· Other related works assigned by the supervisor

Required Qualifications Must-haves (minimum requirements):

· 2 to 5 years of progressive experience in advanced analytics or a quantitative field

· A Master degree or Ph.D. of science or engineering with a focus in data science, computer science, statistics, mathematics, data mining & analytics, actuarial science

· Proven proficiency with analytics scripting languages such as Python, R, SQL and statistical analysis environments such as MATLAB, SPSS or SAS

· A deep understanding of predictive modeling and statistical and stochastic concepts, machine learning approaches, clustering and classification techniques, and optimization algorithms

· Strong communication, dynamic and critical thinking, and story-telling ability (through data) to influence and propose analytics strategies and solutions that challenge and expand the thinking of everyone around you

· Alignment with our values of: safety above all else, respect, commitments

Preference for:

Experience in Petroleum Engineering and Geology, In Situ Recovery, Gas Process & refineries, cyber security, and/or a corporate/functional business background

Experience with unstructured data (e.g. image/pattern recognition, audio analytics)
An accredited professional statistician (PStat)

Job Types: Full-time, Permanent

Benefits:
Dental Care
Extended Health Care
Flexible Schedule
Paid Time Off
Schedule:
Monday to Friday
Experience:
Advanced Analytics: 2 years (Required)
Education:
Master's Degree (Required)
Licence:
Professional Statistician (Preferred)
Work remotely:
Temporarily due to COVID-19",-1.0,Tartan Energy Group I,Calgary,-1,-1,-1,-1,-1,-1,-1,-1,66.5,-1,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,1,0,1,3801,0
105,"ABOUT MOBSQUAD

We are a well-funded, hyper-growth, scale-up looking for an experienced Data Engineer. If you've ever dreamed of working with a top tier technology company scale-up, on leading edge technologies, backed by the very best venture capitalists in the world, then this is your chance.

Some details about MobSquad:
MobSquad solves the significant and growing technology talent shortage faced by US-based start-ups and scale-ups by enabling our clients to quickly have a turnkey ""virtual"" Canadian subsidiary, where Canadian-based software engineers serve our clients individually on an exclusive basis
We've been featured on the front page of The Washington Post, on NPR multiple times, The Financial Times (UK), The Globe and Mail, the Calgary Herald, BetaKit, CBC, Global News, and many other places. other media outlets
We're a Certified B Corporation, were recognized as the third Best Place to Work in Canada in 2020, and have made numerous contributions to charitable organizations as well as a financial commitment to the Upside Foundation. We believe we are playing a key role in enhancing Canada's innovation economy, and have received financial support from the Government of Canada, Province of Alberta, Province of Nova Scotia, and City of Calgary, to support this ambition
You can learn more about us on our website
ABOUT THE ROLE

As a Data Engineer, you will be part of a Canada-based team working remotely for a leading US scale-up. Your team will operate alongside many other talented developers and data scientists in Canada, and you will be an integral part of the tech community that MobSquad has built.

This role requires someone who has demonstrated an ability to develop, test, optimize, and maintain scalable databases, architectures, and pipelines that enable data scientists and software developers to easily analyze and work with data. The ideal candidate has worked closely with data scientists and data architects and is an expert at optimizing data flow for use across broader teams. The candidate should be able to generate ideas and create tools that add greater functionality and usability to data systems within the company.

ABOUT YOU
You have a bachelor's degree in Computer Science, Information Technology, Data Science, Applied Math, Physics, Engineering, or a comparable analytical field from an accredited institution
You are expert in modeling, working with database architectures, and relational databases
You have over three years of experience with big data tools, such as Hadoop (MapReduce, Hive, Pig), Spark, and Kafka
You have experience with SQL databases (PostgreSQL, MySQL) and NoSQL databases (Cassandra, MongoDB)
You have experience creating and working with ETL data transformation and integration processes
You have experience working with enterprise-grade cloud computing platforms such as Microsoft Azure, Amazon Web Services (EC2, EMR, RDS, Redshift), and Google Cloud
You have expertise in relevant programming languages (Python, R, C/C++, Java, Pearl, Scala)
You have a deep understanding of data modeling tools (ERWin, Enterprise Architect, Visio)
You have experience optimizing big data pipelines and extracting value from large disconnected datasets
You have the ability to develop high-quality code adhering to industry best practices (i.e., code review, unit tests, revision control)
WHAT YOU'LL GET @MOBSQUAD
A full-time position that offers competitive compensation
A benefits program delivered through our bespoke digital platform, giving you control, choice, and flexibility. We give you the ability to build your package of benefits covering health (e.g., medical, dental, vision), wellness (e.g., gym, workout gear, massage, transit), and RRSP (retirement savings)
A downtown office location with first-rate amenities, surrounded by great restaurants and easily-accessible transit
For international candidates, sponsorship for an immediate work permit, expedited permanent residency, and Canadian citizenship within four years
At MobSquad, we support and encourage building a work environment that is diverse, inclusive, and safe for all. We invite and welcome applicants of all backgrounds, regardless of race, religion, sexual orientation, gender identity, national origin, or disability.",4.4,MobSquad,Toronto,"Calgary, Canada",1 to 50 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,66.5,-1,data engineer,na,0,1,0,0,0,1,1,1,1,1,0,0,0,0,0,4272,0
106,"Job Description

SDK is looking for Big Data Engineers that will work on the collecting, storing, processing, and analyzing of huge sets of data. The Data Engineer must also have exceptional analytical skills, showing fluency in the use of tools such as MySQL and strong Python, Shell, Java, PHP, and T-SQL programming skills. He must also be technologically adept, demonstrating strong computer skills. The candidate must additionally be capable of developing databases using SSIS packages, T-SQL, MSSQL, and MySQL scripts.

The candidate will also have an ability to design, build, and maintain the business’s ETL pipeline and data warehouse. The candidate will also demonstrate expertise in data modeling and query performance tuning on SQL Server, MySQL, Redshift, Postgres or similar platforms.

Experience:
ETL: 5 years (Preferred)
Software Development: 5 years (Preferred)
Data Integration: 5 year (Preferred)
Spark Programming (Azure Databricks preferable)
Python, Java & SQL
Knowledge of Azure Cloud (Data Platform Technologies)
Experience and commitment to development and testing best practices.
Manage high volume, high traffic GDPR solutions build
SCALA a nice to have
SDK is looking for Big Data Engineers that will work on the collecting, storing, processing, and analyzing of huge sets of data. The Data Engineer must also have exceptional analytical skills, showing fluency in the use of tools such as MySQL and strong Python, Shell, Java, PHP, and T-SQL programming skills. He must also be technologically adept, demonstrating strong computer skills. The candidate must additionally be capable of developing databases using SSIS packages, T-SQL, MSSQL, and MySQL scripts.
The candidate will also have an ability to design, build, and maintain the business’s ETL pipeline and data warehouse. The candidate will also demonstrate expertise in data modeling and query performance tuning on SQL Server, MySQL, Redshift, Postgres or similar platforms.
Base Qualifications
3+ years of demonstrated data engineering experience or development experience
3+ years of experience with Big Data Technologies like Hadoop or Hive
3+ years' experience in custom ETL design, implementation and maintenance
Proficient designing and implementing data models and data integration
Experienced deploying Azure SQL Database, Azure Data Factory and well-acquainted with other Azure services including Azure Data Lake and Azure ML
Experience implementing REST API calls and authentication
Experienced working with agile project management methodologies
Preferred Qualifications
At SDK we believe “perfection” is a process. We hire for fit and invest in training, so our people continue to be the best for themselves, SDK, and SDK's customers.
Education
Computer Science Degree/Diploma
Microsoft Certified: Azure Data Engineer Associate:
Job Types: Looking for full-time employees only. No Contractors. Must be eligible to work in Canada.

Job Types: Full-time, Contract

Experience:
Data Engineering: 5 years (Preferred)
Location:
Edmonton (Required)
Work remotely:
Temporarily due to COVID-19",2.7,SDK,Edmonton,"Fellbach, Germany",501 to 1000 employees,1926,Unknown,-1,-1,$100 to $500 million (CAD),-1,74.5,94,data engineer,na,0,1,0,0,0,1,1,0,1,0,0,1,0,0,0,3086,0
107,"What is the opportunity?

As a Senior Data Scientist, you will analyze, design, and implement organization-wide AIOps solutions at RBC Technology Infrastructure (TI). Leveraging leading edge technologies and various data sets, you will build machine learning based products to facilitate informed decision-making and business process optimization.

What will you do?
Work on challenging and research-based initiatives using advanced machine learning methods focusing on tangible outcomes
Collaborate proactively with various business and operation units to identify business opportunities and designing innovative solutions to optimize processes and promote informed decision-making.
Prepare and integrate large and various types of data (structured/non-structured)
Implement machine learning models, data mining methods, and statistical analysis
Leverage visualization tools/packages to create powerful representations of results
Produce data-driven insights to help in informed decisions and actions by telling a convincing story
Effectively communicate findings to business partners and executives
Collaborate with the development team to deploy production-scale solutions
Quickly learn new methods, tools and technologies presented in research communities to implement and adapt them within the daily analytics exercises
What do you need to succeed?

Must-have
Masters or PhD. in Computer Science, Statistics, or relevant fields.
Expert in Python programming to write production-ready codes. Strong data profiling, cleaning, mining and technical documentation skills
2+ years of experience in building machine learning models
2+ years of experience with NLP and text analytics methods and packages
Experience with time-series analysis, forecasting, and anomaly detection
Experience with big data technologies – parallel processing techniques and Apache Spark, Hadoop ecosystem, NoSQL/SQL databases
Proficient in Linux environment, shell scripting, and Git
Nice-to-have
Software engineering background with a focus on statistics and/or analytics
Strong knowledge and experience of different deep neural networks architectures (RNN, CNN, GAN, seq2seq/Transformers) and transfer learning
Experience with MLOps to build end-to-end pipeline and deploying models
Familiar with container-type environment: Docker, Kubernetes, Openshift
What’s in it for you?
We thrive on the challenge to be our best, progressive thinking to keep growing, and working together to deliver trusted advice to help our clients thrive and communities prosper. We care about each other, reaching our potential, making a difference to our communities, and achieving success that is mutual.
A comprehensive Total Rewards Program including bonuses and flexible benefits, competitive compensation, commissions, and stock where applicable
Leaders who support your development through coaching and managing opportunities
Ability to make a difference and lasting impact
Work in a dynamic, collaborative, progressive, and high-performing team
A world-class training program in financial services
Flexible work/life balance options
Opportunities to do challenging work
Opportunities to take on progressively greater accountabilities
Opportunities to building close relationships with clients
Access to a variety of job opportunities across business and geographies
Learn more about RBC Tech Jobs

Join our Talent Community
Stay in-the-know about great career opportunities at RBC. Sign up and get customized info on our latest jobs, career tips and Recruitment events that matter to you.

Expand your limits and create a new future together at RBC. Find out how we use our passion and drive to enhance the well-being of our clients and communities at rbc.com/careers.

JOB SUMMARY
City: Toronto
Address: 330 Front Street W
Work Hours/Week: 37.5
Work Environment: Office
Employment Type: Permanent
Career Level: Experienced Hire/Professional
Pay Type: Salary + Variable Bonus
Required Travel(%): 0-25
Exempt/Non-Exempt: N/A
People Manager: No
Application Deadline: 08/31/2020
Platform: Technology and Operations
Req ID: 258308
Ad Code(s):",4.0,RBC,Toronto,"Toronto, Canada",10000+ employees,1869,Company - Public,Banks & Building Societies,Finance,$10+ billion (CAD),"Barclays, Morgan Stanley, TD",74.5,151,data scientist,senior,0,1,0,0,0,1,1,0,0,0,0,0,1,0,1,4102,3
108,"About Breather

Breather helps businesses grow with private, modern workspace available for any duration of time, and on completely flexible terms. Our network of 500 spaces spans across 10 markets including Montreal, New York, San Francisco, Los Angeles and London, powered by in-house tech allowing anyone to instantly unlock space anywhere.

Our mission is to empower businesses with access to productive space that grows as they do. With over 10,000+ clients and the support of leading tech and real estate investors, we're already well on our way — and we want your help to reach the next step of the journey.

The Role

The infrastructure team at Breather is looking for a talented and meticulous data engineer: someone that will take ownership of data quality and work to elevate it and make it as relevant as possible. That person will help interpreting the data as well as sit down with stakeholders to determine how to best improve their workflows. The ideal candidate can understand the specifics of Breather's internal data pipelines, intervene to fix problems, suggest and implement ways to improve them. This role offers both the opportunity to gather the big picture of the business and the leisure to suggest and implement technical solutions.

As a Data Engineer at Breather, you will:
Take ownership of the data ingestion pipelines from beginning to end
Help troubleshoot and guard against data integrity problems
Review, optimize and streamline Breather's whole ETL system
Work closely with various internal teams and stakeholders to improve their workflows and understanding of the available data
Audit and improve data warehouse models
Use various data transformation tools to aggregate several sources
Make and implement suggestions for new data ingestion architecture


You will help your team:
Coordinate with various teams to review and improve revenue data
Audit current transformation code to streamline it and update it to use the latest schema version
Coordinate with the real estate team to streamline their data input process
Advise on data requirements / best practices for new projects
Participate in the production and development of business reports


Helpful Skills and Experience you'll need to succeed:
2+ years experience as data engineer
Proficiency with the SQL language
Proficiency with the Python language
Solid understanding of relational database design
Good understanding of cloud technologies involved in an ETL in general
Strong communication skills
Ability to discern and negotiate with stakeholders their needs in order to design relevant, high quality solutions
Sincere desire to acquire and master the big picture of the company's business data
Natural tendency towards using industry best practices

What We Value

At Breather, our company values are not only the principles that link us together in the way we work, but they also keep us aligned on the same path, all working towards connected goals. These standards are what guide us on our collective journey through space(s).
Default to transparency
Create with care
Be a piece of the puzzle
Propose. Build. Deploy.
Perks and Benefits

We hope that you're excited by all the possibilities that come with working at Breather! In addition to our unique culture, we also offer these fun perks and benefits:
Annual health and wellness reimbursement
A generous Paid Time Off package per the calendar year
Annual learning reimbursement that benefits your career growth
Free access to the Breather network of over 500 spaces (and growing, fast!)
Access to comprehensive medical, vision, and dental coverage. Oh, and it's on us
Dog friendly office - bring your dog to work, they'll find plenty of friends waiting to play with them!
Be part of a well-funded, proven startup with big ambitions, competitive salary and company options
Fun work environment and company culture with an upbeat, first-class team plus a kitchen filled with healthy snacks, bagels and chips!",3.6,Breather,Montreal,"Montreal, Canada",201 to 500 employees,2012,Company - Private,Real Estate,Real Estate,Unknown / Non-Applicable,Knotel,74.5,8,data engineer,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,3965,1
109,"At Huron, we're applying machine learning techniques to develop solutions in pathology that are modernizing healthcare, helping pathologists detect cancer and other diseases. We're planning to apply our products in clinical pathology and drug development. The team at Huron is working with unique Artificial Intelligence (AI)/Machine Learning (ML) technologies that are focused on advancing medicine and improving patient care.

We're looking for experienced machine learning engineer/scientist to join our team and help advance our understanding and solve challenges in computational pathology.

Responsibilities:

1. Designing AI/ML pipelines for histopathology images

2. Research and implement appropriate ML algorithms and tools using deep learning and artificial neural networks

3. Develop machine learning applications according to requirements

4. Select appropriate datasets and data representation methods

5. Analyze results for robustness, validity, and out of sample stability

6. Run machine learning tests and experiments

7. Perform statistical analysis and fine-tuning using test results

8. Train and retrain systems, classifiers and networks when necessary

9. Extend existing ML libraries and frameworks

10. Keep abreast of developments in the field

11. Document, summarize, and present findings to a group of peers and stakeholders. across multiple modeling projects

Requirements:

1. MSc/PhD in Engineering, Computer Science, Mathematics or similar field, preferably PhD.

2. 2+ years full time employment or postdoctoral experience building and validating predictive models on structured and unstructured data

3. Experience with supervised and unsupervised machine learning algorithms, and ensemble methods, such as regression, deep neural networks, decision trees, gradient boosting, linear and non-linear models

4. Strong knowledge of neural networks, data augmentation, clustering, and deep learning

5. Understanding of data structures, data modeling and software architecture

6. Deep knowledge of math, probability, statistics and algorithms

7. Ability to write code in Python, Java, and C++

8. Familiarity with machine learning frameworks (Keras/PyTorch/Tensorflow )

9. Excellent communication skills

10. Ability to work in a team

11. Outstanding analytical and problem-solving skills

About Huron Digital Pathology

Based in St. Jacobs, Ontario, Canada, Huron Digital Pathology has a 20+ year history designing sophisticated imaging instrumentation. Our end-to-end digital whole slide imaging solutions combine the award winning TissueScope™ digital slide scanner, image management software, and workflow enhancing accessories. We believe that innovation is the key to making digital pathology a ubiquitous reality. But for us, innovation is about more than just delivering great image quality and fast scanning speeds. It’s also about designing products that are simple to use, easy to integrate with your workflow, and have attractive price-performance characteristics.

Job Types: Full-time, Permanent",2.5,Huron Digital Pathology,St. Jacobs,"Waterloo, Canada",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,74.5,-1,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,3046,0
110,"Reporting directly to the Director of Data Science, this role is pivotal in implementing advanced time series solutions to deliver high quality results to clients.

You will be interacting with multi-function teams, including data integration, model development and other consulting functions to implement best practice and thought leadership.

This role also works very closely with client project sponsors to ensure client satisfaction and business requirement fulfillment.

Duties and Responsibilities

Implement currently available time series forecasting models
Develop customized forecasting algorithms required by specifications of each project
Prototype, simulate and benchmark accuracy of algorithms
Develops production-ready codes in R
Works with main stakeholders including but not limited to: Account Executives, Management, Project Managers and Consulting Teams
Performs various other duties as delegated or assigned.
Required Knowledge, Skills, and Experience

The successful incumbent will have:
Graduate degree in a Statistics, Math Computer Science or Engineering program;
Proficient in time series analysis and forecasting
Fundamental knowledge of supervised and unsupervised Machine Learning
Experience with data preprocessing, anomaly/outlier detection
Advanced programming skills in R language is mandatory;
Knowledge of pharmaceutical industry is an asset;
Capability to adapt in fast changing environment and eager to learn
The ability to travel and work outside regular business hours as required;
Proven, motivated self-starter with the ability to lead by example and approach and solve business problems;
Experience working in cross-functional teams with the agility to learn new software applications and technologies;
Demonstrated time management, problem solving and decision making competencies;
Ability to work autonomously and in teams to effectively prioritize multiple projects and associated deliverables;
Proven excellent communication, including presentation, hands on analytical with business savviness and customer relationship abilities;
Proven ability to comprehend, analyze and research problems of a complex nature, make decisions and/or present recommendations;
Preference for fast paced, rapid start-up culture demonstrating the values of results, teamwork, energy, agility, respect, and can-do environment",3.8,Scarsin,Markham,"Uxbridge, Canada",51 to 200 employees,2002,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (CAD),-1,74.5,18,data scientist,na,1,0,0,0,0,0,0,0,0,0,0,0,1,0,1,2351,0
111,"About Fusion Analytics


We believe in a future where analytics takes the lead role in steering organizations, and that Fusion is positioned as the leading consulting firm for this transformation. Founded in 2005, we are now 30 consultants and will be growing to 50 in the next 3 years. To make this happen we are looking for extremely smart people to join us. Our current client list is a who’s who of amazing companies, including Budweiser, Sobey's, Staples, IKEA, Walmart and Canadian Tire. We love what we do and know you will too.


What makes this role unique

You will become a master in data science, statistical modelling & analytics
Exposure to Canada’s largest and most successful companies
Opportunity for aggressive promotion as we build our team
Work with the smartest team of data scientists in the country
Contribution to company success is encouraged from day one
No politics and we work hard for everyone to succeed
Highly supportive work culture (learn more at
http://www.fusionanalytics.com/team.html
).
Team builders (e.g. BBQs, board game nights)
Equal opportunity employer


Examples of typical projects

Develop a complex analytical model to help a national home decor retailer optimize their business operation
Build an integrated media mix model for a $20 billion international retailer
Work with a major national retailer to develop a predictive model to measure, monitor and forecast key industry indicators


Requirements

A Masters or undergraduate degree with knowledge in data science (Mathematics, Statistics, Engineering, Finance, Science)
3+ years of professional experience related to data science, modelling and analytics
Strong technical skill in data modelling, machine / deep learning models (R, Python, Power Pivot, Power BI)
Strong sense of curiosity, with advanced critical thinking and analytical skills
Passionate about problem-solving and will rise to any challenge
Track record in doing excellent work in a high pressure and fast paced environment


Compensation

Competitive top-tier data scientist level salary
Health & dental benefits for spouse and dependents
Share options at the management level


Start Date

Flexible start dates through 2019 and 2020


Application Deadline

Ongoing


How to Apply

Apply with a PDF copy of your resume and undergraduate transcript.
Please name all files ((applicant name)) - ((document)) for example John Doe - Transcript.pdf.
Your resume should highlight your education, your overall GPA at each academic level, academic scholarships/awards, analytical experience (labeled as Analytical Experience), and other experience (labeled as Other Experience).
We define analytical experience in its broadest sense (working in a medical lab doing tests, software programming, robotic design, engineering projects, financial modeling, etc.).",4.8,Fusion Analytics,Toronto,"Toronto, Canada",1 to 50 employees,2006,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1,74.5,14,data scientist,senior,0,1,1,0,0,0,0,0,0,0,0,0,0,1,1,2821,0
112,"Are you looking for unlimited opportunities to develop and succeed? With work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations.

Job Description

Job Description:

The Senior Data Scientist develops and implements analytics enabled solutions to improve business process, to generate insights, support business goals and strategy development. The Senior Data Scientist also owns and delivers projects of diverse scope, oversees the work of more junior data scientists.

Key Responsibilities:
• Develops and implements analytics enabled solutions to improve business process, to generate insights, support business goals and strategy development
• Develop machine learning-driven and link analysis capabilities to support investigations of Fraud, AML and other financial crimes

• Leverage extensive theoretical and practical knowledge of advanced analytic methods and algorithms, understanding their utility in different problem domains (sparse data, rare event detection, etc), evaluation methodologies and pitfalls, and stays on top of industry & academic developments.

• Owns and delivers projects of diverse scope. Oversees the work of more junior data scientists.
• Works on problems of diverse scope / complexity where analysis of situations or data requires an in-depth evaluation of a variety of factors
• Strong ability to generate relevant, actionable insights based on iterative data analysis, translate data-driven output into business language, and to make appropriate recommendations to respective business stakeholders
• Independently provides analysis on datasets of significant complexity.
• Quickly able to develop enough business insight to connect data sources across multiple diverse and complicated systems.
• Recommends implementable solutions to (or in collaboration with) business partners.
• Considers change management in all aspects of their work. Supports more junior data scientists with Change Management.
• Has intimate understanding of the business value chain and customer lifecycle for a line of business or more. Has fundamental understanding of the business as a whole, and has started to build a network of people for ideation, info sharing, knowledge.
• Understands the corporate climate and culture
• Strong knowledge of the business
• Engages in ongoing discussions and moves others towards a position, appealing to their needs and interests to gain acceptance
• Is able to display empathy with the business and anticipate their push back and areas of concern
• Maintains a strong internal network, begins to network with more senior stakeholders within the organization. Begins to develop an external network and develop their own brand, particular in their own practice area.
• Actively involved in recruitment of data science professionals (campus etc)
• Shares ideas with others, leads brainstorming sessions. Contributes to solutions outside immediate area of expertise. Ensures all voices are heard.
• Actively seeks out coaching and incorporates feedback into their work. Provides guidance and mentorship to more junior data scientists. Promotes best practices within the team. Shares technical expertise with others.
• Owns their career development. Takes advantage of available resources to advance their technical and business skills.
• Understands how their project supports broader business strategy, including the core drivers of business value. Able to prepare a business case on the benefits of their assigned work.
• Incorporates lessons learned throughout the business into their work. Engages with global counterparts to share learnings.
• Strong ability to construct systematic process to implement analytics insights and solutions, this includes (but not limited to):
1) designing a process with multiple relevant parties with clear specifications of roles and responsibilities
2) identifying required tasks, system / data flow and contingency
3) specifying check-and-balance throughout the process
4) establishing rigorous tracking and closed-loop learning
5) implement such process in a scalable way

Education, Experience and Skills:
• Advanced degree in Statistics, Math, Computer Science, or Engineering; or Bachelor’s degree with equivalent technical experience
• Generally, a minimum of 5 years of applicable experience
• Advanced knowledge of programming languages and concepts, e.g., Python

-Insurance or Financial Services industry experience preferred.

-Experience with combating financial crime, including account takeovers, agent misconduct, AML, and identity theft, with advanced analytics and link analysis is a plus

-Demonstrated experience exhibiting innovation and leadership in proposing new strategies and/or tactics based on analysis findings

-Experience with Big Data platforms desired

-Experience working with link analysis and graph databases is a plus

-Experience with analysis of unstructured data desired

-Experience with working Agile desired
• Expert in basic and advanced statistical tests, distributions, maximum likelihood estimators, statistical modelling techniques (XGBoost, regression, cluster / factor / principle components, decision tree, survival analysis, etc.)

• Advanced knowledge of different techniques and knowledge of machine learning algorithms. Basic knowledge of AI toolkits.
• Expert in data visualization tools such as Tableau, QlikView, open source data visualization libraries - ggplot and d3.js
• Advanced knowledge of common database querying languages such as SQL. Capability of applying a systematic, structured approach to explore / navigate / mine massive amount of data, structured or un-structured, to uncover hidden patterns / insights. Strong working knowledge of relational database models (e.g. data vaulting techniques, rules tables).

Decision Authorities:
• Day to Day operational decision-making authority
• Decisions at this position are made using judgment based on skills and knowledge already developed
• Decisions beyond normal day to day may require escalation to management
• Managing projects and major deliverables

If you are ready to unleash your potential it’s time to continue on your career journey with Manulife/John Hancock.

If you are ready to unleash your potential it’s time to start your career with Manulife/John Hancock.

About Manulife

Manulife Financial Corporation is a leading international financial services group that helps people make their decisions easier and lives better. With our global headquarters in Toronto, Canada, we operate as Manulife across our offices in Canada, Asia, and Europe, and primarily as John Hancock in the United States. We provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. At the end of 2019, we had more than 35,000 employees, over 98,000 agents, and thousands of distribution partners, serving almost 30 million customers. As of March 31, 2020, we had $1.2 trillion (US$0.8 trillion) in assets under management and administration, and in the previous 12 months we made $30.4 billion in payments to our customers. Our principal operations are in Asia, Canada and the United States where we have served customers for more than 155 years. We trade as 'MFC' on the Toronto, New York, and the Philippine stock exchanges and under '945' in Hong Kong.

Manulife is an equal opportunity employer. We strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. We are committed to fair recruitment, retention and advancement and we administer all of our practices and programs based on qualification and performance and without discrimination on any protected ground.

It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will consult with applicants contacted to participate at any stage of the recruitment process who request any accommodation. Information received regarding the accommodation needs of applicants will be addressed confidentially.",3.7,Manulife,Toronto,"Toronto, Canada",10000+ employees,1887,Company - Public,Investment Banking & Asset Management,Finance,$50 to $100 million (CAD),"MetLife, ING, Sun Life",74.5,133,data scientist,senior,0,1,0,1,0,1,0,0,0,0,0,0,1,0,1,8204,3
113,"AXIS is an energetic growth company with a seasoned and progressive Management team specializing in assisting organizations with the development and implementation of CRM solutions. At the core of our web, database and custom applications is our Cleansing and Matching department. This team focuses exclusively on converting, parsing, standardizing, verifying / correcting and matching consumer and business information to create a holistic view of the client.

More specifically, our Cleansing and Matching department is focused on assisting clients in the following areas:

Enhancing the quality, relevance, and usability of their customer data
Leverage the cleansed data for analytics, marketing, and profitability
Establish metrics and targets for improvements
Implementing processes to achieve data quality targets
Design and building customer focused databases that links disparate customer records across the enterprise into unified retail and commercial views with the objective of achieving the highest customer experience across all channels
Must Have Skills
Solid understanding and experience with relational databases
Working knowledge of SQL Server Integration Services
Proficiency in writing and debugging T-SQL code
Programming knowledge in (but not limited to) C#/VB.NET/VB6
Experience with Microsoft Office (Access, Excel, and Word)
Areas of Responsibility
Participating in the analysis of Client business objectives and scoping of projects
Development using partner software including SAP Business Objects Data Services (formerly Business Objects DQXI).
Interpret functional specifications
Develop Job scripts (Build/Test)
Data Transformation & Cleansing
Parser Rules Table Development
Matching Rules Table Development
End-to-end job stream
Support in writing functional documents using pre-established templates
Development using C#/VB/SSIS or similar to build interfaces that utilize BO Data Services objects
Analysis of Customer Data Quality using Data Cleansing and Profiling Software and customized SQL Database Software (MS SQL Server, MS Access, MS Excel)
Quality Assurance Testing
Performing detailed Analysis of parsing and matching results obtained, comparing results from multiple software systems / projects
Participates in meetings with both external and internal clients
Research/knowledge improvement in best practices for Data Cleansing, Address Standardization and Customer Linking
Coordinating and applying modifications to the database with project management and development staff
Define and implement data transfer and data conversion strategies
Implement ETL processes and data flows
Maintaining existing T-SQL code and DTS/SSIS packages
General Qualifications/Assets
College or University degree in Computer Science / Mathematics or a related discipline
A minimum of 1-2 years work experience in data processing and/or database development
Ability to work in team as well as independently
Excellent analytical and problem-solving skills as well as attention to detail
Document code with detailed inline comments, and create clear external documentation as required
Good communication skills, both oral and written and ability communicate effectively with both technical and non-technical individuals
Ability to quickly learn and grasp new matching/cleansing partner software and technologies
Experience in marketing database industry and/or data cleansing and matching would be an asset
Design and development experience with SAP Business Objects Data Services a major plus
Please send your cover letter and resume to careers@axis-dbm.com. No attachments other than Microsoft Word or Acrobat PDF will be accepted. You may also copy and paste your resume and cover letter into the email body.",3.5,AXIS Database Marketing,Mississauga,"Mississauga, Canada",1 to 50 employees,1990,Company - Private,-1,-1,Unknown / Non-Applicable,-1,74.5,30,data analyst,na,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,3732,0
114,"Data Scientist

BrainStation is a global leader in digital skills training and development, offering a 12-week Diploma program in Data Science. BrainStation is currently seeking a Data Science professional to lead the delivery of our program through online and in-person teaching. BrainStation Educators are given the unique opportunity to teach, research, and work on real analysis problems, while simultaneously building the future of higher education.

Responsibilities
Lead our 12-week Data Science Diploma program
Help build a world class technical team
Deliver lectures and mentor the next wave of Data Science talent
Co-create BrainStation's full-time Data Science Program that will positively impact the lives and careers of hundreds of individuals across our campuses
Actively work on writing and researching new content to teach the most up to date skills in data science to our students
Apply BrainStation's ""Agile Education"" methodologies to the program to continuously improve the educational experience for students
Constantly improve your own skills, and apply these skills in collaboration with other BrainStation Educators in order to build the digital platform and tools needed to effectively deliver educational material
Define the education experience of the future
Successful candidates will have
2+ years experience as a Data Scientist or Analytics professional and a Bachelor's degree relevant to the subject matter OR 8+ years experience as a Data Scientist or Analytics professional
Experience building and leading teams
Strong command of querying and programming languages (SQL, Python, R), and visualization tools (Tableau, Python packages, etc.), as well as experience applying various methods of numerical and categorical modeling and machine learning principles
Practical experience designing and conducting experiments using a variety of tools and methods, and can speak to their complexities in a simple and logical manner
Experience in a teaching role, and be comfortable speaking to large groups and mentoring others on the job
An empathetic, friendly, and approachable demeanor
A proven ability to work under pressure and meet deadlines
About BrainStation

BrainStation is a global leader in digital skills training and development, with courses, workshops, events, and corporate training offered online and in state-of-the-art campuses in New York, Toronto, Chicago, Vancouver, and Boston. Founded in 2012, BrainStation has worked with over 350 instructors from the most innovative companies, developing cutting-edge, real-world digital training for more than 70,000 professionals and some of the largest corporations in the world. By 2025, BrainStation will have innovation hubs around the world, and will be empowering young minds, powerful politicians, fortune 500 CEOs, and the newest wave of disruptive innovators, on campuses and online.

*Have you been to a campus or joined an online learning opportunity? We are actively seeking individuals that believe in lifelong learning and that have taken part in our On Campus or Online offerings.

NOTE: Only those applicants under consideration will be contacted. Please accept our utmost appreciation for your interest.

BrainStation is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. All qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. If you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.",4.3,BrainStation,Toronto,"New York, NY",51 to 200 employees,2012,Company - Private,Education Training Services,Education,Unknown / Non-Applicable,-1,74.5,8,data scientist,na,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,3719,0
115,"Flipp is a retail technology company that is reinventing the way people shop. We work with the largest retailers and manufacturers in the world to help them transform their business and connect them with tens of millions of shoppers through the next generation digital shopping marketplace.

We are looking for a Sr. Data Scientist to create capabilities and launch ML products into production that lead to automated decision making in the Flipp product to drive revenue or automate manual processes to reduce operational costs. In this role, you will work within the Data Science team and collaborate with our Product and Engineering teams to further the use and understanding of machine learning across the organization. Lastly, you will mentor Data Scientists while raising the standard for data science amongst the team.

Most of the things you will work on:
Coordinate with the data engineering and architecture teams to design solutions for launching successful ML products into production
Build predictive models of user behaviours to power production systems and move key business metrics
Develop prototypes and approaches that leverage advanced statistical and machine learning algorithms
Perform code reviews and provide constructive feedback for other team members
You'll need to have:
Bachelor's Degree in Computer Science, Math, Physics, Engineering, or related quantitative field
4+ years of relevant experience in data science or similar field
Experience with large data sets and distributed computing (Spark)
Experience in working with Scala, Spark, Kafka, Python, R and related big data technologies
Experience with recommendation systems & personalization
Experience with Natural Language Processing and Computer Vision
Experience constructing data models using predictive analytics & strong statistics knowledge
Experience doing quantitative analysis

Here's how we work:


From working with top technologies to sending you to industry-leading conferences, we will make sure you have all that you need to expand your knowledge and grow your career. We have a trust-based culture where all team members are empowered to work in the way that's best for them to thrive.

Our culture is at the center of all that we do, and it has been recognized through numerous accolades over the past three years including: Best Workplaces in Canada, Deloitte 50 Best Managed, Best Workplaces in Canada for Women, Most Admired CEO and Top 10 Most Admired Corporate Cultures.

Here's how to apply:


If you're interested in working with us on the future of shopping, click the ""Apply now"" button to submit your application.

While experience and skillsets are valuable, growth potential and attitudes are equally important. If you're prepared to grow drastically with your team at a world-class learning organization, consider applying. We understand that the most creative solutions require diversity in thought and life experiences.

Flipp is an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Accommodations are available on request for all aspects of the selection process.",3.9,Flipp,Toronto,"Toronto, Canada",201 to 500 employees,2007,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,74.5,13,data scientist,senior,1,1,0,0,0,0,1,0,0,0,0,0,1,0,1,3259,0
116,"The Career Opportunity:

Data Scientist & Marketing Cloud

rickis.com is the established and expanding online channel of Rickis fashions Inc.

cleo.ca is the established and expanding online channel of cleo fashions Inc.

We are looking for an experienced and innovative Data Scientist & Marketing Cloud to represent both Rickis and cleo. This position is based in Rickis Home Office located in Winnipeg, MB.

The Data Scientist & Marketing Cloud will consult and partner with internal and external stakeholders to review, analyze, provide recommendations and execute changes in order to improve and further enhance product data. The successful candidate is self-motivated and focused technical services enthusiast with a passion for cutting edge digital marketing technology. Must possess exceptional written and verbal communication skills and a thirst for knowledge with a sharp eye for detail.

Main Responsibilities:
Collaborate with internal and external stakeholders to develop and support overall digital transformation of the Rickis and cleo brands through the use of technology.
Collaborate closely with Marketing and E-commerce team members on development of the web user experience, delivery and maintenance
Effectively communicate using data storytelling
Proactively identify opportunities and make recommendations to improve product data
Troubleshoot and solve product data issues
Identify and resolve product listing issues: product details, descriptions, performance, measurements, images
Discern which problems are important to solve for the business and identify new ways the business should be leveraging its data.
Work with product specialists and suppliers to enrich product data from various data sources
Optimize existing product listings using basic knowledge of keyword research, image enhancement, copy-write and product search rankings
Design and build journeys like welcome series, cart reminders, promotions, and reactivation/retention campaigns.
Create and review dashboards and reports to help analyze performance and discover where improvements to performance can be made.
Monitor and maintain data quality for both brands marketing databases.
Prepare, test and deploy campaigns utilizing emails, workflows, landing pages, and forms.
Help drive business decision-making by educating and informing teams on digital metrics
Use a variety of software tools, such as spreadsheets, databases, reporting and analytical software to assemble and format data and reports
Develop end to end process documentation for product data management
Establish regular reporting activities for internal and external stakeholders
Work with IT and technical teams to define and automate regular tasks and reporting
Educate team members through training and individual support.
Design solutions to address business needs using Salesforce Marketing Cloud.
Other duties as assigned.
Qualifications:
3-5+ years-experience in product information management
Secondary education in Computer science, Social sciences, Physical sciences, or Statistics.
Have a working knowledge of SQL, CSS, HTML;
Exposure to Salesforce Marketing Cloud (and/or other cloud marketing technology) a plus
Knowledge of mobile, social, and ecommerce marketing;
Experience with various templating languages such as PHP, ASP.NET, and Jinja;
Knowledge of various mobile, social, and ecommerce platforms..
Salesforce Certified Email Specialist or Marketing Cloud consultant certification a plus.
Must be a motivated self-starter with strong interpersonal skills.
Strong communication skills, verbal and written.
Strong organizational skills, attention to detail, and ability to multi-task and shift between projects on a time-sensitive basis.
Strong understanding working with Unstructured Data
Knowledge of Electrical, Comm/Data and Automation products an asset
Advanced Excel skills
Experience working as a member of an e-commerce team a plus.
Understanding of digital technologies as they relate to analytics on an ecommerce site
Knowledge of SEO tools
Strong Project management skills
Experience working with Business Intelligence Tools
We thank all applicants for their interest however, only those selected for an interview will be contacted. Rickis/cleo is an equal opportunity employer. If chosen to participate in the selection process, accommodations are available upon request. We will consult with the applicant to provide or arrange suitable accommodation in a manner that takes into account the applicants accessibility needs",2.8,Cleo/Ricki's,Winnipeg,"Montreal, Canada",1 to 50 employees,-1,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1,74.5,-1,data scientist,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,4514,0
117,"Machine Learning Engineer


We are seeking a dynamic, innovative thinker who is looking for a tremendous opportunity to solve some of the language industry’s most exciting problems. You will be a key member of a small and versatile team.

If you are determined to show the world the power of natural language processing and you revel in the opportunity to execute a project from start to finish, this is the job for you!

Our team style:
We are a small team of developers working in a profitable and rapidly growing company
We strive to be innovative and fast-moving and are passionate about getting things done right
We work collaboratively to grow and learn together
We are not afraid of difficult problems but carefully choose what we spend time on
What you will do:
Implement automated processes to efficiently deploy deep-learning models in production
Collaborate with IT and software development engineers
Research, design, implement, and validate cutting-edge algorithms to analyze diverse sources of data to achieve targeted outcomes
Perform data studies of new and diverse data sources
Conduct modeling and experimental design
Test and validate predictive models
Design, modify, and build new data processes
Generate algorithms and create computer models
Implement new or enhanced software, designed to access and handle data more efficiently
Who you are:
M.Sc. or Ph.D. in Computer Science (or similar) with two years of industry experience in machine learning/deep learning
Experience in deploying deep-learning models in production
Experience with one or more general purpose programming language, including but not limited to Java, Lua, and Python, as well as experience with the Torch, Tensorflow, Pytorch, and Theano frameworks
Ability to write clear, concise, well-structured, and well-organized code
Strong communication skills (orally and in writing)
Experience with microservice architecture
Employment type:
Full-time
Please apply with a resume and cover letter to scribendi (dot) hr (at) scribendi (dot) com detailing your experience in relation to the above-stated job requirements as well as your salary expectations.",2.9,Scribendi,Chatham,"Chatham, Canada",201 to 500 employees,1997,Company - Private,Research & Development,Business Services,$50 to $100 million (CAD),-1,74.5,23,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,2140,0
118,"Want to participate in the evolution of one of the most recognized Fintech software in Canada?

Want to be part of an experienced and dynamic development team?

Are you stimulated by the idea of helping to build a complex infrastructure that generates more than 20 million reports annually?

We want to know more about you!

The data engineer is responsible for the analysis, development and delivery of high quality Croesus environments.

Your daily life:
Design innovative technological solutions and proofs of concept that address specific internal issues.
Support internal and external teams (for example, students) within the framework of Croesus Lab projects.
Keep abreast of technological and scientific advances in areas related to the companys sectors of activity.
Develop and maintain the laboratory infrastructure.
Document the companys technological choices and participate in knowledge transfer and training of other internal teams.
Participate in the drafting of reports for the Scientific Research and Experimental Development Tax Incentive Program (SR&ED), patents, and scientific publications in collaboration with the persons concerned.
Participate in various internal and external innovation initiatives.
Participate in conferences and events related to technology or finance.
Experience in development: C #, Java or other;
Mastering scripting languages such as SQL / Bash / Shell / Perl / Python on Linux;
Experience in databases;
Experience in data processing;
Rigor and thoroughness
Ability to solve problems
Bilingualism (French and English);
Ability to work in a multidisciplinary team.
Assets:
Knowledge in DataScience, Data Lake;
RedShitf, Snowflake;
ETL tools.",3.4,Croesus,Laval,"Montréal-Ouest, Canada",51 to 200 employees,1987,Company - Private,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (CAD),-1,74.5,33,data engineer,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1687,0
119,"This is an opportunity in the exciting and fast-growing transportation technology industry. Public transit is being transformed from a system of static, scheduled fixed-routes, to a dynamic on-demand network, and you’ll be one of the pioneers shaping this transformation.

Data is at the heart of RideCo’s core offering, and drives the decisions we make in both our product and the services offered to our clients. As a Data Engineer Analyst, you will be responsible for building tools and processes to collect, transform, and generate insights and reports on the data needed to make these decisions. As a key technical and analytics resource for operations managers, you’ll have a vital role in shaping the design, performance, and success of our clients’ next-generation on-demand transportation services. At RideCo, you will:
Manage and launch new reporting capabilities: Spearhead the development of an end-to-end data management and analytics platform and new client-facing reporting dashboard. Work with operations managers to transform business requirements into concrete insights. Observe and foster best practices in business process design, implementation, and review.
Use your creative aptitude to extract unique insights: Combine your creative thinking with your analytic skills to transform big data into actionable insights. Direct exploratory data initiatives to uncover business value using statistical and analytic techniques to drive project success and support the company reaching its corporate goals.
Generate and analyze operational performance reports: Build comprehensive performance analysis reports spanning rider user-experience, driver user-experience, marketing, operating efficiency, and unit economics.
Improve internal processes and tooling: Identify ways to further systematize our internal processes, including with new analysis and visualization tools. Share your ideas with team members and collaboratively champion internal process/tooling improvements.
Drive continuous improvement: Collaboratively develop weekly/monthly actions to drive continuous improvements, and to achieve the company’s data objectives (e.g. build new reports, database maintenance, etc) Work with the operations managers, and other stakeholders to execute on initiatives.
Automate: Identify areas of automation within the organization. Champion efforts to streamline processes and improve team productivity.
Your playground / what you’ll learn:

At RideCo you’ll get a chance to play, learn and build with the following tools and technologies, and as part of a cross-functional team that is the world’s foremost innovator in on-demand transit software.
Python
Microsoft Excel, Access and other Office tools
PostgreSQL, MSSQL, Oracle
Building schemas, data normalization, writing optimal SQL queries, debugging existing queries
Development Processes: Agile, continuous integration, Jenkins


Qualifications and Experience:

Required:
3-5 years of experience in data analyst or engineering role(s)
A deep and intuitive understanding of database and SQL experience.
Education:

Undergraduate degree in Engineering / Data Science / Computer Science / Applied Mathematics / Statistics, or related discipline.

Compensation and benefits:

Base salary: $70K - 90K + performance-based bonus or stock options
Work-Life Balance: Flex time, work from home, vacation time
Set-up: Adjustable height desk, high-end computer/laptop, three monitors, ergonomic seating
Benefits Plan: Dental, prescription, disability, massage and more
Food & Fun: Gourmet coffee, teas, juice, snacks, team lunches

Who we are:

http://www.rideco.com

RideCo powers on-demand transit. Public transit agencies use RideCo's cloud-based software platform to provide on-demand shared rides in dynamically routed buses, vans, and cars. Our clients include some of the world’s largest transportation operators such as San Antonio Metro, Los Angeles Metro, San Diego County, Grab, and Calgary Transit.

Have you experienced getting frustrated with transfers and waiting while taking a public bus? Have you seen buses drive around in low-density areas with very few passengers on-board and wondered how inefficient that seems to be? You're likely aware of the first & last mile access challenges faced by transit hubs. We are solving these problems by re-imagining shared mobility. Imagine a world where vehicles have dynamic routes responsive to real-time trip demand. This 'dynamic shuttle' (or van/sedan) would pick you up, on-demand, at or near your doorstep and take you to your destination or transit hub. Along the way, it may pick-up other passengers going in your direction. Your experience will be seamless: less waiting, less walking, fewer transfers, shorter travel time, and timely pickups and drop-offs. RideCo's 'dynamic shuttle' platform enables this seamless experience and low-cost shared rides for vehicle fleet operators and their passengers. By seamlessly moving more people in fewer vehicles we are catalyzing a generational shift in how people get around cities and towns. This means commuters spend less time in transit and more time doing what they enjoy.

RideCo powers a diverse range of use cases, including residential/ suburban travel; first-mile-last-mile connections for transit hubs; and corporate employee transportation. We are investing to scale up and capture the growing demand for on-demand shared rides solutions.

Contact:

Email your resume (or link to your LinkedIn profile) and cover letter to:

RideCo-RdC0393@applications.recruiterbox.com

Email Subject: “Data Engineer Analyst”

In your cover letter or email, please write a few sentences outlining how you meet the requirements for this role.",4.5,RideCo,Waterloo,"Waterloo, Canada",Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1,74.5,-1,data engineer,na,0,1,0,0,1,1,0,0,0,0,0,0,0,0,1,5709,0
120,"Data Analyst Corporate Banking & Payments
LOCATION: TORONTO

Capco – The Future. Now.

Capco is a distinctly and positively different place to work. Much more than consultants, we are active participants in the global financial services industry. Our passionate business and technology professionals enjoy a unique environment where they are actively encouraged to apply intellect, innovation, experience and teamwork. We are dedicated to fully supporting our world class clients as they respond to challenges and opportunities in: Banking, Capital Markets, Finance Risk & Compliance, Insurance, and Wealth and Investment Management. Experience Capco for yourself at capco.com

Let's Talk About You

You want to Own Your Career. You're serious about rising as far and as fast as your work and achievements can take you. And you're ready to write the next chapter of your career story: a challenging and rewarding role as a Data Analyst.

A Word About Us

Capco – Forming the Future of Finance

Capco is a distinctly and positively different place to work. Much more than consultants, we are active participants in the global financial services industry. Our passionate business and technology professionals enjoy a unique environment where they are actively encouraged to apply intellect, innovation, experience and teamwork. We are dedicated to fully supporting our world class clients as they respond to challenges and opportunities in: Banking, Capital Markets, Finance Risk & Compliance, Insurance and Wealth and Investment Management. Experience Capco for yourself at capco.com.

Let's Get Down to Business

Capco is looking for talented, innovative and creative people to join our emerging data analytics team to work on a number of projects and applications.

Responsibilities
Define and obtain source data required to successfully deliver insights and use cases
Determine the data mapping required to join multiple data sets together across multiple sources
Create methods to highlight and report data inconsistencies, allowing users to review and provide feedback
Propose suitable data migration sets to relevant stakeholders
Assist teams with processing, planning, tracking, scope and coordination of data migration sets as required
Work on end-to-end flow of a broad range of analytics use cases
Maintain RAID logs for projects, and ensure that these are fed into the programme effectively
Lead and work closely with all stakeholders creating a strong culture of transparency and collaboration
Adhere strictly to compliance/operational risk controls and due diligence in accordance with regulatory standards, policies and practices
Report concerns or observations in terms of control weaknesses, compliance breaches and operational risk
Maintains control standards, including timely implementation of internal and external audit points
Must Haves
Five (5) or more experience working as a Data Analyst
Demonstrate a continual desire to implement ""strategic"" or ""optimal"" solutions and where possible, avoid workarounds or short-term tactical solutions
Experience in Data Mapping and Business Requirements
Experience in Cash Management or Payments domain is MUST have
Exceptional knowledge of Python
Exceptional knowledge of PySpark
Manage stakeholder expectations and ensure that robust communication and escalation mechanisms are in place across project portfolios
Technical capabilities
Python
Pyspark
Ability to write SQL queries, Scala knowledge preferable and navigate data bases especially Hive, CMD, Putty, Note++
Good knowledge of SDLC and formal Agile processes, with a bias towards TDD and a willingness to test products as part of the delivery cycle
Experience using and flattening XML
Experience with big data programmes
Nice to Haves

We are also looking for individuals who demonstrate the following traits:
A good understanding of control requirements surrounding data handling
Ability to assess operational risks during analysis, implementation, planning and execution phases in conjunction with stakeholders
Knowledge and experience in data quality & governance
Professional experience is important. But it's paramount you share our belief in disruptive innovation that puts clients ahead in a tough market. From Day One, your key skill will be to perceive new and better ways of doing things to give your clients an unfair advantage.

Now Take the Next Step

If you're looking forward to progressing your career with us, then we're looking forward to receiving your application.

For more information about Capco, visit www.Capco.com.

Capco is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics.",3.9,Capco,Toronto,"London, United Kingdom",5001 to 10000 employees,1998,Company - Public,Consulting,Business Services,$1 to $2 billion (CAD),"Deloitte, EY, Accenture",74.5,22,data analyst,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,4838,3
121,"Come and be a part of Amazon's amazing growth story! Amazon.com's Forecasting group is searching for a Data Engineer to join our team. We are pioneers in the fields of demand analysis and forecasting. If you want to learn how to leverage technology to predict the future, this is the team for you.

As a member of the Demand Forecasting team, you'll play a key role in solving some of the world's most complex technical challenges associated with Forecasting. You will apply Large-scale computing, Distributed systems, Data mining, Scalability, Machine learning and Statistical Algorithms techniques - just to name a few.


Our Data Engineer needs to be able to gather and understand data requirements, present it to software engineers, and work in the team to achieve high quality data ingestion goals. You need a passion for complex problems, and enjoy the challenge of operating complex and mission critical systems under extreme loads. Do you think you are up to the challenge? Would you like to learn more and stretch your skills and career?
In this role, you will be a technical expert with significant scope and impact. You will work closely with a group of Software Development Engineers, Product Managers, Data Scientists, and Business Intelligence Engineers to create the data infrastructure and pipelines necessary to drive our teams initiatives.

Successful candidates should come from a strong data engineering background. You need to have experience with structured data, and being able to analyze/transform the data using various tools. Although SQL is a strong requirement, being flexible enough to work in a scripting environment is a must. Often, the pace of innovation and change implies a need to move to new data sources, and our Data Engineers get to participate in deep diving business data in order to understand/measure sources of disparity. Your analytical skills and knowledge of schema metadata will be essential.










Basic Qualifications

· Bachelor's degree in Computer Science, Engineering, Mathematics, or a related technical discipline.
· 4+ years of industry experience in Software Development, Data Engineering, Business Intelligence, Data Science, or related field with a track record of manipulating, processing, and extracting value from large datasets.
· Hands-on experience and advanced knowledge of SQL.
· Experience in Data Modeling, ETL Development, and Data Warehousing.
· Experience using business intelligence reporting tools (Power BI, Tableau, Cognos, etc.).
· Experience using big data technologies (Hadoop, Hive, Hbase, Spark, EMR, etc.).
· Knowledge of Data Management fundamentals and Data Storage principles.
· Experience coding and automating processes using Python or R.
· Strong customer focus, ownership, urgency, and drive.
· Excellent communication skills and the ability to work well in a team.
· Effective analytical, troubleshooting, and problem-solving skills.

Preferred Qualifications

· Masters in computer science, mathematics, statistics, economics, or other quantitative fields.
· Experience working with AWS big data technologies (Redshift, S3, EMR, Glue).
· Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy.
· Experience providing technical leadership and educating other engineers for best practices on data engineering.
· Background in Big Data, non-relational databases, Machine Learning and Data Mining is a plus.",3.9,Amazon,Toronto,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (CAD),"Google, Microsoft, Walmart",74.5,26,data engineer,na,0,1,1,1,0,1,1,1,0,0,0,0,1,0,1,3522,3
122,"Role Purpose:

The primary role of a Data Analyst is to interpret data and turn it into information which can be easily assimilated and interpreted. This role entails scrutinizing large volumes of security logs and telemetry data, interpreting patterns and trends for generating insightful information.

The ideal candidate should be highly skilled in all aspects of data analytics, including mining, generation, and visualization.

Key Accountabilities:
Develop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks.
Define and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution.
Develop and maintain databases by acquiring data from primary and secondary sources and build scripts that will make our data evaluation process more flexible or scalable across data sets.
Mine large data sets, cleanse the data.
Identify, analyse, and interpret trends or patterns in complex data sets.
Evaluate data using analytical and logical reasoning to examine each component of the data provided.
Document procedures, workflows and interpretations.
Providing technical expertise on data storage structures, data mining, and data cleansing.
Supporting the data warehouse in identifying and revising reporting requirements.
Supporting initiatives for data integrity and normalization.
Experience:
Relevant experience in Data Analysis.
Demonstrated experience in handling large data sets.
Experience of statistical methodologies and data analysis techniques
Knowledge & Skills:
Excellent knowledge of Python and data analysis tools.
Technical expertise in data models, database design development, data mining and segmentation techniques
Exposure to Cyber Security domain and domain specific databases is preferred.
Excellent numerical skills.
Adept at queries and report writing.
Strong analytical skills with the ability to collect, organize, analyse, and disseminate significant amounts of information with attention to detail and accuracy.
The capacity to develop and document procedures and workflows.
Knowledge in HIVE and Impala is preferred.
Education:

Bachelor’s Degree in Computer Science Engineering",-1.0,Prevalent,Cochin,"Kochi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,74.5,-1,data analyst,na,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,2305,0
123,"// English version will follow…//

Titre : Scientifique de Données

Relève du : BI Manager

Fonction du poste :
Travailler avec les stakeholders du studio afin de déterminer les opportunités pour valoriser au niveau opérationnel, l’utilisation des données collectées;
Créer des modèles de classification et de prédiction;
Implanter des modèles de détection d’anomalies;
Développer et déployer des services data driven en opération en collaboration avec l’équipe de data engineering;
Supporter l’équipe analytique sur les analyses ad-hoc très complexes;
Exécuter des analyses en profondeur afin de détecter les tendances cachées;
Fournir des rapports avec des nouvelles idées et des recommandations;
Collaborer avec les analystes de projet afin de fournir des outils analytiques pour la production (A/B testing tool, Life Time Value factors detection, Churn prediction factors detection, Fraud detection Tool etc.);
Participer à l’évolution des pratiques analytiques au sein de la division mobile de Square Enix West.
Expériences et qualités requises :

Expérience et qualifications
Msc en Science Informatique, Statistiques, Ingénierie Financière ou tout autre discipline pertinente. PhD préférable;
2-5 ans d’expérience en science des données/machine learning;
Strong expérience en développement en SQL et Python (préférable) ou Spark/Scala/R avec de bonnes connaissances sur les pipelines de données;
Expérience opérationnelle avec les modèles bayésiens et inférentiels.
Bonne métrique des technologies data science de GCP (Cloud TPU, AI Platform AutoML etc.);
Expérience opérationnelle en data mining (GLM/Regression, Random Forest, Test Mining, Network Analysis, série chronologique, etc.);
Expérience en production de jeu est un plus
Bonne connaissance d'une variété d'algorithmes et de techniques d'apprentissage automatique;
Bilingue (français et anglais).
Qualités interpersonnelles
Excellentes habiletés de communication et de présentation;
Capacité de travailler sur plusieurs projets data science à la fois;
Orienté vers l’expérience de nos joueurs dans le produit final;
Capable de collaborer avec d’autres départements (conception, art, animation, narration, programmation, gestion, ect.);
Être à l’aise dans une équipe motivées par les améliorations constantes;
Capacité d’apprentissage rapide et de partage des connaissances avec les autres;
Entreprenariat et humilité;
Être professionnel, donner et recevoir de la rétroaction constructive.
Motivation et intérêts

De l’ambition et de la passion pour les jeux vidéos sont essentielles !

------------------------------

Job Title: Data Scientist

Reports to: BI Manager

Responsibilities:
Work with the studio stakeholders to determine the opportunities to enhance at the operational level the use of the collected data;
Create classification and prediction models;
Implement anomaly detection models;
Develop and deploy data driven services in operation in collaboration with the data engineering team;
Support the analytical team on very complex ad-hoc analyzes;
Perform in depth analysis to uncover hidden patterns;
Provide reports with insights and recommendations;
Collaborate with project analysts to provide analytical tools for production (A / B testing tool, Life Time Value factors detection, Churn prediction factors detection, Fraud detection Tool etc.);
Participate in the evolution of analytical practices within the mobile division of Square Enix West.
Profile

Experience and qualifications:
MS in Computer Science, Statistics, Financial Engineering or a related quantitative field. PhD preferred.
2-5 years of data science/machine learning experience
Strong experience in SQL and Python (preferable) or Spark / Scala / R with good knowledge of data pipelines;
Operational experience with Bayesian and inferential models.
Good mastery of GCP data science technologies (Cloud TPU, AI Platform AutoML etc.);
Operational experience in data mining (GLM / Regression, Random Forest, Test Mining, Network Analysis, time series, etc.);
Game production experience is a plus
Good knowledge of a variety of machine learning algorithms and techniques
Bilingual (French and English).
Interpersonal qualities:
Strong communication and presentation skills;
Ability to work on several data science projects at the same time;
Oriented towards the experience of our players in the final product;
Able to collaborate with other departments (design, art, animation, narrative, programming, management, etc);
Be at ease in a team driven by constant improvements;
Capable of quick-learning and clear communication of what was learned;
Entrepreneurship and humility;
Be professional, ability to give and receive constructive feedback.
Motivation & interest:

Passion and ambition for videogames are essential!",3.2,Square Enix Co.,Montreal,"Tokyo, Japan",1001 to 5000 employees,1975,Company - Public,Video Games,Media,Unknown / Non-Applicable,"Electronic Arts, Activision, Infogrames",74.5,45,data scientist,na,1,1,0,0,0,1,1,0,0,0,0,0,1,0,1,4768,3
124,"About Nōwn
Nōwn POS is the all-in-one customer recognition retail solution. We put the focus on the person behind the purchase. We’re out to prove that traditional loyalty programs don’t work and scalable, authentic connections between a business and their customers is the only path to success. We’re taking over the retail & quick serve markets and we want your help to do it.

About the Role
If you love digging into the root causes of problems, finding patterns and are looking for a dynamic, forward-looking work environment then this is the role for you. You will be responsible for supporting the work of Engineers in developing and delivering data driven products, tools, and workflows.

Responsibilities

Expertly leverage data and visualization tools including SQL, Excel, and Tableau, among others, to present actionable insights
Lead independent analytical research projects
Interpret and define the data needs of business teams
Build visualizations of data using dashboarding, visualization, and other reporting tools
Provide analytical and data-driven decision-making support for key projects
Balance quantitative data analysis with qualitative user insights to uncover how our users interact with our products
Empower our largest enterprise customers to leverage data with as-needed database requests
Our dream candidate has...

Sound understanding of relational databases (SQL Server, Amazon Redshif, NoSQL etc.)
Experience with data visualization and presentation, including tool sets for supporting this
Great communication skills with the equal ability to work with developers as well as translating to non-technical business stakeholders with ease
Has the ability to build and manage databases
Enjoys solving problems and seeks to understand the story behind the numbers
Experience with E-Commerce, Retail and Business Analytics would be an asset
Can turn an abstract question into a series of SQL queries, and can turn data into a story
Nice to have: experience working in a customer-facing environment
Culture Fit

We have a small team and we LOVE working with each other. We want someone who wants to fit and grow with our culture.
This includes working hard, not being afraid of trying anything, helping each other out when needed, and being POSITIVE. Positive energy is big here!
Salary: Commensurate with experience

Here's what we provide

An office conveniently located downtown
Snacks and COFFEE
The opportunity to work with a team of amazing people in an entrepreneurial, forward thinking environment
A dog friendly office
Incredible social events
To apply, please email careers@lucova.com and include your resume.",-1.0,Luc,Toronto,"Toronto, Canada",1 to 50 employees,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1,74.5,-1,data analyst,na,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,2644,0
125,"Data Analyst Citis Innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to Citis Capital Markets, Securities Services and Banking lines of businesses. Our Mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurship spirit. We are currently looking for an excellent data analyst to join one of our cutting edge trade surveillance solutions. It is a highly advanced trade monitoring and analytics product used globally among Citis trading desks. Job Description Explore and analyze datasets to develop new robust controls Work with business partners to design new workflows to transform business requirements into concrete insights Onboard data across the various financial markets via multiple consumption methods (Message buses, SFTP, SQL connectors) Develop automated procedures to improve and optimize existing controls Work together with the R&D team to help guide the Platform roadmap Experience & Qualifications Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to details and accuracy Solid experience in working with data and relational / non-relational databases Hands-on experience in Scripting Languages (Python / R) Experience in troubleshooting code and logs Experience with parsing messages (ex: JSON, XML) and performing multiple data manipulations/ calculations Advantage Experience in Linux Advantage Excellent interpersonal and communication skills in English. BS/BA in Software Engineering or Computer Science advantage, or in Industrial Engineering, Mathematics, Statistics or Economics Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - CA ------------------------------------------------------ Time Type : ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,Citi,Mississauga,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,$10+ billion (CAD),-1,74.5,208,data analyst,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,3143,0
126,"About us

Evolve Biologix is an innovative technology start-up combining the latest advancements in biometric monitoring, machine learning, and artificial intelligence to create real world change. We are a fully funded start-up in Vancouver, BC and our purpose is simple: to empower users to live their best lives.

Evolve Biologix connects cutting edge technology with human biology. Our team is made up of radical dreamers who are committed to the vision of this organization and dedicated to driving real, positive change in this world. Our technology enables users to reimagine their limits and take tangible steps towards leading a more enriching life. If you’re excited by working with revolutionary technology, and being a part of a purpose driven team, we want to hear from you!

About the role

Evolve is seeking a Lead Data Scientist/Consciousness Engineer experienced in translating bio data from wearables into insightful and actionable user metrics. Our bodies communicate in multiple ways. Subtle biorhythms contain indicators of how we’re doing. Translating these through both established and inventive means is our focus. We’re looking for an individual who’s excited about pushing beyond step and calorie counting to deliver life-changing value to our customers.

Your focus will be on bio and physio data analysis, processing, pattern recognition and classification. You will work closely with embedded, mobile, and cloud developers to collaborate and deploy your algorithms across multiple platforms.

Responsibilities
Collaborate with experts in physiological and biomedical fields to interpret biological signals such as PPG, ECG, EEG, Respiration, GSR, Bio-Impedance, and Motion to deliver unique, valuable, and accurate insights to our users
Explore data sets in search of trends that enable us to deliver unique user features
Design, test, and implement efficient algorithms to deploy across our platform spanning embedded, mobile, and cloud
Write high-quality, maintainable, and portable code
Work closely with hardware, firmware, mobile, and cloud teams to translate your work into deployed code
Collaborate with the Product Team on requirements and priorities
Continuously discover and evaluate the latest developments and research papers to derive new techniques and methods of extracting insights
Your background
Minimum of BS in a discipline such as Electrical Engineering, Computer Science, Mathematics, Physics, or equivalent technical field. MS/PhD candidates are preferred. However, relevant experience and the ability to develop production-ready contributions are paramount
Fluent in C, Python/MATLAB
Experience querying both SQL and NoSQL databases
Background in Signal Processing and Machine Learning
Experience translating consumer wearable sensor data such as some of the following: 9-axis motion, PPG, ECG, EEG, GSR signals
Experience developing algorithms to derive and analyze one or more of the following: HR, HRV, AFib, BP, Breath Rate, and/or Motion analysis.
Experience deploying algorithms to one or more of the following: device firmware, mobile applications, and/or cloud-based solutions
Strong awareness of computational complexity and available compute and battery resources
Ability to develop algorithms based on published scientific literature is a bonus
Experience developing AI based platforms including chatbots or text bots is a bonus
Is a friendly and articulate team player, passionate about pushing beyond the norm in search of a better way
Why work with Evolve Biologix?
Flexible and fun work environment filled with passionate and capable people
Tremendous career growth within a fast-paced, inclusive, entrepreneurial culture
Extended health & dental benefits package
Competitive Compensation Package with potential equity and exponential growth
Fun co-work space with Kombucha on tap, coffee to keep you moving, and even a hammock overlooking English Bay to spark your creative
How to apply

Please apply online through our careers page: https://evolvebiologix.com/careers/",2.9,Resilient Management,Vancouver,"Vancouver, Canada",1 to 50 employees,-1,Company - Private,Real Estate,Real Estate,Unknown / Non-Applicable,-1,74.5,-1,data scientist,senior,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,4037,0
127,"About Paytm Labs:
At Paytm Labs, we build technologies that powers Paytm India, the world's fastest growing mobile payments and commerce ecosystem. We use our skills and our biggest asset – data, to make our dent in this universe. We are committed to offering the most transparent, secure, and personalized consumer experience to over 400 million users. We believe that this kind of scale, and the unique problems that it presents attracts curious candidates like yourself.

Job Description:
We are seeking a Data Engineer with a focus on BI, for our personalization and marketing automation team. This team has an impact on every pixel in our mobile app and drives customer engagement and growth by showing relevant products, services and messaging to our customers. Candidates should have technical skills to build real-time and batch data pipelines, and strong analytical capabilities to delve into and understand trends and patterns in the data. You will be working closely with world class software engineers, machine learning engineers and business teams, and the work you do will have a direct impact on the roadmap of our product.

Responsibilities:
Build and maintain batch and real-time data pipelines to power our analytical reports and dashboards
Analysis of historical data to identify trends and support decision making, including written and verbal presentation of results and recommendations
Set up A/B tests and ensure metrics are reported accurately
Identifying data needs and driving data quality improvement projects
Evangelizing data driven decision making within the team and to business & product owners
Understanding the broad range of Paytm data resources, and knowing the right ones to use for the problems at hand

Technial Requirements:
Proficient in at least one programming language like Scala, Java or Python
Experienced in Apache Spark, or other big data processing frameworks
Proficient in SQL
Proficient in software development, and source code management (Git etc)

Qualifications:
BS degree or higher in computer science engineering, statistics, mathematics, econometrics, or a similar quantitative field
3+ years work experience in data engineering, software engineering and/or data analysis
Prior success in working with extremely large datasets using big data technologies
Demonstrated ability to directly partner with business owners to understand product requirements
Effective spoken and written communication to senior audiences, including strong data presentation and visualization skills
Detail-oriented, with an aptitude for solving unstructured problems

Nice to Haves:
Familiarity with AWS services
Experience with data streaming technologies like Kafka, Spark Streaming
What we Offer!
We are proud to announce that we have been certified as a Great Place to Work!
A collaborative, open work environment that fosters ownership, creativity, and urgency
Enrolment in the Group Health Benefits plan right from Day 1, no waiting period
Fuel for the day: Weekly delivery of groceries and all types of snacks to our office
All types of signature drinks from coffee to lattes to cappuccinos
Catered lunch and desserts on a monthly basis!
Ping Pong and Pool: Become the next Paytm Labs Table Tennis/ Pool champ!
And so much more!
Notice for Job Applicants

Following the advice of Canadian health authorities, to mitigate the risk of potential spread of COVID-19 and support social distancing, all recruiting activities including interviews and new hire onboarding will be conducted remotely. While we are doing our best to ensure reasonable response times, please expect potential delays during the recruiting process due to the current situation. Thank you for your patience and understanding during these challenging times.

Don't have Paytm Canada App yet?
Check us out in the Google Play or App Store.

We thank all applicants, however, only those selected for an interview will be contacted.

Paytm Labs is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodations during the recruitment and selection process, please let us know. Paytm Labs is an equal opportunity employer.",3.9,Paytm,Toronto,"Toronto, Canada",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,74.5,6,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,1,0,1,4283,0
128,"Are you looking for unlimited opportunities to develop and succeed? With work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations.

Job Description

The Senior Data Scientist develops and implements analytics enabled solutions to improve business process, to generate insights, support business goals and strategy development. The Senior Data Scientist also owns and delivers projects of diverse scope, oversees the work of more junior data scientists.

Key Responsibilities:
• Develops and implements analytics enabled solutions to improve business process, to generate insights, support business goals and strategy development
• Owns and delivers projects of diverse scope. Oversees the work of more junior data scientists.
• Works on problems of diverse scope / complexity where analysis of situations or data requires an in-depth evaluation of a variety of factors
• Strong ability to generate relevant, actionable insights based on iterative data analysis, translate data-driven output into business language, and to make appropriate recommendations to respective business stakeholders
• Independently provides analysis on datasets of significant complexity.
• Quickly able to develop enough business insight to connect data sources across multiple diverse and complicated systems.
• Recommends implementable solutions to (or in collaboration with) business partners.
• Considers change management in all aspects of their work. Supports more junior data scientists with Change Management.
• Has intimate understanding of the business value chain and customer lifecycle for a line of business or more. Has fundamental understanding of the business as a whole, and has started to build a network of people for ideation, info sharing, knowledge.
• Understands the corporate climate and culture
• Strong knowledge of the business
• Engages in ongoing discussions and moves others towards a position, appealing to their needs and interests to gain acceptance
• Is able to display empathy with the business and anticipate their push back and areas of concern
• Maintains a strong internal network, begins to network with more senior stakeholders within the organization. Begins to develop an external network and develop their own brand, particular in their own practice area.
• Actively involved in recruitment of data science professionals (campus etc)
• Shares ideas with others, leads brainstorming sessions. Contributes to solutions outside immediate area of expertise. Ensures all voices are heard.
• Actively seeks out coaching and incorporates feedback into their work. Provides guidance and mentorship to more junior data scientists. Promotes best practices within the team. Shares technical expertise with others.
• Owns their career development. Takes advantage of available resources to advance their technical and business skills.
• Understands how their project supports broader business strategy, including the core drivers of business value. Able to prepare a business case on the benefits of their assigned work.
• Incorporates lessons learned throughout the business into their work. Engages with global counterparts to share learnings.
• Strong ability to construct systematic process to implement analytics insights and solutions, this includes (but not limited to):
• 1) designing a process with multiple relevant parties with clear specifications of roles and responsibilities
• 2) identifying required tasks, system / data flow and contingency
• 3) specifying check-and-balance throughout the process
• 4) establishing rigorous tracking and closed-loop learning
• 5) implement such process in a scalable way

Education, Experience and Skills:
• Advanced degree in Statistics, Math, Computer Science, or Engineering; or Bachelor’s degree with equivalent technical experience
• Generally, a minimum of 5 years of applicable experience
• Advanced knowledge of programming languages and concepts (e.g. SAS, SPSS, R (different modules) or Python)
• Expert in basic and advanced statistical tests, distributions, maximum likelihood estimators, statistical modelling techniques (regression, cluster / factor / principle components, decision tree, survival analysis, etc.)
• Advanced knowledge of different techniques and knowledge of machine learning algorithms. Basic knowledge of AI toolkits.
• Expert in data visualization tools such as Tableau, QlikView, open source data visualization libraries - ggplot and d3.js
• Advanced knowledge of common database querying languages such as SQL. Capability of applying a systematic, structured approach to explore / navigate / mine massive amount of data, structured or un-structured, to uncover hidden patterns / insights. Strong working knowledge of relational database models (e.g. data vaulting techniques, rules tables).

Decision Authorities:

• Day to Day operational decision-making authority
• Decisions at this position are made using judgment based on skills and knowledge already developed
• Decisions beyond normal day to day may require escalation to management
• Managing projects and major deliverables

If you are ready to unleash your potential it’s time to start your career with Manulife/John Hancock.

About Manulife

Manulife Financial Corporation is a leading international financial services group that helps people make their decisions easier and lives better. With our global headquarters in Toronto, Canada, we operate as Manulife across our offices in Canada, Asia, and Europe, and primarily as John Hancock in the United States. We provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. At the end of 2019, we had more than 35,000 employees, over 98,000 agents, and thousands of distribution partners, serving almost 30 million customers. As of March 31, 2020, we had $1.2 trillion (US$0.8 trillion) in assets under management and administration, and in the previous 12 months we made $30.4 billion in payments to our customers. Our principal operations are in Asia, Canada and the United States where we have served customers for more than 155 years. We trade as 'MFC' on the Toronto, New York, and the Philippine stock exchanges and under '945' in Hong Kong.

Manulife is an equal opportunity employer. We strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. We are committed to fair recruitment, retention and advancement and we administer all of our practices and programs based on qualification and performance and without discrimination on any protected ground.

It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will consult with applicants contacted to participate at any stage of the recruitment process who request any accommodation. Information received regarding the accommodation needs of applicants will be addressed confidentially.",3.7,Manulife,Toronto,"Toronto, Canada",10000+ employees,1887,Company - Public,Investment Banking & Asset Management,Finance,$50 to $100 million (CAD),"MetLife, ING, Sun Life",75.5,133,data scientist,senior,1,1,0,1,0,1,0,0,0,0,0,0,1,0,1,7100,3
129,"Health insurance is critical to guaranteeing people's ability to pay for care and be financially protected when sudden, unexpected illness strikes.

We're tackling some of the industry's toughest problems by employing AI-powered predictive analytics on the messiest data. Together, we can make health insurance more effective, reliable and affordable.
This is how we will achieve cost effective care that works for everyone.

Backed by both Canadian and Silicon Valley based venture capital, the Canadian government, and a team of high-profile entrepreneurs, we are proud to be based in Toronto, Canada at the center and birthplace of deep learning.

Top Reasons to Join Knowtions:

Healthcare is the most impactful field in AI. Your work will make sure people can pay for healthcare when they need it most. This is an extraordinary opportunity to transform healthcare from within the behemoth.

We are solving some of the most complicated problems in our industry. Join us if you want to push the frontier of what AI can do and how AI can transform an entire industry.

We have unparalleled size of proprietary datasets. It's the critical raw ingredient to optimizing healthcare and your playground.

We build and deliver, then explore to build more. Work and grow with a diverse team that brings out the collective genius in each other

Your role

As a ML Engineer, you would be responsible for training, testing, and deploying our data science pipeline: from data extraction and transformation to modelling this data so that it can be efficiently served via our APIs. We are looking for an experienced ML engineer who will bring subject matter expertise and best practices to all aspects of working with big data. This is a full-time role in Toronto, Ontario.

Your team will own

Collaboration with ML Researcher to add new ML services into pipeline
Data distribution and processes for large-scale ML pipelines
Productization and deployment of ML pipelines to on-premise and cloud environments
Leadership in the adoption of best practices for software development and use of Big Data and ML technologies

About you

Care about improving healthcare using the latest in machine learning and artificial intelligence
Own problems end-to-end in a very ownership driven culture
Care more about reviewing and adopting industry wide data science practices to solving problems as opposed to writing a lot of code
Comfortable massaging and cleaning up datasets for loading

Requirements

3+ years of work experience in Machine Learning
Experience architecting and designing high performance server-side components and big data processing pipelines using popular libraries and frameworks
Experience with Tensorflow (or similar libraries) from GPU training, efficient input pipelines (queues, Dataset API, and the like), to deployment of packaged/compiled models, and distributed computing (sharding, clusters, etc.)
Experience resource management service workflow: queue systems (RabbitMQ, Kafka), AWS (RDS, S3, Kubernetes), build systems (Ansible, Terraform, Jenkins, etc.), Docker.
Experience with big data technologies Postgres, Cassandra, Spark, Hadoop, Hive
Experience with developing production code in Python, Java/Scala, C/C++
Masters in Computer Science or a quantitative field

In a typical week, you might...

Improve ML models several times over
Automate various components of the training/test pipelines and model deployments
Importing new clinical data to work with our internal ontologies
Resolve performance issues with various aspects of the pipeline and application

What we offer

Work with awesome people that support and challenge one another to bring out the best in each other
Leadership positions as we continue to grow the team
Competitive salary and participation in company success through employee stock options
Health, dental, and vision benefits
Conference participation and publishing opportunities in ML, AI, NLP, and Bioinformatics
Retreats and outings to bond with your team
Modern office off King and Duncan
Unlimited coffee and snacks",-1.0,Knowtions Resea,Toronto,"Toronto, Canada",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,75.5,-1,machine learning engineer,na,0,1,0,0,0,0,1,1,0,0,0,0,1,1,0,4063,0
130,"Data is the foundation of our business in AI @ Unity. We are looking for a Senior Data Scientist to join our centralized data science team that supports multiple products and teams at Unity. As a Senior member of our team, you will be responsible for not only providing solutions, but identifying new opportunities within our data and solving them with machine learning techniques. Our team develops and implements machine learning models to production and intuitively makes decisions around what approaches to take in solving hard problems.

Some of the problems we solve are player and developer profiling, improving customer retention, personalizing customer experiences, revenue optimization, and using data to improve the Unity engine!

If you have extensive experience working in industry as a data scientist, building and implementing deep learning models in a production environment, and are excited about having a huge impact on the gaming industry then we want to talk with you!

Responsibilities
Influence key partners and drive alignment on data-science and machine learning initiatives
Develop, optimize, and implement deep learning models to deliver a personalized experience for our users
Identify, define, and lead data science and machine learning projects end-to-end
Mentor junior members on the team
Requirements
Industry experience developing, optimizing, and implementing traditional machine learning and deep learning models in a production environment
In-depth knowledge and understanding of deep learning
Deep familiarity with machine learning libraries such as Tensorflow, PyTorch, Keras, scikit-learn, and MLLib
Professional experience leading data projects from problem identification to production
Extensive experience programming with Python and/or Spark
Bonus Points
PhD or Masters in Data Science, Analytics, Statistics, Mathematics, Physics, Economics, Computer Science or another quantitative discipline, or equivalent industry experience
Experience working with petabytes of data
Experience with reinforcement learning
About Unity Technologies

Unity is the world's leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity's platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company's 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com.

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.

Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

#LI-MH1 #SEN",4.9,Unity Technologies,Vancouver,"San Francisco, CA",1001 to 5000 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Epic Games, Electronic Arts, Zynga",75.5,15,data scientist,senior,0,1,0,0,0,0,1,0,0,0,0,0,1,1,1,3897,3
131,"How do you imagine life at an insurance company - its people, its culture, its offices? We bet that if you join Intact, you will be in for quite a surprise!

With offices in downtown Toronto and Montreal, the Lab is a digital innovation hub bringing together actuaries, big data scientists, machine learning experts, geomaticians, meteorologists and software engineers who work together to propose and implement innovative solutions to the complex issues facing us.

Merging the speed and culture of a start-up with the resources and means of a large enterprise, the DataLab is a dynamic team offering exciting challenges, inspiring colleagues and great career opportunities (at one of Canadas Top 100 Employers!)

About you:
Are you a machine learning coding expert who believes we are only in the infancy of artificial intelligence? Are you passionate about advanced analytics and Big Data? Do you stay current with the latest trends in analytics and jump at the chance to experiment with new tools? We have the perfect opportunity for you!
Your Job
Hiring Manager: Amine Mahmoudi

Workplace: Montreal (2020, Blvd. Robert-Bourassa)

YOUR CONTRIBUTION:
Develop innovative solutions for trend recognition using machine learning and advanced statistics
Transform complex databases into relevant conclusions and recommendations
Keep pace with new approaches and trends and use them in your own solutions
Help maintain our data mining tools and platforms
Make actionable recommendations based on the findings
Work with other departments to promote the adoption of analytical principles within the organization
Validate the quality of the analytical approach and project outputs of the other team members
Your Skills
YOUR ASSETS:
Your Masters degree in a relevant discipline (mathematics, science, engineering, operational research, economics, statistics, AI, computer science or a related field)
Your 5 years of experience in the field of advanced statistics, data mining and text mining
A multi-platform production experience with the following commercial and open-source data mining frameworks:
R, Python, GitHub
Expert-level understanding of the underlying theory of machine learning
Expert-level understanding in either computer image analysis, natural language processing or artificial intelligence
Your great teamworking skills
Your ability to focus on vaguely defined issues requiring the application of a creative approach
Your strong communication, time management and work organization skills
Here are a few reasons why others have joined our team:
An award-winning, inspiring workplace that supports its people and recognizes great work (Canadas Top 100 Employers, Aon Platinum Best Employers, LinkedIn Top Company, Glassdoor Best Place to Work & Top CEO, Indeed Top-Rated Workplaces)
Stimulating, challenging projects and development opportunities to help you grow your skills and career
Flexibility in how and where you work
A comprehensive financial rewards program that recognizes your success
An extensive, flexible benefits package
An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased
A casual dress for your day culture that encourages you to be yourself
A $350 annual wellness account that promotes an active lifestyle
Referral Bonus
This role is eligible for employee referral bonus. #myReferrals3000
Eligibility to work in Canada
We are an Equal Opportunity Employer:
At Intact, our values guide everything that we do. We celebrate our differences and appreciate our similarities. Thats why we are committed to building an inclusive and inspiring environment for all employees. If you need a specific accommodation during the recruitment process, please let us know and we will be happy to provide.

Background Checks:
Before receiving a job offer, you may be asked to consent to a background check if its a requirement for the role. This may include: verifying work references, validating education and credentials, employment verification, identity checks, reviewing credit reports, as well as criminal and driving record checks.

Internal Candidates:
For internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. Please note we may have identified other internal candidates through our Employee Development Program, and that the selection process may also be opened to external applicants.

Eligibility:
Its important that you are legally eligible to work in Canada at the time an offer of employment is made. You may be requested to provide proof of eligibility at that time.

About us:
As Canadas largest provider of property and casualty insurance, were not only leading our industry, but were redefining what it means to work for it. As a recognized top employer, were committed to living our values and supporting our dedicated people who bring their best to work each day because they know their work matters.

Our people are at the heart of what we promise getting people back on track and helping them prosper in good times and be resilient in bad times. We have over 13,000 employees who live our values every day and strive to deliver legendary service to our millions of customers across Canada and the U.S.

We have many brands that are a part of the Intact family. In Canada, Intact Insurance and Brokerlink distribute insurance through a wide network of brokers, while belairdirect delivers products direct-to-consumer. In the U.S., OneBeacon Insurance Group handles our specialty insurance line of business.

#li-qc
Glassdoor Sponsored
#GD-Quebec",4.1,Intact,Montreal,"Toronto, Canada",10000+ employees,-1,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),"Aviva Canada, RSA Group, Economical Insurance",75.5,-1,data scientist,senior,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,5629,3
132,"As a Senior Data Scientist at QuantumBlack in Montreal...
You will solve the hardest business problems with our clients in multiple industries worldwide while leading research and development of state-of-the-art Machine learning and statistical methods.
You will play a leading role in bringing the latest advances in deep learning to the world economy, collaborating with industry executives and QuantumBlack experts to find and execute opportunities to improve business performance using data and advanced machine learning models.
The role is ideal for a candidate with a strong R&D background in Machine Learning, combined with a passion for bringing the latest research to real applications. We welcome candidates interested in transitioning from a pure academic R&D background into an applied industry role.
You will also have the opportunity to grow a team of Data Scientists in Montreal that will live at the intersection of R&D and practical application of AI at scale, while collaborating with Data Science experts from other QuantumBlack hubs in Boston, Chicago, London, Sidney, and Sao Paolo.
Role responsibilities
Identify Machine Learning R&D initiatives that have a high potential of applicability in industry.
Work with Quantumblack leadership and Client executives to understand business problems and map them to state-of-the-art analytics and AI solutions.
Use the latest advances in Deep Learning, Reinforcement Learning, and AI, to solve business problems and derive key insights across various industry sectors including Formula 1, pharma, automotive and high-tech.
Work with the recruiting team to build an R&D focused team of data scientists in Montreal.
Build and maintain strong links with the academic world and constantly share ideas and stay ahead of the curve on the latest methods.
Mentor other data scientists and help them grow their knowledge and skills.
Work closely with Data Engineers, Machine Learning Engineers and Designers to build end-to-end analytics solutions for our clients that drive real impact in the real world.
Influence and help shape the R&D roadmap for QuantumBlack, especially on Deep Learning.
Work in a multi-disciplinary environment mixing highly skilled people in data science, data engineering, business and design.
Perhaps most importantly, you will work in one of the most talented and diverse data science teams in the world.
Please submit your CV in English

Visit our Careers site to watch our video and read about our interview processes and benefits.",4.4,McKinsey & Company,Montreal,"New York, NY",10000+ employees,1926,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,"Boston Consulting Group, Bain & Company, Strategy&",75.5,94,data scientist,senior,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,2515,3
133,"Job Summary:

Responsible for translating high-level business requirements into functional specifications and ensuring that deliverables conform with these requirements and the expectation of the process owner. Collaborate with cross-functional operations to establish standardized data and reporting requirements across the organization.

Essential Job Functions:
Write SQL Queries and perform Data Cleanup
Contribute to the development of reports for business and management teams
Champion internal data integrity requirements and initiatives relating to multiple business applications including ERP & CRM
Analyze data within platform and other core business systems and provide insights
Create, build and maintain reports & dashboards in various business systems including BI Software (Cognos), ERP & CRM
Perform SQL Server reporting and scripting tasks
Data mapping
Business Intelligence Experience in Cognos highly preferred
Advanced Excel knowledge (ODBC, VLOOKUP, MACROS)
Minimum Requirements:
Bachelor’s Degree in Computer Science or other related fields.
Database Administrator, Business Intelligence (BI) Analyst.
SQL based ERP System, CRM, EDI
Programming knowledge
Fluent in French and English preferred",1.9,TCP Reliable Manufacturing Inc,Montreal,"Edison, NJ",51 to 200 employees,-1,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$25 to $50 million (CAD),-1,75.5,-1,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1215,0
134,"Machine Learning Engineer
Location


Canada

City


Toronto

Job ID #

37913

Apply Now

Transforming the Future with the Convergence of Simulation and Data
Machine Learning Engineer, Data Analytics Platform

Do you like a challenge, are you a complex thinker who likes to solve problems? If so, then you might be the new Altairian we are searching for. At Altair, your curiosity matters. We pride ourselves on a business culture that enables open, creative thinking, and we deeply value our employees and their contributions towards our clients' success, as well as our own.

Job Summary:

As a Machine Learning Engineer, you will be part of the Product team, working in an R&D capacity for development of features for the Altair Data Analytics Platform.

What You Will Do:

• Researching industry best practices for features to be implemented in the Data Analytics platform, with a focus on MLOps: Model Tracking, Model and Data Lineage, Model Repositories, Model Deployment, Model Monitoring, Model Security and CI/CD/CT
• Ensuring that new features fit within the architecture of the Data Analytics Platform
• Developing Python prototypes of the above MLOps features
• Working closely with developer teams to productize the Python template in the Data Analytics platform, ensuring incremental value delivered with each software development sprint

What You Will Need:

Basics:

Knowledge of the following tools/methodology/languages is required:
• Advanced Python, SQL and R (optional), including experience with data processing and ML pipelines
• Experience working with big data
• Production level experience with Docker and Kubernetes
• 2+ years experience pushing and managing ML models and data pipelines in production
• Nice to have: experience with multiple ML deployment architectures and tools

Soft skills:
• Able to work in a fast-paced environment
• Can collaborate with others and build relationships with multiple teams, including developers, designers, subject matter experts and stakeholders
• Empathy to translate end-user needs into valuable features
• Excellent communication skills – able to communicate complex technical features to non-technical teams and stakeholders. Not afraid to ask for help when needed

How You Will Be Successful:
Envision the Future
Communicate Honestly and Broadly
Seek Technology and Business “Firsts”
Embrace Diversity and Take Risks
What We Offer:
Competitive salary and benefits
Free training on all Altair products
Snacks, gym (specific to region recruiting for), onsite health and wellness office (specific to region recruiting for)
Why Work with Us:

Altair is a global technology company that provides software and cloud solutions in the areas of product development, high performance computing (HPC) and data analytics. Altair enables organizations in nearly every industry to compete more effectively in a connected world, while creating a more sustainable future. With more than 3,000 engineers, scientists and creative thinkers in 25 countries, we help solve our customer’s toughest challenges and deliver unparalleled service, helping the innovators innovate, drive better decisions, and turn today’s problems into tomorrow’s opportunities.

Our vision is to transform customer decision making with simulation, data analytics, and high-performance computing.

For more than 30 years, we have been helping our customers integrate electronics and controls with mechanical design to expand product value, develop AI, simulation and data-driven digital twins to drive better decisions, and deliver advanced HPC and cloud solutions to support unlimited idea exploration. To learn more, please visit altair.com.

Ready to go? #ONLYFORWARD",4.2,Altair Engineering,Toronto,"Troy, MI",1001 to 5000 employees,1985,Company - Public,Computer Hardware & Software,Information Technology,$100 to $500 million (CAD),-1,75.5,35,machine learning engineer,na,1,1,0,0,0,1,0,0,0,0,0,0,1,0,0,3697,0
135,"ABOUT DIGITAL EXTREMES

Founded in 1993 by James Schmalz, Digital Extremes ranks as one of the world’s top independent video game development studios. Originating with the co-creation of Epic Games’ multi-million unit selling Unreal® franchise including Unreal and Unreal Tournament, Digital Extremes went on to develop Dark Sector®, BioShock® for the PlayStation®3, the BioShock 2 multiplayer campaign, and The Darkness® II. The studio has reached its greatest critical and commercial success with the free-to-play action game, Warframe®, boasting a global community of 50 million registered players on PC, PS4™, Xbox One and Nintendo Switch™. For more information about Digital Extremes, visit www.digitalextremes.com. To sign up for Warframe, visit www.warframe.com.

WHY WORK AT DIGITAL EXTREMES

Our culture is centered on providing great opportunities to our employees so that everyone feels they are making a meaningful impact. Developing new and existing talent is our long-term focus. We are honored that our work environment has been consistently recognized as one of “Canada’s Top 100 Employers”. We summon you to join our elite team!

The rewards of a career with Digital Extremes include:
Competitive salary with bonus opportunities
Excellent benefits and paid time off
Matching RRSP plan
Employee Assistance Program (EAP)
Professional development and career support
Fitness and parking/transit subsidies
Daily lunches prepared onsite by our in-studio Executive Chef and professional kitchen staff
All-day snacks and drinks, sleep pods, massage chairs, cold brew, dog therapy days and more

ABOUT THIS POSITION

Digital Extremes is currently seeking a Senior Data Scientist to join our team. You will be working with passionate, highly intelligent game developing ninjas to mine the data to uncover opportunities, drive initiatives and support decisions. As a passionate gamer, you will have experience in the gaming industry as well as demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action. As an ideal candidate, you will also have experience with free to play games.

RESPONSIBILITIES

Collaborate closely with the Data team improving internal processes.
Help marketing and development teams to identify trends and opportunities.
Develop advanced learning algorithms and statistical models to solve critical problems and help deliver incredible player experiences.
Architect, implement, deploy, and maintain data science intensive applications.
Synthesize data from various sources and extract useful information that will lead to improving the player experience, player retention, game design and effective marketing strategies.
Extract and organize data into a reliable user-friendly form and present it to the interested and affected parties on the team.
Follow up with additional analysis once initiatives have begun to determine success or need for continued improvements.
Assist in designing and building business intelligence tools for data mining and reporting.
Suggest improvements in tools and techniques to help scale the team.
Conduct ad hoc data analysis based on current team needs and management priorities.
Mentor other Data scientists with the team.

REQUIREMENTS

Excellent organizational, communication and interpersonal skills
Bachelor’s degree in a technical or quantitative discipline (Mathematics, Economics, Statistics, Computer Science, MIS, other)
Minimum 3 years of tried and true statistical analysis and data mining experience
A passion for video games and understanding of gaming culture
Experience in the gaming industry, specifically Free to Play gaming is a plus
In-depth knowledge of Postgres SQL, Mongo DB, Python Notebooks
Experience in defining/designing/building/managing a data warehouse is a plus
Strong quantitative analysis techniques and qualitative methods, as well as predictive modelling
Demonstrated success presenting complex research data (both qualitative and quantitative) in a clear and compelling manner that inspires action
Excellent organizational, communication and interpersonal skills
Self-starter who can manage their time effectively and has the interest of integrating into a team of passionate, highly intelligent game developing ninjas

JOIN US

Digital Extremes is an equal opportunity employer committed to diversity and inclusion. We welcome and encourage applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the recruitment process. We thank you for your interest, however, only those candidates selected for the next steps in the hiring process will be contacted.",3.5,Digital Extremes Ltd.,London,"London, Canada",201 to 500 employees,1993,Company - Private,Video Games,Media,$100 to $500 million (CAD),-1,75.5,27,data scientist,senior,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,4715,0
136,"GALE is a business agency that brings together an equal balance of business consulting expertise & agency creativity to solve the world’s most complex marketing challenges. We operate without silos to deliver innovative business strategy, data insights, and transformative creative work. We work best with brands that are looking to solve tomorrow’s problems, today. GALE is a global company with offices located in New York, Toronto, Singapore and Bengaluru.

If you’re driven by a passion to build something great, a desire to innovate, and a commitment to achieve excellence in your craft, GALE is a great place for you.

About the Role

We're currently seeking a Senior Data Scientist to join our growing big data team - you will have a passion for working with real world data to deliver products and strategies that yield value. The successful candidate will work with clients and internal stakeholders to define, prototype, and produce custom solutions using state-of-the-art big data platforms, analytics, and machine learning.

The ideal candidate will have a background in a quantitative or engineering field and have experience with large datasets, the AWS or GCP ecosystems, statistics/analysis, and client-facing activities. You will be enthusiastic, creative, results focused, and have enough confidence to define, build, and present models in industries ranging from automotive to retail.

Who you are:
Experience with SQL on one or more of the following databases Hive, PostgreSQL, Oracle, SQL Server, MySQL
Fluency with scripting (Python, Bash, etc.)
Experience with statistical programming languages/packages (R, Scipy/Numpy/Scikitlearn)
Familiarity with Unix/Linux systems and command-line interfaces and editors
Experience loading, cleansing, and analyzing very large datasets

- Experience with Python web frameworks like Flask or Django a plus

- Experience with Python deep learning frameworks like Tensorflow or PyTorch a plus

- 3-5 experience in data science in a services, consulting or agency setting

What you will be doing:

- Supporting the clients by defining and solving specific business problems with hypothesis tests and bespoke models

- Lead the Data science direction on client projects, work with junionr team members to build out solutions

- Ingesting, distributing and manipulating large data sets to understand the structure of client data and ready it for modelling

- Leveraging the GALE Data Science team cluster to create models for item or action recommendation, resource optimization, unsupervised learning of customer dynamics, etc.

- Producing prototypes, POCs, or APIs to showcase and make available models and their outcomes

- Working with strategy and consumer insight teams to craft engaging client presentations to explain models and outcomes",3.3,GALE Partners,Toronto,"New York, NY",201 to 500 employees,2014,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1,75.5,6,data scientist,senior,0,1,0,0,0,1,0,1,0,0,0,0,1,1,1,2801,0
137,"About Paytm Labs:
At Paytm Labs, we build technologies that empowers Paytm India, the world's fastest-growing mobile payments and commerce ecosystem. In addition to the Paytm Canada app. We use our skills and our biggest asset – data, to make our dent in this universe.

We are committed to offering the most transparent, secure, and personalized consumer experience to over 230 million users. We believe that this kind of scale and the unique problems that it presents attracts curious candidates like yourself.

Job Description:
We are looking for engineers with a passion to develop novel machine learning software systems for fraud detection, personalization and CTR prediction and deploy the systems to production, and test them to ensure all client's business needs are covered.

In this team of data scientists, statisticians and machine learning engineers, you will create software that are used by millions of people.
You will perform ETL to build model features using petabyte scale datasets and develop high throughput and low latency systems to serve models in production touching lives of more than 300M customers everyday. You will collaborate with highly innovative engineering teams to put machine learning functionalities into production systems that we build in-house.

We are looking for someone who oozes passion, ownership, and a love of building great things. The Product and Engineering teams will rely heavily on your build. You'll have a ton of trust and responsibility. So, if challenges excite you, and you're ready for a big one, let us know.

Responsibilities:
Perform ETL with massive data from multiple applications and 300 M+ customers
Architect, design and evaluate novel approaches for handling high-volume real-time data streams in an inferencing environment
Own the development, training, optimizing, and deployment of machine learning systems
Develop measurement and feedback systems at web scale to improve the selection of features and/or algorithm design

Qualifications:
Strong software development skills (+3 years working experience), with proficiency in Python or Scala preferred
Experience in building ETL pipelines to perform feature engineering on large-scale dataset using Big Data technologies such as Spark
Ability to explain and present analyses and machine learning concepts to a broad technical audience
Ability to initiate and drive projects to completion with minimal guidance
Knowledge in advanced data structures and can use them to solve problems
You have a Masters degree or equivalent in Computer Science, Engineering, Mathematics or related field
Working knowledge of PyTorch, Tensorflow or other similar frameworks is a plus
Creative, collaborative, & product focused
What we Offer!
We are proud to announce that we have been certified as a Great Place to Work!
A collaborative, open work environment that fosters ownership, creativity, and urgency
Enrolment in the Group Health Benefits plan right from Day 1, no waiting period
Fuel for the day: Weekly delivery of groceries and all types of snacks to our office
All types of signature drinks from coffee to lattes to cappuccinos
Catered lunch and desserts on a monthly basis!
Ping Pong and Pool: Become the next Paytm Labs Table Tennis/ Pool champ!
And so much more!
Notice for Job Applicants

Following the advice of Canadian health authorities, to mitigate the risk of potential spread of COVID-19 and support social distancing, all recruiting activities including interviews and new hire onboarding will be conducted remotely. While we are doing our best to ensure reasonable response times, please expect potential delays during the recruiting process due to the current situation. Thank you for your patience and understanding during these challenging times.

Don't have Paytm Canada App yet?
Check us out in the Google Play or App Store.

We thank all applicants, however, only those selected for an interview will be contacted.

Paytm Labs is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodations during the recruitment and selection process, please let us know. Paytm Labs is an equal opportunity employer.",3.9,Paytm,Toronto,"Toronto, Canada",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,75.5,6,machine learning engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,4294,0
138,"Address:

100 King Street West
Job Family Group:
Data Analytics & Reporting

Applies knowledge of advanced analytic algorithms and technologies (e.g. machine learning, deep learning, artificial intelligence) to deliver better predictions and/or intelligent automation that enables smarter business decisions, improved customer experience, and drives productivity. Applies strong communication and story-telling skills to summarize statistical/algorithmic findings, draw business conclusions, and present actionable insight in a way that resonates with business/groups. Drives innovation through the development of Data & AI products that can be leveraged across the organization and establishes best practices in in alignment with Data & AI governance frameworks of BMO.

Qualifications:
Acts as a trusted advisor to assigned business/group.
Influences and negotiates to achieve business objectives.
Recommends and implements solutions based on analysis of issues and implications for the business.
Assists in the development of strategic plans.
Identifies emerging issues and trends to inform decision-making.
Understands and analyzes complex business problem, then formulates data-driven hypotheses to drive business value.
Builds effective relationships with internal/external stakeholders and ensures alignment.
Supports data collection, integration, and retention requirements for data.
Develops experimental design approaches to validate findings or test hypotheses.
Defines innovative data solutions to loosely defined business problems by leveraging pattern detection over potentially large datasets.
Diagnoses and resolves predictive / analytical model performance issues while monitoring system performance and implementation of efficiency improvements.
Applies innovative and best practices to advanced analytics services to ensure high quality standards.
Sets up change control and testing processes to ensure the quality and consistency of ongoing maintenance work.
Develops analytical solutions and makes recommendations based on an understanding of the business strategy and stakeholder needs.
Provides advice and guidance to assigned business/group on implementation of analytical solutions.
Works with stakeholders to identify the business requirements, understand distinct problems and expected outcomes, and models and frames business scenarios which impact critical business processes and/or decisions.
Works with various data owners to discover and select available data from internal sources and external vendors (e.g. lending system, payment system, external credit rating system, and alternative data) to fulfill analytical needs.
Applies scripting / programming skills to assemble various types of source data (unstructured, semi-structured, and structured) into well-prepared datasets with multiple levels of granularities (e.g., demographics, customers, products, transactions).
Develops agreed analytical solution by applying suitable statistical & machine learning techniques (e.g., A/B testing, prototype solutions, mathematical models, algorithms, machine learning, deep learning, artificial intelligence) to test, verify, refine hypotheses.
Summarizes statistical findings and draws conclusions, presents actionable business recommendations. Presents findings & recommendations in a simple, clear way to drive action.
Documents data flow, systems and processes in data collection to improve efficiency and apply use cases.
Performs experimental design approaches to validate finding or test hypotheses.
Uses the appropriate algorithms to discover patterns.
Builds effective relationships with internal/external stakeholders and ensures alignment.
Supports development of tools and delivers training for data analytics and AI.
Supports development and execution of strategic initiatives in collaboration with internal and external stakeholders.
Leads/participates in the design, implementation and management of core business/group processes.
Focus is primarily on business/group within BMO; may have broader, enterprise-wide focus.
Provides specialized consulting, analytical and technical support.
Exercises judgment to identify, diagnose, and solve problems within given rules.
Works independently and regularly handles non-routine situations.
Broader work or accountabilities may be assigned as needed.
Typically between 5 - 7 years of relevant experience and post-secondary degree in related field of study or an equivalent combination of education and experience.
Advanced degree (Ph.D. preferred) in Computer Science, Mathematics, Physics, Engineering, Statistics, or other quantitative disciplines and/or equivalent experience
Experience with distributed computing language (e.g. Hive / Hadoop/ Spark) & cloud technologies (e.g. AWS Sagemaker, AzureML).
Experience with programming languages (e.g. SQL, Python, R, SAS, SPSS, , Perl) and machine learning /deep learning algorithms/packages (e.g. XGBoost, H2O, SparkML).
Deep proficiency in statistical analysis, quantitative analytics, forecasting/predictive analytics, multivariate testing, and optimization algorithms.
Deep knowledge and technical proficiency gained through extensive education and business experience.
Verbal & written communication skills - In-depth.
Collaboration & team skills - In-depth.
Analytical and problem solving skills - In-depth.
Influence skills - In-depth.
Data driven decision making - In-depth.
We’re here to help

At BMO we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.

As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset.

To find out more visit us at https://bmocareers.com.

BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter.",3.7,BMO Financial Group,Toronto,"Toronto, Canada",10000+ employees,1817,Company - Public,Banks & Building Societies,Finance,$10+ billion (CAD),"CIBC, RBC, TD",75.5,203,data scientist,na,0,1,0,0,0,1,1,1,1,0,0,0,1,1,1,6632,3
139,"BBTV is a media-tech company advancing the world through the creation, distribution, management and monetization of content. BBTV provides end-to-end solutions to content owners including proprietary tech, leading services and enhanced distribution & monetization. We have built proprietary VISO technologies leveraging machine learning, digital signal processing and big data to power our platform and ecosystem. Our key revenue streams represent the most relevant and scalable opportunities for monetization of digital IP across advertising, SaaS/content management, mobile apps and other revenue streams. BBTV is the second largest video property worldwide in terms of unique viewers following only Google, reaching tens of billions of monthly impressions.

As a member of the Data Strategy team & reporting to the Engineering Manager, the Data Engineer is responsible for understanding emerging and evolving usage and data models of our company and designing systems for ingesting and processing various data sources to meet the growing needs of our content creators and business stakeholders.

Key Responsibilities:
Understand the company’s existing applications, operations & tools, and recommend database structural improvements
Analyze and implement recommendations to further improve and expand the company’s current data warehouse solution (Snowflake) and data pipeline
Optimize database/data warehouse performance by identifying and resolving problems with the collection, distribution, and consumption of data
Assist with providing actionable business insights through gathering, analyzing and visualizing large datasets for BBTV and our partners
Design and develop solutions to ensure data integrity across different applications in the organization
Work with the finance team to perform regular data audits
Work collaboratively on BBTV’s Big Data systems; manage the current and historical data for millions of videos, channels & other entities
Work with the IT team and other stakeholders to identify and implement solutions for optimizing costs associated with data storage and data manipulation across different applications
Create & maintain documentation, standards and guidelines for data architecture, data management
Work with the IT team to develop a data security and retention framework
Mentor & share knowledge with other team members especially with respect to data engineering best practices
Work closely with teams outside of R&D to address the day-to-day business needs
A strong candidate will have
Minimum 7 years of technical solutions experience in established and emerging data technologies ideally in a combination of relevant Big Data/Analysis areas such as Hadoop, Redshift and other Industry Big Data Frameworks
Advanced degree in Computer Science or a related field; relevant experience may be considered
Demonstrated expertise and knowledge with data warehousing (especially Snowflake), ETL and related techniques & technologies
Experience in requirements engineering, data architecture, design, development and deployment
Demonstrated experience creating Big Data/Analytics solutions in an enterprise environment
Previous experience with major commercial ERP solutions would be an asset
Solid understanding of data architecture, integration and modeling techniques
Experience leading business intelligence, analytics and visualization projects
Ability to work effectively with different levels of technical and managerial team members and communicate complex topics in an easy-to-understand language (especially with business stakeholders)
Strong technical team leadership, mentorship and collaboration skills
A self-starter with the ability to work independently and with minimal supervision
About BBTV

At BBTV, our team is everything. We offer competitive compensation packages and have a strong focus on diversity, inclusiveness and equitable compensation. We also offer flexible hours and operate on a horizontal management structure that rewards creativity and values transparency.

From our commitment to giving back (support for everyone to volunteer with a charitable or community initiative), our culture committee (social events, team-building, diversity and inclusion), and our support for personal and career development through our learning & development program, we’re not your typical 9-5 gig.

BBTV is an equal opportunity employer and we welcome applications from all people.

We thank all applicants for their interest, however only those selected for an interview will be contacted.

To all recruitment agencies, BBTV does not accept unsolicited agency resumes. Please do not forward resumes to our jobs alias, BBTV employees or any other company location. BBTV is not responsible for any fees related to unsolicited resumes.",3.0,BBTV,Vancouver,"Vancouver, Canada",201 to 500 employees,2005,Company - Private,TV Broadcasting & Cable Networks,Media,Unknown / Non-Applicable,"ZEFR, Fullscreen, Maker Studios",75.5,15,data engineer,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,4786,3
140,"This is your opportunity to join AXIS Capital – a trusted global provider of specialty lines insurance and reinsurance. We stand apart for our outstanding client service, intelligent risk taking and superior risk adjusted returns for our shareholders. We also proudly maintain an entrepreneurial, disciplined and ethical corporate culture. As a member of AXIS, you join a team that is among the best in the industry.
This position is primarily responsible for deriving, documenting and gaining approval for data, reporting / system requirements with respects to Business Intelligence. The MI Data Analyst acts as a liaison between business people, who have a business problem, and IT development and the reporting team (e.g., report, data), who know how to create automated solutions. The MI Data Analyst gathers and understands business needs, determining, documenting and prioritizing requirements from the business and presenting these requirements in a manner that is agreeable, measurable and flexible enough to meet project and stakeholder needs. The MI Data Analyst may design and prototype solutions and will work with the development team to implement and test solutions.
Responsibilities
Through analysis of data, determine requirements for data, reports, analyses, metadata, training, service levels, data quality, and performance
Work with production data to validate business requirements to design appropriate database structures
Map business needs/requirements to subject area model and to logical enterprise model
Perform systems analysis while considering the business implications of the application of technology to the current and future states
Profile data to spot trends as input into root cause, requirement identification/validation and compliance efforts
Assist with the creation of test plans and pre-UAT testing, documenting and tracking issues and ensuring timely issue resolution
Plan and execute tests to verify that the developed data and reports, support the specifications and requirements provided by the business unit and are in accordance with business objectives
Research urgent issues, coordinating with the development team on the same and identifying new requirements, when required
Develop the mockup of the report and/or data solution.
Coordinate and communicate between business and the BI team
Required Skills and Qualifications
2+ years of experience in data warehouse, business intelligence solutions or related discipline
Ability to perform detailed data analysis (i.e. determine the structure, content, and quality of the data through examination of source systems and data samples) with a strong foundation in SQL and RDBMS technology
Working knowledge of ETL/BI concepts and tools such as SSIS, SSRS, Tableau, Business Objects
Expertise in testing complex SQL queries and stored procedures as well as testing Business Intelligence solutions (cubes, reports, dashboards, scorecards) developed in tools such as SSRS, Tableau, Business Objects
Understanding of implementation processes and best practices around data warehousing and business intelligence
Awareness of delivery and operations fundamentals such as data quality management, monitoring and reconciliation controls.
Excel experience, able to create pivot tables, vlookups and review the same with business partners
Property and Casualty insurance experience a plus
Bachelor’s degree in relevant field
Strong oral and written communication skills",3.0,AXIS Capital,Halifax,"Hamilton, Bermuda",1001 to 5000 employees,2001,Company - Public,Insurance Operators,Insurance,$5 to $10 billion (CAD),"Swiss Re, Munich Re",75.5,19,data analyst,na,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,3454,2
141,"Want to work on fun mobile games for popular brands and properties?

As a Data Analyst, you’ll be improving our games with key decisions backed by your analysis and reporting. You’ll have an opportunity to drive the development and growth of data science practices in our company.

You’ll have a degree in a STEM discipline with experience doing data analysis, preferably in gaming. You thrive in a small, multi-disciplinary team and love working with a diverse group of people. You enjoy playing and talking about games!

Are you excited about this opportunity? Then we’re excited to meet you!

Reponsibilities
Find answers to business questions through ad-hoc exploration of data
Run A/B tests to improve our KPIs
Measure and report feature performance to production teams and management
Design, develop, and improve data tools and services
Build reporting dashboards
Collaborate positively in a team environment for the benefit of the company’s goals
Perform any other actions required by management
Requirements
Bachelor’s degree in a STEM discipline
2 or more years of experience as an analyst, data scientist, or related role
Understanding of statistical analysis and methods
Expert level knowledge of SQL with experience querying large data sets
Proficiency analyzing datasets in a spreadsheet program or in a programmatic analysis tool
Experience with data visualization applications
High interest in games, preferably mobile games
Strong written and oral communication skills
Job Types: Full-time, Permanent

Benefits:
Casual Dress
Dental Care
Disability Insurance
Extended Health Care
Life Insurance
Paid Time Off
Vision Care
Schedule:
Monday to Friday
Work remotely:
Temporarily due to COVID-19",-1.0,Epic Story Interact,New Westminster,-1,-1,-1,-1,-1,-1,-1,-1,75.5,-1,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1705,0
142,"Machine Learning / Natural Language Processing Engineer
A degree in Computer Science/Engineering or related field.
4+ programming experience in Python with strong grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc
3+ years of applied experience in ML, deep learning and NLP
Have expert understanding of machine learning and NLP tasks such as classification, feature engineering, information extraction, structured prediction, sentiment analysis, and topic modelling
Fully understand different neural networks (LSTM, seq2seq, etc.), different word embedding models and transfer learning.
Knowledge of packages such as Tensorflow, Pytorch, Keras, Scikit Learn, Pandas, and NLTK.
Experience in a data-driven software engineering environment, with an end-to-end understanding of how to leverage data to make business decisions.
A proven track record in building and maintaining high quality, robust and maintainable code.
Experience building and working within a Continuous Integration framework.
Understanding of Data Warehouse concepts, ETL strategies and best practices.
An appetite for problem solving with a creative and resourceful approach to finding the right solution for the job.
Strong communication and collaboration skills
What sets you apart:
You are a self-motivated and outgoing person who can work closely with business and IT stakeholders.
You understand the relationship between data and business outcomes and can focus on long term strategies for data.
Proficiency with PostgreSQL, Teradata, Hadoop and AWS is an asset.
You have experience working as part of an Agile Team.
Aviva Canada is committed to providing accommodations for people with disabilities during all phases of the hiring process including the application process. If you require an accommodation because of a disability, we will work with you to meet your needs. Applicants need to make their needs known in advance. If you are selected for an interview and require an accommodation, you are encouraged to advise the Talent Acquisition Partner who will consult with you to determine an appropriate accommodation.",3.5,Aviva,Markham,"London, United Kingdom",10000+ employees,1861,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),Legal & General,75.5,159,machine learning engineer,na,0,1,0,0,0,1,0,1,0,0,0,0,1,1,0,2154,1
143,"Maxima Consulting, Inc. started its journey to success in the year 1993 and since then we have been providing technology and consulting services to leading multinational establishments across the globe.
The credit of Maxima s on-going success goes to our excellent ability to reinvent unremittingly along with the vigorously changing business environment. Maxima is the second largest vendor to one of the top custodian bank and has successfully delivered services for more than 26 years.
When someone asks why to choose Maxima Consulting, Inc. it becomes quite tempting to point out our track records. We have helped a number of top notch multinational corporations to transform into sharper, smarter and better business organizations. It s our mission that helps us create such high levels of customer satisfaction and become the top choice for so many clients across a number of industries. Our software professional services are sought for the performance of highly technical duties involving in
Project Management
System Design and Administration
Financial Business Analysis
Application Development
Managed Services

Seeking a consultant with strong experience in capturing / analyzing business / data requirements on different finance systems, database design / modeling, compliance regulatory, data visualization and project management.
Analysis of data loading and integrity of Enterprise Data Warehouse from multiple systems.
Experience in processing complex data set using Excel Macro/VBA for reporting purpose.
Experience with reconciliation supplier data with Third Party Risk Management system and Oracle R12.
Work with Senior Management to develop and implement automated dashboards and analytic tools to track progress against business goals.
Analyze business performance and generate ad-hoc business reports.
Make presentations and reports based on data analysis and expedite root cause analyses against recurring issues and provide insights for strategic planning. Manage data, information, reports etc. and coordinate with various stakeholders.
Experience in creating documentation including Mapping document, Master Tracker document, process training documentation, SOP (Standards of procedure), system use case and UML diagrams, test plan, test scenarios and test cases.
Creating use case, UML diagrams, data flow diagrams, business process and data process models.
Experience with Data visualization tools like Power BI or Tableau.",3.8,Maxima Consulting,Toronto,"Wakefield, MA",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (CAD),-1,75.5,-1,data analyst,na,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,2452,0
144,"Your Role:
This role is for you if you’re passionate about data, telemetry and survey data.

The Company:
Our client is a startup with a great culture and mission. Your contribution to the team will be regarded and appreciated.
Your Responsibilities
Perform research in Natural Language Processing/Deep Learning
build machine learning models
Analyze data sources and perform data collection/annotation
Work with the team to build data pipeline/infrastructure to deliver machine learning algorithms
You Have
Experienced in Python and NLP
Experienced working with machine learning tools (Tensorflow, PyTorch, Keras, Spacy)

Your Salary
Competitive salary and benefits, commensurate with experience.

Next Steps
If this opportunity sounds like something that fits your career path, please apply to this posting; we'd love to talk to you!",3.8,Targeted Talent,Vancouver,"Vancouver, Canada",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1,75.5,-1,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,834,0
145,"Do you want to join an insurtech start-up with a mission to help the insurance industry deliver a better customer experience using AI?

Experience: 5+ years experience

ProNavigator is a venture-backed insurance technology company. Our team is made up of insurance industry veterans, technology experts, and data scientists who’ve come together to build solutions specifically for the insurance industry. ProNavigator's platform incorporates natural language processing and machine learning to improve access to information and automate workflows for customers, distribution partners and employees. We aim to radically simplify and change the way brokers and underwriters work with insurance policies and documents. This is a great opportunity to join a tight-knit, fast growing team.

Our team is expanding, and we seek a highly seasoned Data Scientist to join our experienced data science team and help take it to the next level. As a key member of the team, you will be responsible for the development of innovative concepts, research, predictive modeling, and machine learning algorithms. Our ideal candidate has a strong technical background and at least 5 years of experience defining and bringing software products to market. Experience working at a start-up would be beneficial.

Key Responsibilities:
Collects, cleans, manages, analyzes and visualizes large sets of data using multiple data platforms, tools and techniques
Effectively partner with product and engineering teams to build new data driven and machine learning based features for enriching the broker experience
Create automated learning systems that gracefully scale to increasing complexity and expectation
Work with a sense of ownership and urgency, advocate for experimentation based, agile culture
Required Skills and Qualifications:
Master's or PhD recommended in applied mathematics, statistics, computational linguistics or relevant technical field
5+ years of professional experience in Data Science, geared towards developing and maintaining NLP algorithms
Have superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, random forests, etc.
extensive experience with pandas, numpy, and sklearn. Experience with deep learning frameworks (TensorFlow, Keras, PyTorch, or similar) is a plus
The Perks:
Amazing culture: Tight knit team, hungry and moves fast. Learn more: https://pronavigator.ai/careers/
Benefits after 30 days - health, dental and vision
Competitive salary and vacation
On-site games, weekly lunch and learns where we try different foods, wind down Fridays and more.
Unlimited free coffee and tea. Daily fruit bowl and snacks
Work hard, play hard environment where we love to inspire, motivate and learn in everything we do.
A great group of people to work with who are serious about their work and the mandate, but fun in their approach.
Job Types: Full-time, Permanent

Benefits:
Casual Dress
Dental Care
Extended Health Care
On-site Parking
Vision Care
Schedule:
Monday to Friday
Experience:
Data Scientist: 5 years (Required)
Work remotely:
Temporarily due to COVID-19",4.0,ProNavigator,Kitchener,"Kitchener, ON",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1,75.5,-1,data scientist,senior,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,3120,0
146,"OVERVIEW

We are seeking for a Machine Learning Engineer to develop machine learning models related to predicting the outcome of computational biology and chemistry simulations, as well as the relationship between experimental measurements and related computational simulations. The successful candidate will be working in a multidisciplinary team to explore and create methods for better understanding the correlation between the computationally predicted structure of proteins with the corresponding experimentally derived structures.

Reporting to the Chief Technology Officer, the Machine Learning Engineer will work with a diverse-skilled team including software engineers, geneticists, biochemists, and other machine learning engineers to understand and predict relationships between genomic and proteomic simulations and experimental studies.

Please note this is a one-year term with a possibility for permanent conversion.

ACCOUNTABILITIES
Collaborate with a multidisciplinary team to gain insight into complex biochemical systems
Design computational models to study various interactions such as interactions between genomes, proteins, and binding sites
Extract various features from the computational models and communicate the results back to the team
Predict the behaviour of new protein structures on certain binding sites using the computational models
Work with the team of software engineers to embed your models into production
Perform other related duties in keeping with the purpose and accountabilities of the job
REQUIREMENTS
M.Sc. or Ph.D. in Engineering/Computer Science, or an equivalent combination of experience and knowledge
2+ years' experience applying machine learning and deep learning concepts to real-world problems
Solid programming skills with a focus on writing clean/maintainable code, with 2+ years of experience in Python (preferred), Java, or C++ programming
Good knowledge of machine learning libraries (Tensorflow, Keras, Pytorch, Sklearn, etc.)
Strong analytical ability and mathematical skills
Advanced knowledge of machine learning theory and state of the art practices
Matured communication and critical thinking ability to influence and propose analytics strategies that challenge status quo thinking
Preferences:
Strong background in natural language processing and/or the application of deep learning to genomic/proteomic data
Background in genetics, virology, microbiology, or biochemistry
Familiarity with statistical analysis (such as experiment design and hypothesis testing)
Proficiency in Linux environments
Knowledge of the Agile project management methodology
Portfolio of machine learning projects available for review
QUALITIES WE'RE LOOKING FOR
Aptitude for interdisciplinary collaboration
Highly conscientious with strong follow-through
Capable of performing research on best practices and communicating results to a non-expert audience
Able to apply domain knowledge to ambiguous and novel situations
LOCATION
Vancouver, BC, Canada; Remote work opportunity is available.
WHO WE ARE

Terramera is a cleantech leader focused on fusing AI, science and nature to create revolutionary technologies that transform how we grow food and solve other world-scale challenges. With its Actigate™ Targeted Performance technology and mission to unlock the intelligence in nature to ensure a world that thrives and provides for everyone, Terramera is committed to reducing global synthetic chemical loads in agriculture by 80 percent while increasing global farm productivity by 20 percent by 2030. The privately held company was founded in 2010 and has grown to include a world-class bench of engineers, scientists, advisors and investors. Terramera is headquartered in Vancouver, British Columbia, Canada, has integrated operations that include a research lab, robotics workshop, greenhouse and farm, and has more than 200 patents in its IP portfolio.

Our success begins with our people. We're looking for A-Players who are passionate about making a difference as we are and thrive in environments that are dynamic, challenging and rewarding. Join our movement, as we set a new standard and change the world together as a highly dedicated, innovative, future-focused and solutions-oriented team.

While we thank all applicants for their interest, only short-listed candidates will be contacted. For more information on Terramera, please visit our website at www.terramera.com

Terramera is committed to a diverse workforce and we are an equal opportunity employer.

APPLICATION DEADLINE
Applications will be accepted on a rolling basis.",4.0,Terramera,Vancouver,"Vancouver, BC (Canada), Canada",51 to 200 employees,2010,Company - Private,-1,-1,Unknown / Non-Applicable,-1,75.5,10,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,4588,0
147,"Data Engineer - AI-Based Conversational Banking | FinTech (Vancouver)

Join an exciting enterprise SaaS fintech startup that is using artificial intelligence to change how consumers interact with banks and credit unions.

About Us

Finn AI is a rapidly-growing cloud based SaaS company specializing in providing virtual assistants to banks and credit unions to improve service quality, acquire customers and help consumers manage their money. Working with banks across four continents, including some of the world’s largest brands, our Conversational Banking product is changing how people interact with banks (i.e., their money).

Leveraging our proprietary AI stack for natural language understanding and the richest banking domain data model and library of pre-built use cases in the industry, we are uniquely positioned to help banks and credit unions evolve their default experience to a smart virtual personal banker.

To learn more visit www.finn.ai or follow us on LinkedIn.

The Opportunity

Finn AI is a market leader in an early and rapidly growing market. Our solution helps consumers ‘chat’ to their bank, whenever and wherever they want, simplifying the experience, extending service 24/7 and driving efficiency.

We have a strong cohort of customers including ATB Financial, KOHO, Tyme Bank, Banpro, Fidor Bank, one of the largest US card networks and more -- alongside partners including Visa, Liveperson, MX.com, Temenos and more. Finn AI was named a Gartner ‘Cool Vendor’ in 2018.

Finn AI is a well funded series A startup with a fully agile product development methodology. We are looking for a data engineer professional to join our growing technology team.

As a data centric organization, you play a central role in implementing our data management life cycle strategies and tools, including acquisition, storage, transformation, processing, retention and disposition.

If you like the challenge of delivering real-world data to power our engineering, product design, data science and even marketing and sales, with high quality, good security and under reasonable costs, there is the position for you!

Responsibilities
Design, develop and maintain company databases and data schemas, including operational data, analytics data, and data warehouse
Design, develop and maintain data management tools and pipeline for both internal use and production
Participate in technical evaluation and implementation of data tooling, platforms, automation pipelines and hosting solutions
Maintain the infrastructure of data pipelines, adhering to compliance and security while enabling the use of data
Qualifications
Good understanding of data governance principles and architectural patterns for data structures for enterprise applications
3 or more years developing and managing high volume data pipelines
Strong experience with Postgres, ElasticSearch
Strong Experience working with Python and/or Node
Strong experience of AWS RDS, including its performance tuning and HA operations
Working knowledge of developing and deploying tools with Kubernetes
Experience defining and managing ETL workflows
Experience working with machine learning, including deep learning, statistical methods and non deterministic models a plus
Bonus Points
Experience in Fintech, dealing with financial data
Experience with SoC2 compliant data management
Have worked in a customer deliver environment
Speak more than one language
Experience working in a SAAS organization
Experience working with mxnet, tensorflow or other deep learning frameworks
We are hiring directly or through personal networks and will not accept recruiter referrals.

Package
Competitive compensation rates and vacation time
Stock options in a fast-growing company
Medical, dental, and extended health benefits
Parental leave benefits
Education/ Skills development grant
Flexible working hours, a collaborative, team-based environment
Team events and celebrations
*To meet our compliance obligations we require successful candidates to undergo security screenings including a criminal record check before coming on board. We focus strictly on offences that are directly relevant to employment at Finn AI, and abide by all applicable human rights and privacy legislation.",3.8,Finn.ai,Vancouver,"Vancouver, Canada",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,75.5,6,data engineer,na,0,1,0,0,0,0,0,1,0,0,0,0,1,1,0,4235,0
148,"Job Description

Job Title: Data Engineer

Department: Information Technology

Job Overview and Responsibilities

The Aldo Group’s Datahub team is responsible for providing quality data in a timely manner to our business stakeholders to allow for better decisions, performance & analytics. We use data to fuel innovation.
We are looking for a savvy Data Engineer to join our DataHub team of analytics experts to handle the expansion and optimization of our data, data pipeline architecture, and data flow & collection for cross functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up.
Reporting to the Director of Data Engineering and Visualization, the Data Engineer will support our database architects, data analysts and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. They must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. The right candidate will be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.
Create and maintain optimal data pipeline architecture
Assemble large, complex data sets that meet functional / non-functional business requirements
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Help design and build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader
Work with data and analytics experts to strive for greater functionality in our data systems
Job Requirements
5+ years of experience in a Data Engineer role
Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases, relational, MPP and Cloud based
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
A successful history of manipulating, processing and extracting value from large disconnected datasets
Experience supporting and working with cross-functional teams in a dynamic environment
Experience with big data tools: Hadoop, Message Queues, etc.
Knowledge of relational SQL and NoSQL databases, including Postgres and Cassandra
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, BEAM, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Ability to work with stream-processing systems: Storm, Spark-Streaming, etc.
Capacity to work with object-oriented/object function scripting languages: Python, Scala, etc.
Must be bilingual (French, English)
AWS Associate or Professional Certification, an asset
Experience working with ETLtools, Talend, an asset",3.2,Aldo,Montreal,"SAINT-LAURENT, Canada",10000+ employees,1972,Company - Private,"Department, Clothing, & Shoe Shops",Retail,$5 to $10 billion (CAD),"Collective Brands, Steven Madden",96.0,48,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1,3628,2
149,"Job Title:
Senior Matchmaking Data Scientist
Requisition ID:
R002602
Job Description:


Senior Matchmaking Data Scientist (Van)

Want to be responsible for the gaming experience of millions of players? How about building the infrastructure that supports players from around the world?

Demonware is an independently-run part of Activision Blizzard. We run every part of the players' online experience, from logging in to matchmaking to climbing the leaderboards, for popular video game franchises such as Call of Duty, Crash Bandicoot and Skylanders.

Our services impact almost half a billion players, we solve big company challenges with a small company feel.

If youre excited about working with technologies for low-latency, large scale systems in a collaborative, supportive and inclusive environment then wed love to hear from you!

That sounds amazing, but what kind of impact can I make?


As a member of the Matchmaking team, your responsibilities will focus on improving the end user experience. You will use data analytics to identify areas of opportunity, then by developing online services, and running tests, capitalize on these opportunities.

No previous work experience in the video game industry is required, however the ability to put yourself in the shoes of our players is essential. This role will have a direct impact on the online services for AAA multiplayer games, including Call of Duty.

Sounds awesome, what will my day-to-day look like?
Drive exploration and analysis of large complex data sets, representing hundreds of millions of real-world play sessions
Analyze gamer behavior and patterns to drive improvements for players
Develop predictive models, deploy, and performance tracking and validation
Developing custom backend online services and features that are reliable and scale to be used by millions of players all around the world
Working with game studio engineers to assist in making decisions about the direction of game features based on real data
Providing technical mentorship to other team members through data analytics best practices
Sounds exciting, what would you like to see in my background?
6+ years of relevant work experience
Expertise working with big data, and related tools (like Python Notebooks, Spark, SQL, etc)
Good understanding of the Software Development Lifecycle including, but not limited to, agile software development methodologies (Scrum or Kanban)
Expertise working in Python or C++, or skills in a similar language
Experience with databases (ideally MySQL, Cassandra, and Redis)
Experience with data visualization, and tools (Kibana, Grafana etc)
Degree in Mathematics, Computer Science, Computer Engineering or equivalent program
Bonus Points:

Experience designing systems to make high volumes of data useable (using tools like Kafka, ElasticSearch/Lucene)
Experience working with high-volume, customer-facing applications
Experience working with VMs, Linux containers, Docker and Kubernetes
Whats in it for me?


An excellent salary, with annual performance reviews and discretionary bonuses
5 weeks of vacation, standard
Pension matching and contributions
Top-tier medical, dental, and life insurance coverage
Flexible working practices, based on the belief that the quality of your work is not dependent on the number of hours sitting behind a desk
A culture that emphasizes continual learning and improvement, with opportunities for career progression, travel, and a commitment to open source
Demonware by the numbers:

5 million concurrent online gamers
100+ games
300,000 requests per second at peak
Team Name:",4.1,Demonware,Vancouver,"Dublin, Ireland",51 to 200 employees,2003,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10 to $25 million (CAD),-1,96.0,17,data scientist,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,3592,0
150,"Financial & Program Data Analyst
Financial Officer R21

An eligibility list may be established.
Due to present physical distancing requirements related to COVID-19, the recruitment process for this competition may take place virtually.

Contribute your valued expertise and join this exciting new team!

The Primary Care Division is responsible for setting provincial direction to support achieving a high functioning primary health care system that meets the needs of all British Columbians. This includes developing strategies and policies using a population-based methodology and health sector performance management framework, supporting implementation activities at the provincial, regional and local levels, and measuring and monitoring progress in alignment with the quadruple aim of achieving better health outcomes and experiences for both providers and patients, at sustainable system costs. Further, the Primary Care Division leads reforms that support primary care as the foundation of an integrated system of person and family-centred, full-service, community-based care with a focus on improving attachment and access to quality evidence based primary care services. These reforms are built around team-based care provided through a mix of full-service family practices, Urgent and Primary Care Centres, and Community Health Centres, linked together with one another and with other primary and community care services as part of local Primary Care Networks.

This role will conduct proactive reporting and analysis of financial and other quantitative information pertaining to the Primary Care Division strategic initiatives; participate in the development and maintenance of a framework for setting, measuring, analyzing and reporting on financial and other quantitative performance; and assess and make recommendations on the financial implications of new initiatives.

The capital of British Columbia, Victoria is a beautiful city, with beautiful beaches and harbours, and a variety of provincial parks to explore. Located on Vancouver Island, Victoria offers a bustling downtown scene and has a wide range of restaurants and entertainment venues to choose from.

The BC Public Service is committed to creating a diverse workplace to represent the population we serve and to better meet the needs of our citizens. Consider joining our team and being part of an innovative, inclusive and rewarding workplace.

For complete details about this opportunity, including accountabilities, please refer to the attached job profile. For specific position related enquiries, please contact Barb.Lee@gov.bc.ca. DO NOT SEND YOUR APPLICATION TO THIS EMAIL ADDRESS. For more information about how to complete your job application, add/edit your resume and for more useful tips when applying for jobs, please refer to the Your Job Application page on the MyHR website. If you are still experiencing technical difficulty applying for a competition, please send an e-mail to BCPSA.Hiring.Centre@gov.bc.ca, before the stated closing time, and we will respond as soon as possible to assist you.

NOTE: Applications will be accepted until 11:00 pm Pacific Standard Time on the closing date of the competition.

Job Requirements:
In order to be considered for this position, your application must clearly demonstrate how you meet the education and experience as outlined below:
Post-Secondary education in business/public administration, statistics, commerce, economics or related field and three years of related experience; or
Diploma in a related field and five years of related experience.
Demonstrated experience developing financial analytical/reporting frameworks and analyzing financial reports.
Demonstrated experience in budget development, tracking and financial and data analysis.
Experience preparing reports, briefing notes, and relevant communications materials for and briefing senior executives.
Experience building and maintaining effective relationships with stakeholders.
Experience with issues management and strategic problem solving.
Advanced level abilities in Microsoft Excel.
Preference may be given to applicants with the following:
Experience in analyzing and evaluating program performance.
Experience with contract management.
Experience presenting recommendations to management or executive.
Experience in financial evaluation of large and complex projects.
Experience in project management including project management tools such as: MS projects
Applicants selected to move forward in the hiring process may be assessed on the Knowledge, Skills, Abilities and Competencies as outlined in the attached Job Profile located in the Additional Information section at the bottom of the posting.

A Criminal Record Check (CRC) will be required.

APPLICATION REQUIREMENTS: (Application requirement options and the corresponding screening process)

Cover letter: NO - Please do not submit a cover letter as it will not be reviewed.

Resume: YES - Ensure your resume includes your educational accomplishments, employment history including start and end dates (month and year) of your employment, and any relevant information that relates to the job to which you are applying.

Questionnaire (COMPREHENSIVE): YES - As part of the application process, you will be prompted to complete a comprehensive online questionnaire to demonstrate how you meet the job requirements. Please allot approximately 60 minutes to complete the questionnaire.

IMPORTANT: Comprehensive questionnaire responses will be used to shortlist applicants against the job requirements. Please ensure you include all relevant information about your educational accomplishments and employment history including job titles, start and end dates (month and year) of your employment, and your accountabilities and accomplishments.",3.8,Government of British Columbia,Victoria,"Victoria, Canada",10000+ employees,1858,Government,Government Agencies,Government,$10+ billion (CAD),-1,96.0,162,data analyst,na,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,5812,0
151,"$63, 958 - $87,476 per annum



Metrolinx is connecting communities across the Greater Golden Horseshoe. Metrolinx operates GO Transit and UP Express, as well as the PRESTO fare payment system. We are also building new and improved rapid transit, including GO Expansion, Light Rail Transit routes, and major expansions to Toronto’s subway system, to get people where they need to go, better, faster and easier. Metrolinx is an agency of the Government of Ontario.

The Capital Projects Group, Engineering and Asset Management division is seeking a RAMS Data Analysts to provide expertise in data analytics and reliability, availability, maintainability, and safety (RAMS) to coordinate the development and implementation of data management strategies and data collection systems for the RAMS Team in the Engineering and Asset Management Division. RAMS Data Analyst will identify, analyse and interpret data trends/issues, perform RAMS analysis and make recommendations for improvement in asset RAMS performance.

Key Responsibilities

Performs RAMS analysis and evaluation for Metrolinx assets during the entire lifecycle from concept, through risk assessments, stage gate approvals, design and specifications, construction, systems integration, validation, operation, maintenance, performance monitoring and decommissioning as it applies to Metrolinx assets (including the subways program).
Analyses performance data from existing Metrolinx assets and determines RAMS metrics such as Mean Time Between Failures (MTBF) and Mean Time to Repair (MTTR). Analyse RAMS data from individual assets and asset classes to determine performance trends, asset deterioration and condition which can be applied to new assets in future subway projects maintenance and operating requirements and strategies.
Applies the principles of performance evaluation and prediction to facilitate the improvement of reliability, availability, maintainability, and safety (RAMS) of fleet and infrastructure assets by analysing performance metrics and asset failure history to identify asset performance issues.
Works with and develops reliability simulations and modelling to support predictions of asset replacement/maintenance strategies and associated costs.
Develops and implements data management strategies and data collection systems including the design and development of relational databases for information management and retrieval that optimize statistical efficiency, data quality and supports evidence based decision making.
Imports, cleans, transforms, streamlines, validates and models data to improve data quality and ensures data is accurate and relevant and fosters an understanding of operational, business and system issues/trends while advising on data issues including quality, availability and usability.
Guides asset owners and project delivery teams for proper usage and application of Metrolinx RAMS standards/templates around RAMS Analysis, RCA (root cause analysis), FRACAS (failure reporting, analysis and corrective action system) and FMECA (failure mode, effects and criticality analysis).


Location: 20 Bay St, Toronto

File Number: ENG001D
Completion of a University degree in Mathematics, Economics, Computer Science, Engineering, Information Management, Statistics, or a related discipline, or a combination of education, training and experience deemed equivalent.
Minimum four (4) years’ experience in a Data Analyst or similar role, with a background in technology, information management, relational database design and development, business intelligence, data mining or statistics.
Knowledge of relational database and data warehousing concepts, database management software and tools and computer applications including MS Office Excel (Pivot tables, Power Pivot, formulas, VBA),SQL queries and BI platforms (MS PowerBI and/or Tableau).
Technical expertise in the use and application of data modelling, data visualization, database design, development, investigative and data mining methods and techniques.
Analytical and problem solving skills to collect, organize, analyze, and disseminate significant amounts of information with strict attention to detail and accuracy.
Critical-thinking skills to identify trends in data and provide insight into results and outline recommendations.
Interpersonal and relationship management skills to liaise with stakeholders and business units to identify/manage data/information requirements.
Verbal and written communication skills to prepare reports, update and brief management; provide information and explanations of a technical nature to a range of internal and external stakeholders
Ability to learn new software and tools in an efficient manner
Experience with development in .NET and XML would be an asset
To apply for this position, please submit resume, no later than August 4, 2020.

Please note that applicants must be legally entitled to work in Canada. Accommodation will be provided throughout the hiring process, as required. Applicants must make their needs known in advance.

Please be advised, Metrolinx uses email to communicate with their applicants for open job competitions. A Criminal Record Search may be required of the successful candidate. Should it be determined that any background information provided be misleading, inaccurate or incorrect, Metrolinx reserves the right to discontinue with the consideration of your application.

We thank all applicants for their interest, however, only those selected for further consideration will be contacted. Accommodation will be provided throughout the hiring process, as required.



AN EQUAL OPPORTUNITY EMPLOYER
www.metrolinx.com",3.3,Metrolinx,Toronto,"Toronto, Canada",1001 to 5000 employees,2006,Government,Government Agencies,Government,$2 to $5 billion (CAD),-1,96.0,14,data analyst,na,0,0,1,1,0,1,0,0,0,0,0,0,0,0,1,5661,0
152,"Help us boldly shape retail in Canada

Canadian Tire Corporation’s (CTC) rich heritage of serving Canadians from coast-to-coast dates back to 1922. Our vision is to become the #1 retail brand in Canada by 2022 and we are focused on innovating and making important investments in our business, especially when it comes to our people. To reach our goal, we need the best talent to help us evolve and drive change across the business – and boldly help shape Canada’s retail industry. As we strive to be at the forefront of a complex and vastly changing retail industry, it is an exciting time to join the Canadian Tire family of companies.

The Customer Insights and Analytics Group at Canadian Tire delivers customer-focused analytical solutions and insights that enable lasting and meaningful customer relationships. We are a diverse and dynamic team of analysts, data scientists, developers, and consumer researchers united by a common goal – placing the customer at the center of every business decision. We utilize the latest data technologies and advanced analytical techniques to demystify shopper behaviour and embed those insights deep within the fabric of the business. Genuinely passionate about the transformative power of customer data and our role as the “voice” of our customers, we relentlessly push the boundaries of data analytics to ensure we understand our customers better than anyone else and deliver the experiences that will earn their continued loyalty. Our work is redefining the Canadian Tire shopping experience and is a key pillar in our mission to become the #1 retail brand in Canada.
What you’ll do

Reporting to the Manager, Data Science, the Senior Data Scientist will be responsible for driving analytical innovation and leading the technical and methodological capability within the wider team. They play a critical role in the delivery of our big data analytics roadmap and development of machine learning capabilities. The Senior Data Scientist partners with internal stakeholders to drive the adoption of advanced analytics and machine learning across the business.
Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Writes unit/integration tests, contributes to engineering wiki, and documents work.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Works closely with a team of frontend and backend engineers, product managers, and analysts.
Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.
Designs data integrations and data quality framework.
Designs and evaluates open source and vendor tools for data lineage.
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
Who you are

We are looking for individuals who are:
Creative and courageous, with the ability to manage in an environment of change and ambiguity to help us take bold, strategic moves in this rapidly evolving retail environment
Action oriented, and comfortable taking calculated risks to better serve our customers and business
Outcome focused, critical thinkers with the ability to analyze and visualize, to ensure continuous improvement across our entire business
Collaborative team players with superior influencing skills, who build relationships easily across various stakeholder groups to move initiatives forward
If you’re curious, ready to take on new challenges and open to doing things differently to help us evolve rapidly, then this is definitely the place to be.
What you bring
Knowledge of best practices and IT operations in an always-up, always-available service
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Process oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service
BS or MS degree in Computer Science or a related technical field
4+ years of Python development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Experience in PySpark
Experience in designing end to end solution
Familiar with Design patterns and best practices in designing system
Familiar with orchestration tools such as Airflow
Experience designing, building, and maintaining data processing systems
About Canadian Tire Corporation

Canadian Tire and its family of companies are boldly shaping retail in Canada and we continue to deliver a positive experience for our customers. As one of the most trusted brands in Canada, our employees take pride in the work we do across the country. It’s more than the iconic triangle that keeps our employees around. From benefits and perks, to learning and development opportunities, to our commitment to Jumpstart – these are some of the many reasons why Canadian Tire Corporation is one of Canada’s Top Employers.

To learn more about this team and the Canadian Tire family of companies follow us on LinkedIn.

#LI-CW1",3.6,Canadian Tire Corporation,Toronto,"Toronto, Canada",5001 to 10000 employees,1922,Company - Public,"Department, Clothing, & Shoe Shops",Retail,$10+ billion (CAD),"Home Depot Canada, Lowe's",96.0,98,data scientist,senior,0,1,0,0,0,1,1,0,0,0,0,1,1,0,0,5563,2
153,"About Paytm Labs:
At Paytm Labs, we build technologies that powers Paytm India, the world's’ fastest growing mobile payments and commerce ecosystem. In addition to, the Paytm Canada app. We use our skills and our biggest asset – data, to make our dent in this universe.
We are committed to offering the most transparent, secure, and personalized consumer experience to over 230 million users. We believe that this kind of scale, and the unique problems that it presents attracts curious candidates like yourself.

Job Description:
If working with billions of events, petabytes of data and optimizing for last millisecond is something that excites you then read on! We are looking for Data Engineers who have seen their fair share of messy data sets and have been able to structure them for building useful AI products.

You will be working on writing frameworks building for real time and batch pipelines to ingest and transform events(108 scale) from 100’s of applications every day. Our ML and Software engineers consume these for building data products like personalization and fraud detection. You will also help optimize the feature pipelines for fast execution and work with software engineers to build event driven microservices.

You will get to put cutting edge tech in production and freedom to experiment with new frameworks, try new ways to optimize and resources to build next big thing in fintech using data!
Requirements:
You have previously worked on building serious data pipelines ingesting and transforming > 10 ^6 events per minute and terabytes of data per day.
You are passionate about producing clean, maintainable and testable code part of real-time data pipeline.
You understand how microservices work and are familiar with concepts of data modelling.
You can connect different services and processes together even if you have not worked with them before and follow the flow of data through various pipelines to debug data issues.
You have worked with Spark and Kafka before and have experimented or heard about Flink/Druid/Ignite/Presto/Athena and understand when to use one over the other.
On a bad day maintaining zookeeper and bringing up cluster doesn’t bother you.
You may not be a networking expert but you understand issues with ingesting data from applications in multiple data centres across geographies, on-premise and cloud and will find a way to solve them.
Proficient in Java/Scala/Python/Spark
What we Offer!
We are proud to announce that we have been certified as a Great Place to Work!
A collaborative, open work environment that fosters ownership, creativity, and urgency
Enrolment in the Group Health Benefits plan right from Day 1, no waiting period
Fuel for the day: Weekly delivery of groceries and all types of snacks to our office
All types of signature drinks from coffee to lattes to cappuccinos
Catered lunch and desserts on a monthly basis!
Ping Pong and Pool: Become the next Paytm Labs Table Tennis/ Pool champ!
And so much more!
Don't have Paytm Canada App yet?
Check us out in the Google Play or App Store.

We thank all applicants, however, only those selected for an interview will be contacted.

Paytm Labs is committed to meeting the accessibility needs of all individuals in accordance with the Accessibility for Ontarians with Disabilities Act (AODA) and the Ontario Human Rights Code (OHRC). Should you require accommodations during the recruitment and selection process, please let us know. Paytm Labs is an equal opportunity employer.",3.9,Paytm Labs,Toronto,"Toronto, Canada",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,96.0,6,data engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,3500,0
154,"Prenuvo is an innovative medical technology company specializing in whole body diagnostic imaging. Our mission is to eliminate advanced cancer and disease.

We're looking for a Machine Learning expert to lay the foundation for developing applications for radiologists and consumers.

Successful candidate will need to be ambitious, self-driven and organized. We value speed of execution over perfection. We hire for passion, work ethic and proven ability to deliver.

Required experience
BSc/MSc/PhD in Physics, Mathematics, Biomedical/Software engineering or computer science.
3+ years of experience developing Image Processing / Machine Learning products and pipelines.
Advantage
Familiarity with web development (e.g., Flask, Serverless) and deployment (e.g., Docker) and cloud services (e.g., AWS).
Entrepreneurial experience and/or passion for working in small teams
Peer-reviewed academic publications
To apply: Please reach out with a short paragraph about yourself and a link/pdf to your resume.

Powered by JazzHR",5.0,Prenuvo Inc,Vancouver,"Vancouver, Canada",1 to 50 employees,-1,Company - Private,Healthcare Services & Hospitals,Healthcare,Unknown / Non-Applicable,-1,96.0,-1,machine learning engineer,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1022,0
155,"About LivNao

LivNao is bridging the gap between precision medicine & preventive care to make better mental health easier & more accessible — Our patent-pending deep learning model leverages existing, passively collected sensor data from smartphones to detect changes in mental health with zero input required. Our technology helps deliver just-in-time interventions for users while anonymous & aggregated trends help organizations understand what moves the needle on population health.

The Role:

As a Machine Learning Engineer, you’ll take ownership of various components within our core product. You’ll be focused on helping our customers track their mental health & take action through our just-in-time interventions. You’ll work directly with our Chief of Product & Chief of Technology in a fast-paced environment with lots of room for growth and ownership of work.

About You:
Open-minded & fast-thinking software engineer familiar with agile development methods
Strong adherence to metrics-driven development, with a disciplined and analytical approach to product development
Ability to decompose complex problems and work with a team to solve them
Willingness to learn and better yourself
Responsibilities:
Machine learning applications for our core product
Working with managers to meet user facing product deadlines
Technical:
Familiarity with Python and Pytorch
Bonus Points: Background in Exercise/Health Sciences, PHP
Requirements:
Work 40 hours per week
2+ years of experience applying Machine Learning in industry.
Master Degree or higher in Computer Science, Electronics Engineering or related field.
Job Type: Full-time

Experience:
Machine Learning: 2 years (Required)
Work remotely:
Yes",-1.0,Liv,Vancouver,"Vancouver, Canada",1 to 50 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1,96.0,-1,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,1706,0
156,"Company description

At Accurate Data, we see experience and professional expertise combined with data analytics and human creativity as the most important factors for better decision making and action within your business and with improved profitability, greater productive benefit and better business outcome as the aim.

Job description

RESPONSIBILITIES:
· Must be a flexible team player able to use skills in analysis, programming, data mining and database management. Facilitate the use of relational database systems (SQL Server, Oracle or MySQL) and other data mining tools.
· Assist senior data analysts in analyzing and interpreting data.
· Assist with development of special projects, ad‐hoc requests and analytic support to key decision‐makers.
· Assist in the preparation of research reports for use by stakeholders and university decision‐makers using appropriate visual graphs, charts, and tables to communicate research findings.

MINIMUM QUALIFICATIONS:
This position requires a Bachelor’s degree in a field directly related to the research or data analysis responsibilities and a minimum of one year of research experience; or a Master’s degree in one of the same fields. Progressively responsible work experience may substitute for the college on a year for year basis.

PREFERRED QUALIFICATIONS:
· Bachelor’s degree in information technology, computer science, information systems or equivalent field;
· Two years of demonstrated facility and experience with analysis, programming, data mining, or data management.
· Experience with SAS, SQL statistical functions, or other statistical data packages;
· Ability to collect, organize and analyze data, and present complex material orally and in writing;
· Experience with writing procedures and functions in Oracle and SQL Server database;
· Familiarity with ETL processes and data mining solutions.

Job Types: Full-time, Part-time

Salary: $0.00 per hour

Benefits:
Work From Home
Work remotely:
Yes",-1.0,AccurateD,Toronto,-1,-1,-1,-1,-1,-1,-1,-1,96.0,-1,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1969,0
157,"Role Purpose & Key Accountabilities:

The primary role of a Lead Security Data Scientist at Prevalent AI involves analyzing significantly large volumes of security telemetry data collected from various sources (application logs, network logs, database logs, cloud and perimeter security devices), implement complex Machine Learning algorithms and building advanced models, applying these concepts to real security data sets in single or clustered environments, drawing inferences from the collated data and preparing conclusions out of it, to analyse and assess security risk posture for enterprises.
This role also involves leading a talented team of Data Scientists who employ sophisticated analytics programs, data mining techniques, machine learning and statistical methods to prepare data for use in predictive and prescriptive modelling.

Key accountabilities include:

▪ Developing a firm understanding of the essential business requirements through interaction with, and interrogation of, business SMEs and translating that understanding into models that address the requirements, using data science methods, including:

▪ Data assembly, cleansing, validation

▪ Data visualization

▪ Statistical modelling, supervised and unsupervised machine learning, mathematical programming

▪ Inspecting data to confirm that it is consistent with expectations, modifying designs as necessary.

▪ Communicating predictions and findings to the Organization through effective data visualizations and reports.

▪ Creating prototypes of key data manipulations, visualizations and mathematical modelling elements.

▪ Validating designs with business SMEs via discussions, examples, prototype demonstrations and documentation and iterating designs in response to negotiations with business SMEs.

▪ Conveying the designs to the development teams via discussion, documentation and prototype code.

▪ Developing an understanding of industry trends and best practices.

▪ Creating and follow personal education plan in the technology stack and solution architecture.

Experience & Skills:
▪ Exposure to cyber security domain.

▪ Extensive relevant experience in Data Science.

▪ Hands on experience in production deployment of ML models in large complex environments.

▪ Ability to learn quickly in a fast-paced environment.

▪ Excellent communication and team management skills.

▪ Self-motivated individual capable of working in a fast-paced environment.

▪ Great verbal and written communication skills.

▪ A strong analytical mind-set.

Knowledge:
▪ Good understanding and expertise in processing large datasets.

▪ Good working knowledge in implementation of various ML algorithms in big data environment

▪ Understanding of data visualization tools, such as Tableau, etc.

▪ Familiarity in working with Big Data and common data science tools such as Python, Spark etc. Proficiency in at least one.

▪ Familiarity with Scala, HIVE is desired.

▪ Good scripting and programming skills; SQL proficiency.

▪ Understanding of and proficiency in NLP.

▪ Understanding of a range of statistical and machine learning techniques and algorithms, such as logistic regression, KNN, decision trees, SVM, CNN, etc.

▪ Good understanding of the process workflow:

▪ Problem definition to hypothesis building

▪ Prototype model building using python/R

▪ Implementation of ML problems in big data.

▪ Performance Monitoring & Evaluation of System

Education:
▪ Master’s in Engineering, Science, or Mathematics

Values:

Inquisitive: Inquisitive by nature, hungry for knowledge and excited about new challenges.

Authentic: Genuine, with a desire to create real and lasting relationships with clients, partners and colleagues.

Focused: Tirelessly pursue results, driven by a clear sense of purpose to make clients and partners secure and successful.",-1.0,Prevalent,Cochin,"Kochi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,96.0,-1,data scientist,senior,0,1,0,1,0,1,1,0,0,0,0,0,1,0,0,3826,0
158,"Nokia is a global leader in the technologies that connect people and things. With state-of-the-art software, hardware and services for any type of network, Nokia is uniquely positioned to help communication service providers, governments, and large enterprises deliver on the promise of 5G, the Cloud and the Internet of Things. Serving customers in over 100 countries, our research scientists and engineers continue to invent and accelerate new technologies that will increasingly transform the way people and things communicate and connect.

General Purpose of the Role/Job Position Summary Description:

Nokia Software Core Engineering / Signaling and Media R&D team is seeking for SBC Machine Learning / Data Analytics Specialist in order to address growing business needs of Nokia Session Border Controller (SBC) product. This has to be supported by rapid product evolution and transition to cloud native product architecture.

Therefore, we need Machine Learning / Data Analytics Specialist to join our R&D organization. The candidate(s) in this role will be required to work with R&D members (CTO, other systems engineers/architects, software engineers) as well as product line managers (PLMs) and customer support teams to define, design and deliver cloud native SBC product into both Carrier and Enterprise Markets.
Key Responsibilities / Functions:
Driving product architecture / new function definition to enrich product with machine learning / deep learning capabilities to be used with existing and new product functions,
Cooperation with Product Managers, Product Architect, System Engineers, CTO and Development Teams on defining of product roadmap, feature definitions and backlog prioritization
Identification of product gaps and weaknesses toward competition, addressing them into enhancements/ roadmap, for their respective areas
Supporting design, implementation, test, sales and maintenance of product with the relevant teams
Documenting and presenting product capabilities internally and externally (documentation/ publications and presentations)
Involvement in relevant standardization bodies
Cross-sharing technology & product knowledge among various project team members
Representing R&D internally and externally
Required Minimum Qualifications: (Education, Technical Skills/Knowledge)
Bachelor’s degree or equivalent experience required. Candidate´s with degree in Computer Science or Electrical Engineering will be more relevant. Master’s degree is a plus
At least 6-8 years of professional experience including Systems Engineering and/or system architecture in respective area.
Experience with programming in Python & ML frameworks (i.e. Tensorflow, Keras, PyTorch) and versioning tools
Expertise in one or more of the following machine learning domains: Image Processing, Computer Vision, Natural Language Processing (NLP), Speech/Signal processing
Advanced knowledge in deep learning algorithms
Experience in data visualization tools and methods
Good understanding and hands on experience in software architecture, virtualization, cloud native principles, microservices, containers
English as working language
Desired Qualifications: (Education, Technical Skills/Knowledge)
R&D experience in software design, software development
Knowledge of IMS functions and protocols, specifically Session Border Controller components and functions, VOIP and VoLTE architecture would be an advantage
Experience with VMware, Openstack, AWS, Azure clouds, Software Defined Networking

Canada is committed to building a skilled, diverse workforce reflective of Canadian society. As a result, we promote employment equity and encourage women, aboriginal persons, persons with a disability or members of a visible minority group to apply.
Nokia is an equal opportunity employer that is committed to diversity and inclusion. At Nokia, employment decisions are made regardless of sex, gender identity or expression, sexual orientation, race, ethnic origin, color, creed, religion, national origin, citizenship, age, marital status, physical or mental disability, genetic information or ancestry, protected Veteran or military status, or other characteristics protected by law.",4.2,Nokia,Ottawa,"Nokia, Finland",10000+ employees,1865,Company - Public,Telecommunications Services,Telecommunications,$10+ billion (CAD),"Ericsson-Worldwide, Huawei Technologies, Microsoft",96.0,155,machine learning engineer,na,0,1,0,0,0,0,0,0,1,0,0,0,1,1,0,4187,3
159,"Data Engineer or Scientist-MON16971

Description

BOMBARDIER

At Bombardier, our employees work together to evolve mobility worldwide - one good idea at a time. If you have a good idea, we’ll provide the environment where it will thrive and grow into a great product or customer experience. Your ideas are our fuel.

In your role, you will:
Integrate internal A.I. solutions within evolving Business Intelligence Solutions;
Nurture strong working networks with internal and external stakeholders to access large variety of data sources and enhance A.I. value creation;
Challenge status-quo for data ecosystem and collaboratively innovate solutions to enable A.I. across teams;
Support A.I. teams across multiple business areas by maintain A.I. solution ecosystem;
Manage day-to-day operations within data management and analytics platforms (e.g. Azure / AWS / GCP); and
Articulate software and hardware requirements for A.I. solutions to non-practitioners.
Qualifications

As our ideal candidate,
At least 3 years of work experience designing and implementing AI/data science algorithms/systems and managing the associated data by leveraging, connecting and operationalizing large scale enterprise data solutions and applications using best-known data management and analytics platforms (e.g. Azure / AWS / GCP)
Experience working in an Agile development environment implementing AI/data science algorithms leveraging state-of-the-art programming languages and libraries (e.g. Python, R, Tensorflow, pytorch, mxnet, pandas) and understanding of development and service delivery/management frameworks (e.g. DevOps)
Masters and/or PhD credentials in data science related fields and Engineering background is desired.
Experience deploying A.I. solutions within business functions to improve business competitiveness.
Proven results while navigating through global organizational environments.
Organizational savviness and good communications skills.
Bombardier is an equal opportunity employer and encourages women, Aboriginal people, persons with disabilities and members of visible minorities to apply.

Whether your candidacy is moving on to the next step of the hiring process or not, we will keep you informed by email or by phone. Join us at careers.bombardier.com

Your ideas move people.

#LI-RK1

Job: System Integration
Primary Location: CA-QC-Montreal Dorval
Organization: Aerospace
Schedule: Full-time
Employee Status: Regular

Job Posting: 05.02.2020, 9:53:18 AM

Unposting Date: Ongoing",3.3,Bombardier,Montreal,"Montreal, Canada",10000+ employees,1942,Company - Private,Transportation Equipment Manufacturing,Manufacturing,$10+ billion (CAD),-1,96.0,78,data engineer,na,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,2497,0
160,"Score Media& Gaming Inc. empowers millions of sports fans through its digital media and sports betting products. Its media app‘theScore’ is one of the most popular in North America, delivering fans highly-personalized live scores, news, stats, and betting information from their favorite teams, leagues, and players. The Company’s mobile sports betting app‘theScore Bet’ delivers an immersive and holistic mobile sports betting experience. Natively built for iOS and Android devices, theScore Bet is deeply integrated with theScore’s media app and is currently available to residents of New Jersey. Publicly traded on the TSX Venture Exchange (SCR), theScore also creates and distributes innovative digital content through its web, social and esports platforms.

As a part of the Data Analytics team, you will be a part of a team where data, measurement, and analysis is integral to smart decision making and building awesome products and features. The ideal candidate has a passion for data, a strong background in quantitative analysis and the latest technologies and an interest in professional sports, esports, and gaming.

Typical Work Day at theScore:
Have a deep understanding of how users interact with theScore’s Sports app and website.
Answer questions by using appropriate statistical techniques on available data.
Report and analyze mobile, web, and social data through user path and engagement activity.
Continuously improve analytics implementation and adapt to changing technologies.
Develop, create and execute multivariate or A/B testing.
Drive the data strategy across multiple listening posts (web, mobile, social, surveys, CRM and, market research).
Stay on top of emerging trends in the digital industry.
Other duties as required.
Requirements
University degree in Computer Science, Statistics, Business, or related field.
2+ years of related experience.
Demonstrated ability to work with a variety of analytics tools such as, but not limited to:
Amplitude, Periscope, Looker, Branch, AppsFlyer, Sensor Tower, Google Analytics.
Strong knowledge of relational databases and SQL.
Familiarity with analysis tools; R or Python packages are preferred.
A passion and curiosity for solving analytical problems using quantitative approaches.
Ability to take complex data and present it in a clear and simple manner.
Ability to focus in a fast paced environment and multitask.
Excellent written and oral communications skills.
What We Offer:
Competitive salary with Employee Share Purchase Plan.
Comprehensive Benefits package.
Fun, relaxed work environment.
Education and conference reimbursements.
Located downtown Toronto; easily accessible by public transit.
A/V club, Friday presentations, book library, and more.
Snacks and drinks provided.
Awesome patio with BBQ.
Games room (bring your A game for our FIFA 19, ping pong and foosball tournaments!)
We are an equal opportunity employer. Accommodation will be made upon request.",3.6,theScore Inc.,Toronto,"Toronto, Canada",201 to 500 employees,2012,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,"ESPN, Yahoo",96.0,8,data analyst,na,1,1,0,0,0,1,0,0,0,0,0,0,0,0,1,2945,2
161,"Data Analyst

At Flowmotion Entertainment, we are passionate about making great games and getting them the audience they deserve. We are a game developer and publisher of female-focused casual mobile games, and have brought fun to over 40 million people around the world. We are headquartered in Canada with an international all-star team that spans the globe. Having fun while making a difference in the world is core to who we are, and the revenue from our games have also helped Backpack Buddies, a Canadian charity, provide more than 45,000 meals to children in need.

We partner with top developers around the world to ensure their games attract the audience they deserve and are imagined for sustainable, long-term, profitable growth. We’ve experienced remarkable growth over the past few years, and we’re just getting started!

The Opportunity

Flowmotion is looking for a rockstar Data Analyst, who loves data and mobile games. We collect a ton of information from our games and there’s always huge opportunities for the right person to dig and find gold, making a big difference for our players and for the business. The ideal candidate should be skilled in all aspects of data analytics, including mining, generation, and visualization. Additionally, you should be committed to transforming data into readable, goal-driven reports for continued innovation and growth.

What you will be doing:
Develop, implement, and maintain leading-edge analytic systems, taking complicated problems and building simple frameworks
Work closely with game designers and product managers to understand their analytical needs, including identifying critical metrics and KPIs, and deliver actionable insights to relevant decision-makers
Create best-practice reports based on data mining, analysis, and visualization
Evaluate internal systems for efficiency, problems, and inaccuracies, developing and maintaining protocols for handling, processing, and cleaning data
Proactively analyze data to answer key questions or out of self-initiated curiosity with an eye for what drives game and business performance
Create and maintain rich interactive visualizations through data interpretation and analysis integrating various reporting components from multiple data sources
Define and implement data acquisition and integration logic, selecting appropriate combination of methods and tools within defined technology stack to ensure optimal scalability and performance of the solution
Develop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across data sets
Evaluating and providing required event tracking improvements and additions to existing and new games to ensure the right data is collected
What you need:
Bachelor’s degree in Mathematics, Computer Science, Economics, Statistics or equivalent
2+ years experience mining data as a data analyst
A passion for free-to-play (F2P) mobile games
Strong SQL or Excel skills with the ability to learn other analytic tools. Bonus for experience with Google Cloud Platform and BigQuery.
Proven analytic skills, including mining, evaluation, analysis, and visualization
Technical writing experience in relevant areas, including queries, reports, and presentations
Prior experience with database and model design and segmentation techniques
Strong programming experience with frameworks including XML, Javascript, and ETL
A balance of discipline and flexibility to succeed in a remote work environment and have worked on a team of remote members before.
Great communication skills, fluent in English, both written and verbal
A growth mindset, and commitment to achieving that ‘next level’ in everything you do.
How success will be measured:
Improved key game metrics (retention, monetization, etc.) and marketing metrics (conversions, downloads, etc)
Team harmony through clear communication and leadership
Frequent experiments with clear progress and reported insights/learnings
How we care for our team:
Training & Development - attend conferences and continue your path of development
Discretionary Bonus Program
Flexible Work Schedule, getting to work from home alongside a global team of passionate people living all over the planet
To apply, at minimum send your cover letter and resume to hiring@flowmotionentertainment.com with the word “passion” in the subject line. Even better yet, we’d suggest doing something to really get noticed that will be different than 99% of the applicants who will just send an email hoping to get an interview...",5.0,Flowmotion Entertainment,Vancouver,"Vancouver, Canada",1 to 50 employees,2014,Company - Private,Video Games,Media,Unknown / Non-Applicable,-1,96.0,6,data analyst,na,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,4597,0
162,"Responsibilities

We are looking for a Machine Learning Engineer to work at the intersection of data engineering and data science in the customer analytics domain. This opportunity is for someone who wants to leverage their deep expertise in machine learning and engineering on leading edge, large-scale simulation and constraint optimization systems that operate on big data.

Our ML Engineers are part of a cross-functional engineering team that shapes the vision and architecture of Novantas’s big data/analytics platform, making it easier for data scientists and data engineers to develop data products and serve predictive models to end user applications. They are responsible for developing a reliable and scalable infrastructure that supports the model development, deployment and monitoring lifecycle. They work closely with passionate technical leaders on challenging distributed systems problems that arise from data processing at the customer level at scale and in near real-time.

Desired Skills and Expertise

Candidates should have the following background, skills and characteristics:
Analytically driven with a quantitative degree (e.g. Computer Science, Operations Research, Mathematics, Data Science)
Programming fluency
Expert level Python is required
Working knowledge of R is strongly preferred
Fluency in Scala preferred
Working knowledge of Apache Spark
Exposure to or experience with PMML, SparkML/TensorFlow/PyTorch and developing ML pipelines in Hadoop ecosystem
Knowledge of constraint optimization and simulation is a plus
Interest in the FinTech space
2-10+ years of industry experience is preferred
Self–discipline and willingness to learn
Excellent verbal and written communication skills
Team player and ability to work well with others in an intellectually challenging environment
All candidates must possess work authorization which does not (and will not in the future) require work sponsorship by an employer.

We are proud to be an Equal Opportunity Employer. Please visitwww.novantas.com for more information.",2.9,Novantas,Toronto,"New York, NY",201 to 500 employees,1999,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1,96.0,21,machine learning engineer,na,1,1,0,0,0,0,1,0,0,0,0,0,1,0,0,2047,0
163,"Job Title
Sr Data Scientist

07/27/2020

Department Name
E-commerce

Job Description
Sr Data Scientist

Our entrepreneurial roots and maverick mentality, coupled with the resources and backing of the #1 home improvement retailer in the world, The Home Depot Canada is a unique opportunity for you to become part of a transformative retail disrupter as we continue on our mission to provide the best interconnected shopping experience to our customers. As part of the rapidly growing and highly capable Analytics team, you will be tasked with absorbing billions of rows of data from dozens of sources, organizing them, visualizing them, and analyzing them to help inform both short- and long-term decision-making, tackle problems and derive insights. The team isn’t just making monthly reports or rerunning existing statistical models, it’s doing creative work in an empowering environment with each decision backed by data to support different areas of the customer journey. We need more dreamers, innovators and big thinkers passionate about data and re-imagining the future of retail. Interested in making history with us? If so, apply today to experience what it’s like to be a part of Analytics at The Home Depot Canada.

Position Overview:

The Sr Data Scientist will contribute and help develop the analytical infrastructure and computational capabilities that drive decision making and impact the bottom line performance of Home Depot Canada. By partnering with business leaders and leveraging company and industry data, this role will develop predictive systems and algorithms for identifying trends and driving business solutions. This position's primary focus is to manipulate large datasets to extract meaningful business information using statistics and machine learning techniques.

The successful candidate will be passionate about seeing real world impact of analytics and have a solid understanding of scientific and business needs, as well as the areas of data science that can be transformative and impactful to the retail and eCommerce industry.

Position Responsibilities:
Own the design and development of algorithms and optimize big data architectures and data pipelines
Establish scalable, efficient processes for large scale data analyses, model development and model implementation within a modularized architecture where applicable
Use analytical and statistical rigor to solve complex problems and drive business decisions
Improve upon existing machine learning methodologies by developing new data sources, developing and testing model enhancements, running computational experiments, and fine-tuning model parameters for new models.
Present analysis and resulting recommendations to senior management; Leverage data to present a compelling business case to optimize investments and operations
Utilize code (Python, R, Scala, etc.) for analyzing data and building statistical and machine learning models and algorithms
Design and drive experiments, A/B testing, outlier deep dives and form actionable recommendations. Manage the implementation of those recommendations
Collaborate with product management and engineering groups to develop new products and features
Communicate and educate technical and non-technical employees on analytics and data-driven decision making
Required Experience/Skills:
Master's in Computer Science, Math or related quantitative field (or BS/BA in Computer Science, Math or related quantitative field)
3 years of experience in data mining and statistical analysis, demonstrated ability to identify key insights from data to solve business problems
Experience using advanced statistical and machine learning techniques (clustering, decision tree learning, artificial neural networks, regression, properties of distributions, etc.) and their real-world advantages/drawbacks
Experience using statistical and data manipulation languages (e.g. Python, R, SQL)
Critical thinking, effective written and verbal communication skills
Experience with Google Cloud Platform (such as BigQuery, Compute Engine, Data Flow)
Experience with relational (SQL) and NoSQL Databases
Experience with developing products deployed to production
Location/Division
7095-TORONTO HEAD OFFICE (STORE SUPPORT CENTRE)

Employment Status
Full-Time

Province
Ontario

Last Date to Apply
08/07/2020

Job Category
Corporate Opportunities

Intro Statement
Do you know what makes The Home Depot the largest home improvement retailer in the world? Our people. We do all we can to empower those within the Home Depot to tap into their potential and make a difference where it matters most – for our customers and for themselves.

Do you have what it takes to make an impact on the world’s largest home improvement retailer?

Discover what it’s like to be part of a team responsible for helping millions of people complete thousands of home improvement projects every year. Search corporate careers today.

Closing Statement
Thank you for applying to The Home Depot Canada. Our careers allow you to “unleash your inner orange” to improve the lives of our customers and yourself by helping them to complete their projects. Please note applications will only be accepted online and only those candidates under consideration will be contacted.

The Home Depot Canada is committed to diversity and is an Equal Opportunity Employer.

Knowledge/Experience Required

Required Experience/Skills:
Master's in Computer Science, Math or related quantitative field (or BS/BA in Computer Science, Math or related quantitative field)
3 years of experience in data mining and statistical analysis, demonstrated ability to identify key insights from data to solve business problems
Experience using advanced statistical and machine learning techniques (clustering, decision tree learning, artificial neural networks, regression, properties of distributions, etc.) and their real-world advantages/drawbacks
Experience using statistical and data manipulation languages (e.g. Python, R, SQL)
Critical thinking, effective written and verbal communication skills
Experience with Google Cloud Platform (such as BigQuery, Compute Engine, Data Flow)
Experience with relational (SQL) and NoSQL Databases
Experience with developing products deployed to production",3.7,Home Depot Canada,Ontario,"Toronto, Canada",10000+ employees,1994,Subsidiary or Business Segment,Home Centres & DIY/Hardware Shops,Retail,$2 to $5 billion (CAD),-1,96.0,26,data scientist,senior,0,1,0,0,0,1,0,0,0,1,0,0,1,0,1,6254,0
164,"Wavo is looking for intermediate and senior data engineers to join our technical team.

Digital advertising, technology, & data are changing the way artists & brands approach advertising. With Wavo you will get the rare chance to create services that will be used by todays top artists, managers and brands to help them grow their business through Wavos advertising products.

Wavos technical team is small and efficient, and while we work to a high standard we dont over-manage with specs. We strive to build a workplace where everyone works hard and gets passionate about the big challenges.

We can promise you will never be bored. We are constantly experimenting, testing new approaches and challenging ourselves to master new skills. We try to think outside of the box and build an environment thats both exciting and meaningful.

Responsibilities:

Collaborate with other engineers and teams to implement new features, improvements and fixes needed to build and extend our advertising, and data management platform

You might be a good candidate if you:

- Have a high degree of proficiency with Python.

- Very comfortable with SQL. Experience with Postgres is a plus.

- Knowledge of Apache Spark & pySpark required. Good understanding of ETL pipelines is a plus.

- Familiarity with Docker, CircleCI, and Kubernetes is a plus.

- Are passionate about working with data, and building systems that are highly reliable, maintainable, and scalable

- Are a good communicator and enjoy interacting with people

- Enjoy being part of a highly collaborative, remote enabled environment

- Are comfortable having ownership and control of a project.

Also...

- Today we use AWS for most of our Data infrastructure, so familiarity with that platform is a huge plus.

- Having experience in ad-tech, machine learning, or data ETL /Data ingestion is also to your advantage.

- Finally, all our future projects will be done in a continuous deployment fashion; supported by integrations tests / BDD.

Benefits

======

- Competitive compensation based on experience

- Competitive Equity

- Group health and dental insurance plan

- Flexible hours and vacation

- Free tickets to shows and festivals

- Delicious office snacks

- Company outings & activities

- A dynamic work environment

- Being a part of innovation at the nexus of music, marketing/advertising, and technology

-------------------

If you think youd be a good fit, please contact careers@wavo.me with a copy of your resume.

Equal Opportunity Employer

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",5.0,Wavo,Montreal,"Vancouver, Canada",1 to 50 employees,2018,Company - Private,Internet,Information Technology,$1 to $5 million (CAD),-1,96.0,2,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,1,0,0,2757,0
165,"Data Engineer

REQ:
PHC20-122916
Work Area:
Data Analytics PHC
Base Site:
Hornby Street
City:
Vancouver
Status:
Regular Full Time
FTE:
1.00
Job Category:
Management/Non Union
Post date:
Jun 30, 2020
Category:
Corporate
Hours:
0800-1600

Summary

Reporting to the Manager, Operations Research and Analytics, the Data Engineer develops and establishes scalable, efficient, automated processes for large scale data analyses, and model development, validation and implementation. The position collaborates closely with other members of the Operations Research and Analytics team to create and deploy automated data pre-processing and advanced analytics models through the innovative understanding and use of large data sets to improve clinical processes and patient outcomes, and support data-driven decision making. The ideal candidate will have extensive experience in dimensional modeling, developing advanced analytics algorithms, optimizing processes with advanced analytics solutions, and excellent problem solving ability dealing with huge volumes of corporate and clinical data. The position will also stay apprised of current trends and research on all aspects of data engineering and advanced analytics techniques and works in collaboration with provincial and national colleagues.
Skills
Demonstrated strength in data modeling, ETL development, and data warehousing with solid knowledge of various industry standards such as dimensional modeling, and star schemas etc.
Demonstrated ability to build and optimize ‘big data’ data pipelines, architectures and data sets and computing tools such as Spark, MySQL, Azure, AWS, etc.
Demonstrated knowledge of methods and techniques involved in Advanced Analytics, data mining, statistics, and optimization (including neural networks, reinforcement learning, and adversarial learning).
Coding proficiency in at least one modern programming language (Python, Java, etc)
Demonstrated proficiency working with both relational (SQL) and non-relational databases (NoSQL).
Demonstrated understanding of data privacy, security and related tools such as anonymization and encryption.
Excellent oral and written communication skills and ability to clearly and fluently translate technical findings to non-technical partners and to communicate to multiple audiences using data storytelling and through graphics.
Demonstrated ability to work collaboratively in an interdisciplinary environment and to develop recommendations using facilitation and consensus building.
Strong analytical, critical thinking, and evaluation skills to discern and help solve the important problems facing health care, to identify new ways to leverage our data, and to direct efforts in the right direction.
Education

A Masters’ Degree in Computer Science, Mathematics, Engineering, or other quantitative degree is required plus at least five (5) years’ experience as a Data Engineer or related specialty (e.g., Software Developer, Business Intelligence Engineer, Data Scientist) with a track record of manipulating, processing, and extracting value from large datasets. Experience with healthcare analytics is an asset.
Duties
Creates and maintains optimal data pipeline architecture. Builds analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Builds the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and big data technologies. Re-designs infrastructure for greater scalability.
Assembles large, complex data sets that meet functional/non-functional business requirements. Creates data tools for the operations research and analytics team to assist them in building and optimizing our product into an innovative industry leader.
Identifies, designs, and implements internal process improvements including establishing standards for development processes and technical requirements; automating manual processes; optimizing data delivery, etc. Develops and ensures compliance for data management processes, policies and standards. Implements and enforces controls to maintain data availability and quality.
Recognizes and adopts best practices in data integrity, test design, analysis, validation, and documentation. Tunes application and query performance using profiling tools and SQL.
Researches innovative solutions, develops new concepts, and implements proof-of-concept prototypes by applying expertise in data engineering, advanced analytics, process modeling, and optimization tools and techniques.
Works in close collaboration with other members of the Data Analytics and Health Informatics teams to develop and implement innovative solutions that address pressing operational and clinical challenges within the organization.
Reviews clinical data at aggregate levels on a regular basis using analytical reporting tools to support the identification of risks and data patterns or trends. Creates analytical reports and presentations to facilitate review and adoption of data-driven choices. Collaborates with project/program teams to address data-related questions and to recommend potential solutions.
Works closely with clinical and management teams across PHC to strategize, develop, and implement advanced modelling projects that translate into improved quality of care, clinical outcomes, reduced costs, temporal efficiencies, and process improvements.
Works with stakeholders including the Executive, and Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keeps up-to-date with the latest technology trends and methods by staying abreast of state-of-the-art literature in the fields of advanced analytics, statistical modeling, statistical process control and mathematical optimization.
Perform other duties as required.

Apply Now

Employees of Providence Health Care receive an excellent and comprehensive health benefit package, as per their collective agreement or terms and conditions of employment.
Other benefit packages may apply if this is an affiliate posting.",4.0,Providence Health Care,Vancouver,"Vancouver, Canada",5001 to 10000 employees,1894,Hospital,Healthcare Services & Hospitals,Healthcare,$1 to $2 billion (CAD),"Fraser Health, Vancouver Coastal Health, Alberta Health Services",96.0,126,data engineer,na,0,1,0,0,0,1,1,0,1,0,0,0,0,0,1,6175,3
166,"At ProteinQure, we are building a computational platform for design of protein therapeutics. Our mission is to help to create a world where drugs are engineered, not discovered. We work on treatments for cancer, diabetes, asthma, and cardiovascular diseases, among others, and partner with industry leaders in drug discovery to generate novel therapeutics outside of the conventional chemical space.

Our technology combines computational biophysical models with statistical and machine learning approaches to enable us to search across vast spaces of protein therapeutics. We build and deploy these computational modules using a scalable cloud computing infrastructure and complement their predictions with results from wet lab experiments. We utilize advanced computing architectures based on high-performance GPUs, TPUs and investigate novel methodologies in biophysical modelling and quantum computing.

ProteinQure is a seed-stage company and has recently (Q2 2019) raised its seed round of USD $4M led by top Silicon Valley and Canadian investors.

We're looking for a Machine Learning Scientist to join our team in Toronto (Canada). You should think about joining us if you enjoy using state-of-the-art machine learning algorithms in high impact applications.

We are building out our computational RD team. We are adding members with experience in applying machine learning to biology (and chemistry) systems complement other team members who are leaders in the field of biophysical computational methods. It is a interdisciplinary team with many opportunities for growth and impact.
Responsibilities
Perform research and development of new methods for learning from protein sequence and structure datasets
Unsupervised learning of protein/peptide sequence representation to assist in downstream machine learning engineering within the platform
Development of supervised learning algorithms for protein structure prediction, protein-protein interaction prediction, and protein property prediction
Work with data sets that are diverse in type and size (sparse/big data sets, 3D models, amino acid sequences, structural features)
Work side-by-side with chemists, biologists, and software engineers to develop drug candidates
Assist software engineering team in deployment of ML tools at scale
Help create optimization protocols incorporating predictive tools in ProteinQure platform
Present our work at major conferences and to customers
Nice to haves
Peer-reviewed publications on applications of machine learning in biology, or new methods in natural language processing or computer vision
Experience with other computational tools for biology
Experience working with multiple developers with distributed version control (Git)

Requirements
PhD in relevant field OR Masters and multiple years of working experience
Knowledge of biology, familiarity with biological data (sequence, structure)
Benefits at ProteinQure include medical, dental and vision insurance and health spending account, which you can use on gym memberships or massages. We believe in enabling our employees to be their most productive selves - from extremely ergonomic chairs to standing desks and powerful, portable laptops. Employees are encouraged to buy (and get a refund for) equipment, books, or whatever tools that would make their work life easier.

The office is situated in downtown Toronto, in the Chinatown area, with plenty of great restaurants nearby. Toronto is a great cultural hub (film festivals, theatres, museums and concerts) and supports active lifestyle (amateur sports leagues, waterfront beaches, surfing or even (ice) climbing). Canadian nature offers options for calming retreats and the country is very diverse, welcoming and open to newcomers.

The team is currently composed of 11 people and we’re expecting to grow to 20 people by 2020. The team composition is roughly 40% software engineers and data scientists, 40% computational biologists, medicinal chemists (including experimentalists performing experiments in wet lab) and 20% business and administration.

Celebration of diversity of all forms is embedded in our culture. Great work is the result of diverse thinking and experiences and we have a workplace where those differences can thrive. Over two thirds of the team was born outside of Canada.

Collaborative learning is at heart of what we do at ProteinQure - we have weekly lunch and learns (often with guest lecturers from outside of the company), attend (and organize!) meetups and hackathons and educate each other about best practices. We support our employees and sponsor attendance to conferences or professional events (up to $3000 a year).

Ownership of work is fundamental to way we operate. People will encourage you to problem solve and figure out how to best deliver results. You’re completely free to take vacation (and run errands) as long as you are responsible and performing. The last thing we want to do is micromanage our team. We try empower our employees, trust them to deliver and hold them accountable.

Our hiring process consists of three steps:
• Introductory call (20 min) - we want to get to know you, understand your motivations and needs. This is a chance to ask questions about the company!
• Technical interview (90 min) - Video (or in person). We ask questions to understand your background a little bit better than your CV or GitHub profile can tell us.
• On-site interview (3 hours) - We try to be flexible on the timing of the on-site. If you are not from Toronto area, we’ll cover the travel and accommodation expenses.

We will give you our decision within 5 business days of the on-site interview. For the international candidates, we sponsor visas and help with relocation.",5.0,ProteinQure Inc,Toronto,"Toronto, Canada",1 to 50 employees,2017,Company - Private,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1,96.0,3,machine learning engineer,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,5736,0
167,"Are you a SR. Data Scientist guru? Do you have a degree in Engineering, Statistics, Mathematics, or Computer Science? If so, we want to meet you! We are currently searching for a Sr. Data Scientist to be part of our client’s team of professionals. We are looking for a dynamic and motivated individual who has a passion for Data Analytics.

Our client has been around for over 15 years and has remained a well reputed company in Canada.

Responsibility:
Assemble and analyze data to understand customer behavior external data sources and emerging sources.
Building Pricing models and optimization using gurobi or the like.
Undertake analysis of target customer groups (segments) for specific marketing and pricing programs and assess opportunities and strategies for marketing.
Ad hoc analysis and modeling of data.
Strong experience building customer analytic models like: price elasticity, attrition, lifetime value, churn and segmentation.
Ability to understand business stakeholder’s issues and create valuable insight.
Raise awareness and action of data science within the company to help focus on fact-based decisions.
Support the Department along with the Information Technology Management Department in planning the structure and storage of new customer related data fields.
Represent the department in committees within the organization.
Lead project-based work with key business stakeholders.
Mentor junior members on statistical techniques and experimental design.
Qualifications:
A University degree in Engineering, Statistics, Mathematics, or Computer Science.
Graduate Degree focusing on Operations research. (PhD preferred)
Minimum 10 years working experience with data science techniques: clustering, regression models, classification, anomaly detection and other machine learning techniques.
Minimum 10 years of experience with data analysis tools (eg. SAS, R or Python) and BI visualization for reporting.
Well-developed business analysis, research, and creative problem-solving skills.
Organizational skills and time management skills; planning and project management, and ability to meet multiple deadlines.
Strong communication skills and work ethic.
Highly collaborative team player with an entrepreneurial spirit.
Familiarity with MicroStrategy is an asset.
Contact Details


Don’t miss this opportunity, apply now!

Qualified candidates please submit your resume to saudn@fuzehr.com

or call Saud at (905) 361 - 3987 ext. 126

#OPON",3.6,Fuze HR Solutions,Woodbridge,"Montreal, Canada",51 to 200 employees,2006,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,"Robert Half, Randstad, Adecco",96.0,14,data scientist,senior,1,1,0,0,0,0,0,0,0,0,0,0,1,0,1,2456,3
168,"Job description:

Responsibilities:
Perform ETL with massive data from multiple applications and 300 M+ customers
Architect, design and evaluate novel approaches for handling high-volume real-time data streams in an inferencing environment
Own the development, training, optimizing, and deployment of machine learning systems
Develop measurement and feedback systems at web scale to improve the selection of features and/or algorithm design
Qualifications:
Strong software development skills (+3 years working experience), with proficiency in Python or Scala preferred
Experience in building ETL pipelines to perform feature engineering on large-scale dataset using Big Data technologies such as Spark
Ability to explain and present analyses and machine learning concepts to a broad technical audience
Ability to initiate and drive projects to completion with minimal guidance
Knowledge in advanced data structures and can use them to solve problems
You have a Masters degree or equivalent in Computer Science, Engineering, Mathematics or related field
Working knowledge of PyTorch, Tensorflow or other similar frameworks is a plus
Creative, collaborative, & product focused
Job #43632",3.6,Tundra,Toronto,"Toronto, Canada",201 to 500 employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,96.0,16,machine learning engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,1185,0
169,"Our Telco client in Edmonton is in need of a Data Analyst for an initial 5 month contract.

Responsibilities
Provide data analysis and standard reporting support, which includes the ability to extract data from various source systems and data stores by performing light business coding (SQL, VBA, Unix, etc.) and system parameter setting, perform ad-hoc queries and develop/automate financial/statistical models using a variety of software applications (Excel, Access, etc.). Perform impact analysis on proposed changes evaluating potential impacts on data, applications, and reporting and effectively communicating potential risks/effects to supported business customer base. Ability to interface with management, users, and information technology professionals to solve complex business problems.

Must to have skills:
3+ years experience extracting data from various source systems and data stores by performing light business coding (SQL, VBA, Unix, etc.) and system parameter setting,
Perform ad-hoc queries and develop/automate financial/statistical models using a variety of software applications (Excel, Access, etc.).
Perform impact analysis on proposed changes evaluating potential impacts on data, applications, and reporting and effectively communicating potential risks/effects to supported business customer base.
Ability to interface with management, users, and information technology professionals to solve complex business problems.",3.7,emergiTEL Inc.,Edmonton,"Richmond Hill, Canada",201 to 500 employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (CAD),"Veritaaq, TEKsystems, Procom",96.0,14,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1449,3
170,"Who are we?

SkyHive Technologies is a Vancouver-based artificial intelligence company that invented and
commercialized a methodology called quantum labour analysis, which is the application of
artificial intelligence to analyze a workforce or labour market at its most granular level. Its core
technology applies natural language processing to process millions of supply, demand and
training data points to determine real-time job-level labour market activity. It then uses
proprietary machine learning methods to extract technical skills, soft skills, capabilities,
methodologies, tools, and technologies from all job data. Data is then fed into a proprietary
neural network that serves as the world’s first and only real-time, “live-streamed” job taxonomy
and skills ontology, capturing labour market movements in real-time and at their most granular
level.

Recognized as a top startup by Forbes, Startup Grind, and C100, SkyHive is an award-winning AI
technology that deepens our understanding of labour markets, workforces and individuals,
enabling new ways of acquiring, developing, and engaging talent.
Established in 2017 with the mission of tackling global poverty and social inequality, SkyHive
aims to utilize its exponential technology to stimulate economic empowerment and lifelong
learning; ultimately fostering a stronger, more prepared, and more confident workforce to
welcome a brighter tomorrow.

What do we offer?
Opportunity to get your foot in the door of a fast-growing tech company
Collaborative team environment
Comprehensive health benefits package (nothing comes off your cheque)
Three weeks’ paid vacation to start, paid holidays and birthday leave!
Stock options & gainsharing plan
Social Impact Organization with Certified B-Corp Status
Paid & unpaid volunteer time off
Charitable donation matching program to support your favorite charity.
Opportunity to explore other departments as training and career continues.
Professional development assistance program
Beautiful office in A1 location (Views, view, views) / Remote work
Numerous employee appreciation events throughout the year
*

Who you are: *

You have in-depth knowledge and experience in NLP that you have applied to solve real world
problems in the industry. You are passionate about state-of-the-art technologies and are
excited by the application of theory to real-world problems. You keep up to date with the latest
developments in the field and look for ways to apply them to your current work/role. You find
pragmatic solutions that solve problems in a timely manner.

Qualifications:
Post-graduate or Ph.D. in Computer Science or Machine Learning related degree with a focus on NLP; or equivalent work experience in the field
3+ years NLP applied experience, preferably experience applying NLP research to real world problems in the industry
Experience in building production ML models and understanding of inference challenges at scale
Good theoretical grounding in core machine learning concepts and techniques
Ability to perform comprehensive literature reviews and provide critical feedback on state-of-the-art solutions and how they may fit different operating constraints
Experience with a number of ML techniques and frameworks, e.g., data discretization, normalization, sampling, linear regression, decision trees, SVMs, deep neural networks, etc.
Expertise in one or more of the following domains: recommender systems, information retrieval, information extraction (POS, N/E tagging with HMMs/CRF etc), feature extraction, text classification, etc
Experience with one or more deep learning software frameworks such as Tensorflow and PyTorch
Experience writing complex Python code
Produce deliverable results and see them through from development to production
Nice to haves:
Experience with large-scale systems and data, e.g. Hadoop, distributed systems
Publications in top conferences/journals such as EMNLP, ACL, COLING, TACL, CoNLL,
NeurIPs, ICML, ICASSP, Interspeech
Job Type: Full-time

Salary: $80,000.00 - $120,000.00 per year

Benefits:
Casual Dress
Company Events
Dental Care
Disability Insurance
Employee Stock Purchase Plan
Extended Health Care
Flexible Schedule
Life Insurance
On-site Gym
On-site Parking
Paid Time Off
Tuition Reimbursement
Vision Care
Work From Home
Schedule:
8 Hour Shift
Monday to Friday
Experience:
Natural Language Processing: 3 years (Required)
Python: 3 years (Required)
Location:
Vancouver, BC (Preferred)
Work remotely:
Temporarily due to COVID-19",4.9,SkyHive Technologies Inc.,Vancouver,"Vancouver, Canada",1 to 50 employees,2017,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,79.0,3,data scientist,senior,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,4493,0
171,"Colleagues you’ll love.
A dynamic and collaborative workplace where you can contribute to our story.
An access to over 6,000 free courses for your continuous development and career growth.
Comprehensive benefits from day one.

This is the #YPLife and what working at YP is all about.

What is a Marketing Insights Data Analyst at Yellow Pages?

Want to contribute to the development and prosperity of local small and medium-sized businesses? Welcome to Yellow Pages! As a Google Premium Partner and Facebook Marketing Partner, Yellow Pages is a leader in digital marketing for companies across Canada.

The Marketing insights data analyst is required to develop Marketing Analysis solutions and strategies that provide business insights, improve opportunity identification, and drive monetization to the business. She/He will be responsible for the production, management and delivery of key ad hoc reports to support the growth of the various aspects of the business. The incumbent individual is responsible for extracting, cleaning and presenting data to support Marketing and Sales initiatives.

Responsibilities:

ETL
Automation of Data extraction, Integration, cleaning and preparations to improve productivity and data accuracy.
Analytics
Responsible to extract and transform data into compelling information for management discussion.
Analyze, enhance and manage key performance indicators (KPIs) through effective dashboards on a weekly/monthly/quarterly basis.
Provide ad hoc analytics support for Marketing & Product teams.
Deliver crucial insight and recommendations that impact real-time results.
Reporting
Ownership of creation and distribution of current and future interactive reporting dashboard needs for various business owners across all products & Sales teams.
Why should you apply for this Marketing Insights Data Analyst position?
We bet on everyone potential rather than pressure management
We offer training, a flexible benefits package on your first day, a casual environment where you can wear jeans
We distinguish the most beautiful achievements
We propose to our employees to advance in their career according to their expectations
We work in the amazing Nordelec building which includes a gym
Work schedule from Monday to Friday daytime
What do you need to be a Marketing Insights Data Analyst at Yellow Pages?

Education, Experience and Technical skills:
University degree in Maths/Stats, business, marketing, computer science.
Strong analytical skills utilizing SQL, Excel, Stored Procedures.
BI tools and Visualization Tableau, PowerBI , PowerPoint.
Experience dealing with large & diverse Data Sources (Structured & none-Structured data).
Strong process improvement and automation skills.
Big Plus points: Python/R, Google Cloud, AWS.
Strong interpersonal and communication skills.
Soft Skills and Competencies:
A positive attitude and strong initiative.
A self-starter with ability to work independently.
Ability to interpret and make sound recommendations.
Excellent team and interpersonal skills.
Organizational skills and attention to detail.
Ability in managing multiple tasks.
You are ready to join the Yellow Pages adventure as a Marketing Insights Data Analyst? Send us your resume right now!

About Yellow Pages

We’ve been in the game since 1908 and we continue to transform to offer our 229 000 clients the best possible products and services. We foster business relationships between Canadian small-to-medium businesses and their prospective customers. We do this by providing tailored, locally-relevant digital media and marketing solutions designed with both in mind. Over 73% of our revenue is generated by digital solutions.",3.1,Yellow Pages,Toronto,"Montreal, Canada",501 to 1000 employees,1908,Company - Public,Publishing,Media,$1 to $2 billion (CAD),"Amazon, Yelp, Craigslist",79.0,112,data analyst,na,0,1,1,1,0,1,0,0,0,1,0,0,0,0,0,3673,3
172,"MACHINE LEARNING DEVELOPER – VISION SYSTEMS

About Visual Defence

Founded in 2000, Visual Defence Inc. (VDI) (https://www.visualdefence.com) provides integrated software-centric solutions in the areas of artificial intelligence and security. The company is headquartered in Richmond Hill, Ontario and provides services and products to customers world-wide.

Position

The Machine Learning Developer will work with Visual Defence’s Research and Development team under the guidance of the company’s Director of Research and Development. The Machine Learning Developer will help to develop, fine-tune and improve on Visual Defence’s artificial intelligence products and platforms. Visual Defence’s particular use cases of machine learning revolves around images and computer vision systems.

Job Description

§ Actively participate in the development of Visual Defence’s machine learning platform Inferware (https://www.vidiai.com) and its use cases.

§ Review and improve platform architecture, functionalities, and workflows.

§ Review and optimize models architectures and settings.

§ Fine-tune models generated for production use cases.

§ Knowledge transfer and mentorship to other team-mates.

Qualifications & Competencies

§ Strong, hands-on experience working with Tensorflow

§ Strong, hands-on experience working with Python.

§ Experience with machine learning pertaining to images.

§ Experience with object detection, classification and segmentation applications.

§ Strong verbal and written communication skills.

§ Strong organizational skills, with the ability to meet tight deadlines.

§ Excellent attention to detail and interpersonal skills.

§ Understanding of programming principals.

§ Knowledge of Windows operating systems and domain environments an asset.

§ Self-starter and demonstrate effective time management.

§ Takes rational approach.

§ Fast learner.

Education

§ Received PhD in an engineering, computer science or equivalent program within the last five years from an accredited, publicly-funded Ontario university

Reference ID: Machine Learning Developer

Job Type: Full-time

Benefits:
Dental Care
Extended Health Care
Vision Care
Experience:
Machine Learning: 3 years (Required)
Private Sector: 1 year (Required)
Python: 3 years (Required)
Education:
Post-Doctorate (Required)
Work remotely:
No",2.9,Visual Defence Inc,Richmond Hill,"Richmond Hill, Canada",51 to 200 employees,-1,Company - Private,Security Services,Business Services,$25 to $50 million (CAD),-1,79.0,-1,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,2336,0
173,"Junior GIS Data Analyst
Mississauga
Reference ID: 232072411

Sitechs is partnering with one of our Fortune 500 clients to search for a passionate, dedicated and driven Junior GIS Data Analyst. It is a contract, full-time position.

Your primary duties will be to support an advanced GIS and analytics team with your expertise in GIS and data, including ETL, Digitizing, Spatial Analysis, Validation, and Development. The project will have broad implications in the Canadian tech markets and have a direct impact on consumers across the country. If you’re looking for a challenge in a fast-paced environment with tight deadlines and enterprise data infrastructure, Sitechs welcomes your application.

Responsibilities:
· Digitize Geo-spatial Assets, as well as locate and integrate new Geo-spatial assets
· Support the design of large-scale maps as required
· Support the maintenance, storage and retrieval of assets used as components of geo-spatial data
· Integrate GIS data with other data sources and platforms to improve analysis
· Perform ETL processes on a daily basis
· Review and contribute to existing code / query base
· Write high-performance queries to work efficiently with massive datasets
· Perform data validation, cleaning, and QA to ensure database accuracy
· Collaborate with cross-functional teams to optimize outputs and results
· Support other project team initiatives, including business operations and ad-hoc requests as required

Skills Required:
· Degree/Diploma in GIS, Geospatial Management, Geographic Analysis, Spatial Analysis, Geography, Engineering, Geomatics, Math, Computer Science, or a related discipline
· 1-2 years of experience in MySQL or SQL Server
· 1-2 years of experience in using ArcGIS
· Proficiency with joins, subqueries, pattern matching keywords, advanced functions etc.
· Experience working with and developing triggers, stored procedures and functions
· Working knowledge of geospatial queries
· Ability to quickly learn new technologies in a fast-paced environment
· A dedicated work area and relevant equipment are strongly preferred for this position

We are an equal opportunity organization, and we actively promote diverse work environment and encourage applications from all persons. If you are interested, please submit your application today in PDF form.

Job Types: Full-time, Contract

Work remotely:
Temporarily due to COVID-19",3.9,Sitechs.Inc,Mississauga,"Brisbane, Australia",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,79.0,-1,data analyst,junior,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2392,0
174,"Position

OpsGuru is a global engineering and consulting group. We are experts in the container ecosystem, data processing and analytics, and cloud-native technologies. Our team is formed by network, data, security, DevOps specialists and application developers. OpsGuru empowers customers with technology to solve their business problems and provide the tools to assure success in their digital transformation.

As a Data Engineer, you will be part of the OpsGuru professional services team architecting, designing, automating, and deploying production-grade data services and flows on behalf of our customers to a variety of public clouds such as AWS, Google Cloud and Azure.

Daily Responsibilities
Building complex ETL code using technologies such as; Spark, Nifi, Glue
Building real-time streaming solutions
Developing code using Python, Scala, R languages
Creating complex data solutions and build data pipelines
Establishing credibility and build impactful relationships with our customers
Qualification & Skills
5+ years’ design & implementation experience with distributed applications
3+ years’ of experience in production database architectures and data pipeline development
Demonstrated knowledge of software development tools and methodologies
Experience with Open Source Big Data projects such as; Cassandra, ElasticSearch, Spark, Flink, Kafka.
Public cloud experience (AWS, Google Cloud or Azure)
Excellent communication skills with an ability to right level conversations
Technical degree preferable; Computer Science or Math background desired
Demonstrated ability to adapt to new technologies and learn quickly
Job Types: Full-time, Contract

Benefits:
Work From Home
Schedule:
8 Hour Shift
Monday to Friday
Experience:
Knowledge of software development tools and methodologies: 2 years (Preferred)
Cassandra: 1 year (Preferred)
Kafka: 1 year (Preferred)
Public Clouds (AWS, Azure or Google Cloud): 2 years (Preferred)
Spark: 1 year (Preferred)
ElasticSearch: 1 year (Preferred)
OpenSource: 1 year (Preferred)
Big Data: 1 year (Preferred)
database architectures and data pipeline development: 3 years (Preferred)
Flink: 1 year (Preferred)
Work remotely:
Yes",-1.0,OpsG,Vancouver,"Vancouver, Canada",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,$10 to $25 million (CAD),-1,79.0,2,data engineer,na,1,1,0,0,0,0,1,0,1,1,0,0,0,0,0,2175,0
175,"Summary

The Data (bio)Informatics Science and Engineering (DISE) team at Decipher Biosciences is a passionate group of scientists and software engineers striving to use the best science and engineering knowledge to develop data pipelines and software that make genomic data actionable to cancer patients and their doctors. We develop and deploy machine learning models based whole transcriptome gene expression data to reveal new insights in cancer biology. We also develop software/apps that facilitates better data visualization and interpretation for colleagues, physicians, and patients. We are responsible for maintaining and analyzing one of the largest proprietary transcriptomic data sets in oncology.

As a data scientist, you will work closely with a team of research and production professionals. You will be a key member in preparing, interpreting and analyzing business, genomic and clinical data, providing analysis support to our colleagues and our external partners. You will also participate in our data-related software design, development, and maintenance. This role requires a broad knowledge of cancer biology, oncology, bioinformatics, statistics, and programming, paired with effective communication skills, a strong sense of diligence, and timeliness.

Duties and Tasks
Perform data analysis that contributes to the process improvement of Decipher products
Contribute the design of experiments focused on assay improvement.
Conduct data analysis in support of biopharma clinical trials and collaborations
Support development of novel genomic signatures
Design and implement data reports and dashboards
Contribute to manuscript drafting for peer-reviewed journals and patent filings
Support and assist colleagues and external collaborators in data preparation and analysis
Understanding, maintaining, and improving various databases and schema
Contribute to the maintenance and improvement of the data processing pipelines, automating common data analysis routines into software packages or applications.
Contribute to the research and development of applying latest developments of AI technologies to the Decipher data.
Qualifications:
Graduate degree from a quantitative field with strong programming experience (data science, statistics, bioinformatics, or equivalent).
Proven experience in analysis and interpretation of large-scale gene expression data (microarray, sequencing).
1 year + experience in data science and quantitative data analysis.
1 year + experience in working with cloud platform like GCP.
Familiar with a Linux environment and shell scripting. Experience working with source control tools (Git) in a collaborative programming environment.
Knowledge in cancer biology and genomics. Work/research experience with public genomic data platforms (GEO, CBioPortal, MSigDB, etc or equivalent) is a plus.
Extensive experience of working with R or Python. Experience of building and testing customized R packages.
Software engineering experience in a programming language (GO and Javascript is preferred) is a plus.
Experience in performing complex data analysis on large volumes of data and present findings to collaborators.
Experience in drafting and publishing scientific research papers and addressing comments and feedbacks from collaborators and reviewers.
Strong interpersonal and communication skills (both written and verbal); ability to communicate with people in a wide variety of areas and at various levels from technical specialists to executives
Ability to quickly and efficiently adapt to new concepts and collaborate with cross-function teams and business units.
Critical thinking
Curiosity and eager to learn.
Powered by JazzHR",-1.0,Decipher Bioscien,Vancouver,-1,-1,-1,-1,-1,-1,-1,-1,79.0,-1,data engineer,na,1,1,0,0,0,0,0,0,0,0,0,0,1,0,1,3685,0
176,"Share this job

Location

Montreal
Department

Data & Analytics
Type

full-time
Requisition ID

6921

Apply now

Role description


At Unity Technologies, we believe that the world is a better place with more creators. The Unity Engine is a premier platform for a variety of different 2D and 3D real time interactive media experiences across multiple platforms. From the business of gaming to Film, Animation and Visual Effects and other cutting-edge AR/VR interactive experiences and Industrial Simulations. At DeltaDNA (a division of Unity Technologies) we provide services into the games industry, helping developers and publishers of games to engage with their player base in greater detail. Using our innovative analytical tools to understand player behaviour our clients can then create the best ingame offers and perks. These tools help to create a better all round gaming experience for gamers which in turn helps to drive commercial success. DeltaDNA is a part of Unity Monetization, that specifically, enables developers to grow a successful business around their content through advertising, in-app purchase, and services that optimize player lifetime value to monetize games and other mobile applications.

As Insight Consulting Lead you will lead a team of data scientists and game designers that work with clients to help them gather insights on player experiences to make their games more successful. In addition you will work with marketing, clients partners and product colleagues to promote best practices across the industry and help our clients improve the sophistication of their player management.

Responsibilities
Oversee the execution and completion of insight consulting projects
Manage staff responsible for project deliver, serves as a mentor to team members for technical and consulting skills and ensure high standards of outputs
Provide oversight on project profitability, work prioritization and labor planning
Provide expert pre-sales support to Client Partners and content ideas for marketing on industry trends and best practices
Support platform R&D to embed best practices into our technology solutions
Perform statistical analysis to reveal robust relationships between behaviors and key outcomes like player churn and spending.
Liaising with other analysts and the design team to produce and implement data-driven recommendations to improve game performance and deliver project results in the form of both written reports and client presentations.
Requirements
Experience in an analytic role
Experience with modern relational databases (e.g. Redshift, Vertica, etc) and SQL
Statistical computing in R, Python or similar
Proven consulting experience
Bonus points
Experience of Tableau
Looker Software Experience
An interest in games and basic understanding of the revenue models used in the industry (e.g. premium pricing, micro-transactions, free to play, etc
Excellent verbal and written communication skills including the ability to communicate insights passionately to clients
About Unity Technologies

Unity is the world’s leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity’s platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company’s 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com.

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

Chez Unity Technologies, nous pensons que le monde se porte mieux avec plus de créateurs. Le moteur Unity constitue une plateforme privilégiée pour une grande variété d’expériences interactives 2D et 3D en temps réel sur de multiples plateformes, de l’industrie du jeu vidéo et ses animations aux effets spéciaux du cinéma, en passant par d’autres expériences interactives RA/RV de pointe et les simulations industrielles. DeltaDNA est une division de Unity Technologies qui propose des prestations de services dans le secteur des jeux vidéo, en aidant les développeurs et les éditeurs à établir un dialogue plus fructueux avec leurs joueurs. Grâce à nos outils d’analyse innovants destinés à comprendre le comportement des joueurs, nos clients peuvent ensuite proposer des offres et des avantages de qualité dans le jeu. Grâce à nos outils d’analyse innovants, nos clients sont en mesure de créer une meilleure expérience globale pour les joueurs, contribuant ainsi à leur succès commercial. DeltaDNA fait partie de l’équipe de monétisation de Unity, qui permet aux développeurs de monétiser les jeux et autres applications mobiles pour générer une activité commerciale fructueuse autour de leur contenu au moyen de la publicité, des achats intégrés et des services visant à optimiser la valeur du joueur tout au long de son cycle de vie.

En tant que responsable du service de conseil, vous dirigerez une équipe de spécialistes des données et de concepteurs de jeux qui travailleront avec les clients pour les aider à recueillir des informations sur les expériences des joueurs, dans le but de renforcer le succès de leurs jeux. Par ailleurs, vous travaillerez avec les services marketing, les clients partenaires et les collègues spécialistes des produits pour promouvoir les pratiques exemplaires dans l’ensemble du secteur et aider nos clients à perfectionner la gestion de leurs joueurs.

Responsabilités
Superviser l’exécution et l’achèvement des projets de conseil en matière de connaissances
Gérer le personnel responsable de l’exécution des projets, faire office de tuteur auprès des membres de l’équipe en ce qui concerne les compétences techniques et garantir des résultats de grande qualité
Superviser la rentabilité des projets, la hiérarchisation des travaux et la planification du travail
Fournir un soutien d’avant-vente spécialisé aux clients partenaires et proposer des idées de contenu marketing sur les tendances et les pratiques exemplaires du secteur
Soutenir la recherche et le développement de la plateforme pour intégrer les pratiques exemplaires dans nos solutions technologiques
Procéder à une analyse statistique afin de déterminer les liens étroits entre les comportements des joueurs et les principaux résultats observés, notamment la rotation des joueurs et leurs dépenses
Collaborer avec d’autres analystes et l’équipe de conception pour formuler et appliquer des recommandations fondées sur les données, dans le but d’améliorer les performances du jeu et produire les résultats des projets sous forme de rapports écrits et de présentations aux clients
Exigences
Expérience dans un poste à caractère analytique
Expérience avec les bases de données relationnelles modernes (par exemple Redshift, Vertica, etc.) et SQL
Calcul statistique (R, Python ou similaire)
Expérience avérée en matière d’expertise-conseil
Atouts
Expérience avec Tableau
Expérience avec Looker Software
Un intérêt pour les jeux et des connaissances de base sur les modèles de revenus utilisés dans l’industrie (par exemple, tarification premium, microtransactions, jeu gratuit, etc.)
Excellentes aptitudes à la communication orale et écrite, y compris une capacité à communiquer les idées aux clients avec enthousiasme
À propos de Unity Technologies

Unity est la plateforme la plus utilisée au monde pour la création et l'exécution interactive de contenu 3D en temps réel (RT3D). Des créateurs, notamment des développeurs de jeux vidéo, des artistes, architectes, concepteurs automobiles et cinéastes, utilisent Unity pour donner vie à ce qu'ils ont imaginé. La plateforme de Unity offre un ensemble complet de solutions logicielles pour créer, exécuter et monétiser du contenu interactif 2D et 3D en temps réel pour les téléphones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de réalité augmentée et de réalité virtuelle.

Notre équipe de plus de 1400 personnes assignées à la recherche et au développement fait en sorte que Unity soit à l'avant-garde du développement et assure un soutien optimal pour les plus récentes technologies et plateformes. Les applications développées par les créateurs au sein de Unity ont été téléchargées plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d'appareils uniques. Pour en savoir davantage, visitez le site www.unity.com.

Unity est un employeur axé sur l’égalité qui s’engage à créer un environnement inclusif, innovateur et ce avec les meilleurs talents. Nous offrons des opportunités d’emploi qui ne tiennent pas compte de l’âge, de l’ethnicité, de la religion, des limitations fonctionnelles, du sexe, de l’identité sexuelle ou d’un tout autre statut protégé conformément à la loi. S'il y a des préparatifs que nous pouvons faire pour vous aider à avoir une expérience d'entrevue confortable et positive, n’hésitez pas à nous en faire part.

Les chasseurs de tête et les agences de recrutement ne peuvent pas soumettre un résumé/CV directement sur notre site web ou à un de nos gestionnaires. Nous n’acceptons pas d’être spontanément sollicités par un chasseur de tête et ou une agence; une entente devra être signé entre les deux partis.

#LI-JS1 #SEN",4.9,Unity Technologies,Montreal,"San Francisco, CA",1001 to 5000 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Epic Games, Electronic Arts, Zynga",79.0,15,data analyst,senior,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,10366,3
177,"We’re revolutionizing the way humanity eats, and there’s a lot of room for optimization and growth. That’s where you come in. Your ingenuity will help us continue to drive innovation, making an impact on the reliability, performance, and scalability of Skip’s industry-leading technology.

Think you have what it takes to join an elite team of software developers, engineers, and data scientists? If you want to make your mark on a national brand’s industry-leading technology, Skip’s Engineering Team is the place for you. They drive the innovation of Skip’s platform by improving the reliability, performance, and scalability of the network. GPS tracking, real-time order processing, scheduling, and balancing are just a few of the pieces the Engineering Team integrates into Skip’s world-class service.

What’s On Your Plate:

As a member of our Data team, you will be responsible for the design and implementation of software for systems that power Skip’s Business Intelligence and Data Warehouse. Your experience with cloud technologies and big data provides you with the background to quickly implement changes. Your experience in data management and SQL allows you to contribute to the expanding expertise of the team and keep data components current as product feature change.

Recipe for Success:

Education:
Computer science, software engineering or related degrees
Experience:
Strong experience working with both batch and real-time ETL involving large data sets.
Strong hands-on experience with Python.
Experience in REST APIs is nice to have.
Experience working with AWS and/or Google Cloud Platform environments.
Experience working with MPP databases such as Redshift, Big Query, Teradata and/or columnar databases.
Familiarity with scheduling tools like Airflow.
Strong in Dimensional Modeling concepts.
Experience using version control software, such as Git.
Work well both independently and as part of a team. You will actively participate in design discussions and code reviews.
We are looking for people who:
Have a great attitude.
Thrive in a rapidly evolving environment.
Are eager to contribute to the growth and development of the team.
Work with an entrepreneurial sense of urgency.
Are receptive to feedback and challenging experiences.
Are actively involved in their ongoing personal growth and learning.
How We Work:
We take ownership of our work and work closely with our team.
We move quickly, take risks, and know how to manage the risks.
Regularly refactoring to improve our existing systems — technical debt isn’t an excuse.
Unit tests and code reviews are at our core — confidence in our pull request is the result.
We constantly push our Data technology, design, and architecture forward to meet new challenges.
We face challenges no one can predict — we meet them head-on as a team.
When we have an idea that serves a need, we run with it.
Our teams are kept tight and efficient.
Why work at Skip?

Picture this: you, dressed in your fave casual attire, amongst a team of friendly and passionate colleagues. You feel pride knowing your input and uniqueness are not only embraced but make an impact on a major Canadian company and its satisfied customers. As the company grows, so do you — you meet and surpass new challenges every day.

That’s just a small taste of what it’s like to work at one of Canada’s leading tech companies. If you’re hungry for opportunity, growth, and something meaningful in a dynamic, yet casual environment, we’d love to hear from you.

Note: All employees will be asked to sign a Consent for Disclosure of Personal Information in order to complete a background check. Job offers will be conditional upon results that the Company determines to be satisfactory.",3.3,SkipTheDishes,Calgary,"Winnipeg, Canada",201 to 500 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,79.0,7,data engineer,na,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,3724,0
178,"Toronto AI Lab: AI / Machine Learning Scientist
Location


Toronto, Ontario

Department (Org 2)


Advanced AI Lab E60018

Job Requisition

23481

Apply Now


Company:
LG Electronics R&D

Job Function:
Engineering

At LG, we make products and services that make lives better, easier and happier through increased functionality and fun. Put simply, we offer the latest innovations to make “Life Good” – from home appliances, consumer electronics, vehicle components and mobile communications to business innovations in digital signage, air conditioning, solar and LED lighting. As a global leader, we strive for greatness in product leadership, market leadership and people leadership to realize our growth strategies.

Talk about a mantra. Life’s Good with LG!

AI/Machine Learning Scientist – Toronto

LG is looking to push the boundaries of AI to build innovative product and service solutions to realize LG’s global vision for a connected world. As a part of this initiative, LG has set up an Advanced AI organization in North America centered in Silicon Valley. Further to this initiative, we are looking for passionate and talented AI / Machine Learning Scientists and Engineers for our Toronto AI Lab to work closely with the global AI labs.

You will work on advanced research to make core ML and RL algorithms faster, more accurate and more robust. You will design experiments, invent new algorithms, and create prototype implementations focusing on applications to a variety of challenging business problems in areas of IoT, Connected Home and On Device Computing. You will be encouraged to publish high quality papers and patents and collaborate with leading academia.

You will be based in our new offices in downtown Toronto and work alongside a multi-disciplinary team that includes ML/AI scientists, product managers and software developers to design and launch AI products and solutions that help predict, personalize and transform lifestyles of LG’s global footprint of devices and users.

Seniority will be commensurate with experience and accomplishments.

Principal Duties and Responsibilities
Research and develop advances to improve core AI/Machine Learning algorithms. The research focus includes (but is not limited to) the following:
Network optimization, parameter and hyper-parameter optimization, architecture search, network compression
Model adaptation and learning on the edge
Policy learning and adaptation in RL
Bayesian machine learning
Semi-supervised and unsupervised learning
Distributed learning
Read, understand, implement, and improve state-of-the-art papers in the above topics
Take ownership of projects and build proof-of-concepts (POCs)
Actively participate in the research and academic community by disseminating novel results in top conferences and journals
Stay up-to-date on developments in AI technologies and propose long term research plans
Requirements
PhD in Computer Science, Electrical Engineering, Statistics or related quantitative discipline with a focus on machine learning, optimization theory, or related areas
Strong publication record in machine learning and deep learning at top conferences and journals
A demonstrable track record of developing novel algorithms, solutions, and delivering/deploying prototypes/projects
Experience with deep learning frameworks (e.g., Keras, Tensorflow, Tensorlite, MxNet)
Software engineering experience in two or more of C/C++, Python, Scala, Java, R, Matlab
Experience working with edge-computing frameworks like, CoreML, Greengrass etc. preferred
Last, but not least, a sense of ambition and passion to change the world using AI and machine Learning",3.8,LG Electronics R&D,Toronto,"Englewood Cliffs, NJ",1001 to 5000 employees,1952,Subsidiary or Business Segment,Consumer Electronics & Appliance Shops,Retail,$10+ billion (CAD),"Samsung Electronics America, Panasonic, Whirlpool Corporation",79.0,68,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,3648,3
179,"Environmental Monitoring Networks Data Scientist
Research Officer 21R

This position is located in Victoria, BC. The following locations may also be considered, subject to Ministry operational requirements: Kamloops, Nanaimo, Prince George, Vancouver.
This is a temporary opportunity for approximately 2 years; this may be extended.
Board and lodging and relocation expenses do not apply for temporary opportunities.
An eligibility list may be established.

An opportunity to utilize your exceptional research expertise in the natural resource sector

The Ministry of Environment and Climate Change Strategy is responsible for protecting and enhancing the Province's natural environment. This includes providing timely information on climate change, groundwater, water quality and quantity in lakes and rivers, air quality, and providing systems to support environmental health reporting. The Environmental and Climate Monitoring Section [EMCS] is charged with providing open, scientifically-credible, comprehensive data and information on changes to climate, air, water and groundwater conditions across the Province.

The Environmental Monitoring Network Data Scientist provides specialist advice to Ministry decision makers, and technical and professional staff on the current and required composition of Environmental and Climate Monitoring networks [Hydrometeorological, Hydrological, Groundwater and Water Quality]. Specifically, this position will provide leadership in the field of data science, partnering with technical and policy partners, and other stakeholders to design, develop, and manage data science projects with the objective of informing and achieving the policy and operational objectives of government; and to oversee, design, and conduct detailed statistical analysis, and data visualizations.

For complete details about this opportunity, including accountabilities, please refer to the attached job profile. For specific position related enquiries, please contact Ted.Weick@gov.bc.ca. DO NOT SEND YOUR APPLICATION TO THIS EMAIL ADDRESS. Information and tips about how to complete your job application, including adding or editing your résumé and applying for jobs, are available at the following link: Your Job Application. If you still experience technical difficulties applying for a competition, please send an email to BCPSA.Hiring.Centre@gov.bc.ca, before the stated closing time, and we will respond as soon as possible to assist you.

The BC Public Service is committed to creating a diverse workplace to represent the population we serve and to better meet the needs of our citizens. Consider joining our team and being part of an innovative, inclusive and rewarding workplace.

With over 200 different occupations available in 280 communities across the province, we offer exciting opportunities for your career. Come, be a part of the BC Public Service, a Top 100 Employer that embraces diversity, health and career growth. For more information, please visit What the BC Public Service offers You.

NOTE: Applications will be accepted until 11:00 pm Pacific Time on the closing date of the competition.

JOB REQUIREMENTS:

To be considered for this position, your application must clearly demonstrate how you meet the education and experience as outlined below:

Degree/experience required:
Undergraduate degree in environmental science, geomatics, statistics, mathematics, geography or computer science, or related area with 3 years of experience in environmental monitoring network operations; or,
Graduate degree in environmental science, geomatics, statistics, mathematics, geography or computer science, or related area with 1 year of experience in environmental monitoring network operations.
Experience designing, implementing, interpreting, and communicating complex statistical and spatial analyses.
Experience identifying business problems and providing advice on business enhancements based on findings of data science projects.
Experience creating and delivering presentations for the purpose of decision making preferred.
Valid BC driver’s licence.
Preference may be given to candidates with one or more of the following:
Experience with monitoring technologies and applications in larger operational environmental data collection networks.
Experience creating and delivering presentations for the purpose of decision making.
Experience conducting redundancy/gap analysis for environmental monitoring networks.
Knowledge of, or experience with, Python and R statistical and spatial programming modules, ARC GIS or similar tools for analysis and data visualization.
Applicants selected to move forward in the hiring process may be assessed on the Knowledge, Skills, Abilities and Competencies as outlined in the attached Job Profile.

A Criminal Record Check [CRC] will be required.

APPLICATION REQUIREMENTS:

Cover Letter: NO - Please do not submit a cover letter as it will not be reviewed.

Résumé: YES - A résumé is required as part of your application; however, it may not be used for initial shortlisting purposes.

Questionnaire [Comprehensive]: YES - As part of the application process, you will be prompted to complete a comprehensive online questionnaire to demonstrate how you meet the job requirements listed in the job profile. Please allot approximately 60 minutes to complete the questionnaire.

IMPORTANT: Comprehensive questionnaire responses will be used to shortlist applicants against the job requirements. Please ensure you include all relevant information about your educational accomplishments and employment history, including job titles, start and end dates [month and year] of your employment, and your job related responsibilities, accountabilities and accomplishments. Ensure your questionnaire responses are complete as your résumé may not be used for initial shortlisting purposes.",3.8,Government of British Columbia,Victoria,"Victoria, Canada",10000+ employees,1858,Government,Government Agencies,Government,$10+ billion (CAD),-1,79.0,162,data scientist,na,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,5860,0
180,"Achievers delivers an Employee Success Platform™ that enables social recognition, which dramatically increases employee engagement and drives business success. Designed specifically to meet the needs of today’s workplace, it empowers employees to recognize each other in real time and aligns them to the goals of the company. With more than 5,000,000 annual recognitions, the Platform inspires brilliant performance in 110 countries. Visit us at www.achievers.com to learn more and join us in our mission to change the way the world works.

Why work with us?
We’re a fun-loving, passionate, and highly collaborative team
We believe in moving quickly, failing fast, and adapting to change
We’re committed to achieving technical excellence in everything we do
We value team work, learning from failure and innovation.
Why we'd want to work with you?
You have an undying passion for building world-class software
You’re positive thinking, solution focused and find opportunities instead of problems
You have superb technical chops, but you’re always striving to improve
You want to take ownership over your work and make challenging architecture decisions
You are ambitious and want to be involved in the strategic thinking of platform architecture

What would a typical day look like, you ask? Something like this:
Design, develop, and maintain the software and systems that drive our back-end systems
Extend our platform by researching and applying new technologies to solve business problems
Participate in multi-disciplinary projects with our applications and analytics teams
Contribute to our team’s growing set of development platforms, tools, and processes
Do you have what it takes? We will be responding to applicants that have:
B.Sc. or Masters (preferred) in Computer Science or related field
8+ years of relevant experience
Prior experience with microservices architecture
Experience with messaging systems, preferably Kafka or RabbitMQ
Experience with Restful API
Proficient in web frameworks and PHP as well as other server-side language such as Python, Ruby, Java, JavaScript/React etc.
Advanced knowledge of data structures and security practices
Excellent problem-solving abilities
About Achievers:
As Achievers employees, we are passionate about disruptive technology, welcome constant change, and understand the value of employee success in the workplace. We enjoy coming to work every day because we believe in our product and love our culture. Achievers is more than just a software company; we are industry leaders in the HR space.
Our headquarters are conveniently located in Liberty Village, close to bars, shops and restaurants and are highly accessible by TTC and GO Transit.
We have been recognized in numerous publications for our contributions to HR, for technical excellence and for our outstanding workplace culture:
Achievers is ranked as number 32 on the list of Top 50 Best Workplaces in Canada.
Achievers has been recognized on the 2020 list of Best Workplaces™ for Women in Canada
Achievers has been recognized on the 2020 list of Best Workplaces™ for Inclusion
Achievers has been named one of the Top 10 Employee Recognition Solution Providers Globally
Check out our platform in action here
Our employees are a diverse and inclusive team of passionate, hardworking individuals. Achievers is committed to creating an environment where our employees can do the best work of their lives. We encourage all qualified candidates to apply to join our A-Player family. Accommodations are available on request for candidates taking part in all aspects of the selection process.",4.4,Achievers,Toronto,"Toronto, Canada",201 to 500 employees,2002,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,79.0,18,data engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,3602,0
181,"CGI has an opportunity for an Engineer to join our team in Ottawa. Attributes that define our ideal candidates will include:

Passionate for turning disparate streams of data into organized and actionable analytics
programming acumen, competency in manipulating large volumes of data, and with a solid knowledge of a broad range of technologies for data processing and modeling
Up-to-date with the latest technology trends and have a strong desire to constantly learn
Love solving complex problems and have expertise in world-class data pipelines, from batch to real time implementations
Have demonstrated ability to navigate between the big-picture and implementation details
Highly detailed-oriented with exceptional organizational and follow-through skills
Self-directed and comfortable supporting the data needs of multiple teams and projects
Exceptional communication skills, with an ability to make advanced analytics concepts accessible and understandable to non-technical business users
Value collaboration and urgency; and have a passion for driving impact

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this changesupporting our clients digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com.

No unsolicited agency referrals please.

CGI is an equal opportunity employer. In addition, CGI is committed to providing accommodations for people with disabilities in accordance with provincial legislation. Please let us know if you require a reasonable accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.

Your future duties and responsibilities

Create analytical data infrastructure by gathering, processing, analyzing and structuring large volumes of data from many structured and unstructured data sources, at scale.
Design, develop and implement highly scalable, repeatable and secure data pipelines and transformation processes
Design and build transformation models and data flows for batch, real-time and complex event driven processes
Develop data ingest processes across a variety of third-party APIs, applications and file stores.
Ensure that appropriate controls are in place and all in-motion and at-rest data is secured at all times
Develop data catalogs and data validation scripts to ensure data accuracy, clarity and correctness of key business metrics
Identify and correct data quality issues, performing root cause analysis on internal and external data to answer specific business questions and identify opportunities for improvement
Employ proper data governance to ensure data security and integrity
Research and make recommendations for new data management technologies and software engineering practices. Collaborate on decisions around the use of new tools and practices
Provide guidance to a customer and project team with respect to data requirements, data gaps and level of effort required to deliver a solution
Assist in the development and delivery of pre and post sales POCs and proposals for client engagements
Produce and maintain support documentation and data dictionaries
Travel periodically in support of sales and delivery as needed

Required qualifications to be successful in this role

At least 2 years of experience working on data transformation, curation and integration for batch and near real-time in Cloud and on-prem environments
At least 2 years of hands-on experience working with Big Data technologies such as Spark, Cassandra, Hadoop and/or Hive. Working knowledge of message queuing, stream processing, and highly scalable big data data stores
2 years of experience using one of more data transformation and integration technologies such as Python, Scala, Spark, Spark-Streaming, Kafka Streams and traditional ETL/ELT tools such as DataStage and/or Informatica.
2 years of hands-on experience working with SQL and Non SQL databases such as Oracle, DB2, SQL Server, Postgres, MangoDB and/or CouchDB
Good understanding of microservices architecture and hands-on experience working with REST APIs
At least 1 year of experience working on predictive analytics and data mining projects
Self-directed and demonstrable problem-solving skills
Knowledge of modern software development techniques and methodologies
Knowledge and practice of secure software development processes
Excellent written and verbal communication skills. Ability to communicate effectively with a broad range of constituents
Ability to handle multiple priorities and deadlines
Bachelors degree or diploma in mathematics, informatics, statistics, computer science or information systems (or equivalent combination of skill and experience)",3.5,CGI,Ottawa,"Montreal, Canada",10000+ employees,1976,Company - Public,Consulting,Business Services,$10+ billion (CAD),"IBM, Accenture, Booz Allen Hamilton",79.0,44,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,1,5188,3
182,"What EA Sports does:

EA Sports is one of the leading sports entertainment brands in the world with top-selling video game franchises, award-winning interactive technology, and cross-platform digital experiences. We create connected experiences that ignite the emotion of sports through industry-leading video games including FIFA soccer, Madden NFL football, NHL hockey, NBA LIVE basketball, UFC, and more.

What you'll do on our team:

As a Senior Analyst working within the FIFA Analytics team, your main focus will be on FIFA's Ultimate Team mode and its in-game economy, working primarily with the live content group along with a diverse set of colleagues in analytics around the world. We're looking for a thoughtful, curious person with a passion for diving into data to uncover insights and understand how our players are engaging with Ultimate Team. Your analysis will help ensure that its economy remains well-balanced as new content is continually introduced into the in-game market, so that players of all types can find success and enjoyment in the mode. Youll not only be a data explorer and modeler, but also a storyteller and influencer, driving insights that spur bold decisions for FUT's development team.

Examples of projects you may work on include: establishing the key set of metrics that the team will use to assess the ongoing health of the in-game economy; performing analysis to determine what's driving those metrics into healthy vs. unhealthy states; creating models to predict the value of new content being introduced into the in-game market, and the impact that its introduction will have on Ultimate Team and its players.

What a Senior Analyst will do on our team:
Model trends in our data to predict the ways in which new content and campaigns will affect the in-game economy, its performance, and our players.
Develop strategic insights to help our partners make informed decisions about Ultimate Team campaign and content planning, execution and monitoring.
Receive questions from our partners, determine the best ways that our data can help answer them, and provide those insights through dashboards, reports, or presentations.
Explore player behaviour patterns in our data to identify opportunities to improve the player experience.
Present analyses and findings to our partners in a clear, understandable, and actionable way.
Become an expert in live content strategies and campaigns.
What we're looking for:
A bachelors degree in Statistics, Economics, Data Science, Analytics, Mathematics, or a related field at a minimum; a masters degree in one of these fields is a significant plus
5+ years of experience in an analytics role using data to help guide decisions, preferably in a consumer products-oriented industry (e.g. gaming, e-commerce); experience with practical applications of economic analysis is a significant plus
Excellent SQL querying skills
Proficiency analyzing large datasets in both a spreadsheet program (e.g. Excel, Sheets) and in a programmatic analysis tool (e.g. Python, R)
Experience in practical applications of statistical modeling (e.g. multivariate regression, predictive modeling, clustering, machine learning)
Familiarity with use of data visualization applications (e.g. Tableau, R Shiny)
Passion for games or sports",3.9,Electronic Arts,Vancouver,"Redwood City, CA",5001 to 10000 employees,1982,Company - Public,Video Games,Media,$2 to $5 billion (CAD),"Riot Games, Google, Activision Blizzard",79.0,38,data analyst,senior,1,1,0,1,0,1,0,0,0,0,0,0,1,0,1,3289,3
183,"Fullscript is currently seeking a Marketing Data Analyst to help us in the application and execution of analytics to drive our marketing strategy and optimize our performance. We want employees to challenge ideas, engage in technological debates, and to do the best work of their careers. If you share our values, we’d be excited to talk with you!

What’s Fullscript?

Fullscript is the ultimate, free platform for those who want to do wellness the right way — the personal way — from anywhere. This virtual dispensary has the most comprehensive catalog, integrates with EHRs, automates refill reminders, and offers evidence-based educational content. It’s an always-accessible solution that helps people get better.

How does it work?

A practitioner writes a prescription and sends it to their patient’s electronic device. The patient then purchases the products from the practitioner’s virtual dispensary, and we ship them to the patient’s front door. It’s simple but game-changing for practitioners, now freed from the hassle of inventory, supplier management, and more.

We complement our technology with industry-leading decision support, pulling out all the stops to be indispensable to practitioners. We publish a steady stream of evidence-based resources, medically-reviewed protocols, ingredient reviews, and more to support practitioners in providing patients the best possible treatment. Practitioners give more than they get, so we use our platform to give back.

What’s the role?

The Data team is a key strategic partner at Fullscript, responsible for providing reporting and analytical support for all internal functions to drive effective planning and decision making. Reporting to the Director of Data Analytics, the Data Analyst will be embedded in our Marketing team, performing in-depth exploration and analysis of marketing data in order to guide goals, improve processes and drive recommendations.

This position is located in our Ottawa, Canada office.

What you’ll do
Proactively identify opportunities for tracking and testing of marketing activities (lead generation, campaigns, ads, content, events) with the goal of optimizing performance.
Track and report on project and initiative success by setting appropriate goals, monitoring performance and creating and executing comprehensive analysis plans.
Translate business requirements into analytical projects to identify trends, solve challenging problems and deliver insights.
Present reports and analytical results to key business stakeholders, effectively communicating key findings and recommendations.
Optimize data collection and funnel attribution to broaden the understanding of our lead generation engine and enable opportunities for efficiency and growth.
Champion innovative analytical ideas that enable new opportunities.
What you bring to the team
Minimum of Bachelor’s Degree in a quantitative, analytical or similar field with 2+ years of relevant experience successfully working in an analytical role using relational databases.
Strong, hands-on experience with SQL, data modelling, dashboarding and reporting, with the ability to interpret findings and produce meaningful insights.
Experience with attribution modelling and funnel metrics.
Experience with digital data capture, tagging and the use of digital analytics tools (e.g. Adobe Analytics, Google Analytics, etc.).
Creative problem-solving skills with a passion for uncovering strategic opportunities and solving business problems.
Experience with predictive modelling using analytics packages in languages like Python.
Proven ability to work independently in a fast-paced environment, managing competing priorities on multiple simultaneous projects.
Demonstrated attention to detail.
Strong written and verbal communication skills with the ability to effectively communicate complex ideas and concepts to business users.
Bonus if you have
Experience with a marketing automation tool such as Marketo.
Experience in B2B or SaaS, working in a high-growth environment.
Interest or experience in Health Tech, Integrative Medicine, or supplements.
What do we offer?

We offer competitive pay, a diverse benefits package, a training budget, a discount on supplements, and generous paid time off.

Our Wherever You Work Well policy lets you choose your own office — whether that’s in-person, at home, or both, it’s totally up to you. Many of us organize clubs and get-togethers to meet like-minded people and to make our company a fun place to work. We also believe pups make life better, which means some of our locations are dog-friendly.

What now?

By working at Fullscript, you choose to work in a community of intelligent, diverse, authentic, and talented people. We aren’t afraid to get our hands dirty – or medical-grade clean, that is – to get the job done. If you decide to join the team, you’ll get a chance to shape the future of our company and the integrative health industry.

If this sounds good, apply here. If you’re not sure if your experience matches this listing, apply anyway – we’d love to hear from you.

Want to learn more? Check us out at www.fullscript.com or find us on social media.

Fullscript is committed to diversity in its workforce and is proud to be an equal opportunity employer. We are excited to work with talented people, period. All employment decisions are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national or ethnic origin, gender, age, disability, sexual orientation, gender identity and/or expression, marital or civil status, political affiliation, family or parental status, or any other status protected by the laws or regulations in the jurisdictions in which we operate.

Our team handles a lot of sensitive health information, which means we require all candidates that receive and accept employment offers to complete a background check before being hired.

We are also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an email to accommodations@fullscript.com and let us know the nature of your request and your contact information.",4.7,Natural Partners Fullscript,Ottawa,"Ottawa, Canada",201 to 500 employees,2012,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,79.0,8,data analyst,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,6263,0
184,"StackAdapt is the no. 1 performing native advertising platform helping brands accelerate customer engagement and acquisition. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience.

Ranking the highest in customer satisfaction and performance by G2 Crowd in the DSP category for the fourth time, we're one of the fastest growing companies in Canada and ranks 6th in Deloitte's Technology Fast 50 ranking and 23rd in Fast 500 in North America.

We're looking to add a Data Engineer to our data team! This team works on solving complex problems for StackAdapt's digital advertising platform. You'll be working directly with our data scientists, data engineers, Director of Engineering and CTO on building pipelines and ad optimization models. With access to over 500,000 data sets per second, there's no shortage of data and problems to tackle.

Learn more about our engineering culture here: https://www.stackadapt.com/artificial-intelligence-in-advertising

Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU
We'll be responding to applicants that have:
Proven experience architecting scalable ETL / machine learning pipelines (advertising technology experience preferred but not required)
Strong experience with Apache Spark
Strong programming skills in Scala (Golang and Python is a plus)
Experience in NoSQL databases such as HBase and Aerospike
Experience with data warehouse technologies such as Amazon Redshift, Hive
Experience with AWS, ElasticMapReduce, S3 and EC2 in particular
Experience working with small to mid-size teams, and a rapid development process
Experience with Airflow or other job scheduling libraries is a plus
Understanding of machine learning algorithms
StackAdapters enjoy:
Highly competitive salary
Full benefits from League on day one of employment
Coverage and support of personal development initiatives (conferences, courses, etc)
Fully stocked kitchen with healthy (and some not so healthy) snacks
Monthly presentations from global business leaders and innovators
An awesome parental leave policy
A weekly $15 lunch credit via Ritual
Our weekly Friday social events (sometimes on our 4000sq. ft. outdoor patio)
Quarterly team events like escape rooms, bubble soccer, obstacle courses, indoor skydiving, boat cruises, the list goes on…


About StackAdapt

StackAdapt is a self-serve programmatic advertising platform used by North America’s most exceptional digital marketers. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience. Ad buyers plan, execute, and manage data-driven digital advertising campaigns across all devices, inventory and publisher partners. Ranking a high performer by G2 Crowd in the DSP category for four consecutive years, StackAdapt is also recognized as a LinkedIn Top Startup in 2019.

Our office is located at King and Sherbourne near Toronto's historic Distillery District and the St. Lawrence Market. Our Walk, Bike and Transit Score are all over 90.

We've been recognized for our high performing campaign conversion rates, award winning customer service, and innovation by numerous industry publications including:

6th Fastest on Deloitte Technology's Fast 50 In Canada
StackAdapt’s New Chrome Extension Tackles Recruitment Bias
G2 Crowd's Highest Performing Demand Side Platform
The Globe and Mail 2019 Canada’s Top Growing Companies
Startup 50: The Complete Ranking of Canada’s Top New Growth Companies


StackAdapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. We are an equal opportunity employer and we are happy to work with applicants requesting accommodation at any stage of the hiring process. We welcome and encourage anyone and everyone to apply.",4.1,StackAdapt,Toronto,"Toronto, Canada",51 to 200 employees,2013,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1,79.0,7,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,3872,0
185,"Job Description
Join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive decisions at every level of our organization. The insurance industry is undergoing a transformation and you get to be in the driver’s seat of this data-driven, technology revolution.

You will work on impactful projects that range from predicting customer life-time values and optimizing customer journeys to incorporating novel data sources for building cutting-edge pricing algorithms. You will leverage machine-learning algorithms to automate and predict claim outcomes and find new and innovative ways to impact our customers. This team is exploring the frontiers of the insurance business such as how to harness the data from connected homes and cars to deliver new types of products to customers.

As a senior data-scientist, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. You will propose machine-learning and statistical models for practical applications that impacts millions of customers. You will also mentor and guide your peers in novel approaches and provide peer review for their work. The team has already developed algorithms used in production systems and you will be part of the team that expands the scope of these algorithms. This is your chance to join the InsureTech revolution!

The insurance industry has entered a period of unprecedented change, disruption and rapid technological development. Aviva recognizes that in this rapidly changing environment building a distinctive capability in Data Science is critical - demonstrating this commitment through the development of our Data Science Practice. If you are passionate about Data Science and leveraging your analytical prowess to tackle business challenges, this role could be for you. We are embracing new technology and exploring new ways of working. With our constant advancement, you will be at the forefront of a fast-evolving field. These exciting roles are at the heart of a high-performing Data Science team that is transforming Aviva in the Digital age. Here, we are creating a long-lasting legacy and optimizing every customer’s experience.

What you need to succeed

As a senior data-scientist, you will need the following skills and experience to succeed in the role:
An educational background in computer-science or engineering, math, statistics, physics or related field. A minimum of MSc is required and Phd preferred.
5+ years of experience with model development and working with large datasets. This can include experience from any industry or academia (post-doc experience).
5+ programming experience in Python or R with good grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.
Python/R /Dataiku
REST/XML/JSON/API ingestion
Spark/Impala/Hive
Expertise in machine learning theory and predictive modelling lifecycle
API configuration
Conformance/Alignment to IT/Enterprise Architecture standards (where applicable)
Relevant experience in P&C (preferred)
Shiny App development

Geo-analytics experience (ESRI/KML/KMZ layer development) with specialization in weather & environmental data ingestion
What sets you apart
A growth mindset with versatile skills and able to work through problems from first-principles.
A portfolio of projects that demonstrate your ability to draw inferences from data. This includes participation within the broader data science community including Kaggle competitions or any personal projects with open data.
A can-do teammate who is willing to roll-up the sleeves and do whatever is needed to move projects forward. That means at times you will wear different hats and be a project manager, developer, modeler and chief communicator of solutions.
Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners.
The best problems in the industry are yet to be articulated. We need someone who is creative, self-motivated and can lead projects independently.
Position Objectives
Provide data support to Claims business inclusive of data mining, automated reporting and modelling.
Transformation of complex data sets into meaningful conclusions & recommendations
Develop innovative solutions for pattern recognition using machine learning and statistical approaches
Maintenance of expanding set of data mining tools, frameworks & approaches
Communicate actionable recommendations based on insights/model results
Deliver proactive analysis on CAT exposure, historical performance and decision making using weather and geo-analytical approaches (CAT Analytics role)
Driving co-ordination/delivery accountability of project and BAU delivery based on timelines & direction (Sr Data Scientist)
Driving conformance/Alignment to IT/Enterprise Architecture standards (where applicable) (Sr Data Scientist)
About you

Highly numerate, you will be educated to post graduate (MSc) in a relevant discipline; Mathematics, Statistics, Computer Science. You will bring solid experience in a related role with a record of accomplishment of solving complex non-routine problems; along with expertise in some, if not all, of the following areas: Statistics, Machine Learning, Deep Learning & AI. You will have experience at all stages of data science; problem definition, data acquisition & wrangling, modelling, feature engineering and deployment. Big Data experience (e.g. Hadoop) would be ideal, but not essential. What is equally important is programming knowledge and a gift for coding using: R, Python or Spark. Your knowledge must also come with the ability to explain technical concepts to non-specialists. You will also need the drive to deliver projects –leading teams and coaching development. With these talents, you will be equipped to provide insights and deployments at scale. If you thrive on complex, non-routine problems, you will be right at home here.",3.5,Aviva,Markham,"London, United Kingdom",10000+ employees,1861,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),Legal & General,79.0,159,data scientist,senior,1,1,0,0,0,0,1,0,0,0,0,0,1,1,1,6168,1
186,"Requisition ID: 61162

Career Group: Corporate Office Careers

Job Category: N/A

Travel Requirements: 10 - 20%

Country: Canada (CA)

Province: Ontario (CA-ON)

City: Toronto

Location: Tahoe

Postal Code:

A proudly Canadian retail company, Sobeys began in 1907 as a small meat delivery business in Stellarton, Nova Scotia. Today, Sobeys Inc. serves the food shopping needs of Canadians with approximately 1,500 stores in all 10 provinces under retail banners that include Sobeys, Safeway, IGA, Foodland, FreshCo, Thrifty Foods, and Lawton’s Drug Stores as well as in-store pharmacies, liquor and more than 350 retail fuel locations.

Together with our 123,000 employees and franchise affiliates and a collective passion for delivering exceptional food and shopping experiences, Sobeys’ purpose is to improve the lives of Canadians by helping them Eat Better, Feel Better and Do Better.

All career opportunities will be open a minimum of 5 business days from the date of posting.
Overview
This is an exciting opportunity to join our Innovation and Strategy team at the ground level ! You will be part of our innovation hub located in downtown Toronto where your desire for impact will only be matched by your inate ability to collaborate with other like minded individuals to come up with creative solutions to our retail data science problems.
Job Description
Maintaining, streamlining and hardening existing data pipelines, from ingestion, through ETL and batch processing in order to reliably process billions of records per day.
Build data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real-time M/L applications.
Working with Analytics and Product Management to ensure optimal data design and efficiency.
Assisting Data Analysts and Data Scientists with pipeline and model deployment
Use an analytical, data-driven approach to drive a deep understanding of our fast changing business.
Building data models to deliver insightful analytics while ensuring the highest standard in data integrity.
Job Requirements
Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance or related quantitative field, or equivalent practical experience.
Experience and proficiency with SQL and SQL-like languages
More than 3 years of software engineering experience, especially working on back-end data infrastructure, including CI/CD (i.e. Jenkins) and infrastructure-as-code (i.e. Ansible, Terraform)
Proficiency with at least one of the following languages: Java, Python, Scala.
Proficiency in cloud infrastructure and networking
Proficiency working with Apache Airflow
Proficiency with Spark and/or similar tools in Hadoop/YARN environment and comfortable with Linux operating system.
Ability to creatively solve problems in a fast paced, rapidly changing environment
Ability to navigate ambiguity, drive solutions forward and bring stakeholders along.
Strong problem solving, analytical skills and capability of managing multiple projects and reporting simultaneously across different stakeholders.
Strong structured thinking and the ability to easily break down complex ambiguous problems and propose impactful data modeling designs.
#LI-POST

Sobeys is committed to accommodating applicants with disabilities throughout the hiring process and will work with applicants requesting accommodation at any stage of this process.

While all responses are appreciated only those being considered for interviews will be acknowledged.

We appreciate the interest from the Staffing industry however respectfully request no calls or unsolicited resumes from Agencies.",3.4,Sobeys,Toronto,"Stellarton, Canada",10000+ employees,1907,Subsidiary or Business Segment,Grocery Shops & Supermarkets,Retail,$10+ billion (CAD),"Metro, Loblaw Companies",79.0,113,machine learning engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,1,3667,2
187,"We’re revolutionizing the way humanity eats, and there’s a lot of room for optimization and growth. That’s where you come in. Your ingenuity will help us continue to drive innovation, making an impact on the reliability, performance, and scalability of Skip’s industry-leading technology.

Job Summary:
Think you have what it takes to join an elite team of software developers, engineers, and data scientists? If you want to make your mark on a national brand’s industry-leading technology, Skip’s Engineering Team is the place for you. They drive the innovation of Skip’s platform by improving the reliability, performance, and scalability of the network. GPS tracking, real-time order processing, scheduling, and balancing are just a few of the pieces the Engineering Team integrates into Skip’s world-class service.

As a member of our Data team, you will be responsible for the design and implementation of software for systems that power Skip’s Business Intelligence and Data Warehouse. Your experience with cloud technologies and big data provides you with the background to quickly implement changes. Your experience in data management and SQL allows you to contribute to the expanding expertise of the team and keep data components current as product feature change.

How we work:
We take ownership of our work and work closely with our team.
We move quickly, take risks, and know how to manage the risks.
Regularly refactoring to improve our existing systems — technical debt isn’t an excuse.
Unit tests and code reviews are at our core — confidence in our pull request is the result.
We constantly push our app’s technology, design, and architecture forward to meet new challenges.
We face challenges no one can predict — we meet them head-on as a team.
When we have an idea that serves a need, we run with it.
Our teams are kept tight and efficient.
Experience Needed:
Experience working with both large and real-time data sets.
Strong hands-on experience with Python.
Hands-on experience with backend python frameworks.
Experience in REST APIs.
Experience with AWS and/or Google Cloud Platform data components.
Experience working with tools, languages and protocols such as Redshift, Big Query and/or columnar databases.
Familiarity with scheduling tools like Airflow.
Strong in Dimensional Modeling concepts.
Experience using version control software, such as Git.
Work well both independently and as part of a team. You will actively participate in design discussions and code reviews.
Qualifications:
Computer science, software engineering or related degrees.
We are looking for people who:
Have a great attitude.
Thrive in a rapidly evolving environment.
Are eager to contribute to the growth and development of the team.
Work with an entrepreneurial sense of urgency.
Are receptive to feedback and challenging experiences.
Are actively involved in their ongoing personal growth and learning.
What It’s Like To Work At Skip

Picture this: you, dressed in your fave casual attire, amongst a team of friendly and passionate colleagues. You feel pride knowing your input and uniqueness are not only embraced but make an impact on a major Canadian company and its satisfied customers. As the company grows, so do you — you meet and surpass new challenges every day.

That’s just a small taste of what it’s like to work at one of Canada’s leading tech companies. If you’re hungry for opportunity, growth, and something meaningful in a dynamic, yet casual environment, we’d love to hear from you.

Note: All employees will be asked to sign a Consent for Disclosure of Personal Information in order to complete a background check. Job offers will be conditional upon results that the Company determines to be satisfactory.",3.3,SkipTheDishes,Winnipeg,"Winnipeg, Canada",201 to 500 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,79.0,7,data engineer,na,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,3731,0
188,"IT/IQ Tech Recruiters is seeking a Data Scientist to join our client in Montreal, QC.

Why work with our client?
Competitive compensation
Centrally located
Transit accessible
Responsibilities
Developing core algorithms and models to enhance network design, operation, optimization and monitoring
Work closely with subject matter experts in other teams to develop and continuously improve models, and help translate business needs into data science projects
Being a leading Machine Learning authority; staying at the forefront of the newest technologies, prototypes, and being proactive in Machine Learning communities
Provide mentorship to your peers
Top Skills Required
Have 3-5 years of applied experience in data science
Have experience in various machine learning use cases, such as, time series analysis, regression and classification
Have the agile mindset; delivering value iteratively
Have expert understanding of machine learning techniques; knowledge of tools and packages such as TensorFlow, PyTorch, Keras, Scikit-Learn, XGBoost, Matplotlib.
Have good knowledge of deep learning and more traditional machine learning algorithms
Have the ability to build, validate, deploy and monitor alliteratively advanced predictive models
Have excellent scripting and programming skills (such as Python, SQL)
Have experience in conducting Machine Learning projects
Have a positive, team-focused attitude and strong collaboration skills
Have excellent written and communication skills to present complete and cohesive findings
Have the ability to produce clear, logical and convincing arguments and explain complex ideas simply
Must be legally eligible to work in Canada
Why work with us?
Build a long-term relationship with an experienced recruitment expert
Access to the ‘hidden’ job market – opportunities across Canada that aren’t posted on job boards
Get a high-level understanding of market dynamics affecting your industry
Gain insight into the culture of the company you’re applying for before submitting your profile
About Us

IT/IQ Tech Recruiters provides contract and permanent IT recruitment services to employers across Canada. We have a specialized approach to recruiting, segmenting our recruitment teams into specialty practice areas focusing on Development, PMO, Infrastructure and BI/CRM/ERP skill sets.

This approach enables our recruiters to become specialists; they know the market and work hard to understand each candidates’ capabilities, goals, career ambitions and quickly present them with the best possible opportunities. We are committed to helping candidates develop their careers and to helping our clients grow their business and complete important projects successfully.

We create opportunities for IT Professionals to empower business.",2.8,IT IQ TECH RECRUITERS LTD,Vancouver,"Vancouver, Canada",1 to 50 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (CAD),"Randstad, TEKsystems, TEEMA Solutions Group",79.0,18,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,1,1,0,2769,3
189,"About Etraveli Group

Etraveli is one of the leading global flight centric Online Travel Agencies (OTAs) with €4bn+in annual gross sales. We also operate flygresor.se, the #1 metasearcher in Sweden and Tripstack, the independent B2B arm of the group offering a variety of complex technology solutions.

Our diverse, dynamically growing team of 1000+ talented professionals is always on the lookout for more members to join our ranks and explore unlimited business opportunities together! Our 110 websites in 70+ countries across the globe include (but are not limited to) gotogate.com, pamediakopes.gr, mytrip.com, flightnetwork, supersavertravel.se, trip.ru & flygresor.se.

About Tripstack

TripStack is a brand under the Etraveli Group, It is revolutionizing the travel & technology field with a mission to challenge the status quo by solving difficult problems and changing the way millions of people travel.

We offer unique flight content, consisting of Virtual Interline & Low-Cost carriers in one search - this enables our partners to offer the end consumer the most relevant flight options at the lowest price.

Our company’s core values are what form our foundation. They inform how we work, how we execute, how we choose our future teammates and how we present ourselves to the world as TripStack employees.

Playing to Win.

#1 within flights

At TripStack we play as a team, we win as a team and we constantly aim to become better. We challenge convention, ourself and our teammates. We dare to think big and we value those who think differently.

Drive for Excellence

Good is not good enough.

We show a never give up attitude and we move fast, knowing we sometimes make mistakes, but that is needed to keep a high pace and to solve complicated stuff. And what we do is complicated, but by driving for high quality & excellence we simplify the product offering, enabling the end user more and cheaper ways to travel.

Act with Ownership

Have pride in your work

At TripStack we expect all to take accountability for your work but also accountability for the team work. We value proactivity, employees who take initiative to get things done- also when it is out of normal scope - it help us achieve our goals.

TripStack is part of the Etraveli Group, a global online travel agency and the fastest growing in Europe whose presence across the web spans 50 countries.

The Role
We are looking for an experienced data engineer to join our Virtual Interlining team for TripStack. Virtual Interlining is a technology we provide that combines flights from different carriers that don’t traditionally work together to go from point A to B via C. These unique fares provide significantly lower prices to the end consumer and much higher flight margins to our partners. Did you know that there are nearly 45 million flights operated worldwide on an annual basis? Indexing that data to provide customers with better flight options is a daunting and exciting mission.

You will use various methods to transform raw data into useful data systems. For example, you will create algorithms and conduct statistical analysis. Overall, you will strive for efficiency by aligning data systems with business goals.

To succeed in this role, you should have strong analytical and programming skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages (preferably golang, python) and knowledge of machine learning methods would be considered an asset. You should have a good understanding of data warehousing concepts, having worked with large datasets and designed star/snowflake schemas. Experience with data processing tools like Apache Hadoop, Spark, Apache Druid( real-time OLAP) would be considered an asset.

Responsibilities:
Analyze and organize raw data
Build data systems and pipelines
Evaluate business needs and objectives
Interpret trends and patterns
Conduct data analysis and report on results
Prepare data for prescriptive and predictive modeling
Build prototypes
Combine raw information from different sources- flat files, databases, NoSQL caches
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition and prototype them using machine learning
Collaborate with Data Scientists and Architects on several projects
Requirements
Bachelor’s degree in Computer Science or technical discipline required. Master’s degree not mandatory but would be considered an asset.
4 years previous experience as a data engineer or in a similar role
Technical expertise with data models, data mining, and segmentation techniques
Knowledge of programming languages (Golang, Java, and Python)
Hands-on experience with SQL database design and proficient at writing SQL queries specifically Postgres
Knowledge of Apache Hadoop, Spark an asset
Knowledge of real-time OLAP like Apache Druid is an asset
Exceptional numerical and analytical skills",2.4,Etraveli Group,Toronto,"Uppsala, Sweden",1001 to 5000 employees,-1,Company - Private,Travel Agencies,Travel & Tourism,Unknown / Non-Applicable,-1,79.0,-1,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,4957,0
190,"Zymeworks is a clinical-stage biopharmaceutical company dedicated to the discovery, development and commercialization of next-generation bispecific and multifunctional biotherapeutics, initially focused on the treatment of cancer. Zymeworks’ suite of complementary therapeutic platforms and its fully-integrated drug development engine provide the flexibility and compatibility to precisely engineer and develop highly-differentiated product candidates.

About the Position

Zymeworks is looking for a highly motivated AI / machine learning associate scientist for protein design applications development within the Technology team. This candidate will work along with the Molecular Simulations, Bioinformatics and Software Engineering team, building comprehensive computational protein modeling and data analytics platforms for use in biologics engineering and drug discovery. We are seeking candidates with experience in developing and applying supervised and unsupervised machine learning algorithms to address challenges in biomolecular design and optimization. Our scientific staff have opportunities to impact the entire computational method development process, from devising the algorithms to implementation, and direct application in biologics modeling and optimization, pushing the boundaries of in silico therapeutics design.

This is a permanent, full-time position located at our headquarters in Vancouver, BC and will report to a Senior Scientist in the Technology team.

Key Responsibilities
Design, develop, validate and document state-of-the-art discriminative and generative deep learning algorithms for antibody and protein therapeutics engineering and optimization.
Leverage public databases and Zymeworks’ proprietary data as well as in-house computational infrastructure to develop scalable tools and automated workflows for biotherapeutics engineering and optimization.
Implement, train, test and compare various ML approaches for the problem at hand, drive to develop the most optimal and efficient algorithmic solution.
Work closely with protein engineers, drug developers and translational scientists to identify new opportunities, gather requirements, design and develop machine learning techniques to help advance early-stage therapeutics design processes.
Communicate the advantages and caveats of the developed technology to technically-diverse internal audiences and external partners.
Attend conferences and participate in the preparation of patents and publications
Qualifications & Experience
MS/Ph.D. in Computer Science, Statistics, Applied Math, Physics, Chemistry, Biological Sciences or a related field.
In-depth experience with modern and classical ML methods with 2 to 5 years of practical experience designing, training and validating such algorithms
Candidates are expected to have basic knowledge of molecular sciences and protein structure function relations.
Strong statistical foundation and working knowledge of supervised and unsupervised learning algorithms, in particular, deep generative models like Boltzmann Machines, Variational Autoencoders, GANS, etc
Experience working with Deep Learning frameworks (e.g. TensorFlow/Keras, PyTorch)
Proficient in at least one of C, C++, Java, or Fortran, and proficient in a scripting language (eg Python, Perl, Ruby)
Preferred Experience
Source-code management systems such as Git, Github, Bitbucket etc.
Algorithm parallelization, and knowledge of GPU computation and CUDA
Scaling ML algorithms, and hyper-parameter optimization strategies in cloud computing environments such as AWS
Why Work for Us?

At Zymeworks, we stand for innovation, integrity, collaboration and care.

We come from many countries, cultures, races, ethnicities, abilities and nationalities. We bring our passions including singing, biking, swimming, dancing, cooking, volunteering, parenting, coaching and much more! We are proud of our nearly equal balance of men and women and strengthened by our non-binary and transgender team members. Every employee belongs.

We offer challenging career opportunities, competitive benefits and an environment that recognizes and rewards performance.

To learn more about Zymeworks Inc. and our current openings, please visit our website at https://zymeworks.bamboohr.com/jobs/.

NOTE TO EMPLOYMENT AGENCIES: Zymeworks values our relationships with our Recruitment Partners. We will only accept resumes from those partners whom have been contracted by a member of our Human Resources team to collaborate with us. Zymeworks is not responsible for any fees related to resumes that are unsolicited or are received without contract.

#LI-PT1",4.4,Zymeworks Inc,Vancouver,"Vancouver, Canada",201 to 500 employees,2003,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1,79.0,17,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,4642,0
191,"WHO WE ARE


Namaste Technologies began as an international cannabis eCommerce company operating in 20 countries. We have years of data collected on legal cannabis users and by combining machine learning technology with telemedicine apps, we leverage this data to provide our customers with a world class cannabis purchasing experience.

WHO YOU ARE


We are looking for a Senior Data Analyst to join our team. You will be partnering with our product managers to assess strategic initiatives, develop actionable insights and drive operational analytics.

As our business is constantly trying to delight its customers, data takes a crucial place. By leveraging all the knowledge we collect about our customers’ journey, we can take informed decisions on the future of our products. Examples of questions to answer are “What is the conversion rate of this specific step?” or “What is the impact of an A/B Test segment on the Average Order Value?”. Helping all the departments (Finance, Marketing...) understand and use data is also of prime importance.

Candidates are expected to be highly analytical, self-directed and excellent communicators. Ideal candidates have a proven track record of cross functional project management and extensive analytics experience. We are a data driven organisation so previous experience with query and scripting languages such as SQL and Python or a strong desire to learn these skills is preferred. The ideal candidate will thrive in a fast-paced environment, possess a high level of intellectual curiosity, and focus on generating results while exhibiting the highest personal and professional integrity and ethics.

In addition to intellectual curiosity and aptitude, we look for candidates who are excited by technology, either from a professional or personal background.

ROLES & RESPONSIBILITIES
Provide strategic ad-hoc analysis to engineering teams, senior leaders, and FP&A. Report and iterate on key operational and financial metrics.
Collaborate with our Engineering squads to create dashboards presenting KPIs for our products and our business activities.
QUALIFICATIONS
Minimum three years in an analytical role
Ability to present to and context switch between peer groups and senior level management.
Ability to independently explore and analyse high volume datasets.
Experience with data transformation processes, using Python.
Working experience with our visualisation tool, Tableau.
Experience with data storytelling.
Degree in accounting, economics, mathematics, engineering/computer science, or other relevant field that demonstrates quantitative competence.",1.0,Namaste Technologies,Toronto,"Toronto, Canada",1 to 50 employees,-1,Company - Public,Other Retail Shops,Retail,$1 to $5 million (CAD),-1,79.0,-1,data analyst,senior,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,2610,0
192,"We are actively seeking a Data Analyst for a successful and well established cross platform studio. The successful candidate has proven experience analyzing data to inform product strategy and direction. This is full time permanent role.
Your background includes:
3+ years experience in a similar role.
A graduate degree or related professional experience in consulting, consumer insights, or product strategy or revenue strategy.
Experience writing SQL queries, Excel, PowerPoint, Tableau, Python (or similar)
Love of video games and geek culture.
This role is open to local candidates based in the Vancouver area. Although we appreciate all interest, only those candidates selected for an interview will be contacted.

At Creative Technology Resources (CTR), we have very high expectations of ourselves to consistently deliver quality to the client and candidates that were so fortunate to partner with every day. We deliver talented, driven individuals to our clients so that together we are building teams that thrive. Our clients are made up of teams of industry veterans whose expertise and interests are driving the creation of the worlds next great digital products & services. Together, we can create some of the best experiences ever made.

View all our open positions here",5.0,Creative Technology Resources,Burnaby,"Vancouver, Canada",1 to 50 employees,2012,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (CAD),-1,79.0,8,data analyst,na,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1283,0
193,"Overview


Crosslinx Transit Solutions (CTS) is a consortium comprised of EllisDon, SNC-Lavalin, Aecon, and ACS - Dragados. CTS has been selected by Metrolinx and Infrastructure Ontario to deliver the Eglinton Crosstown Light Rail Transit Project and is seeking highly qualified, experienced personnel to join the team of this complex P3 design and construction project

The Data Analyst & Reports Developer position will be within the Systems Integration Team with primary focus on collecting missing data from vendors and project managers / package leads. Much of this data is project-wide asset data that needs to reside in our CMMS software (QFM).

Responsibilities


The person in this role will perform tasks as directed by the Systems Integration Authority:
Collect and prepare all data to be imported into our CMMS software such as geography, assets, planned preventative maintenance schedules, Testing & Commissioning events, asset lifecycle, personnel, contractor
Champion the Asset Data Sync (ADS) system (SharePoint to QFM) and related project deliverables
Interface with CMMS vendor on a weekly basis
Build dashboards and reports as required
Perform other tasks as requested for the Systems Integration Team
Qualifications
Bachelor’s degree or college diploma related to engineering, technology, or computer science, or sufficient work experience in a related field
5+ years prior work experience in a similar role
QFM or other CMMS, IWMS, CAFM asset management software experience is ideal
AFP / PPP / P3 payment mechanism or performance-based contracts knowledge
Sound knowledge of MS Office
Must be an MS Excel wizard (data manipulation, preparation for database importing)
Knowledge on topics such as: String manipulation, schemas, data types, barcoding, ETL, SFTP, web services, APIs (SOAP, RESTful), XML
Solid understanding of SQL
MS Power BI reporting and dashboard design skills
MS SharePoint design and good housekeeping skills
Crystal Reports exposure
Keen attention to detail and accuracy of data is paramount
Technically knowledgeable, exemplar communication skills, motivated self-starter, team player
Python experience is an asset",3.4,Crosslinx Transit Solutions,North York,"Toronto, Canada",201 to 500 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,51.5,-1,data analyst,na,0,1,1,0,1,1,0,0,0,0,0,0,0,0,0,2157,0
194,"Responsibilities:

· Act as the functional and technical SME on Data Science.

· Steer client requirement gathering discussions and obtain a thorough understanding of client business processes, aims, objectives, and constraints.

· Lead the Services Team on customizations and enhancements to data analytics solutions to match client requirements.

· Develop PoCs, strategies, and provide direction to clients and Services Team around segmentation projects, including creation of statistical models, rules definitions, and criteria for analyses

· Supporting Sales and Marketing from a technical standpoint to educate clients on services capabilities in the data analytics space.

· Provide direction to business teams to perform analytics on client data.

· Build trust with the client and establish self as the technical point of contact for all data analytics questions.

· Drive technical architecture meetings and help clients select the right architecture for their solutions that meet both functional and non-functional requirements.

Requirements/Qualifications:

· 10+ years of working experience in designing, architecting, and deploying enterprise level solutions.

· Master's degree in Computer Science, Mathematics or Statistics.

· Experience in building at least 1 Data Analytics solution, involving segmentation work, and generation of statistical model(s).

· Development experience in R, Python, and SAS.

· Highly effective communication and collaboration skills working in a distributed team environment.

· Conveys technical information to technical and non-technical audiences.

· Technical leadership and strong independent problem solving skills.

We are ONLY seeking candidates with Secret Clearance

Job Type: Full-time

Salary: $35.00-$78.00 per hour

Schedule:
Monday to Friday
Experience:
business analysis: 5 years (Preferred)
Education:
Bachelor's Degree (Required)",3.5,Mastech InfoTrellis,Toronto,"TORONTO, Canada",1 to 50 employees,-1,Company - Private,Consulting,Business Services,$1 to $5 million (CAD),-1,51.5,-1,data analyst,na,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,1896,0
195,"Job description:

Responsibilities:
Perform ETL with massive data from multiple applications and 300 M+ customers
Architect, design and evaluate novel approaches for handling high-volume real-time data streams in an inferencing environment
Own the development, training, optimizing, and deployment of machine learning systems
Develop measurement and feedback systems at web scale to improve the selection of features and/or algorithm design
Qualifications:
Strong software development skills (+3 years working experience), with proficiency in Python or Scala preferred
Experience in building ETL pipelines to perform feature engineering on large-scale dataset using Big Data technologies such as Spark
Ability to explain and present analyses and machine learning concepts to a broad technical audience
Ability to initiate and drive projects to completion with minimal guidance
Knowledge in advanced data structures and can use them to solve problems
You have a Masters degree or equivalent in Computer Science, Engineering, Mathematics or related field
Working knowledge of PyTorch, Tensorflow or other similar frameworks is a plus
Creative, collaborative, & product focused
Job #43632",3.6,Tundra,Toronto,"Toronto, Canada",201 to 500 employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,51.5,16,machine learning engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,1185,0
196,"Are you interested in being part of a small team tasked to build the next-generation industry-leading platform for healthcare markets? We are looking for smart, passionate, and a highly skilled Data Analyst to join the effort to define and build the future of MacroHealth. You will be joining a team that's developing the data platform for advanced analytics. The work youll do directly impacts the experience of our customers.

About us:

The U.S. health sector is complex and dynamic - a vast and diverse network of entities that impacts the population and economy like no other industry. At USD$3.3 Trillion, healthcare spending represents nearly 18% of U.S. GDP. It is complex and inefficient, with estimates of fraud and waste ranging up to 30% of total spending. Health service buying, selling, and settlements have seen little change in the past decade despite clear changes in available information, technology, regulation, and market consolidation.

Enter MacroHealth. MacroHealth is a mission driven company. We are building the most advanced and trusted market platform for health service payers and providers. The companys vision is to create Intelligent Health Markets by building technology, knowledge and relationships that enable payers and providers to optimize the buying and selling of health services.

We are expanding our team of passionate thought leaders as we pursue our goal of disrupting the U.S. health sector with our vision and technology. We are committed to developing leading edge solutions in a supportive environment focused on customer success and employee fulfillment.

What youll do:
Maintain clean data by verifying, validating, and filtering data if needed,
Organize and automate the existing reports,
Develop reporting tools telling the story of business optimization,
Build and maintain self-service reporting portal,
Provide data insights on demand and proactively in order to assist operations,
Work closely with the sales engineering team,
Document all systems-related processes and flows,
Stay current with new technologies, constantly evolving our systems to advance the maturity and capabilities of our platforms,
Present analytics and insights to customers,
Identify and evaluate external data sources
Fit in a people-first culture of teamwork and respect,
What youll need:
Excellent documentation skills,
Bachelor's degree or equivalent practical experience,
5 years of experience with data analytics and working with enterprise data,
5 years of experience with SQL,
Hands on experience with PowerBI, Tableau, Azure Data Factory,
Some Machine Learning experience,
Strives to stay up to date with the best practices of data analytics in the industry,
Customer facing work experience is an asset
Experience working in the healthcare market before is an asset.",-1.0,MacroHea,Vancouver,"Kirkland, WA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,51.5,-1,data analyst,na,0,0,1,1,0,1,0,0,1,0,0,0,1,0,0,2807,0
197,"Reporting to the Analytics Manager, the Senior Data Scientist is responsible for answering sophisticated business questions using complex data patterns. He/She will advocate, evangelize and build innovative data-fuelled models that support our success. The ideal candidate demonstrates a strong passion for producing new, creative and leading-edge analytics solutions.

RESPONSIBILITIES

Translate complex analytical results into actionable business initiatives
Develop a deep understanding of the business, its data, and patterns
Extract data from multiple sources to uncover opportunities or detect issues
Research and develop learning models, perform statistical analysis and deliver data reviews and optimization to internal teams and executives
Partner with strategic business stakeholders to provide evidence-based guidance
Contribute to data mining architecture, modeling standards and data analysis methodologies
Design and implement accessible, high-impact visualizations that clearly communicate conservation results, elucidate patterns, promote accountability, generate actionable insights, and facilitate decision making
Work iteratively in collaboration with different teams to refine initial concepts and prototypes that can be presented to stakeholders for feedback
Develop and continuously improve processes, tools, and techniques
Stay abreast of emerging tools and technologies

REQUIREMENTS

Master’s or PhD degree in Statistics, Mathematics, Quantitative Methods, or a related field
A minimum of 5 years experience in analytics / data science with a focus on driving business impact
Strong understanding of advanced modeling techniques, such as Machine Learning, nonparametric approaches and neural networks
Excellent programming skills using SQL, Python, and statistical softwares (eg. R, SAS)
Experience with data manipulation technologies and knowledge of programming languages
Extensive experience solving analytical problems using quantitative approaches
Experience using Spark or similar languages, an asset
Experience with e-Commerce, an asset
Experience in econometric models, an asset
Understanding of web analytics, an asset

SKILLS

Highly analytical and detail oriented
Capacity to synthesize, simplify and present complex information to technical and business stakeholders at various levels of the organization
Ability to design and present complex data sets in a variety of visually compelling formats
Ability to thrive in a fast-paced, performance-driven environment
Team player with solid interpersonal skills

----------

Relevant du Gestionnaire des analyses, le Scientifique des données principal est chargé de répondre aux questions d’affaires sophistiquées à l’aide de schémas de données complexes. Il/Elle va promouvoir, evangelizer et bâtir des modèles de données novateurs qui soutiennent notre succès. Le candidat idéal est passionné par la production de solutions d’analyse nouvelles, créatives et avant-gardistes.

RESPONSABILITÉS

Traduire des résultats analytiques complexes en initiatives d’affaires actionnables
Développer une compréhension approfondie des affaires, des données et des schémas de l’entreprise
Extraire les données de plusieures sources pour découvrir des opportunités ou détecter des problèmes
Développer des modèles d’apprentissage, effectuer des analyses statistiques et fournir des examens de données et l’optimisation des données aux équipes et aux directeurs internes
Travailler étroitement avec les intervenants stratégiques afin d’offrir une orientation basée sur les preuves
Contribuer à l’exploration des données, l’architecture, les normes de modèles et les méthodologies d’analyse des données
Concevoir et mettre en oeuvre des visualisations accessibles à impact élevé qui communiquent clairement les résultats de conservation, éclaircissent les schémas, favorisent la responsabilisation, génèrent des observations actionnables et facilitent la prise de décisions
Travailler de façon itérative en collaboration avec différentes équipes pour raffiner les concepts et prototypes originaux qui peuvent être présentés aux parties prenantes pour leur rétroaction
Développer et continuellement améliorer les processus, les outils et les techniques
Rester à l’affût des technologies et outils émergents

EXIGENCES

Maîtrise ou Doctorat en Statistiques, Mathématiques, Méthodes quantitatives, ou un domaine connexe
Un minimum de 5 années d’expérience en analyse / science des données visant à faire un impact sur les affaires
Solide compréhension des techniques de modélisation avancées telles que l’apprentissage machine, les techniques non paramétriques et les réseaux neutres
Excellentes compétences de programmation avec SQL, Python et logiciels statistiques (ex. R, SAS)
Expérience avec les technologies de manipulation des données et connaissance des langages de programmation
Vaste expérience en résolution de problèmes analytiques avec approches quantitatives
Expérience avec Spark ou langages similaires, un atout
Expérience e-commerce, un atout
Expérience avec les modèles économétriques, un atout
Compréhension de l’analytique Web, un atout

COMPÉTENCES

Solides aptitudes analytiques et soucieux du détail
Capacité à synthétiser, simplifier et présenter de l’information complexe aux parties prenantes techniques et d’affaires à tous les niveaux de l’entreprise
Capacité à concevoir et présenter des ensembles de données complexes dans une variété de formats visuellement attrayants
Habileté à réussir dans un environnement orienté sur la performance et au rythme rapide
Esprit d’équipe et fortes compétences relationnelles",3.9,SSENSE,Montreal,"Montreal, Canada",501 to 1000 employees,2003,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1,51.5,17,data scientist,senior,0,1,0,0,0,1,1,0,0,0,0,0,1,0,1,5605,0
198,"Are you a SR. Data Scientist guru? Do you have a degree in Engineering, Statistics, Mathematics, or Computer Science? If so, we want to meet you! We are currently searching for a Sr. Data Scientist to be part of our client’s team of professionals. We are looking for a dynamic and motivated individual who has a passion for Data Analytics.

Our client has been around for over 15 years and has remained a well reputed company in Canada.

Responsibility:
Assemble and analyze data to understand customer behavior external data sources and emerging sources.
Building Pricing models and optimization using gurobi or the like.
Undertake analysis of target customer groups (segments) for specific marketing and pricing programs and assess opportunities and strategies for marketing.
Ad hoc analysis and modeling of data.
Strong experience building customer analytic models like: price elasticity, attrition, lifetime value, churn and segmentation.
Ability to understand business stakeholder’s issues and create valuable insight.
Raise awareness and action of data science within the company to help focus on fact-based decisions.
Support the Department along with the Information Technology Management Department in planning the structure and storage of new customer related data fields.
Represent the department in committees within the organization.
Lead project-based work with key business stakeholders.
Mentor junior members on statistical techniques and experimental design.
Qualifications:
A University degree in Engineering, Statistics, Mathematics, or Computer Science.
Graduate Degree focusing on Operations research. (PhD preferred)
Minimum 10 years working experience with data science techniques: clustering, regression models, classification, anomaly detection and other machine learning techniques.
Minimum 10 years of experience with data analysis tools (eg. SAS, R or Python) and BI visualization for reporting.
Well-developed business analysis, research, and creative problem-solving skills.
Organizational skills and time management skills; planning and project management, and ability to meet multiple deadlines.
Strong communication skills and work ethic.
Highly collaborative team player with an entrepreneurial spirit.
Familiarity with MicroStrategy is an asset.
Contact Details


Don’t miss this opportunity, apply now!

Qualified candidates please submit your resume to saudn@fuzehr.com

or call Saud at (905) 361 - 3987 ext. 126

#OPON",3.6,Fuze HR Solutions,Woodbridge,"Montreal, Canada",51 to 200 employees,2006,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,"Robert Half, Randstad, Adecco",51.5,14,data scientist,senior,1,1,0,0,0,0,0,0,0,0,0,0,1,0,1,2456,3
199,"Our Telco client in Edmonton is in need of a Data Analyst for an initial 5 month contract.

Responsibilities
Provide data analysis and standard reporting support, which includes the ability to extract data from various source systems and data stores by performing light business coding (SQL, VBA, Unix, etc.) and system parameter setting, perform ad-hoc queries and develop/automate financial/statistical models using a variety of software applications (Excel, Access, etc.). Perform impact analysis on proposed changes evaluating potential impacts on data, applications, and reporting and effectively communicating potential risks/effects to supported business customer base. Ability to interface with management, users, and information technology professionals to solve complex business problems.

Must to have skills:
3+ years experience extracting data from various source systems and data stores by performing light business coding (SQL, VBA, Unix, etc.) and system parameter setting,
Perform ad-hoc queries and develop/automate financial/statistical models using a variety of software applications (Excel, Access, etc.).
Perform impact analysis on proposed changes evaluating potential impacts on data, applications, and reporting and effectively communicating potential risks/effects to supported business customer base.
Ability to interface with management, users, and information technology professionals to solve complex business problems.",3.7,emergiTEL Inc.,Edmonton,"Richmond Hill, Canada",201 to 500 employees,2006,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (CAD),"Veritaaq, TEKsystems, Procom",51.5,14,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1449,3
200,"Tangent Animation is the vision of Animation and Film Production industry professionals, with combined experience that encompasses CG Animation, Live Action Film Production, Visual Effects, and Software Development. Tangent Animation employs open source solutions to create high quality animated feature films. What sets us apart from other studios is our use of Blender, an open source software to make our animated films. This approach has helped us in curbing the cost of licensed software and build an opportunity to invest in additional artistic and programming talent.

Tangent Animation is currently recruiting for Jr. Data Analyst to work collaboratively with our studio team.

Responsibilities include -
Responsible for tracking and reporting on department initiatives and status reports
Analyze different projects for trends, volume, demographics, and operator metrics to support management decisions
Update and manage information as requested by Associate Producer
Log information into the MS Project database or other platforms
Utilize the Microsoft Project database to carry out statistical analysis and ad hoc reporting as required
Develop analytics to identify trend lines across several data sources and projects within the organization
Assist in root cause analysis and driving resolution of critical production data quality issues as needed
Create / maintain all Production Documentation
Working with assigned dashboards and checklists, reviewing to ensure all requirements have been captured (Quality Assurance)
Work with PM’s and Financial Controller as requested by AP
Manage time sheet approval process and OT database
Additional duties as required
Requirements
Required to a minimum of AS degree, but a bachelor’s degree in Information Management, Computer Science, or Statistics Mathematical, or in a technical field is preferred
Minimum of 1 to 2 years of experience handling a database with large datasets.
Strong Excel skills and ability to build reports and automate things
Knowledge of additional databases such as SQL Server and MySQL. It is also vital to understand project management and familiar with data warehousing, data mining, and data mapping
Required to work under tight schedules, ability to effectively manage and prioritize multiple work assignments
Applicants must also be capable of presenting their findings clearly via reports and oral presentations to senior colleagues
Work effectively in a team-oriented environment, and independently in a fast-paced, and changing environment
Verbal and written communication skills to converse and collaborate with all levels of employees
Ability to pay meticulous attention to detail, factoring every piece that might alter the validity of data
Project management knowledge
Transparency and the ability to be constructive
Benefits
Great company culture, with a team that is very technically proficient, highly motivated & excited to work on projects that will change the industry
Competitive health and dental benefits
Casual dress-code
Tangent Animation is an equal opportunity employer and welcomes applications from all suitably qualified persons regardless of their race, sex, disability, religion/belief, sexual orientation or age. We are committed to providing reasonable accommodation upon request for candidates taking part in the recruitment process.

We thank you for your interest, however, only those candidates selected for an interview will be contacted.",4.7,Tangent Animation,Winnipeg,"Winnipeg, Canada",201 to 500 employees,-1,Company - Private,Film Production & Distribution,Media,Unknown / Non-Applicable,-1,51.5,-1,data analyst,junior,1,0,0,0,0,1,0,0,0,0,0,0,0,0,1,3454,0
201,"The Business

GradTests.com is a leading provider of practice psychometric tests to graduates, students and young professionals.

The Role

An analytics all rounder role. The core purpose of the role is to derive insights from data to improve the product, the customer experience and ultimately the business. We're looking for someone with a nice blend of technical skills, and softer skills like business acumen, decision making and communication skills.

You'll do things like:
Set up, run and analyse A/B experiments
Define and measure metrics for the business to follow
Create and maintain dashboards to track KPIs
Work with the product team to prioritise the next set of features
Dig into trends to quickly understand what is happening and why
Find and define new datasets to track
Produce ad hoc analyses
Skills and experience

Non negotiables:
SQL
Python
Basic knowledge of stats
Business acumen
Strong communication skills
Nice to haves:
Experience in product analytics for a top tier tech company
Experience in creating, running and assessing A/B tests
Experience in working with developers, especially on experimentation
Experience in ML/AI
Experience in a visualisation tool like Tableau
Job Type: Full-time

Salary: $80,000.00 - $120,000.00 per year

Experience:
Python: 1 year (Preferred)
SQL: 1 year (Preferred)",-1.0,GradTests (gradtests.c,Vancouver,-1,-1,-1,-1,-1,-1,-1,-1,51.5,-1,data analyst,na,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1325,0
202,"Skill: Data Engineer Lead /Architect - Pentaho

Role / Tier: Senior Consultant / Tier 2

What are we looking:
Expert in Data Architecture, Data Strategy and Roadmap
for large and complex organization and systems and implemented large scale
end-to-end Data Management & Analytics solutions
Expert in Data Quality, Data Profiling, Data
Governance, Data Security, Metadata Management, MDM, Data Lake, Data
Archival and Data Migration strategies using appropriate tools
Hands-on experience with ETL (Extract-Transform-Load)
tools, Data Cataloguing (Talend, Pentaho, Informatica)
Expert in building and operationalizing Big Data
platforms in cloud using AWS
Expert in AWS PAAS and Data Services
Expert in automating data pipelines in a Big Data
ecosystem, DevOps and CICD
Experience in building Open APIs and microservices
along with loosely coupled architecture
Hands-on experience with analytical tools, languages,
or libraries (e.g. Python, Spark etc)
Hands-on experience with the Hadoop stack (e.g.
MapReduce, Sqoop, Hive, Hbase, Spark, Python, Kafka)
Exposure to and an understanding of Agile scrum
methodologies and experience of working in an Agile team
Exposure to and basic understanding of collaboration
tools like Slack, Teams, and JIRA






About Virtusa:

Teamwork, quality of life, professional and personal development: values that Virtusa is proud to embody. When you join us, you join a team of 21,000 people globally that cares about your growth — one that seeks to provide you with exciting projects, opportunities and work with state of the art technologies throughout your career with us.

Great minds, great potential: it all comes together at Virtusa. We value collaboration and the team environment of our company and seek to provide great minds with a dynamic place to nurture new ideas and foster excellence.

Virtusa was founded on principles of equal opportunity for all, and so does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need.

Learn more at www.virtusa.com",3.1,Virtusa,Toronto,"Westborough, MA",10000+ employees,1996,Company - Public,IT Services,Information Technology,$1 to $2 billion (CAD),Capgemini Invent,51.5,24,data engineer,na,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,2253,1
203,"Job Overview:

The Senior Data Analyst is a critical role for the execution of Commercial Solutions data strategy governing a broad portfolio of products within all three verticals (Real Estate, Government & Utilities and Financial Services) of the Value Added Solutions business (VAS).

The incumbent will be responsible for developing, maintaining and enhancing data analytics products for the VAS business with a strong focus on visualization through dashboard. As an expert in VAS data and data visualization, the incumbent will take a significant role in supporting the VAS verticals in data visualization products. The incumbent will also participate in the delivery of other data products, enhancement of data quality and coverage, and enhancement of the quality and accuracy of the products delivered by the Data Analytics team

Responsibilities:
Developing, maintaining and enhancing data visualization products for the VAS Business
Delivering data analytics product solutions to key customers and partners
Acquiring more and better data, enhancing data quality and coverage
Required Skills:
Bachelor degree in the field of Business Analytics, Statistics or Quantitative Analysis
At least 3-5 years working experience in data analytics, statistics or quantitative analysis
Proven experience in designing and developing data visualization tools
Strong experience in data visualization using Tableau
Good experience with various data analytic tools such as R, SAS, and Python
Good communicator with strong written and oral communication skills
Product development and/or sales support experience preferred",3.4,Teranet,Toronto,"Toronto, Canada",501 to 1000 employees,1991,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (CAD),-1,51.5,29,data analyst,senior,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1612,0
204,"Faculty of Health Sciences - Research Associate - Data Analyst - Limited Term

Tracking Code

2013-136

Job Description

Faculty of Health Sciences

Number of Positions: 1

Position Title: Research Associate - Data Analyst

Appointment Type: Limited Term

Hours of work: 16 hours per week

Posting Date: July 29, 2020

Closing Date: August 6, 2020

Job Summary: Data Analyst for a newly funned CIHR grant. This position is critical to the success of the project

Nature of work:
This position reports to Dr. Shilpa Dogra and Dr. David Rudoler
Responsibilities/accountabilities:
Conduct longitudinal analyses with databases
Work includes applying extensive knowledge in the field to perform high-level, complex research activities.
Required Skills

Education
Minimum of a Master's Degree in either epidemiology, kinesiology/health science, biostatistics or statistics.
PhD is preferred
* Verification of Academic credentials may be required

Required Experience

Experience with longitudinal analyses with databases such as the Canadian Longitudinal Study on Aging
Expertise in aging or physical activity research is considered beneficial to this role
How to Apply:

Interested candidates should submit in electronic format a covering letter and their resume. Applications will be accepted until August 6, 2020 or until a suitable candidate is found. We appreciate all applications received; however, only those candidates selected for an interview will be contacted.

Ontario Tech University is an equal opportunity employer and welcomes applications from all qualified candidates, while especially encouraging applications from women, members of visible minorities, Indigenous peoples, persons with disabilities, and persons of any sexual orientation, gender identity, and gender expression. All qualified candidates are encouraged to apply; however, Canadians and permanent residents will be given priority.

Ontario Tech University respects people's different needs and therefore will take all reasonable steps to ensure accommodation for applicants where appropriate. If you require an accommodation to participate in the recruitment process, please notify the Human Resources Department. For more information about the universities policies for accommodating employees with disabilities please review the university’s Accessibility Policy

The university acknowledges the lands and people of the Mississaugas of Scugog Island First Nation which is covered under the Williams Treaties. We are situated on the Traditional Territory of the Mississaugas, a branch of the greater Anishinaabeg Nation which includes Algonquin, Ojibway, Odawa and Pottawatomi.

Job Location

Oshawa, Ontario, Canada
Expected End Date

12/31/2020

Expected Start Date

7/1/2020

Campus Travel

N/A

Salary Grade

Hourly",4.0,UOIT,Oshawa,"Oshawa, Canada",1001 to 5000 employees,2003,College / University,Colleges & Universities,Education,$100 to $500 million (CAD),-1,51.5,17,data analyst,na,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,2799,0
205,"Are you passionate about analytics and eCommerce? Are you always looking to understand the “why” behind a specific trend or anomaly in data? If yes, we’re looking for someone like you to join our rapidly growing eCommerce & Technology team as a Data Analyst.

At Best Buy Canada, we believe empowered people and teams make smarter, faster, and more creative decisions. Our department is a truly Agile environment, where the distance between any one person and senior leadership is microscopic. Here, you’ll work on something big, small, or super cool and before you can blink 100,000 people will see it.

You’ll create fast, learn fast, and develop fast. Oh, and sometimes you’ll fail fast too. That’s ok. (Honestly.) It’s all part of the process.

As a Data Analyst you’ll be designing analytics tools and finding insights to optimize sales and profit. You’ll dive deep into exciting analytics projects and deliver data-driven insights to help other team members make real-time inventory, pricing and assortment decisions. All in all, your work will help our teams use data, rather than intuition, to identify opportunities and build a world-class experience for our customers.

What you’ll be doing:
Analyze transactional and online customer behavior data to identify sales and profit opportunities
Provide insights to buyers to support inventory and pricing decisions
Develop, implement, and maintain interactive reporting solutions for monitoring and analyzing business performance, using both enterprise BI software (Qlik, Power BI)
Design tools to deliver insights faster and influence decision making using scripting languages like R and Python
Conduct deep dive analytics projects, integrating various data sets and utilizing advanced analytics concepts
Maintain an in-depth knowledge of business performance, key drivers, opportunities, and successes by leading business reviews, especially during key events like Black Friday/Boxing Day
Evangelize existing tools and data sets to empower the business teams to answer their own questions and develop a culture of self-serve analytics and data-driven decision making
What you’ll need to succeed:
2+ years of experience in reporting and developing dashboards and tools using an Enterprise Business Intelligence tool (i.e. Qlikview, Tableau, Power BI)
Intermediate to Advanced proficiency with SQL
Familiarity with script languages such as R and Python
Advanced business understanding of the retail or eCommerce space
Bonus points:
1+ year(s) experience working in an Agile environment; familiarity with JIRA, Confluence
Experience using Adobe Analytics or Google Analytics",3.8,Best Buy,Burnaby,"Richfield, MN",10000+ employees,1966,Company - Public,Consumer Electronics & Appliance Shops,Retail,$10+ billion (CAD),-1,51.5,54,data analyst,na,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,2629,0
206,"Who are we?

SkyHive Technologies is a Vancouver-based artificial intelligence company that invented and
commercialized a methodology called quantum labour analysis, which is the application of
artificial intelligence to analyze a workforce or labour market at its most granular level. Its core
technology applies natural language processing to process millions of supply, demand and
training data points to determine real-time job-level labour market activity. It then uses
proprietary machine learning methods to extract technical skills, soft skills, capabilities,
methodologies, tools, and technologies from all job data. Data is then fed into a proprietary
neural network that serves as the world’s first and only real-time, “live-streamed” job taxonomy
and skills ontology, capturing labour market movements in real-time and at their most granular
level.

Recognized as a top startup by Forbes, Startup Grind, and C100, SkyHive is an award-winning AI
technology that deepens our understanding of labour markets, workforces and individuals,
enabling new ways of acquiring, developing, and engaging talent.
Established in 2017 with the mission of tackling global poverty and social inequality, SkyHive
aims to utilize its exponential technology to stimulate economic empowerment and lifelong
learning; ultimately fostering a stronger, more prepared, and more confident workforce to
welcome a brighter tomorrow.

What do we offer?
Opportunity to get your foot in the door of a fast-growing tech company
Collaborative team environment
Comprehensive health benefits package (nothing comes off your cheque)
Three weeks’ paid vacation to start, paid holidays and birthday leave!
Stock options & gainsharing plan
Social Impact Organization with Certified B-Corp Status
Paid & unpaid volunteer time off
Charitable donation matching program to support your favorite charity.
Opportunity to explore other departments as training and career continues.
Professional development assistance program
Beautiful office in A1 location (Views, view, views) / Remote work
Numerous employee appreciation events throughout the year
*

Who you are: *

You have in-depth knowledge and experience in NLP that you have applied to solve real world
problems in the industry. You are passionate about state-of-the-art technologies and are
excited by the application of theory to real-world problems. You keep up to date with the latest
developments in the field and look for ways to apply them to your current work/role. You find
pragmatic solutions that solve problems in a timely manner.

Qualifications:
Post-graduate or Ph.D. in Computer Science or Machine Learning related degree with a focus on NLP; or equivalent work experience in the field
3+ years NLP applied experience, preferably experience applying NLP research to real world problems in the industry
Experience in building production ML models and understanding of inference challenges at scale
Good theoretical grounding in core machine learning concepts and techniques
Ability to perform comprehensive literature reviews and provide critical feedback on state-of-the-art solutions and how they may fit different operating constraints
Experience with a number of ML techniques and frameworks, e.g., data discretization, normalization, sampling, linear regression, decision trees, SVMs, deep neural networks, etc.
Expertise in one or more of the following domains: recommender systems, information retrieval, information extraction (POS, N/E tagging with HMMs/CRF etc), feature extraction, text classification, etc
Experience with one or more deep learning software frameworks such as Tensorflow and PyTorch
Experience writing complex Python code
Produce deliverable results and see them through from development to production
Nice to haves:
Experience with large-scale systems and data, e.g. Hadoop, distributed systems
Publications in top conferences/journals such as EMNLP, ACL, COLING, TACL, CoNLL,
NeurIPs, ICML, ICASSP, Interspeech
Job Type: Full-time

Salary: $80,000.00 - $120,000.00 per year

Benefits:
Casual Dress
Company Events
Dental Care
Disability Insurance
Employee Stock Purchase Plan
Extended Health Care
Flexible Schedule
Life Insurance
On-site Gym
On-site Parking
Paid Time Off
Tuition Reimbursement
Vision Care
Work From Home
Schedule:
8 Hour Shift
Monday to Friday
Experience:
Natural Language Processing: 3 years (Required)
Python: 3 years (Required)
Location:
Vancouver, BC (Preferred)
Work remotely:
Temporarily due to COVID-19",4.9,SkyHive Technologies Inc.,Vancouver,"Vancouver, Canada",1 to 50 employees,2017,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,51.5,3,data scientist,senior,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,4493,0
207,"Teranet is seeking an experienced Big Data Engineer to support its Data Analytics program. In this role, the successful candidate will be responsible for the ongoing monitoring and maintenance of Teranet’s data lake and the in-house developed and third-party software tools used to maintain it. In addition, the Big Data Engineer will work with consumers of the Teranet data lake to develop data views and data feeds according to their business needs and requirements. As part of this effort, the Big Data Engineer will be responsible for publishing data sets and views to the Teranet Data Analytics visualization platform so the data are accessible to downstream consumers. The Big Data Engineer will also collaborate with Teranet’s security team to ensure proper data access controls are in place, data is properly secured, and access activities are auditable.

Key responsibilities include:
Maintain and monitor Teranet’s data lake feeds
Manage, maintain and oversee Teranet’s data lake Big Data platform (Cloudera)
Prepare the data views for downstream data lake consumers (e.g. Data Scientists and Analysts)
Optimization of Teranet’s Big Data environment, applications and data views
Design, build and test data queries for data views and feeds for downstream data lake consumers
Design, build and integrate additional data sources into the Teranet data lake
Design, build and test analysis/data models to support downstream data lake consumers
You are someone who:
Continuously seeks to improve your knowledge of data analytics technologies and best practices
Strives to understand business drivers and strategy in order to understand business requirements
Takes a collaborative approach to assignments and works well with others
Is a good communicator with strong written and oral communication skills
Clearly documents your work so that it can be readily understood by others
Takes ownership and accountability for your assignments and responsibilities
Takes pride in delivering detail-oriented, thoughtful, thorough, and quality results
Key qualifications:
Bachelor’s degree in Computer, a quantitative field, or equivalent practical experience
3-4 years working with Hadoop related technologies (Spark, Hive, MapReduce, Sqoop, Impala)
Advanced software development experience with Scala, Java, SQL and Python
Familiarity with visualization and statistical modeling tools and languages (Tableau, R)",3.4,Teranet,Toronto,"Toronto, Canada",501 to 1000 employees,1991,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (CAD),-1,51.5,29,data engineer,na,0,1,0,1,0,1,1,0,0,0,0,0,0,0,0,2407,0
208,"Advanced Analyst

The EA Marketing Analytics team is looking for an analytics professional to take on the role of Advanced Analyst at our Vancouver studio. At EA, an Advanced Analyst is a Manager-level team contributor, and we are looking for someone who can take our analytics to a new level by digging into diverse data sets relating to our marketing campaigns, applying leading edge data analytics techniques, conducting experiments, extracting insights, creating evocative data visualizations and communicating recommendations to our marketing partners in ways that create clarity and influence the business.

Ideal candidate:


In addition to an ability to build statistical models that turn numbers into knowledge, we are looking for strategic business acumen and the ability to build relationships across a global network of technical, marketing, and communications teams. You need to be able to use data to become a trusted advisor to our marketing partners, allowing us to reach new heights in our player acquisition, engagement, and monetization programs. If you can combine this with a pioneering spirit, commitment to team success, and a passion for the video game industry, this might be the right job for you.

What you will do:
Work with marketing partners to understand their problems, identify those that can be best solved with data, prioritize opportunities based on impact, and provide analysis in ways that will lead to action.
Select and analyze an array of internal and third-party data sources to find the marketing signal in the noise.
Develop and evangelize methods and models for understanding how marketing channels can expand player awareness, interest, acquisition, monetization, while improving existing analytical methodologies and processes.
Analyze the return on marketing strategies, campaigns and other programs and make recommendations according to your findings.
Design crisp data visualizations and presentations to tell compelling data stories to partners and influence the business.
Produce and maintain interactive dashboards and other automated reporting to inform the business.
While not a management role, you will provide leadership, expertise, guidance and mentorship to others in the Marketing Analytics team on a daily basis.
Skills and knowledge expected:


Combination of ability and passion for using data to improve the business.
Approach analyses with structured, strategic thinking to develop a plan before digging into data.
Strong collaboration skills that allow you to excel in matrix team environments.
Skill in applying quantitative methodologies such as correlation analysis, regression modeling, cluster analysis, factor analysis to provide marketing insights.
Apply analytical thinking to organize and interpret data from marketing channels such as online video, social media, websites, email, and online ad platforms.
Programmatically collect, organize, analyze data from web APIs.
Data visualization skills that reveal the meaning in the data using tools like Tableau, R Shiny, Data Studio, Power BI, Looker.
Powerful enthusiasm for continuous learning, improvement, and sharing.
Background and technical skills:


University degree in Mathematics, Statistics, Economics, Quantitative Marketing or equivalent.
5 years relevant hands-on analytical experience, preferably in video-gaming, technology, digital marketing or media.
Proficiency in R statistical programming (or equivalent) to explore diverse data sets and create descriptive and predictive models.
SQL skills including experience querying datasets from multiple sources.",3.9,Electronic Arts,Vancouver,"Redwood City, CA",5001 to 10000 employees,1982,Company - Public,Video Games,Media,$2 to $5 billion (CAD),"Riot Games, Google, Activision Blizzard",51.5,38,data analyst,na,1,0,1,1,0,1,0,0,0,0,0,0,0,0,1,3596,3
209,"Colleagues you’ll love.
A dynamic and collaborative workplace where you can contribute to our story.
An access to over 6,000 free courses for your continuous development and career growth.
Comprehensive benefits from day one.

This is the #YPLife and what working at YP is all about.

What is a Marketing Insights Data Analyst at Yellow Pages?

Want to contribute to the development and prosperity of local small and medium-sized businesses? Welcome to Yellow Pages! As a Google Premium Partner and Facebook Marketing Partner, Yellow Pages is a leader in digital marketing for companies across Canada.

The Marketing insights data analyst is required to develop Marketing Analysis solutions and strategies that provide business insights, improve opportunity identification, and drive monetization to the business. She/He will be responsible for the production, management and delivery of key ad hoc reports to support the growth of the various aspects of the business. The incumbent individual is responsible for extracting, cleaning and presenting data to support Marketing and Sales initiatives.

Responsibilities:

ETL
Automation of Data extraction, Integration, cleaning and preparations to improve productivity and data accuracy.
Analytics
Responsible to extract and transform data into compelling information for management discussion.
Analyze, enhance and manage key performance indicators (KPIs) through effective dashboards on a weekly/monthly/quarterly basis.
Provide ad hoc analytics support for Marketing & Product teams.
Deliver crucial insight and recommendations that impact real-time results.
Reporting
Ownership of creation and distribution of current and future interactive reporting dashboard needs for various business owners across all products & Sales teams.
Why should you apply for this Marketing Insights Data Analyst position?
We bet on everyone potential rather than pressure management
We offer training, a flexible benefits package on your first day, a casual environment where you can wear jeans
We distinguish the most beautiful achievements
We propose to our employees to advance in their career according to their expectations
We work in the amazing Nordelec building which includes a gym
Work schedule from Monday to Friday daytime
What do you need to be a Marketing Insights Data Analyst at Yellow Pages?

Education, Experience and Technical skills:
University degree in Maths/Stats, business, marketing, computer science.
Strong analytical skills utilizing SQL, Excel, Stored Procedures.
BI tools and Visualization Tableau, PowerBI , PowerPoint.
Experience dealing with large & diverse Data Sources (Structured & none-Structured data).
Strong process improvement and automation skills.
Big Plus points: Python/R, Google Cloud, AWS.
Strong interpersonal and communication skills.
Soft Skills and Competencies:
A positive attitude and strong initiative.
A self-starter with ability to work independently.
Ability to interpret and make sound recommendations.
Excellent team and interpersonal skills.
Organizational skills and attention to detail.
Ability in managing multiple tasks.
You are ready to join the Yellow Pages adventure as a Marketing Insights Data Analyst? Send us your resume right now!

About Yellow Pages

We’ve been in the game since 1908 and we continue to transform to offer our 229 000 clients the best possible products and services. We foster business relationships between Canadian small-to-medium businesses and their prospective customers. We do this by providing tailored, locally-relevant digital media and marketing solutions designed with both in mind. Over 73% of our revenue is generated by digital solutions.",3.1,Yellow Pages,Toronto,"Montreal, Canada",501 to 1000 employees,1908,Company - Public,Publishing,Media,$1 to $2 billion (CAD),"Amazon, Yelp, Craigslist",51.5,112,data analyst,na,0,1,1,1,0,1,0,0,0,1,0,0,0,0,0,3673,3
210,"Company Description

null
Job Description

What you'll do

Reporting into the Senior Manager of Analytics, The E-Commerce Marketing Data Analyst, will work closely with E-Commerce teams and with teams across the company including Marketing, Media, CRM, Strategic Planning and Business Intelligence.



We are looking for:

Strong Communicator

An excellent oral and written communicator with the ability to communicate effectively with both technical and non-technical stakeholders

Analytical Thinker

You are determined in your quest to understand data. You have experience in advanced analytics, programming and statistical tools

Strategic Thinker

A strategic cross-functional thinker able to gather buy-in from senior leadership for analytical and measurement framework approaches

Web Analytics
Construct and maintain dashboards that allow users to understand performance compared to internal benchmarks and to generate insight
Transform quantitative output into actionable, realistic marketing tactics
Identify and Extract relevant performance analysis data
Contribute to defining KPIs that better reflect performance of web initiatives as executions become increasingly more robust
Coordinate Analytics projects (Tracking / Tagging, connecting technologies, point of contact for the IT support teams)
Collaborate with BI teams to understand data structure to measure customer engagement
Create narratives from complex data sources that will be consumed by broad internal audiences
Conduct ad hoc analysis for E-com teams, and management priorities
Be able to confidently present analysis in front of senior management and be flexible in adapting to unexpected questions


E-Commerce Performance Analyst
Act as company expert on e-commerce marketing performance for NCSA markets
Facilitate decision-making with meaningful analysis and reports
Perform ROI analysis on Ubisoft’s key e-commerce initiatives
Provide analysis & recommendations to senior management
Identify emerging trends and Ubisoft’s position relative to the rest of the industry
Partner closely with E-commerce teams to support marketing objectives
Provide ad hoc reporting and analysis as needed
Identify gaps and opportunities in marketing support with actionable recommendations
Effortlessly move between objective analyst role and e-commerce support role
Qualifications

What you bring
Bachelor degree in a technical or quantitative discipline (Mathematics, Economics, Statistics or other applicable fields)
Minimum 2 years experience in a similar role with hands-on data analysis
Experience in a marketing analytics role and channels performance analysis
E-commerce experience
Expert Excel and PowerPoint skills, ability to take and combine multiple data sources and present insights
Storyteller with capability to present actionable insight in a meaningful way
Experience with business intelligence and data warehouse solutions, ideally Tableau, Adobe Analytics, SQL or other related programs
Ability to work in high-pressure, time-constrained situations
Ability to manipulate and combine multiple data sources and present insights that drive business decisions at all levels of the organization
Strong quantitative skills, experience utilizing scientific analytics methods, qualitative methods, and quantitative analysis techniques, as well as predictive modeling
Must be detail oriented, self-motivated and time efficient
Strong written and verbal communication skills in French & English
Knowledge of video game industry a plus
What to send our way
Your CV, highlighting your education, experience, and skills
Additional Information

At Ubisoft Montreal, a preeminent developer of video games located in Montreal’s dynamic Mile-End neighbourhood since 1997, we offer a work environment unique in the industry for allowing you to build and cultivate games that are part of critically acclaimed, iconic AAA franchises of international repute.

When you join Ubi Montreal, you enter a community of passionate, extraordinary developers connected by their need to innovate, to be creative and to work with the latest technology. You’ll discover a world where employees enjoy constant career advancement, a supportive learning environment, and competitive compensation packages.

More than anything, at Ubi Montreal, you will regularly ship a variety of big, quality titles – Assassin’s Creed, Far Cry, Rainbow Six, Watch_Dogs, For Honor and… well we can’t disclose all our secrets just yet… – and work with some of the most talented people in the industry.

We are an equal-opportunity employer and value diversity at our company. We do not discriminate on the basis of race, ethnicity, religion, gender, sexual orientation, age or disability status.",3.8,Ubisoft,Montreal,"Montreuil, France",10000+ employees,1986,Company - Public,Video Games,Media,$2 to $5 billion (CAD),"Electronic Arts, Activision, Konami",51.5,34,data analyst,na,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,4728,3
211,"MACHINE LEARNING DEVELOPER – VISION SYSTEMS

About Visual Defence

Founded in 2000, Visual Defence Inc. (VDI) (https://www.visualdefence.com) provides integrated software-centric solutions in the areas of artificial intelligence and security. The company is headquartered in Richmond Hill, Ontario and provides services and products to customers world-wide.

Position

The Machine Learning Developer will work with Visual Defence’s Research and Development team under the guidance of the company’s Director of Research and Development. The Machine Learning Developer will help to develop, fine-tune and improve on Visual Defence’s artificial intelligence products and platforms. Visual Defence’s particular use cases of machine learning revolves around images and computer vision systems.

Job Description

§ Actively participate in the development of Visual Defence’s machine learning platform Inferware (https://www.vidiai.com) and its use cases.

§ Review and improve platform architecture, functionalities, and workflows.

§ Review and optimize models architectures and settings.

§ Fine-tune models generated for production use cases.

§ Knowledge transfer and mentorship to other team-mates.

Qualifications & Competencies

§ Strong, hands-on experience working with Tensorflow

§ Strong, hands-on experience working with Python.

§ Experience with machine learning pertaining to images.

§ Experience with object detection, classification and segmentation applications.

§ Strong verbal and written communication skills.

§ Strong organizational skills, with the ability to meet tight deadlines.

§ Excellent attention to detail and interpersonal skills.

§ Understanding of programming principals.

§ Knowledge of Windows operating systems and domain environments an asset.

§ Self-starter and demonstrate effective time management.

§ Takes rational approach.

§ Fast learner.

Education

§ Received PhD in an engineering, computer science or equivalent program within the last five years from an accredited, publicly-funded Ontario university

Reference ID: Machine Learning Developer

Job Type: Full-time

Benefits:
Dental Care
Extended Health Care
Vision Care
Experience:
Machine Learning: 3 years (Required)
Private Sector: 1 year (Required)
Python: 3 years (Required)
Education:
Post-Doctorate (Required)
Work remotely:
No",2.9,Visual Defence Inc,Richmond Hill,"Richmond Hill, Canada",51 to 200 employees,-1,Company - Private,Security Services,Business Services,$25 to $50 million (CAD),-1,51.5,-1,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,2336,0
212,"Do you have what it takes to win?

Like a championship team, a leading global sports brand is built with a solid foundation of players at all levels who have an unending desire and dedication not only to succeed, but also to win. At Peak Achievement Athletics, our championship team is deeply committed to developing the most innovative sports equipment in the industry and we are always looking to strengthen our roster with talented players.

Want to join our team as a Data Engineer?

The Data Engineer is responsible for developing and delivering a large-scale database platform that can efficiently enable our analysts to transform data into intelligence. The system design will dramatically reduce the time spent on data preparation tasks and have the inherent ability to scale with business growth and complexity. The Data Engineer will become intimately familiar with the architecture of Bauer Hockey systems & enterprise data structures, and be responsible for diving deep into code while simultaneously developing UI solutions for the Sales Operations super users. The Data Engineer will liaise with multiple technical teams and business teams across international geographies. The database management system will operate on a global scale driving automation and scaling for the wider organization. The role of the Data Engineer will include incorporating data management best practices into the scoping, design and development of the database. The Data Engineer will also be responsible for effectively organizing testing, implementation, support, and the development of user and technical documentation such as guidelines or instructions as necessary.

Qualifications:
Bachelor's degree in Computer science or a related field (MBA a plus) with 3+ years of practical work experience or the equivalent combination of education and experience.
Comprehensive knowledge of database technologies including, but not limited to Google Cloud, AWS, SQL, Hadoop, SAP HANA, and Alteryx.
Hands-on experience developing platforms that translate big data into business insight.
Strong knowledge of data structures and operating systems.
Knowledge of database maintenance and administration techniques.
Experience with Machine Learning languages is a plus.
Desire to work in a high-paced environment.
Strong problem-solving skills and the ability to work independently.
Strong written and verbal communication skills.
Interested yet? Good. Us too. We're pretty sure you'll want to know we offer one of the most generous benefits packages around. Things like a 401(k) retirement plan, casual work environment, and a host of other perks we don't have room to mention here.

We're interested in learning more about you and appreciate you taking the time to apply online at www.bauer.com.

Only those persons chosen for an interview will be contacted.

Peak Achievement Athletics is committed to employing a diverse workforce.",3.6,Bauer Hockey,Mississauga,"Exeter, NH",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,51.5,-1,data engineer,na,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,2918,0
213,"About the Opportunity:

As part of the Data Hub team at AIR MILES, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flows and collection for cross functional teams. The pipeline needs to be scalable, repeatable, and secure. You will work with some of the largest and most varied data sets (both batch and real-time) in Canada. You will expand and develop the AIR MILES Cloud analytical platform that enables business users, data analysts and data scientists to make data driven decisions, build innovative data products and roll out advanced analytics.

What will you bring?
Ability and desire to work in our collaborative environment: open team room, pair programming and fluid interactions with all products and operations teams.
Focusing on building solutions utilizing an agile approach: close relationships with Product Managers, communicating and digesting real time feedback, and working smartly to build story cards on daily basis.
Passionate about Big Data and the latest trends and developments. We strongly believe in and encourage continuous learning.
You are self-driven, need minimal supervision and comfortable pushing your own projects and getting things done.
Experience with Python, Spark, and SQL
Experience building ‘big data’ pipelines, architectures, and datasets
Experience with Amazon AWS and other cloud platforms
Experience with Databricks
Experience with Agile methodologies as well as familiar with CI/CD tools (Jenkins, Travis, github)
Experience in ETL and Data Modeling preferred
Experience in designing and implementing streaming applications is preferred
Fully understand standard architecture methodologies, processes and best practices
About AIR MILES

Today, there are more ways than ever to engage shoppers. At AIR MILES, we believe that understanding the people behind the purchase is key to winning their hearts – and their wallets. For over two decades and from more than fifty locations around the globe, we have paired expertise in shopper behavior with advanced analytics to uncover the data-driven insights that drive successful loyalty, marketing and merchandising solutions. At AIR MILES, we know that in coming together we are at our strongest – and that together we can help shape the future for our clients, their shoppers and our communities. AIR MILES is an Alliance Data company. For more information, visit www.loyalty.com

About ADS

Alliance Data® (NYSE: ADS) is a leading global provider of data-driven marketing and loyalty solutions serving large, consumer-based industries. The Company creates and deploys customized solutions, enhancing the critical customer marketing experience; the result is measurably changing consumer behavior while driving business growth and profitability for some of today's most recognizable brands. Alliance Data helps its clients create and increase customer loyalty through solutions that engage millions of customers each day across multiple touch points using traditional, digital, mobile and emerging technologies. An S&P 500 and Fortune 500 company headquartered in Plano, Texas, Alliance Data consists of three businesses that together employ more than 16,000 associates at approximately 100 locations worldwide. For more information, visit www.alliancedata.com

Alliance Data is an Equal Employment Opportunity employer. Accordingly, we will make reasonable accommodations to respond to the needs of people with disabilities in accordance with legislation.

Alliance Data participates in E-Verify.

Check us out – AIR MILES on Stack Overflow | LinkedIn | Glassdoor | Facebook |Twitter | Blog | Instagram

Company: AIR MILES",-1.0,AIR MI,Toronto,"Toronto, Canada",501 to 1000 employees,1992,Company - Private,Advertising & Marketing,Business Services,$2 to $5 billion (CAD),-1,64.0,28,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,3691,0
214,"Junior GIS Data Analyst
Mississauga
Reference ID: 232072411

Sitechs is partnering with one of our Fortune 500 clients to search for a passionate, dedicated and driven Junior GIS Data Analyst. It is a contract, full-time position.

Your primary duties will be to support an advanced GIS and analytics team with your expertise in GIS and data, including ETL, Digitizing, Spatial Analysis, Validation, and Development. The project will have broad implications in the Canadian tech markets and have a direct impact on consumers across the country. If you’re looking for a challenge in a fast-paced environment with tight deadlines and enterprise data infrastructure, Sitechs welcomes your application.

Responsibilities:
· Digitize Geo-spatial Assets, as well as locate and integrate new Geo-spatial assets
· Support the design of large-scale maps as required
· Support the maintenance, storage and retrieval of assets used as components of geo-spatial data
· Integrate GIS data with other data sources and platforms to improve analysis
· Perform ETL processes on a daily basis
· Review and contribute to existing code / query base
· Write high-performance queries to work efficiently with massive datasets
· Perform data validation, cleaning, and QA to ensure database accuracy
· Collaborate with cross-functional teams to optimize outputs and results
· Support other project team initiatives, including business operations and ad-hoc requests as required

Skills Required:
· Degree/Diploma in GIS, Geospatial Management, Geographic Analysis, Spatial Analysis, Geography, Engineering, Geomatics, Math, Computer Science, or a related discipline
· 1-2 years of experience in MySQL or SQL Server
· 1-2 years of experience in using ArcGIS
· Proficiency with joins, subqueries, pattern matching keywords, advanced functions etc.
· Experience working with and developing triggers, stored procedures and functions
· Working knowledge of geospatial queries
· Ability to quickly learn new technologies in a fast-paced environment
· A dedicated work area and relevant equipment are strongly preferred for this position

We are an equal opportunity organization, and we actively promote diverse work environment and encourage applications from all persons. If you are interested, please submit your application today in PDF form.

Job Types: Full-time, Contract

Work remotely:
Temporarily due to COVID-19",3.9,Sitechs.Inc,Mississauga,"Brisbane, Australia",51 to 200 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,64.0,-1,data analyst,junior,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2392,0
215,"Summary

The Data (bio)Informatics Science and Engineering (DISE) team at Decipher Biosciences is a passionate group of scientists and software engineers striving to use the best science and engineering knowledge to develop data pipelines and software that make genomic data actionable to cancer patients and their doctors. We develop and deploy machine learning models based whole transcriptome gene expression data to reveal new insights in cancer biology. We also develop software/apps that facilitates better data visualization and interpretation for colleagues, physicians, and patients. We are responsible for maintaining and analyzing one of the largest proprietary transcriptomic data sets in oncology.

As a data scientist, you will work closely with a team of research and production professionals. You will be a key member in preparing, interpreting and analyzing business, genomic and clinical data, providing analysis support to our colleagues and our external partners. You will also participate in our data-related software design, development, and maintenance. This role requires a broad knowledge of cancer biology, oncology, bioinformatics, statistics, and programming, paired with effective communication skills, a strong sense of diligence, and timeliness.

Duties and Tasks
Perform data analysis that contributes to the process improvement of Decipher products
Contribute the design of experiments focused on assay improvement.
Conduct data analysis in support of biopharma clinical trials and collaborations
Support development of novel genomic signatures
Design and implement data reports and dashboards
Contribute to manuscript drafting for peer-reviewed journals and patent filings
Support and assist colleagues and external collaborators in data preparation and analysis
Understanding, maintaining, and improving various databases and schema
Contribute to the maintenance and improvement of the data processing pipelines, automating common data analysis routines into software packages or applications.
Contribute to the research and development of applying latest developments of AI technologies to the Decipher data.
Qualifications:
Graduate degree from a quantitative field with strong programming experience (data science, statistics, bioinformatics, or equivalent).
Proven experience in analysis and interpretation of large-scale gene expression data (microarray, sequencing).
1 year + experience in data science and quantitative data analysis.
1 year + experience in working with cloud platform like GCP.
Familiar with a Linux environment and shell scripting. Experience working with source control tools (Git) in a collaborative programming environment.
Knowledge in cancer biology and genomics. Work/research experience with public genomic data platforms (GEO, CBioPortal, MSigDB, etc or equivalent) is a plus.
Extensive experience of working with R or Python. Experience of building and testing customized R packages.
Software engineering experience in a programming language (GO and Javascript is preferred) is a plus.
Experience in performing complex data analysis on large volumes of data and present findings to collaborators.
Experience in drafting and publishing scientific research papers and addressing comments and feedbacks from collaborators and reviewers.
Strong interpersonal and communication skills (both written and verbal); ability to communicate with people in a wide variety of areas and at various levels from technical specialists to executives
Ability to quickly and efficiently adapt to new concepts and collaborate with cross-function teams and business units.
Critical thinking
Curiosity and eager to learn.
Powered by JazzHR",-1.0,Decipher Bioscien,Vancouver,-1,-1,-1,-1,-1,-1,-1,-1,64.0,-1,data engineer,na,1,1,0,0,0,0,0,0,0,0,0,0,1,0,1,3685,0
216,"Title: Data Engineer
Job ID: MK151996610
Location: Vancouver, BC

Our client is looking for a Data Engineer to develop, manage and maintain all the data sources.

What you’ll do:
Develop, manage, and maintain an up to date map of all the data sources
Create, implement, and enforce data management policies, procedures, and standards,
Monitor data health, data quality, and compliancy according to client's data policy,
Design, build, and launch efficient and reliable data pipelines to move and transform data,
Develop additional tools and refine processes to help with analytics at client,
Collaborate with the customer engineers, data analysts/scientists, and business owners
Fit in a people-first culture of teamwork and respect,
What you’ll need:
3-5 years of experience of working in start-ups and larger companies in a high-tempo, dynamic environments,
Excellent documentation skills,
must have experience with SQL
Experience with at least one scripting programming language, such as Python or Go
Knowledge of at least one backend programming language, such as Java or Scala,
Experience with MS Azure stack. Work experience with ADF would be an asset
Strives to stay up to date with the best practices of data management,
Has worked in the healthcare market before, an asset
For more information about TEEMA and to consider other career opportunities, please visit our website at www.teemagroup.com",4.7,TEEMA,Vancouver,"Litchfield Park, AZ",201 to 500 employees,2008,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (CAD),-1,64.0,12,data engineer,na,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,1405,0
217,"Position

OpsGuru is a global engineering and consulting group. We are experts in the container ecosystem, data processing and analytics, and cloud-native technologies. Our team is formed by network, data, security, DevOps specialists and application developers. OpsGuru empowers customers with technology to solve their business problems and provide the tools to assure success in their digital transformation.

As a Data Engineer, you will be part of the OpsGuru professional services team architecting, designing, automating, and deploying production-grade data services and flows on behalf of our customers to a variety of public clouds such as AWS, Google Cloud and Azure.

Daily Responsibilities
Building complex ETL code using technologies such as; Spark, Nifi, Glue
Building real-time streaming solutions
Developing code using Python, Scala, R languages
Creating complex data solutions and build data pipelines
Establishing credibility and build impactful relationships with our customers
Qualification & Skills
5+ years’ design & implementation experience with distributed applications
3+ years’ of experience in production database architectures and data pipeline development
Demonstrated knowledge of software development tools and methodologies
Experience with Open Source Big Data projects such as; Cassandra, ElasticSearch, Spark, Flink, Kafka.
Public cloud experience (AWS, Google Cloud or Azure)
Excellent communication skills with an ability to right level conversations
Technical degree preferable; Computer Science or Math background desired
Demonstrated ability to adapt to new technologies and learn quickly
Job Types: Full-time, Contract

Benefits:
Work From Home
Schedule:
8 Hour Shift
Monday to Friday
Experience:
Knowledge of software development tools and methodologies: 2 years (Preferred)
Cassandra: 1 year (Preferred)
Kafka: 1 year (Preferred)
Public Clouds (AWS, Azure or Google Cloud): 2 years (Preferred)
Spark: 1 year (Preferred)
ElasticSearch: 1 year (Preferred)
OpenSource: 1 year (Preferred)
Big Data: 1 year (Preferred)
database architectures and data pipeline development: 3 years (Preferred)
Flink: 1 year (Preferred)
Work remotely:
Yes",-1.0,OpsG,Vancouver,"Vancouver, Canada",1 to 50 employees,2018,Company - Private,IT Services,Information Technology,$10 to $25 million (CAD),-1,64.0,2,data engineer,na,1,1,0,0,0,0,1,0,1,1,0,0,0,0,0,2175,0
218,"Experienced Data Engineer
Overview

Marketmuse Inc.'s M4 Lab is seeking an experienced Python & Java/Scala engineer to help create the next generations of content analytics and content generation technologies. This role blends production software development, big data, and machine learning. The engineer will work on natural language processing systems that try to understand the semantics, intent, and topical structure of vast amounts of web content at scale. This role requires extensive knowledge and experience in architecting and developing data-intensive applications.
About Us

Marketmuse Inc. is a rapidly growing institutionally-backed content planning technology firm with offices in Montreal, Boston, and New York City. We are the premier provider of enterprise content planning technologies and are recognized as a leading technology for content marketing functions. MarketMuse's new M4 Lab (the MarketMuse Montreal Machine Monograph Lab) will be a hub for our advanced machine learning and data sciences teams working on cutting-edge R&D to improve our systems' quality of content understanding, knowledge representation, and machine learning powered content generation assistance tools. Our software also helps our clients optimize or create content ranging from short blog posts to long whitepapers.
Responsibilities

Design and implement reliably distributed data pipelines
Implement scalable architectures of machine learning prototype solutions geared towards solving natural language processing, knowledge representation, and natural language generation problems
Create parallelized and/or distributed versions of existing algorithms
Maintain and develop existing machine learning models
Collaborate with research scientists, architects and product management to design and program innovative strategic and tactical solutions that meet market needs with respect to functionality, performance, reliability, realistic implementation schedules, and adherence to development goals and principles
Gather and determine requirements for new features from internal colleagues

Required Skills

Experience with architecting data-intensive applications
Experience writing software in Python, Scala and/or Java. Experience working with data structures, algorithms and software design
Knowledge of data warehousing concepts, including data warehouse technical architectures, infrastructure components, tools and environments (such as Apache Beam, Hadoop, Spark, Pig, Hive, MapReduce, Flume)
Experience with test-driven development
Experience working effectively with software engineering teams
Mentor others in achieving their career growth potential

Required Education and Experience Level

At least 5 years of engineering experience with Java/Scala/Python
At least 2 years of distributed or highly threaded software development experience

Preferred But Optional Skills

MS in Computer Science, Computer Engineering or related fields
Experience with workflow tools like Airflow, Luigi, etc.

Experience with data mining or machine learning applications
Hands-on experience implementing new research ideas with a neural network training framework such as Tensorflow, Keras, or PyTorch",4.5,MarketMuse,Montreal,"Boston, MA",1 to 50 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,64.0,6,data engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,3195,0
219,"About the Company

Created in 1989, SCALIAN is a leading multinational engineering consultancy firm specialized in Digital Systems and Operation Performance.Our expertise serves various technological sectors; aerospace, defense, railway, energy, healthcare, banking, IOT and the manufacturing industry, providing distinctive support to their development and operations. SCALIAN works with top companies where our collaborators play a critical role on some of the most challenging projects out there. This guarantees that our team is constantly expanding their expertise and knowledge horizon meanwhile supporting some of the best companies in the world.

As Canada has recently become a major hub for technology, Scalian has exported its know-how across the Atlantic. Since its creation in 2014, the Canadian subsidiary has experienced rapid growth and created strong relationships with its customers while constantly growing its client portfolio. In order to continue this beautiful success story, Scalian Canada is looking for new talents who wish to actively participate in spreading our value and expertise

Your Mission

As a member of the Data Engineering team, your mission is to actively participate in company’s Data Strategy and its evolution. Your work will allow the company to offer better services and develop new products based on data.

Role & Main Responsibilities
Be a key contributor to the Data Strategy
Create and maintain optimal and scalable data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and ‘big data’ technologies.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Keep data separated and secure across national boundaries through multiple data centers.
Be an active member of the business transformation
Work with stakeholders including the Executive, CX and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Be an inspirational and motivational colleague
Be an inspirational and motivational colleague
Share knowledge with team members & participate in various learning-sharing activities
Contribute to the collaborative and stimulating work environment
Be a change agent & Agile mindset promoter
Be connected to the industry to know tendencies and suggest innovative ideas
Qualifications
Softskills
Willingness to participate in all levels of project work when necessary.
Excellent English and French written and verbal communication skills.
Join the engine that is changing the company, pointing towards the next horizon of growth through digital innovations to support our customers in their success.
Technical skills
Bachelor's degree in Computer Science, Engineering, or related field.
A minimum of 3 years industry experience working with data, coding and scripting (Python/Java/Scala/SQL/JS/Bash), design and testing.
A minimum of 3 years experience developing and administering large data systems.
Solid knowledge of CS fundamentals in algorithms and data structures.
Experience supporting and working with cross-functional teams in a dynamic environment. Experience with big data tools: Hadoop, Spark, Kafka.
Experience with relational SQL and NoSQL databases, including SQL Server and CosmosDb.
Experience with automated data pipeline and workflow management tools: DevOps, ARM, Data Factory, Airflow.
Experience with Microsoft cloud services: Azure, Databrick.
Experience with stream-processing systems: Storm, Spark-Streaming.
Job Type: Full-time

Benefits:
Dental Care
Extended Health Care
Life Insurance
RRSP Match
Vision Care
Schedule:
8 Hour Shift
Overtime
Work remotely:
No",3.7,Scalian Inc,Montreal,"Labege, France",1001 to 5000 employees,1989,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,64.0,31,data engineer,na,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,4076,0
220,"Share this job

Location

Montreal
Department

Data & Analytics
Type

full-time
Requisition ID

6921

Apply now

Role description


At Unity Technologies, we believe that the world is a better place with more creators. The Unity Engine is a premier platform for a variety of different 2D and 3D real time interactive media experiences across multiple platforms. From the business of gaming to Film, Animation and Visual Effects and other cutting-edge AR/VR interactive experiences and Industrial Simulations. At DeltaDNA (a division of Unity Technologies) we provide services into the games industry, helping developers and publishers of games to engage with their player base in greater detail. Using our innovative analytical tools to understand player behaviour our clients can then create the best ingame offers and perks. These tools help to create a better all round gaming experience for gamers which in turn helps to drive commercial success. DeltaDNA is a part of Unity Monetization, that specifically, enables developers to grow a successful business around their content through advertising, in-app purchase, and services that optimize player lifetime value to monetize games and other mobile applications.

As Insight Consulting Lead you will lead a team of data scientists and game designers that work with clients to help them gather insights on player experiences to make their games more successful. In addition you will work with marketing, clients partners and product colleagues to promote best practices across the industry and help our clients improve the sophistication of their player management.

Responsibilities
Oversee the execution and completion of insight consulting projects
Manage staff responsible for project deliver, serves as a mentor to team members for technical and consulting skills and ensure high standards of outputs
Provide oversight on project profitability, work prioritization and labor planning
Provide expert pre-sales support to Client Partners and content ideas for marketing on industry trends and best practices
Support platform R&D to embed best practices into our technology solutions
Perform statistical analysis to reveal robust relationships between behaviors and key outcomes like player churn and spending.
Liaising with other analysts and the design team to produce and implement data-driven recommendations to improve game performance and deliver project results in the form of both written reports and client presentations.
Requirements
Experience in an analytic role
Experience with modern relational databases (e.g. Redshift, Vertica, etc) and SQL
Statistical computing in R, Python or similar
Proven consulting experience
Bonus points
Experience of Tableau
Looker Software Experience
An interest in games and basic understanding of the revenue models used in the industry (e.g. premium pricing, micro-transactions, free to play, etc
Excellent verbal and written communication skills including the ability to communicate insights passionately to clients
About Unity Technologies

Unity is the world’s leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity’s platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company’s 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com.

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

Chez Unity Technologies, nous pensons que le monde se porte mieux avec plus de créateurs. Le moteur Unity constitue une plateforme privilégiée pour une grande variété d’expériences interactives 2D et 3D en temps réel sur de multiples plateformes, de l’industrie du jeu vidéo et ses animations aux effets spéciaux du cinéma, en passant par d’autres expériences interactives RA/RV de pointe et les simulations industrielles. DeltaDNA est une division de Unity Technologies qui propose des prestations de services dans le secteur des jeux vidéo, en aidant les développeurs et les éditeurs à établir un dialogue plus fructueux avec leurs joueurs. Grâce à nos outils d’analyse innovants destinés à comprendre le comportement des joueurs, nos clients peuvent ensuite proposer des offres et des avantages de qualité dans le jeu. Grâce à nos outils d’analyse innovants, nos clients sont en mesure de créer une meilleure expérience globale pour les joueurs, contribuant ainsi à leur succès commercial. DeltaDNA fait partie de l’équipe de monétisation de Unity, qui permet aux développeurs de monétiser les jeux et autres applications mobiles pour générer une activité commerciale fructueuse autour de leur contenu au moyen de la publicité, des achats intégrés et des services visant à optimiser la valeur du joueur tout au long de son cycle de vie.

En tant que responsable du service de conseil, vous dirigerez une équipe de spécialistes des données et de concepteurs de jeux qui travailleront avec les clients pour les aider à recueillir des informations sur les expériences des joueurs, dans le but de renforcer le succès de leurs jeux. Par ailleurs, vous travaillerez avec les services marketing, les clients partenaires et les collègues spécialistes des produits pour promouvoir les pratiques exemplaires dans l’ensemble du secteur et aider nos clients à perfectionner la gestion de leurs joueurs.

Responsabilités
Superviser l’exécution et l’achèvement des projets de conseil en matière de connaissances
Gérer le personnel responsable de l’exécution des projets, faire office de tuteur auprès des membres de l’équipe en ce qui concerne les compétences techniques et garantir des résultats de grande qualité
Superviser la rentabilité des projets, la hiérarchisation des travaux et la planification du travail
Fournir un soutien d’avant-vente spécialisé aux clients partenaires et proposer des idées de contenu marketing sur les tendances et les pratiques exemplaires du secteur
Soutenir la recherche et le développement de la plateforme pour intégrer les pratiques exemplaires dans nos solutions technologiques
Procéder à une analyse statistique afin de déterminer les liens étroits entre les comportements des joueurs et les principaux résultats observés, notamment la rotation des joueurs et leurs dépenses
Collaborer avec d’autres analystes et l’équipe de conception pour formuler et appliquer des recommandations fondées sur les données, dans le but d’améliorer les performances du jeu et produire les résultats des projets sous forme de rapports écrits et de présentations aux clients
Exigences
Expérience dans un poste à caractère analytique
Expérience avec les bases de données relationnelles modernes (par exemple Redshift, Vertica, etc.) et SQL
Calcul statistique (R, Python ou similaire)
Expérience avérée en matière d’expertise-conseil
Atouts
Expérience avec Tableau
Expérience avec Looker Software
Un intérêt pour les jeux et des connaissances de base sur les modèles de revenus utilisés dans l’industrie (par exemple, tarification premium, microtransactions, jeu gratuit, etc.)
Excellentes aptitudes à la communication orale et écrite, y compris une capacité à communiquer les idées aux clients avec enthousiasme
À propos de Unity Technologies

Unity est la plateforme la plus utilisée au monde pour la création et l'exécution interactive de contenu 3D en temps réel (RT3D). Des créateurs, notamment des développeurs de jeux vidéo, des artistes, architectes, concepteurs automobiles et cinéastes, utilisent Unity pour donner vie à ce qu'ils ont imaginé. La plateforme de Unity offre un ensemble complet de solutions logicielles pour créer, exécuter et monétiser du contenu interactif 2D et 3D en temps réel pour les téléphones mobiles, les tablettes, les ordinateurs, les consoles et les appareils de réalité augmentée et de réalité virtuelle.

Notre équipe de plus de 1400 personnes assignées à la recherche et au développement fait en sorte que Unity soit à l'avant-garde du développement et assure un soutien optimal pour les plus récentes technologies et plateformes. Les applications développées par les créateurs au sein de Unity ont été téléchargées plus de trois milliards de fois par mois en 2019, sur plus de deux milliards d'appareils uniques. Pour en savoir davantage, visitez le site www.unity.com.

Unity est un employeur axé sur l’égalité qui s’engage à créer un environnement inclusif, innovateur et ce avec les meilleurs talents. Nous offrons des opportunités d’emploi qui ne tiennent pas compte de l’âge, de l’ethnicité, de la religion, des limitations fonctionnelles, du sexe, de l’identité sexuelle ou d’un tout autre statut protégé conformément à la loi. S'il y a des préparatifs que nous pouvons faire pour vous aider à avoir une expérience d'entrevue confortable et positive, n’hésitez pas à nous en faire part.

Les chasseurs de tête et les agences de recrutement ne peuvent pas soumettre un résumé/CV directement sur notre site web ou à un de nos gestionnaires. Nous n’acceptons pas d’être spontanément sollicités par un chasseur de tête et ou une agence; une entente devra être signé entre les deux partis.

#LI-JS1 #SEN",4.9,Unity Technologies,Montreal,"San Francisco, CA",1001 to 5000 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Epic Games, Electronic Arts, Zynga",64.0,15,data analyst,senior,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,10366,3
221,"We’re revolutionizing the way humanity eats, and there’s a lot of room for optimization and growth. That’s where you come in. Your ingenuity will help us continue to drive innovation, making an impact on the reliability, performance, and scalability of Skip’s industry-leading technology.

Think you have what it takes to join an elite team of software developers, engineers, and data scientists? If you want to make your mark on a national brand’s industry-leading technology, Skip’s Engineering Team is the place for you. They drive the innovation of Skip’s platform by improving the reliability, performance, and scalability of the network. GPS tracking, real-time order processing, scheduling, and balancing are just a few of the pieces the Engineering Team integrates into Skip’s world-class service.

What’s On Your Plate:

As a member of our Data team, you will be responsible for the design and implementation of software for systems that power Skip’s Business Intelligence and Data Warehouse. Your experience with cloud technologies and big data provides you with the background to quickly implement changes. Your experience in data management and SQL allows you to contribute to the expanding expertise of the team and keep data components current as product feature change.

Recipe for Success:

Education:
Computer science, software engineering or related degrees
Experience:
Strong experience working with both batch and real-time ETL involving large data sets.
Strong hands-on experience with Python.
Experience in REST APIs is nice to have.
Experience working with AWS and/or Google Cloud Platform environments.
Experience working with MPP databases such as Redshift, Big Query, Teradata and/or columnar databases.
Familiarity with scheduling tools like Airflow.
Strong in Dimensional Modeling concepts.
Experience using version control software, such as Git.
Work well both independently and as part of a team. You will actively participate in design discussions and code reviews.
We are looking for people who:
Have a great attitude.
Thrive in a rapidly evolving environment.
Are eager to contribute to the growth and development of the team.
Work with an entrepreneurial sense of urgency.
Are receptive to feedback and challenging experiences.
Are actively involved in their ongoing personal growth and learning.
How We Work:
We take ownership of our work and work closely with our team.
We move quickly, take risks, and know how to manage the risks.
Regularly refactoring to improve our existing systems — technical debt isn’t an excuse.
Unit tests and code reviews are at our core — confidence in our pull request is the result.
We constantly push our Data technology, design, and architecture forward to meet new challenges.
We face challenges no one can predict — we meet them head-on as a team.
When we have an idea that serves a need, we run with it.
Our teams are kept tight and efficient.
Why work at Skip?

Picture this: you, dressed in your fave casual attire, amongst a team of friendly and passionate colleagues. You feel pride knowing your input and uniqueness are not only embraced but make an impact on a major Canadian company and its satisfied customers. As the company grows, so do you — you meet and surpass new challenges every day.

That’s just a small taste of what it’s like to work at one of Canada’s leading tech companies. If you’re hungry for opportunity, growth, and something meaningful in a dynamic, yet casual environment, we’d love to hear from you.

Note: All employees will be asked to sign a Consent for Disclosure of Personal Information in order to complete a background check. Job offers will be conditional upon results that the Company determines to be satisfactory.",3.3,SkipTheDishes,Calgary,"Winnipeg, Canada",201 to 500 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,64.0,7,data engineer,na,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,3724,0
222,"Vendasta is seeking a Data Engineer to ensure data quality and access in order to drive our growth and success as a company!

As a Data Engineer, you will work closely with members of our Business Intelligence and Infrastructure teams to improve data pipelines that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization. You will implement processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it. The selected candidate must enjoy coordinating with interdisciplinary teams, learn quickly, and be comfortable working independently!

Responsibilities
Maintain the integrity of the Data Mart that feeds the Looker visualization application, ensure accurate representation of data in Looker
Participate in process improvement initiatives and assist in automating processes currently requiring manual efforts
Develop and foster a working relationship with other analysts, software developers, product managers, sales, marketing, and executive
Become the expert in multiple data sources and create/implement innovative and sustainable solutions
Collaborates with analytics and business teams to improve data pipelines that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it
Writes unit and integration tests and documents work.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture

Skills & Qualifications
Degree in Computer Science or a related technical field
3+ years of development experience
Experience with programmatic workflow schedulers like Airflow, Cadence, or Luigi
Demonstrated expertise with databases and various querying techniques (SQL, NoSQL, API)
Experience with Looker or similar BI Application (Tableau, PowerBI, MicroStrategy) considered an asset
Well developed communication and presentation skills",4.3,Vendasta Technologies,Saskatoon,"Saskatoon, Canada",201 to 500 employees,2008,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (CAD),-1,64.0,12,data engineer,na,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,2339,0
223,"Toronto AI Lab: AI / Machine Learning Scientist
Location


Toronto, Ontario

Department (Org 2)


Advanced AI Lab E60018

Job Requisition

23481

Apply Now


Company:
LG Electronics R&D

Job Function:
Engineering

At LG, we make products and services that make lives better, easier and happier through increased functionality and fun. Put simply, we offer the latest innovations to make “Life Good” – from home appliances, consumer electronics, vehicle components and mobile communications to business innovations in digital signage, air conditioning, solar and LED lighting. As a global leader, we strive for greatness in product leadership, market leadership and people leadership to realize our growth strategies.

Talk about a mantra. Life’s Good with LG!

AI/Machine Learning Scientist – Toronto

LG is looking to push the boundaries of AI to build innovative product and service solutions to realize LG’s global vision for a connected world. As a part of this initiative, LG has set up an Advanced AI organization in North America centered in Silicon Valley. Further to this initiative, we are looking for passionate and talented AI / Machine Learning Scientists and Engineers for our Toronto AI Lab to work closely with the global AI labs.

You will work on advanced research to make core ML and RL algorithms faster, more accurate and more robust. You will design experiments, invent new algorithms, and create prototype implementations focusing on applications to a variety of challenging business problems in areas of IoT, Connected Home and On Device Computing. You will be encouraged to publish high quality papers and patents and collaborate with leading academia.

You will be based in our new offices in downtown Toronto and work alongside a multi-disciplinary team that includes ML/AI scientists, product managers and software developers to design and launch AI products and solutions that help predict, personalize and transform lifestyles of LG’s global footprint of devices and users.

Seniority will be commensurate with experience and accomplishments.

Principal Duties and Responsibilities
Research and develop advances to improve core AI/Machine Learning algorithms. The research focus includes (but is not limited to) the following:
Network optimization, parameter and hyper-parameter optimization, architecture search, network compression
Model adaptation and learning on the edge
Policy learning and adaptation in RL
Bayesian machine learning
Semi-supervised and unsupervised learning
Distributed learning
Read, understand, implement, and improve state-of-the-art papers in the above topics
Take ownership of projects and build proof-of-concepts (POCs)
Actively participate in the research and academic community by disseminating novel results in top conferences and journals
Stay up-to-date on developments in AI technologies and propose long term research plans
Requirements
PhD in Computer Science, Electrical Engineering, Statistics or related quantitative discipline with a focus on machine learning, optimization theory, or related areas
Strong publication record in machine learning and deep learning at top conferences and journals
A demonstrable track record of developing novel algorithms, solutions, and delivering/deploying prototypes/projects
Experience with deep learning frameworks (e.g., Keras, Tensorflow, Tensorlite, MxNet)
Software engineering experience in two or more of C/C++, Python, Scala, Java, R, Matlab
Experience working with edge-computing frameworks like, CoreML, Greengrass etc. preferred
Last, but not least, a sense of ambition and passion to change the world using AI and machine Learning",3.8,LG Electronics R&D,Toronto,"Englewood Cliffs, NJ",1001 to 5000 employees,1952,Subsidiary or Business Segment,Consumer Electronics & Appliance Shops,Retail,$10+ billion (CAD),"Samsung Electronics America, Panasonic, Whirlpool Corporation",64.0,68,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,3648,3
224,"Software Data Engineer:

Vancouver, BC / Work from Home in BC.

Our client is focused on using big data and machine learning to gather, process, and analyze large data sets and to build data services that are used by customers for cybersecurity research and threat intelligence. This is a full time position in Vancouver, BC and has flexibility to work from home.

You will work as part of a collaborative team of smart and engaged engineers. Expect to spend most of your time solving complex data processing problems and building highly scalable backend services. You will work in an environment where productivity is fostered. You will spend very little time in meetings, and you won't be distracted by processes that get in the way of high-quality results. You will work with big data and machine learning that matters.

Job Responsibilities:

· Design, code and maintain massive data gathering, processing and delivery systems

· Discover, analyze and validate new data sets to add value for our customers

· Solve necessarily complex distributed systems problems as simply as possible

· Research and employ cutting edge techniques to move well beyond internet scale data

· Architect and build data delivery solutions in a microservice environment

· Provide code reviews and design feedback for teammates

· Work with both realtime and offline data processing pipelines to get the best data available to our customers as soon as possible

· As a senior member on the team, you will also mentor more junior engineers on the team

Requirements

· Python3 experience: 2+ years

· Data Engineering experience: 4+ years

· Experience with software development in a Linux/Unix environment.

· Experience with large-scale MySQL and NoSQL (Cassandra, ElasticSearch) data sets, or a strong desire to learn

· Experience processing and serving up big data sets with technologies like Hadoop, Hive, and NoSQL databases

· Experience with web-scale data collection

· Proficient with the technologies behind highly-scalable web services (e.g. caching, load balancing, sharding).

· Positive attitude with strong attention to detail and a desire to produce high-quality results.

· History of working effectively in a small team environment. A strong team player and ability to troubleshoot complex problems.

· Experience in designing, building and maintaining large-scale data infrastructures

· Code/Build/Deployment such as: GITLAB

· Bachelor's degree or higher in Computer Science or related field

· Excellent written and verbal communication skills

· Proven ability to interact, evangelize, present and influence at all levels of companies, from C-suite to engineers

· Excited about security space!

Pluses:

· Experience with data mining or machine learning techniques.

· Experience with vast array of text codec and encoding.

· Experience delivering micro-service architectures.

· Experience with CI/CD

· Experience with Kubernetes

· Java/Scala, C, or R development experience.

· Some familiarity with front end development (AngularJS, ReactJS, JavaScript/jQuery, Ajax, CSS).

· Experience in Data Pipelines such as Kafka or Apache Airflow

· Experience with serverless technology such as Amazon Lambda or Google Compute Engine",5.0,NxT Level,Vancouver,"Tacoma, WA",1 to 50 employees,2017,Company - Private,IT Services,Information Technology,$1 to $5 million (CAD),-1,64.0,3,data engineer,na,1,1,0,0,0,1,0,0,0,0,0,0,1,0,0,3239,0
225,"Environmental Monitoring Networks Data Scientist
Research Officer 21R

This position is located in Victoria, BC. The following locations may also be considered, subject to Ministry operational requirements: Kamloops, Nanaimo, Prince George, Vancouver.
This is a temporary opportunity for approximately 2 years; this may be extended.
Board and lodging and relocation expenses do not apply for temporary opportunities.
An eligibility list may be established.

An opportunity to utilize your exceptional research expertise in the natural resource sector

The Ministry of Environment and Climate Change Strategy is responsible for protecting and enhancing the Province's natural environment. This includes providing timely information on climate change, groundwater, water quality and quantity in lakes and rivers, air quality, and providing systems to support environmental health reporting. The Environmental and Climate Monitoring Section [EMCS] is charged with providing open, scientifically-credible, comprehensive data and information on changes to climate, air, water and groundwater conditions across the Province.

The Environmental Monitoring Network Data Scientist provides specialist advice to Ministry decision makers, and technical and professional staff on the current and required composition of Environmental and Climate Monitoring networks [Hydrometeorological, Hydrological, Groundwater and Water Quality]. Specifically, this position will provide leadership in the field of data science, partnering with technical and policy partners, and other stakeholders to design, develop, and manage data science projects with the objective of informing and achieving the policy and operational objectives of government; and to oversee, design, and conduct detailed statistical analysis, and data visualizations.

For complete details about this opportunity, including accountabilities, please refer to the attached job profile. For specific position related enquiries, please contact Ted.Weick@gov.bc.ca. DO NOT SEND YOUR APPLICATION TO THIS EMAIL ADDRESS. Information and tips about how to complete your job application, including adding or editing your résumé and applying for jobs, are available at the following link: Your Job Application. If you still experience technical difficulties applying for a competition, please send an email to BCPSA.Hiring.Centre@gov.bc.ca, before the stated closing time, and we will respond as soon as possible to assist you.

The BC Public Service is committed to creating a diverse workplace to represent the population we serve and to better meet the needs of our citizens. Consider joining our team and being part of an innovative, inclusive and rewarding workplace.

With over 200 different occupations available in 280 communities across the province, we offer exciting opportunities for your career. Come, be a part of the BC Public Service, a Top 100 Employer that embraces diversity, health and career growth. For more information, please visit What the BC Public Service offers You.

NOTE: Applications will be accepted until 11:00 pm Pacific Time on the closing date of the competition.

JOB REQUIREMENTS:

To be considered for this position, your application must clearly demonstrate how you meet the education and experience as outlined below:

Degree/experience required:
Undergraduate degree in environmental science, geomatics, statistics, mathematics, geography or computer science, or related area with 3 years of experience in environmental monitoring network operations; or,
Graduate degree in environmental science, geomatics, statistics, mathematics, geography or computer science, or related area with 1 year of experience in environmental monitoring network operations.
Experience designing, implementing, interpreting, and communicating complex statistical and spatial analyses.
Experience identifying business problems and providing advice on business enhancements based on findings of data science projects.
Experience creating and delivering presentations for the purpose of decision making preferred.
Valid BC driver’s licence.
Preference may be given to candidates with one or more of the following:
Experience with monitoring technologies and applications in larger operational environmental data collection networks.
Experience creating and delivering presentations for the purpose of decision making.
Experience conducting redundancy/gap analysis for environmental monitoring networks.
Knowledge of, or experience with, Python and R statistical and spatial programming modules, ARC GIS or similar tools for analysis and data visualization.
Applicants selected to move forward in the hiring process may be assessed on the Knowledge, Skills, Abilities and Competencies as outlined in the attached Job Profile.

A Criminal Record Check [CRC] will be required.

APPLICATION REQUIREMENTS:

Cover Letter: NO - Please do not submit a cover letter as it will not be reviewed.

Résumé: YES - A résumé is required as part of your application; however, it may not be used for initial shortlisting purposes.

Questionnaire [Comprehensive]: YES - As part of the application process, you will be prompted to complete a comprehensive online questionnaire to demonstrate how you meet the job requirements listed in the job profile. Please allot approximately 60 minutes to complete the questionnaire.

IMPORTANT: Comprehensive questionnaire responses will be used to shortlist applicants against the job requirements. Please ensure you include all relevant information about your educational accomplishments and employment history, including job titles, start and end dates [month and year] of your employment, and your job related responsibilities, accountabilities and accomplishments. Ensure your questionnaire responses are complete as your résumé may not be used for initial shortlisting purposes.",3.8,Government of British Columbia,Victoria,"Victoria, Canada",10000+ employees,1858,Government,Government Agencies,Government,$10+ billion (CAD),-1,64.0,162,data scientist,na,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,5860,0
226,"As a full spectrum AWS integrator, we assist hundreds of companies to realize the value, efficiency, and productivity of the cloud. We take customers on their journey to enable, operate, and innovate using cloud technologies – from migration strategy to operational excellence and immersive transformation.

If you like a challenge, you’ll love it here, because we’re solving complex business problems every day, building and promoting great technology solutions that impact our customers’ success. The best part is, we’re committed to you and your growth, both professionally and personally.

Overview

Our Big Data Engineers are experienced technologists with technical depth and breadth, along with strong interpersonal skills. In this role, you will work directly with customers and our team to help enable innovation through continuous, hands-on, deployment across technology stacks. You will work to build data pipelines and by developing data engineering code ( as well as writing complex data queries and algorithms.

If you get a thrill working with cutting-edge technology and love to help solve customers’ problems, we’d love to hear from you. It’s time to rethink the possible. Are you ready?
What You’ll Be Doing:
Build complex ETL code
Build complex SQL queries using MongoDB, Oracle, SQL Server, MariaDB, MySQL
Work on Data and Analytics Tools in the Cloud
Develop code using Python, Scala, R languages
Work with technologies such as Spark, Hadoop, Kafka, etc.
Build complex Data Engineering workflows
Create complex data solutions and build data pipelines
Establish credibility and build impactful relationships with our customers to enable them to be cloud advocates
Capture and share industry best practices amongst the community
Attend and present valuable information at Industry Events
Traveling up to 50% of the time

Qualifications & Experience:

3+ years design & implementation experience with distributed applications
2+ years of experience in database architectures and data pipeline development
Demonstrated knowledge of software development tools and methodologies
Presentation skills with a high degree of comfort speaking with executives, IT management, and developers
Excellent communication skills with an ability to right level conversations
Technical degree required; Computer Science or Math background desired
Demonstrated ability to adapt to new technologies and learn quickly
About Rackspace Technology
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.
More on Rackspace Technology
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know.",3.6,Rackspace Technology,Calgary,"San Antonio, TX",5001 to 10000 employees,1998,Company - Private,IT Services,Information Technology,$2 to $5 billion (CAD),"USAA, Microsoft, Amazon",64.0,22,data engineer,na,1,1,0,0,0,1,1,1,0,0,0,0,0,0,0,3933,3
227,"As a leading mobile games developer, Jam City is looking to “level up” our talent for our Bingo team in Toronto. We’re on the hunt for innovators who consider themselves dynamic, collaborative and thrive in a fast-paced environment.

PERKS & BENEFITS
Unlimited Vacation, Paid Sick Days & Holidays*
100% Employee Covered Medical, Dental, Vision Plan Base Plan*
Life Insurance, RRSP matching, Flexible Spending Accounts & More*
Catered Lunches & Well-stocked Kitchens
Company Events such as movie night, pub night and more…
You'll be equipped with a high-end laptop, monitor and mobile device
Convenient location in downtown Toronto’s entertainment and technology district
*Only applies to full-time positions.

ABOUT THE ROLE
We are currently looking for a Data Analyst to join our Bingo Pop team! You will get the opportunity to work with some of gaming’s top talent, while lending your analytical talents to help us create top-tier mobile games. Our ideal candidate would have a strong appetite to learn, inquire and apply their knowledge to give informed proposals on the design of our game.
RESPONSIBILITIES
Building reports, dashboards and data visualizations that are used everyday by team leads and executives.
Developing new metrics and player cohorts to unlock insights into player behavior.
Assisting in the design of new game features.
Helping to manage billions of rows of data along with our data pipeline.
Responding to ad-hoc requests from the executive, financial or marketing teams when insights into our data are needed.
QUALIFICATIONS
BA/BS degree or equivalent.
1+ years of experience working with data on a live product.
Strong data analysis skills using spreadsheets and querying databases.
Previous startup experience is desirable, comfort in an agile environment.
Strong understanding of SQL or Redshift and proficiency in data visualization.
Strong attention to detail and proven analytical skills.
The ability to communicate and present information clearly.
An appetite to learn, grow, and take on increasingly more responsibility.
A strong desire to answer questions that can drive actionable decisions.
Knowledge of the mobile gaming industry in order to provide recommendations on game design.
NICE TO HAVE
Experience working on a free to play mobile game.
ABOUT JAM CITY
Jam City is an award-winning mobile entertainment studio providing unique and deeply engaging games that appeal to a broad, global audience.

Led by CEO Chris DeWolfe, former MySpace co-founder and CEO, and COO Josh Yguado, former 20th Century Fox executive, Jam City is the creative powerhouse behind some of the highest-grossing and most enduring mobile games. Jam City’s global franchise Cookie Jam has generated more than half a billion dollars, and Panda Pop has more than 120 million downloads to date.

The company also is the go-to studio for Hollywood, having developed immersive, narrative-rich mobile games around iconic entertainment brands. The company’s popular RPG game Harry Potter: Hogwarts Mystery was the #1 game in more than 40 countries at its launch in April 2018.

Jam City has nine studios located in Los Angeles (HQ), Berlin, Buenos Aires, Bogotá, Burbank, Cedar Falls, San Diego, San Francisco, and Toronto.",4.0,Jam City,Toronto,"Los Angeles, CA",501 to 1000 employees,2010,Company - Private,Video Games,Media,Unknown / Non-Applicable,-1,64.0,10,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,3233,0
228,"Guavus is a young and fast-growing company whose mission is to provide Communication Service Providers (CSPs) with a competitive advantage in the ability to accurately understand their mobile subscribers’ behaviors and extract value from this knowledge.

We are at pivotal point in our history where big data innovation can impact businesses and individuals in new and unforeseen ways, but we need exceptionally smart people to join our team who are:

Passionate about getting the job done,
Relentless about flawless execution,
Committed to solving problems creatively, and
Believe in the collective intelligence to design, build and engineer extraordinary products and solutions that are useful to all.

If this sounds like you, please reach out we’d love to hear from you.

Your Role

Guavus is looking for a highly motivated and talented Sr. Data Engineer to participate in the development of the most advanced solutions in the Big Data space by using agile methodologies. The developer will actively participate and collaborate with data team to design and implement data pipelines integrating advanced AI/ML models.

Responsibilities
Develop and maintain batch and streaming data pipelines with big data technologies such as Spark, Kafka, Hive, HDFS, HBase, Phoenix, Impala etc.
Work closely with data scientists to produce ML/AI pipelines.
Analyze and implement proof of concepts related to big data technologies
Analyze new technologies (DB, Storage, Compute Engines)
Produce quality code that is well documented
Qualifications and Experience
Four (4) years of experience in a data engineer position
Holder of a Degree in Computer Science or Engineering
Experience in Cloud and non-Cloud based Hadoop ecosystem
Experience in data warehousing and ETL development
Fluent in Java & with some Scala knowledge.
Fluent in SQL
Experience in performant and highly scalable applications
Experience in distributed framework and technologies e.g. Columnar Database, NoSQL and Hadoop
Experience in Linux and shell scripting.
Basic knowledge or interest in Python
Fluency in English, both written and spoken
Speaking French is an asset
Working conditions

This opportunity consists of full-time job and is located in the Mile Ex area of Montreal, Canada.",2.7,Guavus,Montreal,"San Jose, CA",201 to 500 employees,2006,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (CAD),-1,64.0,14,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,2248,0
229,"CGI has an opportunity for an Engineer to join our team in Ottawa. Attributes that define our ideal candidates will include:

Passionate for turning disparate streams of data into organized and actionable analytics
programming acumen, competency in manipulating large volumes of data, and with a solid knowledge of a broad range of technologies for data processing and modeling
Up-to-date with the latest technology trends and have a strong desire to constantly learn
Love solving complex problems and have expertise in world-class data pipelines, from batch to real time implementations
Have demonstrated ability to navigate between the big-picture and implementation details
Highly detailed-oriented with exceptional organizational and follow-through skills
Self-directed and comfortable supporting the data needs of multiple teams and projects
Exceptional communication skills, with an ability to make advanced analytics concepts accessible and understandable to non-technical business users
Value collaboration and urgency; and have a passion for driving impact

Build your career with us.

It is an extraordinary time to be in business. As digital transformation continues to accelerate, CGI is at the center of this changesupporting our clients digital journeys and offering our professionals exciting career opportunities.

At CGI, our success comes from the talent and commitment of our professionals. As one team, we share the challenges and rewards that come from growing our company, which reinforces our culture of ownership. All of our professionals benefit from the value we collectively create.

Be part of building one of the largest independent technology and business services firms in the world.

Learn more about CGI at www.cgi.com.

No unsolicited agency referrals please.

CGI is an equal opportunity employer. In addition, CGI is committed to providing accommodations for people with disabilities in accordance with provincial legislation. Please let us know if you require a reasonable accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.

Your future duties and responsibilities

Create analytical data infrastructure by gathering, processing, analyzing and structuring large volumes of data from many structured and unstructured data sources, at scale.
Design, develop and implement highly scalable, repeatable and secure data pipelines and transformation processes
Design and build transformation models and data flows for batch, real-time and complex event driven processes
Develop data ingest processes across a variety of third-party APIs, applications and file stores.
Ensure that appropriate controls are in place and all in-motion and at-rest data is secured at all times
Develop data catalogs and data validation scripts to ensure data accuracy, clarity and correctness of key business metrics
Identify and correct data quality issues, performing root cause analysis on internal and external data to answer specific business questions and identify opportunities for improvement
Employ proper data governance to ensure data security and integrity
Research and make recommendations for new data management technologies and software engineering practices. Collaborate on decisions around the use of new tools and practices
Provide guidance to a customer and project team with respect to data requirements, data gaps and level of effort required to deliver a solution
Assist in the development and delivery of pre and post sales POCs and proposals for client engagements
Produce and maintain support documentation and data dictionaries
Travel periodically in support of sales and delivery as needed

Required qualifications to be successful in this role

At least 2 years of experience working on data transformation, curation and integration for batch and near real-time in Cloud and on-prem environments
At least 2 years of hands-on experience working with Big Data technologies such as Spark, Cassandra, Hadoop and/or Hive. Working knowledge of message queuing, stream processing, and highly scalable big data data stores
2 years of experience using one of more data transformation and integration technologies such as Python, Scala, Spark, Spark-Streaming, Kafka Streams and traditional ETL/ELT tools such as DataStage and/or Informatica.
2 years of hands-on experience working with SQL and Non SQL databases such as Oracle, DB2, SQL Server, Postgres, MangoDB and/or CouchDB
Good understanding of microservices architecture and hands-on experience working with REST APIs
At least 1 year of experience working on predictive analytics and data mining projects
Self-directed and demonstrable problem-solving skills
Knowledge of modern software development techniques and methodologies
Knowledge and practice of secure software development processes
Excellent written and verbal communication skills. Ability to communicate effectively with a broad range of constituents
Ability to handle multiple priorities and deadlines
Bachelors degree or diploma in mathematics, informatics, statistics, computer science or information systems (or equivalent combination of skill and experience)",3.5,CGI,Ottawa,"Montreal, Canada",10000+ employees,1976,Company - Public,Consulting,Business Services,$10+ billion (CAD),"IBM, Accenture, Booz Allen Hamilton",64.0,44,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,1,5188,3
230,"Achievers delivers an Employee Success Platform™ that enables social recognition, which dramatically increases employee engagement and drives business success. Designed specifically to meet the needs of today’s workplace, it empowers employees to recognize each other in real time and aligns them to the goals of the company. With more than 5,000,000 annual recognitions, the Platform inspires brilliant performance in 110 countries. Visit us at www.achievers.com to learn more and join us in our mission to change the way the world works.

Why work with us?
We’re a fun-loving, passionate, and highly collaborative team
We believe in moving quickly, failing fast, and adapting to change
We’re committed to achieving technical excellence in everything we do
We value team work, learning from failure and innovation.
Why we'd want to work with you?
You have an undying passion for building world-class software
You’re positive thinking, solution focused and find opportunities instead of problems
You have superb technical chops, but you’re always striving to improve
You want to take ownership over your work and make challenging architecture decisions
You are ambitious and want to be involved in the strategic thinking of platform architecture

What would a typical day look like, you ask? Something like this:
Design, develop, and maintain the software and systems that drive our back-end systems
Extend our platform by researching and applying new technologies to solve business problems
Participate in multi-disciplinary projects with our applications and analytics teams
Contribute to our team’s growing set of development platforms, tools, and processes
Do you have what it takes? We will be responding to applicants that have:
B.Sc. or Masters (preferred) in Computer Science or related field
8+ years of relevant experience
Prior experience with microservices architecture
Experience with messaging systems, preferably Kafka or RabbitMQ
Experience with Restful API
Proficient in web frameworks and PHP as well as other server-side language such as Python, Ruby, Java, JavaScript/React etc.
Advanced knowledge of data structures and security practices
Excellent problem-solving abilities
About Achievers:
As Achievers employees, we are passionate about disruptive technology, welcome constant change, and understand the value of employee success in the workplace. We enjoy coming to work every day because we believe in our product and love our culture. Achievers is more than just a software company; we are industry leaders in the HR space.
Our headquarters are conveniently located in Liberty Village, close to bars, shops and restaurants and are highly accessible by TTC and GO Transit.
We have been recognized in numerous publications for our contributions to HR, for technical excellence and for our outstanding workplace culture:
Achievers is ranked as number 32 on the list of Top 50 Best Workplaces in Canada.
Achievers has been recognized on the 2020 list of Best Workplaces™ for Women in Canada
Achievers has been recognized on the 2020 list of Best Workplaces™ for Inclusion
Achievers has been named one of the Top 10 Employee Recognition Solution Providers Globally
Check out our platform in action here
Our employees are a diverse and inclusive team of passionate, hardworking individuals. Achievers is committed to creating an environment where our employees can do the best work of their lives. We encourage all qualified candidates to apply to join our A-Player family. Accommodations are available on request for candidates taking part in all aspects of the selection process.",4.4,Achievers,Toronto,"Toronto, Canada",201 to 500 employees,2002,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,64.0,18,data engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,3602,0
231,"What EA Sports does:

EA Sports is one of the leading sports entertainment brands in the world with top-selling video game franchises, award-winning interactive technology, and cross-platform digital experiences. We create connected experiences that ignite the emotion of sports through industry-leading video games including FIFA soccer, Madden NFL football, NHL hockey, NBA LIVE basketball, UFC, and more.

What you'll do on our team:

As a Senior Analyst working within the FIFA Analytics team, your main focus will be on FIFA's Ultimate Team mode and its in-game economy, working primarily with the live content group along with a diverse set of colleagues in analytics around the world. We're looking for a thoughtful, curious person with a passion for diving into data to uncover insights and understand how our players are engaging with Ultimate Team. Your analysis will help ensure that its economy remains well-balanced as new content is continually introduced into the in-game market, so that players of all types can find success and enjoyment in the mode. Youll not only be a data explorer and modeler, but also a storyteller and influencer, driving insights that spur bold decisions for FUT's development team.

Examples of projects you may work on include: establishing the key set of metrics that the team will use to assess the ongoing health of the in-game economy; performing analysis to determine what's driving those metrics into healthy vs. unhealthy states; creating models to predict the value of new content being introduced into the in-game market, and the impact that its introduction will have on Ultimate Team and its players.

What a Senior Analyst will do on our team:
Model trends in our data to predict the ways in which new content and campaigns will affect the in-game economy, its performance, and our players.
Develop strategic insights to help our partners make informed decisions about Ultimate Team campaign and content planning, execution and monitoring.
Receive questions from our partners, determine the best ways that our data can help answer them, and provide those insights through dashboards, reports, or presentations.
Explore player behaviour patterns in our data to identify opportunities to improve the player experience.
Present analyses and findings to our partners in a clear, understandable, and actionable way.
Become an expert in live content strategies and campaigns.
What we're looking for:
A bachelors degree in Statistics, Economics, Data Science, Analytics, Mathematics, or a related field at a minimum; a masters degree in one of these fields is a significant plus
5+ years of experience in an analytics role using data to help guide decisions, preferably in a consumer products-oriented industry (e.g. gaming, e-commerce); experience with practical applications of economic analysis is a significant plus
Excellent SQL querying skills
Proficiency analyzing large datasets in both a spreadsheet program (e.g. Excel, Sheets) and in a programmatic analysis tool (e.g. Python, R)
Experience in practical applications of statistical modeling (e.g. multivariate regression, predictive modeling, clustering, machine learning)
Familiarity with use of data visualization applications (e.g. Tableau, R Shiny)
Passion for games or sports",3.9,Electronic Arts,Vancouver,"Redwood City, CA",5001 to 10000 employees,1982,Company - Public,Video Games,Media,$2 to $5 billion (CAD),"Riot Games, Google, Activision Blizzard",81.0,38,data analyst,senior,1,1,0,1,0,1,0,0,0,0,0,0,1,0,1,3289,3
232,"At LG, we make products and services that make lives better, easier and happier through increased functionality and fun. Put simply, we offer the latest innovations to make “Life Good” – from home appliances, consumer electronics, vehicle components and mobile communications to business innovations in digital signage, air conditioning, solar and LED lighting. As a global leader, we strive for greatness in product leadership, market leadership and people leadership to realize our growth strategies.

Talk about a mantra. Life’s Good with LG!

AI/Machine Learning Scientist – Toronto

LG is looking to push the boundaries of AI to build innovative product and service solutions to realize LG’s global vision for a connected world. As a part of this initiative, LG has set up an Advanced AI organization in North America centered in Silicon Valley. Further to this initiative, we are looking for passionate and talented AI / Machine Learning Scientists and Engineers for our Toronto AI Lab to work closely with the global AI labs.

You will work on advanced research to make core ML and RL algorithms faster, more accurate and more robust. You will design experiments, invent new algorithms, and create prototype implementations focusing on applications to a variety of challenging business problems in areas of IoT, Connected Home and On Device Computing. You will be encouraged to publish high quality papers and patents and collaborate with leading academia.

You will be based in our new offices in downtown Toronto and work alongside a multi-disciplinary team that includes ML/AI scientists, product managers and software developers to design and launch AI products and solutions that help predict, personalize and transform lifestyles of LG’s global footprint of devices and users.

Seniority will be commensurate with experience and accomplishments.

Principal Duties and Responsibilities

Research and develop advances to improve core AI/Machine Learning algorithms. The research focus includes (but is not limited to) the following:
Network optimization, parameter and hyper-parameter optimization, architecture search, network compression
Model adaptation and learning on the edge
Policy learning and adaptation in RL
Bayesian machine learning
Semi-supervised and unsupervised learning
Distributed learning
Read, understand, implement, and improve state-of-the-art papers in the above topics
Take ownership of projects and build proof-of-concepts (POCs)
Actively participate in the research and academic community by disseminating novel results in top conferences and journals
Stay up-to-date on developments in AI technologies and propose long term research plans
Requirements

PhD in Computer Science, Electrical Engineering, Statistics or related quantitative discipline with a focus on machine learning, optimization theory, or related areas
Strong publication record in machine learning and deep learning at top conferences and journals
A demonstrable track record of developing novel algorithms, solutions, and delivering/deploying prototypes/projects
Experience with deep learning frameworks (e.g., Keras, Tensorflow, Tensorlite, MxNet)
Software engineering experience in two or more of C/C++, Python, Scala, Java, R, Matlab
Experience working with edge-computing frameworks like, CoreML, Greengrass etc. preferred
Last, but not least, a sense of ambition and passion to change the world using AI and machine Learning",3.4,LG Electronics,Toronto,"Seoul, South Korea",10000+ employees,1958,Company - Public,Consumer Products Manufacturing,Manufacturing,$10+ billion (CAD),Samsung Electronics,81.0,62,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,3436,1
233,"Founded over the fall of 2016 by Tech Entrepreneur Amir Mansour, BlackSwan is a fantastically fast-growing startup at the cutting edge of e-commerce and Ad Tech. BlackSwan is now exiting stealth mode and further consolidating its leadership position on the market.

This is where you come in…

What are we looking for?

You’re ambitious and pride yourself on your ferocious attention to details.
You desire to be part of an elite, all-star, all-sharing, all-learning team.
You take pride in your devoted work ethic.
You love numbers and pride yourself on your mathematical intuition
Technical Requirements
Proficiency in Elastic Stack (Kibana, logstash specifically)
Extremely strong analytical and mathematical abilities
Experience with NOSQL databases such as Elasticsearch
Expertise in Excel
Preferences will be given to candidates who have
Experience in the Ad Tech space
Experience with NOSQL databases such as Elasticsearch
Perks
Extremely Competitive package with profit sharing / bonus plan.
Stock Options eligibility for star performer.
Flexible work schedules
Endless opportunity for personal/professional growth
Work on cutting-edge technologies",4.0,Evercore,Montreal,-1,Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,81.0,-1,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1156,0
234,"Fullscript is currently seeking a Marketing Data Analyst to help us in the application and execution of analytics to drive our marketing strategy and optimize our performance. We want employees to challenge ideas, engage in technological debates, and to do the best work of their careers. If you share our values, we’d be excited to talk with you!

What’s Fullscript?

Fullscript is the ultimate, free platform for those who want to do wellness the right way — the personal way — from anywhere. This virtual dispensary has the most comprehensive catalog, integrates with EHRs, automates refill reminders, and offers evidence-based educational content. It’s an always-accessible solution that helps people get better.

How does it work?

A practitioner writes a prescription and sends it to their patient’s electronic device. The patient then purchases the products from the practitioner’s virtual dispensary, and we ship them to the patient’s front door. It’s simple but game-changing for practitioners, now freed from the hassle of inventory, supplier management, and more.

We complement our technology with industry-leading decision support, pulling out all the stops to be indispensable to practitioners. We publish a steady stream of evidence-based resources, medically-reviewed protocols, ingredient reviews, and more to support practitioners in providing patients the best possible treatment. Practitioners give more than they get, so we use our platform to give back.

What’s the role?

The Data team is a key strategic partner at Fullscript, responsible for providing reporting and analytical support for all internal functions to drive effective planning and decision making. Reporting to the Director of Data Analytics, the Data Analyst will be embedded in our Marketing team, performing in-depth exploration and analysis of marketing data in order to guide goals, improve processes and drive recommendations.

This position is located in our Ottawa, Canada office.

What you’ll do
Proactively identify opportunities for tracking and testing of marketing activities (lead generation, campaigns, ads, content, events) with the goal of optimizing performance.
Track and report on project and initiative success by setting appropriate goals, monitoring performance and creating and executing comprehensive analysis plans.
Translate business requirements into analytical projects to identify trends, solve challenging problems and deliver insights.
Present reports and analytical results to key business stakeholders, effectively communicating key findings and recommendations.
Optimize data collection and funnel attribution to broaden the understanding of our lead generation engine and enable opportunities for efficiency and growth.
Champion innovative analytical ideas that enable new opportunities.
What you bring to the team
Minimum of Bachelor’s Degree in a quantitative, analytical or similar field with 2+ years of relevant experience successfully working in an analytical role using relational databases.
Strong, hands-on experience with SQL, data modelling, dashboarding and reporting, with the ability to interpret findings and produce meaningful insights.
Experience with attribution modelling and funnel metrics.
Experience with digital data capture, tagging and the use of digital analytics tools (e.g. Adobe Analytics, Google Analytics, etc.).
Creative problem-solving skills with a passion for uncovering strategic opportunities and solving business problems.
Experience with predictive modelling using analytics packages in languages like Python.
Proven ability to work independently in a fast-paced environment, managing competing priorities on multiple simultaneous projects.
Demonstrated attention to detail.
Strong written and verbal communication skills with the ability to effectively communicate complex ideas and concepts to business users.
Bonus if you have
Experience with a marketing automation tool such as Marketo.
Experience in B2B or SaaS, working in a high-growth environment.
Interest or experience in Health Tech, Integrative Medicine, or supplements.
What do we offer?

We offer competitive pay, a diverse benefits package, a training budget, a discount on supplements, and generous paid time off.

Our Wherever You Work Well policy lets you choose your own office — whether that’s in-person, at home, or both, it’s totally up to you. Many of us organize clubs and get-togethers to meet like-minded people and to make our company a fun place to work. We also believe pups make life better, which means some of our locations are dog-friendly.

What now?

By working at Fullscript, you choose to work in a community of intelligent, diverse, authentic, and talented people. We aren’t afraid to get our hands dirty – or medical-grade clean, that is – to get the job done. If you decide to join the team, you’ll get a chance to shape the future of our company and the integrative health industry.

If this sounds good, apply here. If you’re not sure if your experience matches this listing, apply anyway – we’d love to hear from you.

Want to learn more? Check us out at www.fullscript.com or find us on social media.

Fullscript is committed to diversity in its workforce and is proud to be an equal opportunity employer. We are excited to work with talented people, period. All employment decisions are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national or ethnic origin, gender, age, disability, sexual orientation, gender identity and/or expression, marital or civil status, political affiliation, family or parental status, or any other status protected by the laws or regulations in the jurisdictions in which we operate.

Our team handles a lot of sensitive health information, which means we require all candidates that receive and accept employment offers to complete a background check before being hired.

We are also committed to providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an email to accommodations@fullscript.com and let us know the nature of your request and your contact information.",4.7,Natural Partners Fullscript,Ottawa,"Ottawa, Canada",201 to 500 employees,2012,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,81.0,8,data analyst,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,6263,0
235,"Job Description
Join an exciting team of actuaries, data scientists and engineers at the forefront of using data to drive decisions at every level of our organization. The insurance industry is undergoing a transformation and you get to be in the driver’s seat of this data-driven, technology revolution.

You will work on impactful projects that range from predicting customer life-time values and optimizing customer journeys to incorporating novel data sources for building cutting-edge pricing algorithms. You will leverage machine-learning algorithms to automate and predict claim outcomes and find new and innovative ways to impact our customers. This team is exploring the frontiers of the insurance business such as how to harness the data from connected homes and cars to deliver new types of products to customers.

As a senior data-scientist, you will be part of a dynamic small team with exposure to different business partners and direct influence on future products and innovative solutions. You will propose machine-learning and statistical models for practical applications that impacts millions of customers. You will also mentor and guide your peers in novel approaches and provide peer review for their work. The team has already developed algorithms used in production systems and you will be part of the team that expands the scope of these algorithms. This is your chance to join the InsureTech revolution!

The insurance industry has entered a period of unprecedented change, disruption and rapid technological development. Aviva recognizes that in this rapidly changing environment building a distinctive capability in Data Science is critical - demonstrating this commitment through the development of our Data Science Practice. If you are passionate about Data Science and leveraging your analytical prowess to tackle business challenges, this role could be for you. We are embracing new technology and exploring new ways of working. With our constant advancement, you will be at the forefront of a fast-evolving field. These exciting roles are at the heart of a high-performing Data Science team that is transforming Aviva in the Digital age. Here, we are creating a long-lasting legacy and optimizing every customer’s experience.

What you need to succeed

As a senior data-scientist, you will need the following skills and experience to succeed in the role:
An educational background in computer-science or engineering, math, statistics, physics or related field. A minimum of MSc is required and Phd preferred.
5+ years of experience with model development and working with large datasets. This can include experience from any industry or academia (post-doc experience).
5+ programming experience in Python or R with good grasp of software engineering standard methodologies such as code-reusability, modularity, use of repos, etc.
Python/R /Dataiku
REST/XML/JSON/API ingestion
Spark/Impala/Hive
Expertise in machine learning theory and predictive modelling lifecycle
API configuration
Conformance/Alignment to IT/Enterprise Architecture standards (where applicable)
Relevant experience in P&C (preferred)
Shiny App development

Geo-analytics experience (ESRI/KML/KMZ layer development) with specialization in weather & environmental data ingestion
What sets you apart
A growth mindset with versatile skills and able to work through problems from first-principles.
A portfolio of projects that demonstrate your ability to draw inferences from data. This includes participation within the broader data science community including Kaggle competitions or any personal projects with open data.
A can-do teammate who is willing to roll-up the sleeves and do whatever is needed to move projects forward. That means at times you will wear different hats and be a project manager, developer, modeler and chief communicator of solutions.
Amazing people skills and able to translate and communicate complex algorithms to non-technical individuals. Someone who understands that it is not enough to just have a phenomenal algorithm but meaningful to build an agreement for the solution from different partners.
The best problems in the industry are yet to be articulated. We need someone who is creative, self-motivated and can lead projects independently.
Position Objectives
Provide data support to Claims business inclusive of data mining, automated reporting and modelling.
Transformation of complex data sets into meaningful conclusions & recommendations
Develop innovative solutions for pattern recognition using machine learning and statistical approaches
Maintenance of expanding set of data mining tools, frameworks & approaches
Communicate actionable recommendations based on insights/model results
Deliver proactive analysis on CAT exposure, historical performance and decision making using weather and geo-analytical approaches (CAT Analytics role)
Driving co-ordination/delivery accountability of project and BAU delivery based on timelines & direction (Sr Data Scientist)
Driving conformance/Alignment to IT/Enterprise Architecture standards (where applicable) (Sr Data Scientist)
About you

Highly numerate, you will be educated to post graduate (MSc) in a relevant discipline; Mathematics, Statistics, Computer Science. You will bring solid experience in a related role with a record of accomplishment of solving complex non-routine problems; along with expertise in some, if not all, of the following areas: Statistics, Machine Learning, Deep Learning & AI. You will have experience at all stages of data science; problem definition, data acquisition & wrangling, modelling, feature engineering and deployment. Big Data experience (e.g. Hadoop) would be ideal, but not essential. What is equally important is programming knowledge and a gift for coding using: R, Python or Spark. Your knowledge must also come with the ability to explain technical concepts to non-specialists. You will also need the drive to deliver projects –leading teams and coaching development. With these talents, you will be equipped to provide insights and deployments at scale. If you thrive on complex, non-routine problems, you will be right at home here.",3.5,Aviva,Markham,"London, United Kingdom",10000+ employees,1861,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),Legal & General,81.0,159,data scientist,senior,1,1,0,0,0,0,1,0,0,0,0,0,1,1,1,6168,1
236,"StackAdapt is the no. 1 performing native advertising platform helping brands accelerate customer engagement and acquisition. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience.

Ranking the highest in customer satisfaction and performance by G2 Crowd in the DSP category for the fourth time, we're one of the fastest growing companies in Canada and ranks 6th in Deloitte's Technology Fast 50 ranking and 23rd in Fast 500 in North America.

We're looking to add a Data Engineer to our data team! This team works on solving complex problems for StackAdapt's digital advertising platform. You'll be working directly with our data scientists, data engineers, Director of Engineering and CTO on building pipelines and ad optimization models. With access to over 500,000 data sets per second, there's no shortage of data and problems to tackle.

Learn more about our engineering culture here: https://www.stackadapt.com/artificial-intelligence-in-advertising

Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU
We'll be responding to applicants that have:
Proven experience architecting scalable ETL / machine learning pipelines (advertising technology experience preferred but not required)
Strong experience with Apache Spark
Strong programming skills in Scala (Golang and Python is a plus)
Experience in NoSQL databases such as HBase and Aerospike
Experience with data warehouse technologies such as Amazon Redshift, Hive
Experience with AWS, ElasticMapReduce, S3 and EC2 in particular
Experience working with small to mid-size teams, and a rapid development process
Experience with Airflow or other job scheduling libraries is a plus
Understanding of machine learning algorithms
StackAdapters enjoy:
Highly competitive salary
Full benefits from League on day one of employment
Coverage and support of personal development initiatives (conferences, courses, etc)
Fully stocked kitchen with healthy (and some not so healthy) snacks
Monthly presentations from global business leaders and innovators
An awesome parental leave policy
A weekly $15 lunch credit via Ritual
Our weekly Friday social events (sometimes on our 4000sq. ft. outdoor patio)
Quarterly team events like escape rooms, bubble soccer, obstacle courses, indoor skydiving, boat cruises, the list goes on…


About StackAdapt

StackAdapt is a self-serve programmatic advertising platform used by North America’s most exceptional digital marketers. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience. Ad buyers plan, execute, and manage data-driven digital advertising campaigns across all devices, inventory and publisher partners. Ranking a high performer by G2 Crowd in the DSP category for four consecutive years, StackAdapt is also recognized as a LinkedIn Top Startup in 2019.

Our office is located at King and Sherbourne near Toronto's historic Distillery District and the St. Lawrence Market. Our Walk, Bike and Transit Score are all over 90.

We've been recognized for our high performing campaign conversion rates, award winning customer service, and innovation by numerous industry publications including:

6th Fastest on Deloitte Technology's Fast 50 In Canada
StackAdapt’s New Chrome Extension Tackles Recruitment Bias
G2 Crowd's Highest Performing Demand Side Platform
The Globe and Mail 2019 Canada’s Top Growing Companies
Startup 50: The Complete Ranking of Canada’s Top New Growth Companies


StackAdapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. We are an equal opportunity employer and we are happy to work with applicants requesting accommodation at any stage of the hiring process. We welcome and encourage anyone and everyone to apply.",4.1,StackAdapt,Toronto,"Toronto, Canada",51 to 200 employees,2013,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1,81.0,7,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,3872,0
237,"Requisition ID: 61162

Career Group: Corporate Office Careers

Job Category: N/A

Travel Requirements: 10 - 20%

Country: Canada (CA)

Province: Ontario (CA-ON)

City: Toronto

Location: Tahoe

Postal Code:

A proudly Canadian retail company, Sobeys began in 1907 as a small meat delivery business in Stellarton, Nova Scotia. Today, Sobeys Inc. serves the food shopping needs of Canadians with approximately 1,500 stores in all 10 provinces under retail banners that include Sobeys, Safeway, IGA, Foodland, FreshCo, Thrifty Foods, and Lawton’s Drug Stores as well as in-store pharmacies, liquor and more than 350 retail fuel locations.

Together with our 123,000 employees and franchise affiliates and a collective passion for delivering exceptional food and shopping experiences, Sobeys’ purpose is to improve the lives of Canadians by helping them Eat Better, Feel Better and Do Better.

All career opportunities will be open a minimum of 5 business days from the date of posting.
Overview
This is an exciting opportunity to join our Innovation and Strategy team at the ground level ! You will be part of our innovation hub located in downtown Toronto where your desire for impact will only be matched by your inate ability to collaborate with other like minded individuals to come up with creative solutions to our retail data science problems.
Job Description
Maintaining, streamlining and hardening existing data pipelines, from ingestion, through ETL and batch processing in order to reliably process billions of records per day.
Build data support for our personalization and experimentation efforts, solving problems from statistical test automation to building real-time M/L applications.
Working with Analytics and Product Management to ensure optimal data design and efficiency.
Assisting Data Analysts and Data Scientists with pipeline and model deployment
Use an analytical, data-driven approach to drive a deep understanding of our fast changing business.
Building data models to deliver insightful analytics while ensuring the highest standard in data integrity.
Job Requirements
Bachelor’s degree in Engineering, Computer Science, Statistics, Economics, Mathematics, Finance or related quantitative field, or equivalent practical experience.
Experience and proficiency with SQL and SQL-like languages
More than 3 years of software engineering experience, especially working on back-end data infrastructure, including CI/CD (i.e. Jenkins) and infrastructure-as-code (i.e. Ansible, Terraform)
Proficiency with at least one of the following languages: Java, Python, Scala.
Proficiency in cloud infrastructure and networking
Proficiency working with Apache Airflow
Proficiency with Spark and/or similar tools in Hadoop/YARN environment and comfortable with Linux operating system.
Ability to creatively solve problems in a fast paced, rapidly changing environment
Ability to navigate ambiguity, drive solutions forward and bring stakeholders along.
Strong problem solving, analytical skills and capability of managing multiple projects and reporting simultaneously across different stakeholders.
Strong structured thinking and the ability to easily break down complex ambiguous problems and propose impactful data modeling designs.
#LI-POST

Sobeys is committed to accommodating applicants with disabilities throughout the hiring process and will work with applicants requesting accommodation at any stage of this process.

While all responses are appreciated only those being considered for interviews will be acknowledged.

We appreciate the interest from the Staffing industry however respectfully request no calls or unsolicited resumes from Agencies.",3.4,Sobeys,Toronto,"Stellarton, Canada",10000+ employees,1907,Subsidiary or Business Segment,Grocery Shops & Supermarkets,Retail,$10+ billion (CAD),"Metro, Loblaw Companies",81.0,113,machine learning engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,1,3667,2
238,"We’re revolutionizing the way humanity eats, and there’s a lot of room for optimization and growth. That’s where you come in. Your ingenuity will help us continue to drive innovation, making an impact on the reliability, performance, and scalability of Skip’s industry-leading technology.

Job Summary:
Think you have what it takes to join an elite team of software developers, engineers, and data scientists? If you want to make your mark on a national brand’s industry-leading technology, Skip’s Engineering Team is the place for you. They drive the innovation of Skip’s platform by improving the reliability, performance, and scalability of the network. GPS tracking, real-time order processing, scheduling, and balancing are just a few of the pieces the Engineering Team integrates into Skip’s world-class service.

As a member of our Data team, you will be responsible for the design and implementation of software for systems that power Skip’s Business Intelligence and Data Warehouse. Your experience with cloud technologies and big data provides you with the background to quickly implement changes. Your experience in data management and SQL allows you to contribute to the expanding expertise of the team and keep data components current as product feature change.

How we work:
We take ownership of our work and work closely with our team.
We move quickly, take risks, and know how to manage the risks.
Regularly refactoring to improve our existing systems — technical debt isn’t an excuse.
Unit tests and code reviews are at our core — confidence in our pull request is the result.
We constantly push our app’s technology, design, and architecture forward to meet new challenges.
We face challenges no one can predict — we meet them head-on as a team.
When we have an idea that serves a need, we run with it.
Our teams are kept tight and efficient.
Experience Needed:
Experience working with both large and real-time data sets.
Strong hands-on experience with Python.
Hands-on experience with backend python frameworks.
Experience in REST APIs.
Experience with AWS and/or Google Cloud Platform data components.
Experience working with tools, languages and protocols such as Redshift, Big Query and/or columnar databases.
Familiarity with scheduling tools like Airflow.
Strong in Dimensional Modeling concepts.
Experience using version control software, such as Git.
Work well both independently and as part of a team. You will actively participate in design discussions and code reviews.
Qualifications:
Computer science, software engineering or related degrees.
We are looking for people who:
Have a great attitude.
Thrive in a rapidly evolving environment.
Are eager to contribute to the growth and development of the team.
Work with an entrepreneurial sense of urgency.
Are receptive to feedback and challenging experiences.
Are actively involved in their ongoing personal growth and learning.
What It’s Like To Work At Skip

Picture this: you, dressed in your fave casual attire, amongst a team of friendly and passionate colleagues. You feel pride knowing your input and uniqueness are not only embraced but make an impact on a major Canadian company and its satisfied customers. As the company grows, so do you — you meet and surpass new challenges every day.

That’s just a small taste of what it’s like to work at one of Canada’s leading tech companies. If you’re hungry for opportunity, growth, and something meaningful in a dynamic, yet casual environment, we’d love to hear from you.

Note: All employees will be asked to sign a Consent for Disclosure of Personal Information in order to complete a background check. Job offers will be conditional upon results that the Company determines to be satisfactory.",3.3,SkipTheDishes,Winnipeg,"Winnipeg, Canada",201 to 500 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,81.0,7,data engineer,na,0,1,0,0,0,1,0,1,0,1,0,0,0,0,0,3731,0
239,"IT/IQ Tech Recruiters is seeking a Data Scientist to join our client in Montreal, QC.

Why work with our client?
Competitive compensation
Centrally located
Transit accessible
Responsibilities
Developing core algorithms and models to enhance network design, operation, optimization and monitoring
Work closely with subject matter experts in other teams to develop and continuously improve models, and help translate business needs into data science projects
Being a leading Machine Learning authority; staying at the forefront of the newest technologies, prototypes, and being proactive in Machine Learning communities
Provide mentorship to your peers
Top Skills Required
Have 3-5 years of applied experience in data science
Have experience in various machine learning use cases, such as, time series analysis, regression and classification
Have the agile mindset; delivering value iteratively
Have expert understanding of machine learning techniques; knowledge of tools and packages such as TensorFlow, PyTorch, Keras, Scikit-Learn, XGBoost, Matplotlib.
Have good knowledge of deep learning and more traditional machine learning algorithms
Have the ability to build, validate, deploy and monitor alliteratively advanced predictive models
Have excellent scripting and programming skills (such as Python, SQL)
Have experience in conducting Machine Learning projects
Have a positive, team-focused attitude and strong collaboration skills
Have excellent written and communication skills to present complete and cohesive findings
Have the ability to produce clear, logical and convincing arguments and explain complex ideas simply
Must be legally eligible to work in Canada
Why work with us?
Build a long-term relationship with an experienced recruitment expert
Access to the ‘hidden’ job market – opportunities across Canada that aren’t posted on job boards
Get a high-level understanding of market dynamics affecting your industry
Gain insight into the culture of the company you’re applying for before submitting your profile
About Us

IT/IQ Tech Recruiters provides contract and permanent IT recruitment services to employers across Canada. We have a specialized approach to recruiting, segmenting our recruitment teams into specialty practice areas focusing on Development, PMO, Infrastructure and BI/CRM/ERP skill sets.

This approach enables our recruiters to become specialists; they know the market and work hard to understand each candidates’ capabilities, goals, career ambitions and quickly present them with the best possible opportunities. We are committed to helping candidates develop their careers and to helping our clients grow their business and complete important projects successfully.

We create opportunities for IT Professionals to empower business.",2.8,IT IQ TECH RECRUITERS LTD,Vancouver,"Vancouver, Canada",1 to 50 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (CAD),"Randstad, TEKsystems, TEEMA Solutions Group",81.0,18,data scientist,na,0,1,0,0,0,1,0,0,0,0,0,0,1,1,0,2769,3
240,"Company DescriptionSquare builds common business tools in unconventional ways so more people can start, run, and grow their businesses. When Square started, it was difficult and expensive (or just plain impossible) for some businesses to take credit cards. Square made credit card payments possible for all by turning a mobile phone into a credit card reader. Since then Square has been building an entire business toolkit of both hardware and software products including Square Capital, Square Terminal, Square Payroll, and more. We’re working to find new and better ways to help businesses succeed on their own terms—and we’re looking for people like you to help shape tomorrow at Square.Job Description

Square began with a simple yet revolutionary piece of hardware—the Square Reader. We have expanded that vision to give our merchants access to the latest secure payment technologies (contactless and chip cards) and easy-to-use Point of Sale products. Today our hardware carries over $30 billion in transactions annually. Measuring the performance of our hardware, and the journey in getting the hardware to our merchants, is essential in ensuring that our merchants’ experience with Square is as seamless as possible.

We need your help to collect data about our hardware, organize that data, and make it available to analysts across Square. As a member of the Hardware data engineering team, you will define, develop, and manage a variety of data infrastructure components and pipelines so that our analytics teams and collaborators have trusted data to inform decisions and insights.

You will:
Join the small but mighty Hardware data engineering team that partners with internal Hardware data consumers to understand their needs and to source the right data sets to work on
Work in a remote environment that allows you to build scalable Hardware data pipelines and tools to ingest data from internal/external sources to our cloud data stack (Snowflake / AWS)
Develop data structures to support flexible analysis of this data, including creating data models, structuring optimized ETLs, designing validation scripts
Troubleshoot technical issues with platforms, data discrepancies, alerts, etc.
Be a voice between the Hardware team and Square’s data community. Help the hardware team’s data producers embrace best-practices, represent the hardware team’s voice in data infrastructure planning discussions.
Report into a data engineering manager on the Platform Infrastructure Engineering team
Qualifications

You have:
3+ years building and supporting reporting data systems built on columnar oriented RDBMS systems (e.g. Snowflake, BigQuery, Redshift, Vertica, etc.)
Strong experience building data pipelines from heterogeneous data sources (e.g. Event streams, Flat Files, RDBMS, REST APIs, SFTP, etc.) to support real-time operational and analytical workloads
Technical accomplishments working with SQL, ETL, and Apache Airflow; and knowledge of at least one mature programming language (Ruby (and Rails), Python, Java, Go, or similar)
Experience with Linux/OSX command line, version control software (git), and general software development
Experience with cloud based data tools and services (e.g. AWS Lambda/S3/Transfer, GCP Cloud Functions/GCS, Fivetran, etc.)
Additional InformationAt Square, our purpose is to empower – within and outside of our walls. In order to build the best tools for the businesses and customers we support all over the world, we have to start at home with a workforce as diverse and empowered as our sellers. To this end, we take great care to evaluate all employees and job applicants equally, based on merit, competence, and qualifications. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status, or any other characteristic protected by law. We encourage candidates from all backgrounds to apply. Applicants in need of special assistance or accommodation during the interview process or in accessing our website may contact us by sending an email to assistance(at)squareup.com. We will treat your request as confidentially as possible. In your email, please include your name and preferred method of contact, and we will respond as soon as possible.

Perks

At Square, we want you to be well and thrive. Our global benefits package includes:
Healthcare coverage
Retirement Plans
Employee Stock Purchase Program
Wellness perks
Paid parental leave
Flexible time off
Learning and Development resources",4.0,Square,Toronto,"San Francisco, CA",1001 to 5000 employees,2009,Company - Public,Computer Hardware & Software,Information Technology,$2 to $5 billion (CAD),-1,81.0,11,data engineer,na,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,4549,0
241,"You are a sharp, disciplined individual who has a passion for mobile games. Your experience helps to demonstrate your superior quantitative analytical skill and a scientific thought process. Your expertise paves the way for working with our game team to optimize every facet of player retention and monetization to ensure the continued success of our games. Large data sets are your playground and you can’t wait to join the fun!

Sound like a match? Kabam Vancouver is looking for an Associate Data Analyst to join us! We don’t just make games, we play and love them too.
You will contribute by:
Providing support to cross-functional teams across the organization to understand overall business goals, improve reporting, and assist with larger scale projects as needed
Finding answers to business questions via hands-on exploration of data sets using SQL, dashboards, statistical analysis, and data visualizations
Generating and maintaining a suite of dashboards and reports for teams throughout the organization
Creating and managing multiple A/B tests to gain valuable insights on KPIs including retention, acquisition, and monetization
Measuring the success of product features after release and optimize their performance through rapid, data-driven iteration
Aiding in task prioritization and general project management within the data team
Your background includes:
0-2 years of industry data analysis experience, with solid knowledge of statistical methods
Bachelor’s Degree, preferably in a STEM discipline
Expert SQL skills and experience querying very large data sets
Proven ability to thrive using multiple mixed, varied, and inconsistent data sources
Fundamental knowledge of project management methodologies
Comfort presenting complicated material to diverse audiences
It would be nice to have:
Experience with Google BigQuery, Tableau, JIRA and/or other project management software
Experience working for a social or mobile game developer
Understanding of game design concepts and principles
MBA or Master’s Degree
Together, we can create and support some of the best games ever made.

About Kabam
Kabam is a world leader of developing entertaining, immersive, and highly social multiplayer games for mobile devices. They merge consumer behaviour with the art of game design to create experiences that are enjoyed by millions of players across the globe. Each game has raised the benchmark in mobile gaming, bringing high-quality graphics, next-generation technology and revolutionary gameplay to the console in every player’s pocket.
Kabam has partnered with leading entertainment brands like Disney, Hasbro and Universal to create mobile games based on some of the world’s most iconic franchises.

Kabam’s games have generated hundreds of millions of downloads including Fast & Furious 6: The Game, Fast & Furious: Legacy, Marvel Contest of Champions, Transformers: Forged to Fight, Shop Titans and Mini Guns. These games have also received multiple awards such as Apple’s Editor’s Choice and Google Play’s Best Game of the Year.

Founded in 2006, Kabam has studios and offices in Vancouver, Montreal, Charlottetown, San Francisco and Austin. Kabam is a wholly-owned subsidiary of Netmarble Games.",4.1,Kabam,Vancouver,"Vancouver, Canada",501 to 1000 employees,2006,Company - Private,Video Games,Media,Unknown / Non-Applicable,"GREE, Electronic Arts, Glu Mobile",81.0,14,data analyst,na,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,3213,3
242,"Certarus Ltd. (Certarus) is the North American leader in the delivery of compressed natural gas (CNG). We are a private company whose business is delivering Low Carbon Energy Solutions through the compression, transportation and integration of CNG for the energy services, mining, forestry and industrial sectors. Our solutions target diesel and propane fuel displacement to lower operating costs and reduce environmental impact for companies operating in these market segments. We are a high growth company with over 220 employees in 8 states and provinces. For more info, check out http://www.certarus.com.

Summary:

Certarus is creating an innovative technology platform to drive business efficiencies and to accommodate the Companys rapid growth trajectory. Having established a core foundation of leading technologies (AI, IIoT, Edge Computing), Certarus is looking to leverage its data to strengthen its competitive advantage. Reporting to the Manager of Technology & Business Process, the individual will be relied upon to spearhead multiple data projects end-to-end. This well-rounded role involves data architecture planning, as well as hands-on execution of data integration, transformation, analytics, and delivery. We are looking for an experienced data professional who is eager to help define and influence the technical direction of the organization.

This position is based in our corporate Calgary office.

Key Duties and Responsibilities:
Build reports, dashboards and visualizations to provide actionable insights for company stakeholders. Gather feedback and drive the build, measure, learn process
Build analytical models leveraging statistical methodologies (experiment, prove out, produce)
Write queries and programs to transform data and integrate multiple sources into data models
Take ownership of data architecture and develop in-depth knowledge of all datasets and linkages
Optimize data storage / warehousing, working with the Is the external cloud infrastructure provider
Gather requirements from leadership and business users to scope out data deliverables
Support and automate data collection activities
Analyse data and recommend potential opportunities to improve operational efficiency
Prepare and maintain comprehensive documentation to support data governance and product development initiatives including data flow diagrams and metric definitions
Provide training to non-technical users on how to use dashboards or leverage data insights
Support responsibilities including BI tool maintenance and ad-hoc analysis requests
Other duties as assigned
Requirements:
Minimum of 5 years' analytics / business intelligence experience in a professional environment
Self-motivated individual accustomed to working in a fast-paced, high performance environment
Strong PowerBI skills, or equivalent experience with other data visualization tools and systems
Advanced SQL skills including building complex database queries and optimizing performance
Knowledge of data analytics best practices (statistical analysis, data mining etc.)
Experience preparing and maintaining technical documentation and performing data governance process support
Strong communication and interpersonal skills; ability to collaborate with cross-functional teams.
Experience with Microsoft Technology Stack (Azure, PowerApps/Automate, SharePoint, PowerShell) an asset
Experience with R, Python, ML/AI methodologies an asset
Logistics and/or Oil and Gas business knowledge an asset
Experience working with SCADA, Transportation Management, and Field Ticketing data an asset
Post-secondary degree in Computer Science, Statistics or related technical discipline, or equivalent industry experience.
Certarus offers a competitive compensation package, including base salary, bonus, benefits and long-term incentives. Above all, we offer unlimited career advancement opportunities with a dynamic, rapidly growing organization.

Powered by JazzHR",5.0,Certarus Ltd.,Calgary,"Calgary, Canada",51 to 200 employees,-1,Company - Private,Oil & Gas Services,"Oil, Gas, Energy & Utilities",Unknown / Non-Applicable,-1,81.0,-1,data analyst,na,0,1,1,0,0,1,0,0,1,0,0,0,0,0,1,3942,0
243,"Zymeworks is a clinical-stage biopharmaceutical company dedicated to the discovery, development and commercialization of next-generation bispecific and multifunctional biotherapeutics, initially focused on the treatment of cancer. Zymeworks’ suite of complementary therapeutic platforms and its fully-integrated drug development engine provide the flexibility and compatibility to precisely engineer and develop highly-differentiated product candidates.

About the Position

Zymeworks is looking for a highly motivated AI / machine learning associate scientist for protein design applications development within the Technology team. This candidate will work along with the Molecular Simulations, Bioinformatics and Software Engineering team, building comprehensive computational protein modeling and data analytics platforms for use in biologics engineering and drug discovery. We are seeking candidates with experience in developing and applying supervised and unsupervised machine learning algorithms to address challenges in biomolecular design and optimization. Our scientific staff have opportunities to impact the entire computational method development process, from devising the algorithms to implementation, and direct application in biologics modeling and optimization, pushing the boundaries of in silico therapeutics design.

This is a permanent, full-time position located at our headquarters in Vancouver, BC and will report to a Senior Scientist in the Technology team.

Key Responsibilities
Design, develop, validate and document state-of-the-art discriminative and generative deep learning algorithms for antibody and protein therapeutics engineering and optimization.
Leverage public databases and Zymeworks’ proprietary data as well as in-house computational infrastructure to develop scalable tools and automated workflows for biotherapeutics engineering and optimization.
Implement, train, test and compare various ML approaches for the problem at hand, drive to develop the most optimal and efficient algorithmic solution.
Work closely with protein engineers, drug developers and translational scientists to identify new opportunities, gather requirements, design and develop machine learning techniques to help advance early-stage therapeutics design processes.
Communicate the advantages and caveats of the developed technology to technically-diverse internal audiences and external partners.
Attend conferences and participate in the preparation of patents and publications
Qualifications & Experience
MS/Ph.D. in Computer Science, Statistics, Applied Math, Physics, Chemistry, Biological Sciences or a related field.
In-depth experience with modern and classical ML methods with 2 to 5 years of practical experience designing, training and validating such algorithms
Candidates are expected to have basic knowledge of molecular sciences and protein structure function relations.
Strong statistical foundation and working knowledge of supervised and unsupervised learning algorithms, in particular, deep generative models like Boltzmann Machines, Variational Autoencoders, GANS, etc
Experience working with Deep Learning frameworks (e.g. TensorFlow/Keras, PyTorch)
Proficient in at least one of C, C++, Java, or Fortran, and proficient in a scripting language (eg Python, Perl, Ruby)
Preferred Experience
Source-code management systems such as Git, Github, Bitbucket etc.
Algorithm parallelization, and knowledge of GPU computation and CUDA
Scaling ML algorithms, and hyper-parameter optimization strategies in cloud computing environments such as AWS
Why Work for Us?

At Zymeworks, we stand for innovation, integrity, collaboration and care.

We come from many countries, cultures, races, ethnicities, abilities and nationalities. We bring our passions including singing, biking, swimming, dancing, cooking, volunteering, parenting, coaching and much more! We are proud of our nearly equal balance of men and women and strengthened by our non-binary and transgender team members. Every employee belongs.

We offer challenging career opportunities, competitive benefits and an environment that recognizes and rewards performance.

To learn more about Zymeworks Inc. and our current openings, please visit our website at https://zymeworks.bamboohr.com/jobs/.

NOTE TO EMPLOYMENT AGENCIES: Zymeworks values our relationships with our Recruitment Partners. We will only accept resumes from those partners whom have been contracted by a member of our Human Resources team to collaborate with us. Zymeworks is not responsible for any fees related to resumes that are unsolicited or are received without contract.

#LI-PT1",4.4,Zymeworks Inc,Vancouver,"Vancouver, Canada",201 to 500 employees,2003,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,Unknown / Non-Applicable,-1,81.0,17,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,4642,0
244,"What's Bench? Check us out in Fintech Impact, Perkins + Will, Daily Hive, BC Business, and our Instagram.

We're a passionate and fun group of people working hard to solve a tough problem for millions of entrepreneurs. For many small businesses, keeping up to date on their books means trading off time spent actually running their businesses. Bench solves this dilemma by taking bookkeeping off of our clients hands. We've paired sleek, user-friendly software with a team of bookkeepers to provide monthly bookkeeping at an incredibly accessible price, giving entrepreneurs the time and the confidence to run the businesses they love.

Bench is post Series B, capitalized by a team of Silicon Valley and New York investors. We're scaling fast and we're not slowing down anytime soon. In just a few short years, we've grown from four co-founders to over 400 Benchmates. We're looking for the brightest minds who love solving tough problems to join us on this incredible journey, in pursuit of bringing financial mastery to our clients.

What does the BizOps department look like?

Bench's Business Operations team designs, configures and builds the systems and processes that enable the rapid scaling of our Go-to-Market and operational teams. Being a member of this team means you'll play an integral role in increasing the efficiency and efficacy of Bench, with a focus on finance related data and reporting outputs. As the dedicated finance analyst on the BizOps team, you'll be empowered to help build efficiencies into our current data and be a financial voice when new decisions are made. You'll be an influencer and a key contributor to driving the success & growth of a company that's changing what's possible in the industry.

What you'll be getting up to:
Reconciling financial reporting across various data sources (Google sheets, Redshift, Tableau)
Increasing the connectivity of our financial model to other reporting in order to minimize this reconciliation
Building new functionality into our financial model in Google sheets
Developing SQL queries to gather and aggregate meaningful financial data from Stripe and Salesforce data stored in a Redshift data warehouse
Creating automated connections between these new custom data sources and our financial model, and using these new sources to help Bench forecast better
Identifying opportunities for better forecasting, and developing approaches to do so
You are responsible for project managing these approaches, and ultimately taking potential improvements from ideation all the way to delivery
You will be a thought-leader in the data community at Bench
Responsible for distilling the finance needs of Bench into well-formed proposals for how we manage and build our data, how we measure various metrics across the business, and how we leverage existing data to generate new insights into Bench's finances
Identify and execute automation opportunities within the revenue recognition process
Preparing and building ad-hoc data tables and query's related requests from the finance team
May include: employee data, compensation data, and revenue data
Act as a liaison between Finance and BizOps for any data related questions
To be successful in this role, you'll need to have:
High proficiency in sheets: You should have a full understanding of all major google sheets (or Excel) functionalities. You have the ability to build and maintain streamlined and well-structured dashboards, using multiple live data sources. You will spend a significant portion of time working in our Google sheets forecasting environment, connecting it to other data sources, and aligning reporting across multiple teams.
Strong analytical skills: You have an analytical mind and are capable of breaking down large problems into smaller ones. You demonstrate a strong handle on logic and structured problem solving. You'll be responsible for taking high-level broad questions and distilling them into actionable projects.
Strong project management skills: You'll be tackling multiple complex problems at one time; you should have impeccable time management and ruthless prioritization!
Communication: A high degree of communication skills is necessary. You'll be responsible for using multiple methods to communicate results, insights, and future opportunities. Having experience creating decks, project plans, progress updates, and in person presentations to stakeholders is required. Stakeholders will represent a diverse group of skills and experience, so you'll need to be highly skilled at crafting communications that 'fit' the audience.
Not just a data-consumer, rather an active member of the full pipeline: You have experience in being an active member of the full data pipeline. In this role, you will not only consume and analyze data to surface insights but will play an active role in data-collection, overall data strategy, and architecture.
It could be an even better fit if you have:
Experience in a CRM environment: It is preferred that you have some experience with a CRM environment (we use Salesforce). Generating Salesforce reports to automate data-distribution to different analytical environments will allow you to go above and beyond.
Strong to medium proficiency SQL: At a minimum, you should be comfortable running simple queries in a Redshift environment. Experience in other coding languages will serve as a replacement for SQL skills, as it is a strong indicator that you'll be able to grow your SQL skills.
Experience working with a finance team: It is preferred that you have experience working with finance teams in the past and can generally understand the various components of a set of financial statements and monthly reporting processes.
Extra bonus points if you have:
Basic data-warehousing experience using Redshift: Some experience building relational data sources in Redshift & table materialization will allow you to go above and beyond.
The extra details:
This is a full-time permanent position because we want to spend lots of time with your wonderful self!
This position offers an annual salary, stock options, and an extended benefits package that includes health, dental, and vision.
Once safe to do, we'll return to work in our downtown Vancouver office. It's dog-friendly, close to lots of great restaurants, and easily accessible via transit. We also pride ourselves on our office coffee and the fridge is always stocked, compliments of Bench",4.1,Bench,Vancouver,"Vancouver, Canada",201 to 500 employees,2013,Company - Private,Accounting,Accounting & Legal,Unknown / Non-Applicable,-1,81.0,7,data analyst,na,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,6436,0
245,"About Etraveli Group

Etraveli is one of the leading global flight centric Online Travel Agencies (OTAs) with €4bn+in annual gross sales. We also operate flygresor.se, the #1 metasearcher in Sweden and Tripstack, the independent B2B arm of the group offering a variety of complex technology solutions.

Our diverse, dynamically growing team of 1000+ talented professionals is always on the lookout for more members to join our ranks and explore unlimited business opportunities together! Our 110 websites in 70+ countries across the globe include (but are not limited to) gotogate.com, pamediakopes.gr, mytrip.com, flightnetwork, supersavertravel.se, trip.ru & flygresor.se.

About Tripstack

TripStack is a brand under the Etraveli Group, It is revolutionizing the travel & technology field with a mission to challenge the status quo by solving difficult problems and changing the way millions of people travel.

We offer unique flight content, consisting of Virtual Interline & Low-Cost carriers in one search - this enables our partners to offer the end consumer the most relevant flight options at the lowest price.

Our company’s core values are what form our foundation. They inform how we work, how we execute, how we choose our future teammates and how we present ourselves to the world as TripStack employees.

Playing to Win.

#1 within flights

At TripStack we play as a team, we win as a team and we constantly aim to become better. We challenge convention, ourself and our teammates. We dare to think big and we value those who think differently.

Drive for Excellence

Good is not good enough.

We show a never give up attitude and we move fast, knowing we sometimes make mistakes, but that is needed to keep a high pace and to solve complicated stuff. And what we do is complicated, but by driving for high quality & excellence we simplify the product offering, enabling the end user more and cheaper ways to travel.

Act with Ownership

Have pride in your work

At TripStack we expect all to take accountability for your work but also accountability for the team work. We value proactivity, employees who take initiative to get things done- also when it is out of normal scope - it help us achieve our goals.

TripStack is part of the Etraveli Group, a global online travel agency and the fastest growing in Europe whose presence across the web spans 50 countries.

The Role
We are looking for an experienced data engineer to join our Virtual Interlining team for TripStack. Virtual Interlining is a technology we provide that combines flights from different carriers that don’t traditionally work together to go from point A to B via C. These unique fares provide significantly lower prices to the end consumer and much higher flight margins to our partners. Did you know that there are nearly 45 million flights operated worldwide on an annual basis? Indexing that data to provide customers with better flight options is a daunting and exciting mission.

You will use various methods to transform raw data into useful data systems. For example, you will create algorithms and conduct statistical analysis. Overall, you will strive for efficiency by aligning data systems with business goals.

To succeed in this role, you should have strong analytical and programming skills and the ability to combine data from different sources. Data engineer skills also include familiarity with several programming languages (preferably golang, python) and knowledge of machine learning methods would be considered an asset. You should have a good understanding of data warehousing concepts, having worked with large datasets and designed star/snowflake schemas. Experience with data processing tools like Apache Hadoop, Spark, Apache Druid( real-time OLAP) would be considered an asset.

Responsibilities:
Analyze and organize raw data
Build data systems and pipelines
Evaluate business needs and objectives
Interpret trends and patterns
Conduct data analysis and report on results
Prepare data for prescriptive and predictive modeling
Build prototypes
Combine raw information from different sources- flat files, databases, NoSQL caches
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition and prototype them using machine learning
Collaborate with Data Scientists and Architects on several projects
Requirements
Bachelor’s degree in Computer Science or technical discipline required. Master’s degree not mandatory but would be considered an asset.
4 years previous experience as a data engineer or in a similar role
Technical expertise with data models, data mining, and segmentation techniques
Knowledge of programming languages (Golang, Java, and Python)
Hands-on experience with SQL database design and proficient at writing SQL queries specifically Postgres
Knowledge of Apache Hadoop, Spark an asset
Knowledge of real-time OLAP like Apache Druid is an asset
Exceptional numerical and analytical skills",2.4,Etraveli Group,Toronto,"Uppsala, Sweden",1001 to 5000 employees,-1,Company - Private,Travel Agencies,Travel & Tourism,Unknown / Non-Applicable,-1,81.0,-1,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,4957,0
246,"Job Type: Permanent
Primary Location: Vancouver, British Columbia, Canada
All Available Locations: Vancouver

Learn from deep subject matter experts through mentoring and on the job coaching.
Partner with clients to solve their most complex problems.
Be empowered to lead and have impact with clients, our communities and in the office.
“At Deloitte we value the opportunity to network and build relationships with skilled individuals, even in periods where we are not actively hiring. If you would like to apply to this future opportunity role, and have the required qualifications, you can expect to be contacted by the recruitment team within a few days""

You love to wrestle down data puzzles, you embrace the potential that data represents, you aspire to solve data problems no one else can, and above all, you want to use data to make impacts that matter – if that is you, then Omnia AI is where you want to be.
What will your typical day look like?
As a Big Data Engineer on our Data & Analytics Modernization team within the Omnia AI practice, you are passionate about data and technology solutions, are driven to learn about them and keep up with market evolution. You will play an active role throughout the entire engagement cycle, specializing in modern data solutions including data ingestion frameworks, data pipeline development, Hadoop-based data lake architectures and orchestration. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.

Specifically, in this role, you will:
Engineer Big Data ingestion and pipeline frameworks to populate on-premise or cloud-based data lakes
Translate business rules and requirements into data objects, produce associated data models and source to target mappings and write abstracted, reusable code components accordingly
Plan/schedule tasks, lead small development teams, and mentor junior colleagues
Facilitate technical meetings with client staff, and advise client with technical option analyses based on leading practices
About the team
Omnia AI, Deloitte’s Artificial Intelligence (AI) practice is comprised of a collaborative team of experts who use their hands-on experience with cutting-edge information assets to facilitate successful AI transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Data & Analytics Modernization team helps clients design and implement the data platform architectures – be it in the cloud or on-premise – required to enable cutting-edge AI solutions. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes.
Enough about us, let’s talk about you
You are someone with:
3+ years implementation experience leveraging Hadoop ecosystem technologies such as HDFS, MapReduce, Pig, Sqoop, Spark, Hive, Kafka, etc. on-premise and/or in the cloud (e.g. AWS, Azure, GCP)
3+ years experience with analysis, design, development, testing and deployment of data pipeline (ETL) services leveraging the Big Data technology stack for batch and/or real-time messaging/streaming environments
Experience writing complex SQL queries, extracting and importing disparate data from source systems, and data manipulation based on requirements
Experience with Agile development methods in data-oriented projects
Completed Bachelor’s Degree (or higher) in quantitative areas such as Computer Science, Information Management, Big Data & Analytics, or related field is desired
If you believe you have what it takes to be a successful member of our team, please apply now. We know your career is important to you and it's important to us, too. This role is just the first step of a highly successful career we can help you build.

The time is right for you to join Deloitte. Get your career off to great start. What impact will you make?

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:
You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.
The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.",3.9,Deloitte,Vancouver,"New York, NY",10000+ employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (CAD),"Amazon, PwC, McKinsey & Company",81.0,170,data engineer,na,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,5615,3
247,"Le Data Engineer sera responsable doptimiser lentrepôtde données de lentreprise, tout en participant au virage vers lintelligence
artificielle .

PLUS PRÉCISEMENT

Analyser létat de la situation actuelle et se
familiariser avec lentrepôt de données;

Améliorer la communication entre les différents systèmes
et optimiser la gestion des flux de données;

Effectuer une preuve de concept afin de bâtir une
architecture et de standardiser les systèmes;

Optimiser lentrepôt complet des données de lentreprise
et proposer de nouvelles recommandations;

Travailler dans un environnement AWS avec Snowflake,
Kafka, SQL et noSQL.

PROFIL

3+ années dexpérience titre de Data
Engineer;

Expérience avec lArchitecture de Haute
Disponibilité;

Expérience avec Snowflake (fort atout);

Bonnes connaissances de Kafka et des ETL
Batch Processing;

Connaissances en Python ou Bash (atouts);

BAC en informatique ou léquivalent;

Maîtrise de la langue française et/ou
anglaise.",5.0,DELAN,Montreal,"Montréal, Canada",1 to 50 employees,1997,Company - Private,-1,-1,Less than $1 million (CAD),-1,81.0,23,data engineer,na,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,962,0
248,"WHO WE ARE


Namaste Technologies began as an international cannabis eCommerce company operating in 20 countries. We have years of data collected on legal cannabis users and by combining machine learning technology with telemedicine apps, we leverage this data to provide our customers with a world class cannabis purchasing experience.

WHO YOU ARE


We are looking for a Senior Data Analyst to join our team. You will be partnering with our product managers to assess strategic initiatives, develop actionable insights and drive operational analytics.

As our business is constantly trying to delight its customers, data takes a crucial place. By leveraging all the knowledge we collect about our customers’ journey, we can take informed decisions on the future of our products. Examples of questions to answer are “What is the conversion rate of this specific step?” or “What is the impact of an A/B Test segment on the Average Order Value?”. Helping all the departments (Finance, Marketing...) understand and use data is also of prime importance.

Candidates are expected to be highly analytical, self-directed and excellent communicators. Ideal candidates have a proven track record of cross functional project management and extensive analytics experience. We are a data driven organisation so previous experience with query and scripting languages such as SQL and Python or a strong desire to learn these skills is preferred. The ideal candidate will thrive in a fast-paced environment, possess a high level of intellectual curiosity, and focus on generating results while exhibiting the highest personal and professional integrity and ethics.

In addition to intellectual curiosity and aptitude, we look for candidates who are excited by technology, either from a professional or personal background.

ROLES & RESPONSIBILITIES
Provide strategic ad-hoc analysis to engineering teams, senior leaders, and FP&A. Report and iterate on key operational and financial metrics.
Collaborate with our Engineering squads to create dashboards presenting KPIs for our products and our business activities.
QUALIFICATIONS
Minimum three years in an analytical role
Ability to present to and context switch between peer groups and senior level management.
Ability to independently explore and analyse high volume datasets.
Experience with data transformation processes, using Python.
Working experience with our visualisation tool, Tableau.
Experience with data storytelling.
Degree in accounting, economics, mathematics, engineering/computer science, or other relevant field that demonstrates quantitative competence.",1.0,Namaste Technologies,Toronto,"Toronto, Canada",1 to 50 employees,-1,Company - Public,Other Retail Shops,Retail,$1 to $5 million (CAD),-1,71.5,-1,data analyst,senior,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,2610,0
249,"We are actively seeking a Data Analyst for a successful and well established cross platform studio. The successful candidate has proven experience analyzing data to inform product strategy and direction. This is full time permanent role.
Your background includes:
3+ years experience in a similar role.
A graduate degree or related professional experience in consulting, consumer insights, or product strategy or revenue strategy.
Experience writing SQL queries, Excel, PowerPoint, Tableau, Python (or similar)
Love of video games and geek culture.
This role is open to local candidates based in the Vancouver area. Although we appreciate all interest, only those candidates selected for an interview will be contacted.

At Creative Technology Resources (CTR), we have very high expectations of ourselves to consistently deliver quality to the client and candidates that were so fortunate to partner with every day. We deliver talented, driven individuals to our clients so that together we are building teams that thrive. Our clients are made up of teams of industry veterans whose expertise and interests are driving the creation of the worlds next great digital products & services. Together, we can create some of the best experiences ever made.

View all our open positions here",5.0,Creative Technology Resources,Burnaby,"Vancouver, Canada",1 to 50 employees,2012,Company - Private,Staffing & Outsourcing,Business Services,$10 to $25 million (CAD),-1,71.5,8,data analyst,na,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1283,0
250,"132 ENG Inc. is an exclusive Engineering and Technical Services Company. We offer staffing placement and recruiting services for engineering, technical writing, Data Scientists and Data Engineers. Partner with 132 ENG experts who have proven expertise and depth of knowledge to find the position you deserve.

We are currently accepting applications for Machine Learning Engineer / Data Analyst with 2 - 8 years experience.

B.S. in computer science, mathematics, with additional training in AI(machine learning, deep learning, natural language processing and computer vision), or Masters Degree or PH D with applicable experience.

Our clients have exciting opportunities with various options for advancement. We will work with you to find a good fit and the remunerable compensation you deserve.

We are seeking skills and experience with one or more languages, python, C++, R, AI (machine learning, deep learning, natural language processing and computer vision).

A strong GitHub account or a good portfolio of projects.

Veteran Friendly
Please be patient with the application process. We will respond to each application.

Let us help you find a good fit and the job you deserve.

132 ENG Inc. Diversity Statement
We embrace an approach to diversity and inclusion. We are building and nurturing an environment where inclusiveness is a reflex not a slogan. An environment where pride, passion, and belonging transcends any role. Where excellence, innovation and social responsibility is our culture.",-1.0,132 ENG I,Toronto,-1,-1,-1,-1,-1,-1,-1,-1,71.5,-1,data analyst,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,1504,0
251,"Responsibilities

We find that the most successful candidates for the Data Engineer position are natural and relentless problem solvers who are passionate about working with data to solve business problems. These individuals demonstrate ease with quantitative analysis, can work well as part of small multi-disciplinary teams, have a keen interest in software engineering and are passionate about developing leading edge analytical business applications.

Our Data Engineers are part of the engineering team responsible for data architecture, back-end development and maintenance of our proprietary decision support software applications. They work closely with product management and the front-end development team to ensure that our products are constantly improving and have leading edge functionality.

You can expect the following responsibilities:
Collaborate with Product Management and other engineers on the team to make product improvements and develop new features
Hands-on SQL Server development (Stored Procedures, Functions etc)
Migrate complex data processing from SQL Server to Big Data using Spark, Scala in the near future.
Create and maintain detailed documentation and functional design specifications
Perform ongoing backend Database maintenance of existing applications
Provide technical information to assist in the development of client facing product documentation
Author and participate in software design and code reviews
Adhere to change management protocols and version control
Present demonstrations of new features to internal product teams as well as high level firm leadership and partners
Desired Skills& Expertise

Aspiring candidates should have the following background, skills and characteristics:
Bachelor’s degree, preferably in computer science, or engineering field
3+ years of experience in SQL Server development
1+ years of ETL experience using flat files and other RDBMS
Experience in troubleshooting and debugging SQL code
Familiarity with Tableau
Familiarity with the design, development and maintenance of best-in-class BI capabilities, including data warehouse data structures and data pipelines spanning Spark/Hadoop and RDBMS worlds
Expert-level database development experience in SQL Server, preferably for reporting data marts and business intelligence solutions, including writing stored procedures for complex business logic in T-SQL
Familiarity of architectural design patterns for micro-services leveraging relational and big data technologies is an added plus
Familiarity with Agile development process, SVN or other change management protocols would be a plus
Proven track record of academic and/or professional success
Exceptional analytical thinking ability, ease with quantitative analysis, and excellent problem-solving skills
Self–discipline and willingness to learn
Ability to work well with others in a high-pressure environment
Excellent verbal and written communication skills
All candidates must possess work authorization which does not (and will not in the future) require work sponsorship by an employer.

We are proud to be an Equal Opportunity Employer. Please visitwww.novantas.com for more information.",2.9,Novantas,Toronto,"New York, NY",201 to 500 employees,1999,Company - Private,Financial Analytics & Research,Finance,Unknown / Non-Applicable,-1,71.5,21,data engineer,na,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,3179,0
252,"Career Category
Scientific
Job Description


Amgen is dedicated to discovering transformative medicines that address the leading causes of death and disability. Within Amgen’s Research and Development organization, the Computational and Data Sciences (CDS) team strives to revolutionize the design and discovery of breakthrough differentiating therapeutics. Driven by passion and commitment, the CDS team provides actionable insights from physical and data modeling to accelerate therapeutic discovery.

Amgen has new opportunities for enthusiastic data scientists with backgrounds in computational biology or chemistry to join our CDS team where you will utilize your expertise to develop models and algorithms in collaboration with multidisciplinary teams of computational and experimental scientists. Providing technical leadership and partnering across broad discovery areas of research, you will:
Develop and implement groundbreaking machine learning and other data science solutions.
Collaborate with computational and experimental scientists to develop and optimize predictive models that directly impact the discovery pipeline.
Provide technical leadership to data scientists and engineers.
Basic Qualifications

Doctorate degree and 3 years of related data sciences experience

OR

Master’s degree and 6 years of related data sciences experience

OR

Bachelor’s degree and 8 years of related data sciences experience

Preferred Qualifications:
PhD in in Computational Sciences, Applied Math, Statistics or related quantitative field.
Strong track record of research accomplishments including five or more scientific publications or conference presentations.
At least 10 years experience applying both traditional data sciences and deep machine learning to molecular sciences and drug discovery.
Expertise in advanced data science techniques and tools, machine learning, supervised/unsupervised learning and statistical analysis.
Experience with UNIX, Python, C++, TensorFlow, PyTorch, Keras.
Strong communication, project management and technical leadership skills with an enthusiasm for working in an interdisciplinary team environment.
Join Us


If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.

Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.

As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients.

Amgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.Amgen will consider for employment qualified applicants with criminal histories in a manner consistent with the San Francisco Fair Chance Ordinance.",3.8,Amgen,Burnaby,"Thousand Oaks, CA",10000+ employees,1980,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (CAD),"Genentech, AbbVie, Janssen Biotech",71.5,40,machine learning engineer,senior,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,3340,3
253,"Company Overview

Quandl is transforming how business decisions are made.

Data is the most important resource of the 21st century, and Quandl is at the heart of the emerging data economy. Over the last 5 years, weve built the worlds largest and most successful data marketplace: a platform where over 400,000 professionals buy, sell, create and consume data. Quandl today is used by everybody from academics to AIs; from two-person fintech startups to billion-dollar hedge funds.

Job Summary

We are looking to hire a Data Engineer Co-op for a minimum of 8 months who will work with our team of Data Scientists and Engineers to create software tools to enhance our analytical capabilities.

This is an excellent opportunity for a talented soon-to-be graduate to join a highly qualified and experienced team, help solve difficult but valuable problems, and acquire a wide variety of skills across multiple domains.

Responsibilities

In this role, you will:
Enhance and automate our existing big data pipeline
Create new analytical tools powered by the latest advancements in Machine Learning
Gain substantial breadth of experience in analyzing disparate data sources and in doing so, expand your knowledge of finance and investments
Apply best practices in software development to ensure all solutions are well documented, efficient, and massively scalable
The Candidate

The ideal candidate will have:
Advanced knowledge and experience in Python or R
Basic knowledge and experience in big data and cloud computing technology: Spark, AWS, Amazon EC2, DataBricks, Redshift
Basic knowledge of financial markets and an interest in finance and economics
Entrepreneurial and enthusiastic about working in a fast-paced startup environment
Excellent time management, analytical, and organization skills
Great verbal and written communication skills
Proficiency with Microsoft Office tools
Currently enrolled as a third- or fourth-year post-secondary student at a Canadian institution in Mathematics, Physics, Computer Science, Computer Engineering, or equivalent program
Our Company Culture

We believe in working productively on important and interesting challenges, with talented individuals who are nice to each other.
Productivity matters. We believe in getting things done.
Our mission matters. We believe in what were doing, and why its important.
Competence matters. We learn and grow by working with teammates who are excellent at their job.
Niceness matters. Life is too short to put up with unpleasant behavior.
We are strongly committed to diversity and equality of opportunity. We are proud to have a team that is 40% women, 40% first-generation immigrant, and 30% visible minority. We strive to create an environment that is welcoming and inclusive for everyone.

Benefits and Perks

We offer:
A competitive salary and incentives
Flexible work from home/office hours and generous vacation time
Family-friendly company policies and culture
Avenues for growth: in technology, business and leadership
A collegiate and collaborative yet high-performance environment
Interesting and challenging problems to work on
Colleagues who are motivated, talented and a pleasure to work with
A beautiful and centrally located office, easily accessible by transit and filled with perks
Frequent company off-sites and social events
Qualified and interested applicants are invited to send their resume and cover letter to jobs@quandl.com.

Powered by JazzHR",4.3,Quandl Inc,Toronto,"Toronto, Canada",51 to 200 employees,2012,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,71.5,8,data engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,3447,0
254,"As part of the analytics engine you will build with a team of talented devs, you will work on building a predictable data pipeline with a constrained data model providing customers with data-led insight. What you create will have a direct impact on how customers analyze industry and company trends. You enjoy working in a startup culture and are keen to take initiative. You are a self-starter and a critical thinker who enjoys working on a solution you are passionate about and working with a team that is collaborative.

Our client is a leading software company that is making ground breaking changes within the construction space. Their solution allows for the most important aspects of their customers and employees lives to be solved - safety, peace of mind, ease of tracking mundane and time consuming tasks in real-time AND all in one platform. As they continue to grow their team in Vancouver, we are looking for a Data Engineer.

Requirements
5+ years experience in developing large scale end-to-end data pipelines, data ingestion, and visualization
A computer science university degree or college diploma in computer science
Experience with relational databases, expert in writing SQL scripts
A passion for software development
An interest in problem-solving
Experience in the following is a plus:
Javascript, Python
PostgreSQL
Apache spark
AWS toolset
Experience working in a product development environment
Perks:

Competitive salary + Health & Dental (After 3 Month Probation)

Collaborative environment of experienced professionals.

Participation in the early stages of a company; small team with lots of room to grow!

Fully stocked kitchen of snacks, beer Fridays, games nights, and more!

Office located in Downtown Vancouver, close to transit, shopping, restaurants, and panoramic waterfront views!

Powered by JazzHR",-1.0,Meda Agency I,Vancouver,"Vancouver, Canada",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,71.5,-1,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,1837,0
255,"Data Engineer


Eagle is currently seeking a Data Engineer for a six (6) month contract opportunity, scheduled to begin immediately.

Key Responsibilities

The successful candidate will be responsible for:
Creating optimal data pipeline architecture optimizing the AWS tech stack;
Developing and building data pipelines using ETL/ELT logic in an appropriate language;
Building massive lake for big data and deploying AWS tech stack;
Spinning up appropriate AWS tools instances (EMR, EC2, etc.) for a variety of jobs;
Ingesting multiple data sources into AWS lake for business consumption and automation employing a variety of languages and tools (i.e. scripting languages) to ingest data from multiple systems;
Developing scheduled automated batch jobs;
Setting up the data environment, data repositories and processes, data refreshes, and structuring the data in a way that is useable for agile analysis;
Creating data sets in the appropriate formats;
Developing data set processes for data modeling, mining and production;
Designing and creating all related extraction, transformation and load of data functions by designing the best possible ETL process around those goals;
Developing, constructing, and testing designs to ensure smoothly system operations;
Implementing ways to maintain and improve data reliability, efficiency, and quality;
Collaborating closely with data architects, data scientists and product team members on project goals;
Assisting with infrastructure development and appropriate access to data;
Working closely with Data Architect, Lead Architect and DevOps;
Developing automation priorities as assigned by Data Lead to enable Business team to improve efficiency;
Participating in Data Governance Development;
Supporting and developing data pipeline based on Data principles and vision; and,
Ensuring pipeline designs are portable and ability migrate between cloud systems.
Skills and Qualifications

The qualified candidate must have:
Experience with PowerBI;
ETL/Data experience;
Spark/Python development experience;
AWS Cloud experience (Data Lake, Data Warehouse, AWS tools); and,
Experience with AWS Quicksight is nice to have.
Don’t miss out on this opportunity, apply online today!

Eagle is an equal opportunity employer and will provide accommodations during the recruitment process upon request. We thank all applicants for their interest; however, only candidates under consideration will be contacted. Please note that your application does not signify the beginning of employment with Eagle and that employment with Eagle will only commence when placed on an assignment as a temporary employee of Eagle.

JOB#67260",4.0,Eagle Professional Resources,Calgary,"Ottawa, Canada",51 to 200 employees,1996,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (CAD),"S.i. Systems, Procom, Veritaaq",71.5,24,data engineer,na,0,1,1,0,0,0,1,1,0,0,0,0,0,0,0,2655,3
256,"Join SADA as a Data Engineer!

Your Mission

As a Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data issues facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring a combination of batch or streaming data pipelines, data lakes and data warehouses.

You will be recognized as an established contributor by your team. You will contribute design and implementation components for multiple projects. You will work mostly independently with limited oversight. You will also participate in client-facing discussions in areas of expertise.

Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage adaptability. This means that not only do our engineers understand that change is inevitable, but they embrace this change to continuously broaden their skills, preparing for future customer needs.

Your success comes from your enthusiasm, insight, and positive impact. You will be given direct feedback quarterly with respect to the scope and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, your collaboration with your peers, and the consultative skill you demonstrate in customer interactions.

As you continue to execute successfully, we will build a personalized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events. Due to the COVID-19 pandemic, travel has been temporarily restricted.

Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.

Training - Ongoing with a first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment
Required Qualifications:
Expertise in at least one of the following domain areas:
Big Data: managing Hadoop clusters (all included services), troubleshooting cluster operation issues, migrating Hadoop workloads, architecting solutions on Hadoop, experience with NoSQL data stores like Cassandra and HBase, building batch/streaming ETL pipelines with frameworks such as Spark, Spark Streaming and Apache Beam, and working with messaging systems like Pub/Sub, Kafka and RabbitMQ.
Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for minimizing downtime. May involve conversion between relational and NoSQL data stores, or vice versa.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or other customer-facing role
Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Applied experience operationalizing machine learning models on large datasets
Knowledge and understanding of industry trends and new technologies and ability to apply trends to architectural needs
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem
About SADA

Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA's values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.
Make them rave
Be data driven
Be one step ahead
Be a change agent
Do the right thing
Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!

Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, RRSP, professional development reimbursement program as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core: 3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.",4.7,SADA,Toronto,"North Hollywood, CA",51 to 200 employees,2000,Company - Private,IT Services,Information Technology,$100 to $500 million (CAD),-1,71.5,20,data engineer,na,0,1,0,0,0,1,1,0,0,1,0,0,1,0,0,6270,0
257,"Nous sommes à la recherche d’un(e) Data Engineer pour rejoindre l’équipe de notre client, leader au Canada dans une des industries les plus en croissance!

Cette entreprise accès sur l’innovation et bien établie a le bonheur de ses employés à coeur et dans leur ADN: tout y fait pour leur offrir une expérience hors-du-commun que ce soit au bureau ou actuellement à la maison.

En temps normal, leurs locaux ultra-modernes sont situès à Laval.

Le Data Engineer fera partie de l’équipe données et sera amené à proposer de nouvelles façon de faire sur le traitement des données et la conversion et la manipulation des données.

Il sera amené à transformer et migrer de gros volumes de données ainsi que participer à l’amélioration des processus et automatisation des outils de travail.

Responsabilités:

Création de scripts
Mise en place d’outils pour améliorer la migration, extraction et transformation de données
Travailler à partir de diverses sources données
Rédaction de scénarios de tests
Mettre en place des solutions innovantes pour le traitement de données massives en tenant compte des critères de performance et sécurité
Participer aux déploiements et la maintenance des environnements

Exigences:

Environ 2 ans d’expérience dans un poste similaire
Expérience avec de programmation avec des langage de scripting tels que Python, Bash, Shell et dans des environnements Linux
Connaissance poussée des bases de données et bases de données relationnels ainsi que langage SQL
Expérience en traitement et manipulation des données
Expérience en modélisation d’entrepôts de données (l’expérience sur RedShift, Snowflake sera un atout)
Expérience avec des outils BI et de visualisation de données (PowerBI ou autre)
Être familier avec les services AWS
Expérience avec des pipelines de données automatisées (Apache Airflow, Luigi etc.)
Expérience dans des équipes Agile et avec les différents outils CI/CD (Git, Jenkins, Docker)
Capacité à communiquer en français (essentiel)",-1.0,Bridge Ele,Laval,"Montreal, Canada",1 to 50 employees,2017,Company - Private,Consulting,Business Services,Unknown / Non-Applicable,-1,71.5,3,data engineer,na,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,1978,0
258,"Machine Learning Engineer
Design, develop and implement end-to-end machine learning production pipelines (data exploration, sampling, training data generation, feature engineering, model building, and performance evaluation).
Apply fundamental data science methods such as regression, segmentation, causal inference and machine learning to provide analytical insights.
Ensures that data pipelines and models are scalable, repeatable, and secure, and can serve multiple users within the organization.
Apply design-thinking and agile mindset in working with other engineers, and business stakeholders to continuously experiment, iterate and deliver on new initiatives.
Help drive transformation by identifying new business opportunities through leveraging data and machine learning. Collaborate with sales and marketing, product, technology, investment management & other enterprise data and AI teams to evolve analytics strategies for the business.
Explore new capabilities and technologies to drive innovation, and share insights from conferences, recent research, and projects focused on statistics, machine learning, and data science with the business.

What do you need to succeed?

Must have:
BS, MS, or PhD in Mathematics, Statistics, Computer Science, Engineering or equivalent
Extensive experience with Python and software engineering fundamentals
Strong data modeling and data analytics skills
Practical experience applying machine learning algorithms and libraries to a business problem
Demonstrated ability to present analytical insights effectively to technical and non-technical stakeholders
Ability to launch production quality machine learning models in collaboration with engineering team
Strong sense of ownership and growth mindset

Nice to have:
Experience with statistical techniques and their applications in sales and marketing functions
Extensive domain knowledge in sales/marketing, financial products or asset management
Effective data storytelling and design thinking
Experience with big data and cloud technologies such as PySpark, Hadoop and S3
Understanding of scalable ETL pipelines in Docker/Kubernetes environment",3.4,CoreHR Solutions Inc.,Toronto,"Toronto, Canada",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,71.5,-1,machine learning engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,1,2144,0
259,"Keyrus Canada is looking for a Data Engineer.

Your main mission:
You will play a key role in providing our clients with business intelligence and ETL solutions to manage their data assets. You will work directly with our client's to add value to their data intelligence environment through the use of tools such as Alteryx and Tableau. You will be responsible for the entire end to end analytics solution, from backend data engineering, manipulation, and cleansing, to front-end data visualization.

Conduct business and functional requirements gathering and provide projects estimates.
Design and develop data models and ETL processes to feed data warehouses.
Design and develop reports and dashboards for informational/operational needs according to best practices.
Document business intelligence and information management solutions.
Support your colleagues in the implementation.
Perform/document tests (unit/integrated) for the solutions you have participated in.
Carry out activities in compliance with and promoting the Business Intelligence norms and standards established by the organization.
Coach your team members and colleagues.
Write all types of documents to feed an internal community of users and also to make presentations.

Our ideal candidate:
At least 3+ years of experience as a Business Intelligence Developer, working directly with tools such as Alteryx, Talend or SSIS for ETL as well as with a data visualization tool such as Tableau
Experience working with a relational database (SQL, Oracle, etc.) and data modeling
Knowledge of data visualization best practices and cloud warehouses (i.e. Snowflake, Redshift) would be an asset
Knowledge of cloud data pipelines setup and Python would be an asset
Experience working with business teams to translate functional requirements into technical requirements
Minimum of a Bachelor's Degree in IT or related field
Must be eligible to work in Canada without a present or future Keyrus-sponsored Visa/Work Permit

You love:
Contributing to make your solutions impactful
Expressing your ideas and share your opinions
Working in a growing company
Celebrating your success
Being yourself with your colleagues and have fun in your work
Working in an inspiring environment
Enjoy from many work benefits

Keyrus Canada, that’s:
A success-story in Data and Digital!
High added value projects to optimize performance and competitiveness of our clients as well as accelerating their transformation
20 years of expertise in consulting and integration of innovative solutions based on:
Data Intelligence (Business intelligence, Big Data & Analytics, information management, training externalization)
Digital Experience (Innovation and digital strategy, digital marketing and CRM, digital commerce, digital performance, digital experience)
Management & Transformation (strategy and innovation, transformation, project support and performance management)
3000 talents in 17 countries and 5 continents
A DNA focused on innovation and entrepreneurship

Why joining us?

To integrate in a community of curious and passionate experts and to evolve in a multi-cultural environment promoting international mobility.

Because you are a #DataGeek, #DigitalAddict, #InnovationLover!",3.9,Keyrus,Canada,"Levallois-Perret, France",1001 to 5000 employees,1996,Company - Public,IT Services,Information Technology,$100 to $500 million (CAD),"Slalom, Accenture, Teknion Data Solutions",71.5,24,data engineer,na,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,3229,3
260,"About Molecular You

Molecular You is a personalized health company with a mission to help people take control of their health through personal health assessments and preventive action plans. The company analyzes the broadest range of biomarkers in North America, from a single blood sample, to give a dynamic view of an individual’s health.

MY Health Intelligence is the company’s digital health platform that brings together biomarkers, expert analysis and the latest global research in a visually intuitive dashboard. Founded by world leading scientists and clinicians, the company was originally part of the University of British Columbia’s (UBC) Personalized Medicine Initiative.

We are building something challenging and unique, with the potential to change healthcare for the better. Expect to learn a lot and solve interesting problems every day in a dynamic, team-oriented working environment. You will be working with a team of brilliant scientists and developers. We might add (with a hint of bias) that we are a pretty fun(ny) team!

Opportunity

We are seeking a motivated, dynamic, and detail-oriented Data Engineer/Scientist to join our team at our Vancouver, BC location on a 8-month contract position with the possibility of going full-time. You will report to and work closely with our Development lead and Director of Data Science. You’ll be handling the design and construction of scalable management systems and ensuring that all data systems meet company requirements.. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.

Core Responsibilities
Develops and maintains scalable data pipelines to support continuing increases in data volume and complexity.
Collaborates with the relevant teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Works closely with a team of frontend and backend engineers, product managers, and analysts to develop strategy for long term data platform architecture.
Develop data set processes for Data Modeling, Mining and Production.
Develop simulation program using multi-dimensional datasets
Survey designated research area and keep curated information as up to date as possible
Participate in discussions revolving around integrative biology and multi-omics (genomics, metabolomics, proteomics) in scientific meetings
Performs other duties as assigned
Qualifications/Experience

Two or more years of demonstrated experience with the following:
Experience with Amazon Web Services, data warehousing, and building data pipelines
Proficiency in data science packages (eg. Python and/or R) and databases (eg. SQL)
Experience with Ruby (Ruby on Rails)
Experience with statistical and/or machine learning methods (eg. longitudinal data analysis, principal component analysis, ROC curves, regression, classification, clustering)
Experience with data visualizations tools (eg. Tableau)
Clear verbal and written communication.
Ability to work independently and as part of a team.
Ability to meet tight deadlines and deal with multiple concurrent tasks.
How to apply

Please send us your resume and cover letter, explaining why you’re a fit for this role and our company. We appreciate your interest! Please note that only those candidates selected for an interview will be contacted.

** Applicants must currently reside in BC, Canada or be willing to relocate.",-1.0,Molecular You,Vancouver,-1,-1,-1,-1,-1,-1,-1,-1,71.5,-1,data engineer,na,0,1,0,1,0,1,0,1,0,0,0,0,1,0,0,3603,0
261,"Tech Entrepreneur AI/Machine Learning Engineer


Do you have dreams of founding your own startup?

Do you love solving global, human and technological problems?

Let's build the future together!

Your opportunity and benefits:
Technical lead/co-founder of your own company
Solve problems by commercializing cutting edge technology Major impact!
Annual salary and equity in the company of course
Mentorship, coaching and support were here for you!
Access to high level tech and consumer electronics industry contacts all the big companies
Cool Startup environment celebrations, endless lattes, healthy snacks
Your skills:
PhD or Masters in Computer Science, Mathematics, Data Science or equivalent computational field
Experienced in the field of machine learning and artificial intelligence
In-depth knowledge of programming/implementation ability in Python, C++ or other languages, familiarity with ML paradigms (e.g. TensorFlow)
Follows trends in technology
Develop prototypes of innovative data for different products.
Experience in various implementing models and technologies
Your Personality prototype is:
Self-motivated researcher, proactively seeks for solutions of challenging problems.
Strong cross-functional leadership and team building skills
Excellent verbal and written communication skills
Creative, productive, multi-tasking and obsessed with problem-solving
Performance minded development with optimization skills
Resourceful, with a high tolerance for ambiguity and posses strong project planning/management skills
Hacker personality
Our technical leads are known internally as Entrepreneurs-in-Residence (EiR) and are the heart of our start-up foundry. The Co-Founders and leaders of our companies are the innovative drive behind our success.

About TandemLaunch

TandemLaunch is a unique Canadian start-up foundry. We create cutting-edge technology companies based on research taken straight from major university labs. We focus on commercializing innovations in consumer electronics, hardware-enabled technologies, machine learning, and embedded systems, and operate all companies on-site in our Montréal, Canada workspace.

TandemLaunch identifies novel university inventions to bring to market. A start-up is then formed and funded in stages totalling $600K over a 12-18 month incubation period. The Technical Lead directs the new start-up through to graduation and raise their first Series A venture capital investment. After which they are spun-off and incorporated as an independent company.

Areas of interest include, but are not limited to:

> Machine learning, optical physics, embedded systems, computer vision, nanoscale materials, neuroengineering, wireless communications, aerospace/UAVs, biometrics, energy harvesting, small-scale robotics, AR/VR hardware, and digital signal processing.",3.9,TandemLaunch,Montreal,"Montreal, Canada",1 to 50 employees,2010,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,71.5,10,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,2822,0
262,"XE is looking for a world-class Data Engineer to join the XE Data Science team. The XE Data Science team supports the most popular apps and websites relating to currency in the world. Our platform absorbs and processes large amounts of data, and millions of events daily, using Amazon Web Services to support our currency informational and transactional products.

In this role you will be a part of the team responsible for engineering the next generation of the XE.com data platform, working with Data Scientists, marketing and operations, to create frameworks and tools to process data at scale.

You will stay on top of best practices and be responsible for disseminating that information to other members of the development team. You will have an interest in using the latest open-source technologies and be an advocate for continuous improvement.

Responsibilities:
Create performant API services within the AWS environment
Create and manage NoSQL data layer services such as DynamoDB for use with performant APIs
Create and manage AWS Glue jobs to manage ETL of data from disparate sources (Kinesis, API, S3) to power S3 data lakes
Create and manage Redshift clusters to source and provide warehouse data to business
Develop, maintain and enhance our data services, including existing Glue jobs and Lambda services (Python / Node.js)
Keep up on best practices for data systems architecture, particularly in a cloud-based environment
Self-motivated with a desire to automate CICD pipeline using Jenkins, Gitlab CI, and Terraform
Respect security and privacy issues
Ensure all components are highly scalable, maintainable and monitored
Optimization of cloud services for security, cost and performance
Requirements
Degree in Computer Science, Software Engineering, or related discipline
AWS certifications are a plus
Strong knowledge of developing and maintaining data API services in a cloud environment
Ability to adapt quickly and develop in-depth technical understanding of new applications and complex technologies
A strong interest in data and the insights it can provide to better serve our customers
Experience with relational and unstructured databases and data lakes
Knowledge of data-mining and analytics
An understanding of business goals and how data policies can affect them
Strong communication and collaboration skills
A strong understanding of the concepts associated with privacy and data security
Benefits
Competitive Salary
Health, Dental and Vision Benefits
RRSP Employer Match
Free Birthday Off
Personal Days
Employee Appreciation Days
Annual Holiday Parties
Complimentary Coffee Bar
On-Site Gym",3.2,Xe,Newmarket,"Bracknell, United Kingdom",201 to 500 employees,1993,Company - Private,Financial Transaction Processing,Finance,$100 to $500 million (CAD),-1,71.5,27,data engineer,na,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,2622,0
263,"Field Cost Analyst (Data Analyst)
Location: Nisku, Alberta
Division:
Employment duration: Full time
Employee Referral Bonus:
Description
Field Cost Analyst (Data Analyst)
HDD
Nisku, AB

At Michels Canada, We Do That. Our company is passionate about our business, our customers and our talent! We are cultivating a culture of excellence and aspire to be best-in-class in the industry. Michels Canada is committed to supporting Canada’s prosperous future by constructing safe, reliable infrastructure solutions to serve the public’s energy, water and wastewater, and transportation needs. We care about doing what is best for our people, our customers, the communities in which we work and our country. We strive to provide our employees with meaningful and challenging work, and an engaging and collaborative environment in a fast paced setting.

What We Offer
Competitive compensation
A challenging and rewarding work environment
An opportunity to be part of an exciting, growing business!
Your Opportunity with Michels Canada

The Field Cost Analyst is a key member of the Michels Canada field project support team. The Field Cost Analyst is required to support the ongoing operational, production and administrative functions of the project. The Field Cost Analyst will, based on direction from the Project Manager, liaison with the PM and Owner to administer project requirements per the Prime Contract, with the objective of stewarding consistency and identifying and mitigating risks.

We are looking for individuals to fill future vacancies for upcoming HDD projects.

Your Key Responsibilities
Maintain and promote a strong safety culture for all employees, vendors, and customers and follow all safety policies, procedures and regulations. Identify and communicate workplace hazards and correct or seek assistance in correcting unsafe actions or conditions
Review the Prime Contract and all project documentation to identify, monitor, and analyze the variances from the baselines. Initiate project change orders to accurately capture data including cost, schedule and resource impacts
Establish the construction tracking and control systems utilizing the templates provided in accordance to the project WBS and Contractor Interface and Reporting requirements
Understand Prime Contract notice requirements. Interface with the subcontractors to ensure accurate and timely submittal of daily LEM Sheets, Equipment & PO Log’s, progress and schedule updates
Ensure that all activities within the project schedule are updated (start and finish dates) and supported by the physical percentage of completed tasks based on the progress report and agreed performance baseline
Review of subcontractor Invoices, ensuring that the coding, amounts, and reported quantities are in agreement with the information provided by the subcontractor to date, and in agreement with the terms and conditions of the subcontract
Provide the Project Controls Analyst the contractor Forecast to Complete (FTC) values based on the collection of subcontractor information and reviews
Ensure Field Project Closeout process is completed, including hours and costs, and the completion of the subcontractor invoicing
Assist the project teams in their review of contractual documentation and provide data-driven recommendations on contract terms and conditions. Provide guidance and support regarding Contractual requirements
Support the identification & reporting of Cost and Schedule impacts, as well as the risk and support recovery planning/mitigation where necessary
Ensure project compliance with internal corporate requirements related to contract administration
Adhere to all corporate policies and ethics codes, i.e., Corporate Code of Conduct
Other duties as assigned
Your Capabilities and Credentials
Minimum 5 years related experience is required (preference to those with contracts administrator backgrounds)
Possess strong computer skills: Proficiency in MS Office including MS Word, MS Excel, MS Visio and MS Project
Contract experience in a manufacturing, oil & gas or construction environment is preferred
Experience analyzing data and creating reports based on data analysis.
Must possess a valid driver license for the type(s) of vehicles which may be driven and an acceptable driving record
Travel 15%-25% of the time
Apply Now!

We offer competitive total compensation, meaningful and challenging work, and an engaging and collaborative environment. For more information on our company, please visit our website at www.michelscanada.com. To apply, please submit your resume and cover letter on the Careers portion of our website.

We thank all applicants for their interest; however only those selected for an interview will be contacted. Michels Canada is committed to creating a diverse workforce and an inclusive culture, as an equal opportunity employer we encourage applications from all qualified individuals.

Michels Canada is committed to supporting Canada’s prosperous future by constructing safe, reliable infrastructure solutions to serve the public’s energy, water and wastewater, and transportation needs. Michels Canada is headquartered in Nisku, Alberta, Canada, and serves many industries, including pipeline, HDD, tunneling, and Direct Pipe.

Our capabilities span from relining deteriorating sewer and water mains and utility maintenance holes in expanding metropolitan areas, to building tunnels for wastewater treatment plants under the most densely populated regions of Canada. We construct reliable pipelines and underground river crossings for the critical growing energy sector. Michels is well equipped to mobilize equipment and personnel to projects in highly urban and very remote locations across Canada.

Michels delivery methods include bid-build, design-bid-build and public-private partnerships (P3). We are a preferred partner on large-scale joint ventures in multiple segments of our business. We care about doing what is best for our people, our customers, the communities in which we work and our country.",3.5,Michels Corporation,Nisku,"Brownsville, WI",1001 to 5000 employees,1959,Company - Private,Building & Construction,"Building, Repair & Maintenance",$2 to $5 billion (CAD),-1,71.5,61,data analyst,na,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6035,0
264,"Summary of Position and Responsibilities

As part of Xanadu’s Machine Learning team, the selected candidate will be responsible for working with a multidisciplinary team of machine learning experts and quantum algorithm developers to bring machine learning models into production. They will develop, deploy, and maintain code, models, and pipelines leveraging various cloud providers and services; automate model training, testing, deployment, and monitoring; and design solution architectures for data driven applications.

Prospective applicants must have strong technical, programming, and mathematical skills. They must possess the ability to evaluate established methods and tools, learn new ones quickly, and apply their knowledge to solve practical problems. Applicants should be self-motivated and demonstrate the ability to successfully meet objectives. Familiarity with quantum computing is not essential for this position, but is a definite plus.

Basic Qualifications and Experience
MSc in Machine Learning, Mathematics, Computer Science, Physics, Engineering, or a related field.
Experience building and deploying production-grade machine learning applications at scale.
Strong software engineering skills across multiple languages (Python, Scala, Java, C++, etc.)
Experience building and supporting development environments for Machine Learning/Data Science teams.
Experience with distributed computing frameworks like Spark, Dask, or Hadoop.
Preferred Qualifications and Experience
PhD in Machine Learning, Mathematics, Computer Science, Physics, Engineering, or a related field.
Solid mathematical understanding of machine learning, statistical modelling, probability theory, and linear algebra.
Experience with frontend and backend web application development.
Passionate about agile software processes, data-driven development, reliability, testing, and continuous delivery.
Familiarity with and experience working in a fast-growing technology start-up environment.
If you are interested in this opportunity, please submit a copy of your CV along with a cover letter outlining why you think this is the right role for you!

At Xanadu, we are committed to fostering an inclusive, safe, and equitable culture that meets the needs of all individuals. We actively support a barrier-free workplace and ensure team members feel included, valued, and heard. We are dedicated to being a fair and equitable employer, and that includes the representation of women in STEM. Should you require accommodations at any point during the recruitment process please contact Human Resources at hr@xanadu.ai (mailto: hr@xanadu.ai).",-1.0,Xanadu Quantum Technologies I,Toronto,-1,-1,-1,-1,-1,-1,-1,-1,71.5,-1,data engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,2629,0
265,"IT’S all ABOUT THE DATA…
Posted: 2020-06-09
Closing: When Filled
Location: Edmonton Kingsway
You’re definitely a “Techie” who’s passionate about finding the right solutions and ensuring a smooth-running system environment. You are not afraid to pave the way for bigger and better things. As a Data Engineer for our AMA Insurance Information Technology department, you’ll be responsible for the collecting, sorting, processing, analyzing of huge sets of data, and creating the visualizations. We are looking for a someone whose primary focus will be on finding creative optimal solutions to use for these purposes, then maintaining, implementing, and monitoring them.
WHAT MOVES YOU
You have good analytical and problem-solving skills for technology and business.
You’re an excellent communicator and an even better listener — it’s probably why you’re also a great negotiator.
You’re not only motivated to go above and beyond in your own role, you know how to motivate others and get everyone on board.
You love being able to share your knowledge and experience to help others grow and excel in their careers.
Your superior organizational skills leave no room for clutter — in your workspace or in your brain.
You’re the ultimate multi-tasker, able to juggle multiple projects and requests with ease in a deadline-oriented environment – and you make it look easy.
You thrive in a collaborative environment, where change is the name of the game.
You’re comfortable working directly with all levels of management to accomplish common goals.
WHAT YOU’LL DO
Report to the Manager, Data Engineering (Insurance).
Recommend practices in the design & implementation of solutions which enhance our customers experience.
Design & develop data framework to support customer events (Data Modelling, ETL, Data Cleansing, Data Enrichment).
Investigate new products, tools, and data technologies (Big Data, Data Mining, Deep Learning) to add value to the business; ensure applications are on the right platform and that we’re in a sustainable position moving forward.
Collaborate with business units and IT to define and document: data reporting and business analytics requirements, cubes, data dictionaries, data models and dashboards.
Ongoing development and enhancements of data integrity processes, data quality assurances, reporting, analysis, and formats.
Synthesize user requirements keeping in mind data, business process and system restrictions and assist in translating requirements.
Converting data into relevant consumable information to help business in making informed decisions through data mining, statistical and predictive modeling.
Provide operational support for existing data warehouse environment.
Use best practices to write well designed, testable, and efficient code.
Identify technical debt/operational improvements & implement solutions.
Meet with business partners to understand & gather requirement for strategic initiatives.
Work in a collaborative space with a team of people.
WHAT YOU’VE DONE
You have a technical diploma related to Computing Science, Statistics, Business or have an equivalent combination of education and experience.
You have a minimum of 3 years’ progressive experience in data analysis and/or business analysis.
You are familiar with Design & Engineering of Data Warehouses (Data Modelling, ETL, Data Cleansing, Data Enrichment).
Experience with Data Mining & Deep Learning using algorithms.
Experience with Big Data technologies such as Hadoop, Spark, Data Bricks, Azure Data Lake, Kafka, etc. would be an asset.
Experience with Business Intelligence technologies such as Power BI, Excel Pivot Tables, Cubes, SSRS, etc.
Proven track record with Agile/Scrum Methodologies.
Practical experience with software development and data engineering practices.
Skilled with test driven development (TDD), continuous integration and deployment.
Passion for using network, and internet security including encryption and authentication mechanisms.
WHAT YOU’LL GET
Competitive salary.
Flexible benefits.
Outstanding employer-paid Pension Plan.
Great AMA discounts.
Unlimited learning opportunities.
Growth opportunity as a leader
Paid vacation and floater day.
We thank all applicants for their interest; however, only those selected for an interview will be contacted.",2.7,Alberta Motor Association,Edmonton,"Edmonton, Canada",1001 to 5000 employees,-1,Non-profit Organisation,Membership Organisations,Business Services,$100 to $500 million (CAD),-1,71.5,-1,data engineer,na,0,0,1,0,0,0,1,0,1,0,0,0,0,1,1,4293,0
266,"At Kinaxis, who we are is grounded in our common belief that people matter. Each one of us plays an important part in accomplishing our work, building our culture and making a global impact.

Every day, we're empowered to work together to help our customers make fast, confident planning decisions. This is how we create a better planet for each other, for our customers and for generations to come. Our cloud-based platform RapidResponse ensures that the products we need everything from medicine and cars, to day-to-day items like toothpaste make it to market and into our hands when we need them with minimal ecological footprint.

We make the world better, and you can too.

Senior Data Analyst


Job location: our office in Toronto, Canada

As the Data Analyst / Senior Data Analyst, you will be part of the team that tackles this challenge. If you love solving complex problems, analyzing complex datasets, finding insights from data, and learning new technologies, this role is for you.

What You Will Be Doing
Liaise between Analytics, Engineering and Data Science teams to support continuous improvement for product analytics including data science models performance and machine learning outputs
Evaluate and measure models' outputs to ensure client requirements are met
Define and implement metrics and KPIs that will drive business success
Automate internal communication of product and models performance measurement to enable proactive research and improvements
Answer business questions by using appropriate statistical techniques
Support the creation of insights and analysis and their translation into accessible formats
Who You Are
Expertise in SQL, Python a must and hands on experience with cloud infrastructure preferred
Strong analytical and problem solving skills
Bachelor's degree in any quantitative field or related experience in analytics
Excellent communication skills, ability to clearly explain technical terms to non-technical audience
Experience in retail, e-commerce, or supply chain would be considered an asset
What we have to offer
Challenging Work - We love solving highly complex problems. And as the global leaders in our industry, we never stop innovatingour work is never ""done. That's because across our teams and in all roles, every employee is empowered to bring their best ideas forward and to jump in and solve the problems they're passionate about.
Great People - We take our work seriously, but we don't take ourselves too seriously! It's in our DNA to celebrate, laugh, and have fun. We are stronger, together, when we are open, honest, and above all, real. Every person is valued here and plays an important role in our shared success.
Global Impact - As a global team spanning continents, boundaries, and cultures, every day we are inspired by the impact our work has on our colleagues, our customers, our communities, and the world at large.
For more information, visit the Kinaxis web site at www.kinaxis.com or the company's blog at http://blog.kinaxis.com/.

Kinaxis invites candidates to apply to its welcoming community. Accommodations are available upon request for applications in all aspects of the recruitment process. If you require accommodation, please contact Human Resources at accommodation@kinaxis.com",4.7,Kinaxis,Toronto,"Kanata, Canada",501 to 1000 employees,1984,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (CAD),-1,71.5,36,data analyst,senior,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,3269,0
267,"Overview :

auticon Canada enables companies to leverage a largely untapped pool of technology talent and we are the first and largest technology services company in Canada to recruit and employ people with autism spectrum disorder (ASD) as IT consultants. With the skills of our people, we consistently deliver high quality projects for clients across Canada.

auticon Canada is driven by the mission and belief that the cognitive abilities of people with ASD deliver exceptional business value. We are a fast-growing Canadian company that is committed to enabling people on the spectrum to learn, grow, and develop sustainable and rewarding careers in technology.

We are currently looking for experienced Data Engineers and Data Scientists to join our team of consultants and work on client projects in Calgary, Montreal, and Toronto.

Responsibilities:

As an Intermediate Data Scientist, you will work on challenging and rewarding client projects with responsibilities that include:

· Conducting data mining and applying statistical and mathematical analyses to identify trends, solve analytical problems, optimize performance, and gather intelligence.

· Develop and apply methods to identify, collect, process, and analyze large volumes of data to build and enhance products, processes, and systems.

· Identifying patterns in data for use in predictive applications.

Background & Skills

We are looking for people with:

· Bachelor’s Degree in Computer Science or areas such as Business Intelligence, Artificial Intelligence, Machine Learning

· Demonstrated proficiency in applied programming and/or manipulation of data leveraging : Python, R, SQL, Java...

· 3+ years' experience working in a big data environment

· Experience applying machine learning to domain specific applications, such as geospatial intelligence, natural language processing, behavioral modeling, social computing, time series prediction, computer vision, …etc. is a strong asset.

· Fluency in English

· Ability to work in French is a strong asset

Why should you come on board ?

· Because you will benefit from a business philosophy that values the exceptional cognitive abilities of people on the autism spectrum, and focuses on your strengths.

· Because auticon is an entrepreneurial, fast-growing for purpose company.

· Because auticon can help you develop an exciting career, while promoting, autonomy and self confidence.

· Because you are looking at adding social impact to your professional activity.

· Because you will be able to enhance your human and professional experience while benefiting from the support and services provided by our job coaches and project managers.

· Because you will be able to develop your skills in a professional environment designed to reduce stress, and promote inclusion.

· Because you will be able to benefit from a business environment that promotes learning and personal growth throughout your career.

“The on-boarding process at auticon has been specifically designed to help me demonstrate the pluses I bring to the company. When I describe to people the on-boarding process and the care and attention that is taken when placing a consultant on a client site, they always wonder why these things are not done for everyone. auticon has helped me be the best version of me, help client companies get the best from me, and provide an example of how companies can work with the neurodiverse.” - David, auticon consultant.

Apply Now !

Applicants interested in this opportunity can send us their resume by going to https://auticon.ca/online-application-form/

Reference ID: 2

Job Types: Full-time, Part-time, Permanent

Benefits:
Employee Assistance Program
Flexible Schedule
Work From Home
Schedule:
Monday to Friday
Experience:
Data science: 2 years (Required)
Work remotely:
Yes",5.0,auticon,Calgary,"Berlin, Germany",201 to 500 employees,2011,Unknown,-1,-1,Less than $1 million (CAD),-1,71.5,9,data scientist,senior,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,3820,0
268,"Company Description

The Company

Hitachi Solutions is an impact-driven global leader in consulting dedicated to delivering competitive, end-to-end solutions based on the Microsoft Cloud. Our deeply connected teams are unified by our values and our commitment to helping clients succeed and compete with the largest global enterprises. We are a division of the 38th largest company in the world and carry the strength of a vast network of interconnected Hitachi companies all while remaining nimble, agile, and ready to pivot at a moment’s notice.

Hitachi Solutions started as three founding partners and transformed into nearly 2,000 consultants, developers, and support personnel all around the globe. With 36 Microsoft Partner of the Year awards, Hitachi Solutions has established itself as a leading partner in the ever-growing landscape of technology consulting.

The Culture

Our team is a mix of curious, fun, and get it done. We celebrate collaborative thought leadership and individual talents so that our ideas are translated into real-world results.

Each day, our team members show up to work as a blank slate with the sole purpose of coloring their canvases with knowledge. We are a complex group of resilient learners and encourage one another to go beyond the limits of conventional expectations. As a member of the dynamic Hitachi Solutions team, you will be challenged, pushed, and unconditionally supported in your efforts to drive the business forward.

** THIS ROLE IS OPEN TO ANY CANDIDATES FROM WITHIN CANADA**

Job Description

As an Analytics Data Engineer for Hitachi’s Azure Cloud Enablement Team you will be responsible to deliver high quality modern data solutions while being part of a dynamic and fast-growing team consisting of endless opportunities.

The successful candidate will be a self-motivated, passionate individual who strives to be the best at what he/she does and creates a trail of ecstatic Customers for life. This person will love to learn, contribute to the team and wants to be part of something great.

Knowledge and Experience
Hands-on experience with the Azure Data Platform (Data Factory, Data Lake, Data Warehouse, Blob Storage, SQL DB, Analysis Services)
Data quality (profiling, cleansing, enriching)
Data Modeling – including design from conceptual to logical to physical data models
Considered to be an expert in T-SQL
Hands-on experience with MPP database technologies such as Azure SQL DW, Teradata Netezza, etc.
Experience with multiple components listed, required:
Power BI including DAX
Database migration from legacy systems to new solutions
DevOps
Interpreted languages (i.e. python, C-sharp, Java, Scala, etc.)
Databricks
LogicApps
PowerApps
HDInsight
D365FO / CE experience as it pertains to data extraction
Knowledge of Cap Theorum and Distributed Database Management Systems, iis considered an asset.
Opportunity for a career path into a Data Scientist role if desired
Qualifications

Required skills / qualifications
Proven ability to engage customers to understand customer challenges and needs to develop technical solutions
3+ years of hands on experience working with the Azure Platform and its relevant components
Proven experience of architecting Azure services into a solution platform on Microsoft Azure for Analytics
Minimum 5 years hands on development experience with ELT/ETL using MS SQL Server, Oracle or similar RDBMS Platform
Familiarity with data visualization tools (e.g. PowerBI, Tableau etc.)
Experience or desire to coach, mentor and provide leadership to team members
Post-secondary degree/diploma in Business, Computer Science or a related discipline;
Strong communication skills, both written and verbal
Prepared for domestic and US travel as required
Preferred considered an asset, NOT required:
Project management experience
Databricks and Spark SQL
Previous Consulting experience
Additional Information

Opportunity Benefits:
· Medical and Dental Benefit Package (including Long Term and Short Term Disability)
· Base salary plus targeted bonus package
This position can be based anywhere in Canada, though travel might be required.",4.0,Hitachi Solutions,Toronto,"Tokyo, Japan",10000+ employees,-1,Subsidiary or Business Segment,IT Services,Information Technology,Unknown / Non-Applicable,-1,152.0,-1,data engineer,na,0,1,1,1,0,1,1,0,1,0,0,0,0,0,0,4128,0
269,"Listing Info
Finesse – Ottawa, Canada

We understand the importance of a system that works together. Join our team of leaders to begin a rewarding career.

Current Need – This job is located in British Columbia, Canada. All applicants must have the right to work in Canada in order to be considered for this role.

The Enterprise DBA / Data Analyst is a member of the Enterprise Tools team, focusing on administration of the Microsoft SQL Server infrastructure used to support over 35 line of business applications and 90 databases, including the Data Warehouse and data integration services across the IWS business unit while meeting regulatory requirements and compliance standards. Approximately 50% DBA duties and 50% Data Warehousing duties.

Manages the SQL Server environments, including Production, Test, and Development
Responsible for High Availability and Disaster Recovery capabilities and strategy, such as fail-over clustering, backups, and log shipping
Monitors and optimizes performance and troubleshoots both functional and performance related issues
Provisions databases, permissions, and other configuration as required
Oversees Data Warehousing strategy and implementation
Contributes to the design and standards around dimensional data models, extract-transform-load (ETL), and reporting
Manages the IWS QlikView infrastructure
Develops databases, ETL, and reports as required
Follows standards for documentation, configuration management and change management
Carries out other tasks as assigned
Qualifications

Minimum Requirements

+ years experience in database administration
Additional Knowledge & Skills

years combined working experience as a DBA, database developer, and/or data analyst preferred
Critical Skills

Strong administration experience with Microsoft SQL Server, including failover-clustering (FCI), log shipping or Availability Groups
Experience in T-SQL database development, including views, complex stored procedures, functions, CLR functions and the like
Experience with SQL Server Reporting Services (SSRS) and SQL Server Integration Services (SSIS) or similar reporting/ETL tools
Experience with monitoring tools, such as SQL Sentry, for server health and performance
Any experience with other BI tools such as QlikView, Tableau, MS PowerPivot / PowerView / Semantic Model is an asset
Any experience with Oracle / PL-SQL is an asset
Excellent English communications (written and verbal) to communicate effectively with peers and stakeholders across the organization
Excellent interpersonal skills
Excellent organizational skills
Able to learn quickly and independently
Education
year degree in computer science or related field or equivalent experience",3.3,Finesse-Tech,British Columbia,"Bihar, India",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,152.0,-1,data analyst,na,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,2700,0
270,"At Bond, we design creative and innovative solutions for our clients, all with the goal of helping them build ever-stronger loyalty to their brands. That can take us in some pretty amazing directions, and as a Data Engineer, you’ll have your hands on the wheel as we drive the future of loyalty.

Working on the bleeding edge of exciting technology, you're afforded the opportunity to experiment with new tools and attempt radically different approaches than traditional software engineering affords. Every day with the Data Engineering team is different and each project presents its own set of new and exciting challenges. Things shift very quickly in our industry and we rely on the Data Engineering team to keep us ahead of the curve and moving in the right direction.

Here's what we want:
Problem Solver: You are curious and loves exploring multiple approaches to find the most efficient, scalable solution and solve a problem
Collaborative: You work well with other people
Passionate: A passion for Big Data and an interest in the latest trends and developments constantly researching new tools and data technologies
Self-starter: You are comfortable helping your team get things done
Here's what you'll be doing:
Design, implement, and maintain data pipelines for extraction, transformation, and loading of data from a wide variety of data sources to various data services
Identify, design, and implement system performance improvements
Identify, design, and implement internal process improvements
Automate manual processes and optimize data delivery
Useful skills/background: You may or may not tick off every box, and that's ok. Each person brings a different background and different skills. If you think you are a good match for what we are looking for tell us why, and tell us what you are doing to improve yourself and we'll see what we can do to help!
A degree in Computer Science/Engineering or related field
2-4 years of experience in a software engineering environment
Experience with SQL and NoSQL systems
Knowledge of Hadoop, Spark, Kafka or other equivalent technologies
Proficiency in some of the following languages: Scala, Java, Python, Bash
Experience with automated testing systems
Mentorship, collaboration, and communication skills
Knowledge of data modelling, data warehousing, ETL processes, and business intelligence reporting tools
Experience working with CI/CD, containerization, and virtualization tools such as Gitlab, Jenkins, Kubernetes, Docker
Experience with tools like Databricks, Snowflake or PowerBI
Why Join Us?

Bond Brand Loyalty is proud to be recognized as one of Canada’s Best Managed Companies.

We’re 400(ish) people working tirelessly together to make the world a more loyal place. You’ll be joining a hyper-talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. You’ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client’s biggest business challenges.

If you’re looking to build your career, build your skills and build bonds apply today!

Bond Brand Loyalty welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.",3.2,Bond Brand Loyalty,Mississauga,"Mississauga, Canada",201 to 500 employees,1980,Company - Private,Advertising & Marketing,Business Services,$100 to $500 million (CAD),"LoyaltyOne, Aimia",152.0,40,data engineer,na,0,1,1,0,0,1,1,0,0,0,0,0,0,0,0,3275,2
271,"Company Profile

TTT Studios is a digital innovation studio working for a global client list in multiple industries. Over the past eight years, we have built multiple applications and patented a portfolio of technologies. This experience puts us in a strong position to cater to larger accounts and launch our own products.

We are a family. We have fun. Design means everything to us and we have the technical chops to deliver what lesser programmers might describe as spooky magic. We expect amazing things from every TTT family member and drive each other to achieve greatness.

Role Summary - Big Data Engineer (Contractor)

We are looking for a talented and experienced big data engineer who is meticulous with designing and then developing data platforms for TTT Studios' client projects. The ideal candidate should have a deep understanding of best practices when it comes to building data pipelines and applications to stream and process datasets at low latencies.

Job Specifics
Big data platform architecture design.
Large dataset processing and migration.
Writing clean, readable, and testable code.
Ensuring the best performance and user experience of the application.
Seeing through a project from conception to finished product.
Work closely with the engineering team.
Documenting architecture and technical specs for a backend application.
Directly conversing with clients and stakeholders.
Skills and Qualifications
3+ years of experience in big data analytics platform.
Expertise in Spark, Akka, Kafka/Pulsar, AWS EKS
Experience in Cassandra database and Snowflake platform.
Proficient in Scala/Java programming language.
Experience writing technical documentation and software architecture.
Understanding of REST APIs, OOP, and related best practices.
Nice to have: Python, Ruby on Rails
Nice to have: Experience building CI/CD pipelines.
Hiring Process
Complete this application and include your resume or CV.
If your profile matches what we are looking for, we'll contact a you and setup a short phone call.
We will also setup an interview at our offices or via Zoom. We'll talk about your experience, what do you think about patterns, architecture, and some common situations while developing an app.
We will send you a challenge your way! You will be working with the team solving a specific task regarding an API and a backend service.
After finishing the code challenge, we'll come to a decision.
A Day at TTT Studios

The work culture at TTT is second to none. On arrival, head to the kitchen for your daily caffeine fix before joining the team in our open-plan office space. Once you've settled in, our engineering team will onboard you with our development processes and technical standards. Equipped with the tools you need, get ready to jump into action. Working from home is always an option.

Our clients operate across a wide range of industries that span from tourism to communications. For every project you take on, you’ll encounter intellectually stimulating and impactful technical challenges that keep you on your toes. For an idea of some of the projects we’ve taken on in the past, check out our case studies here.

As you work, keep your eyes peeled for our office dogs who will trot by and welcome you to the TTT family. To help combat work stress, our perks include work flexibility, monthly happy hours, weekly lunch & learns, yoga lessons twice a week, and a cozy massage chair overlooking Vancouver’s scenic waterfront. The team at TTT is passionate about creating software that impacts lives, and management does everything it can to plant the seeds that will propel you to greater heights.

More from Us

TTT Studios is an award winning digital innovation studio focused on empowering businesses through technology. #1 ranked Canadian custom software and mobile app developer. Our values are integrity, passion and excellence. We’re obsessed with delivering quality work. That’s why our team consists of designers and engineers of the highest calibre. We also strongly believe in empowering the community by being heavily involved in local and international events as speakers, educators, and sponsors. Whether you’re a developer, designer, management or co-op student, every single person here contributes to who we are as a company.",4.6,TTT Studios,Vancouver,"Vancouver, Canada",1 to 50 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Atimi Software, Dynamic Leap, Finger Food Advanced Technology Group",152.0,10,data engineer,na,0,1,0,0,0,0,1,1,0,0,0,1,0,0,0,4282,3
272,"The Data Warehouse Services team plays a vital role in our organization. They are responsible for storing vast quantities of data from many sources and responsible for disseminating data across the organizations to various different groups. They are one of the backbones of data at our organization and they are seeking a Senior Data Analyst to join their team.

The Job:
Work with internal constituents, including; Directors, Analysts, and Developers to understand business requirements/goals, and help capture the strategy, content, and features for layout of our reporting environments.
Working with business partners at all levels to discuss data analysis/requirements
Analyze data and structure from data marts
Work effectively in a fast-paced environment, where multi-tasking may be necessary
Participate in brainstorming sessions regarding functional requirements, content organization, process flow, and report specifications.
Develop queries for investigation of data issues or creation of new report structures for business units.
Partner with Database administrators and developers to establish high-level time and effort estimates based on client requirements during report project kickoffs, and then refining the estimate during each iteration.
Collaborate with Project Managers to identify project status, potential risks and issues.
Become a subject area expert
Assist in the coordination of development roadmaps
Qualifications:
Use knowledge of tools to create extract analysis from SQL server/excel/powerbi/cubes is a must
Strong customer support experience is a must (dealing with internal clients)
This is a senior position so we require strong technical skills:
TSQL / SQL / Mysql
Excel
PowerBI
Understanding Data flow Concepts
Understanding Business Model Concepts
As an equal opportunity employer, we celebrate diversity and are committed to creating an inclusive environment for all employees",3.4,MindGeek Careers,Montreal,"Luxembourg, Luxembourg",1001 to 5000 employees,2004,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1,152.0,16,data analyst,senior,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1915,0
273,"Master or PhD in Computer Science, Machine Learning, Statistics or a related quantitative field.
4+ years of hands-on experience in applied machine learning, and predictive modeling and analysis.
Algorithm and model development experience for large-scale applications
Experience using Python, or other programming or scripting language, as well as with R, MATLAB.
Solid understanding of foundational statistics concepts, NLU and ML algorithms: linear/logistic regression, random forest, boosting, GBM, NNs, etc.
Language required for job: English

Terms of employment: Full time, permanent

Job location: 510 West Georgia Street, Vancouver, V6B 0M3

The Smart Home team is focused on making Alexa the user interface for the home. From the simplest voice commands (turn on the lights, turn down the heat) to use cases spanning home security, home entertainment, and the home environment, we are evolving Alexa into intelligent, indispensable companion that automates daily routines, simplifies interaction with appliances and electronics, and alerts when something unusual is detected.

You will be part of a team delivering features that are highly anticipated by media and well received by our customers. Here are a few links that highlight working with Alexa.

Meet the Alexa Software Team:
https://www.youtube.com/watch?v=KpXEsrjcj6Y

Charlie Kindel, Director, Alexa Smart Home, CEDIA Keynote:
https://www.youtube.com/watch?v=tatp2M5hG-M
Amazon Echo Emerges as a Surprise Leader in Smart Home Platform War:
[url=https://www.forbes.com/sites/aarontilley/

You can make your Amazon Alexa Smarter:
[url=http://fortune.com/video/

How to make the Amazon Echo the Center of Your Smart Home:
[url=http://www.wired.com/

As a Machine Learning Scientist, you will work with software developers and other teams to design and implement NLU models for how customers use and interact with smart devices in their homes. You will help lay the foundation to move from directed device interactions to learned behaviors that enable Alexa to proactively take action on behalf of the customer. And, you will have the satisfaction of working on a product your friends and family can relate to, and want to use every day. Like the world of smart phones less than 10 years ago, this is a rare opportunity to have a giant impact on the way people live.

Salary $97,800 to 163,800/yr, commensurate with experience

All applicants must meet qualifications above.

Benefits: Amazon provides a full range of benefits for our global employees and their eligible family members. Eligible employees may also receive signing bonuses and Amazon Restricted Stock Units. This position is eligible for further pay increases and bonuses at the company's discretion. While they might vary from location to location, Amazon benefits for Canada may include:
Health Care
Savings Plans
Income Protection
Paid Time Off
Employee Stock
Signing Bonuses
Amazon offers competitive packages, growth potential and a challenging and exciting work environment. Amazon and its affiliates are Equal Opportunity Employers. Visit www.Amazon.com/careers for more information.",-1.0,"AMZN CAN Fulfillment Svcs, ",Vancouver,-1,-1,-1,-1,-1,-1,-1,-1,152.0,-1,data scientist,na,0,1,0,0,0,0,0,0,0,0,0,0,1,0,1,3122,0
274,"LOCATION: Calgary, Alberta (CA-AB)
JOB NUMBER: 28716

Why you should join us:
We are living in an era of transformation – as a company, as an industry and as a global community. Suncor is evolving and we’re calling it Suncor 4.0. Technology and digital solutions are a big part of this, but unleashing the full potential of our people is what will get us where we need to be.

An essential part of our evolution is creating value through data and becoming a data-informed enterprise where employees can apply their knowledge, draw insights and make the best possible decisions. Hiring specialists like yourself will help us implement our Advanced Analytics strategy and transform our business. It’s all about strengthening our future through digital technology, unleashing the full potential of our people, and creating an engaging and productive workplace.

As a Data Engineer, you will play an active role throughout the entire engagement cycle, from architecture and design, to build test and deploy; specializing in rapid deployment of data pipelines and analytics solutions, including orchestration, automated testing and quality control, continuous integration/deployments, versioning and environment management.

If you’re passionate about data, and thirsty for new approaches that provide insights into the most complex challenges through the architecting of data for advanced analytics, this role is for you!

Are you ready to help us solve problems we’ve never been able to address before? Join us and be part of transforming Suncor’s future!

You will use your expertise to:
Work on multiple projects as a technical team member or lead, driving user story analysis and elaboration for data requirements
Ensure all automated processes preserve data by managing the alignment of data availability and integration processes
Develop, construct and automate data pipelines that allow for leading edge analytical models
Perform technology and product research to better define requirements, resolve important issues and improve the overall capability of the data ingestion and transformation stack
Translate complex functional and technical requirements into detailed, design, and high performing end to end data pipelines
Derive and develop the automation and promotion of data pipelines from development to test to production
Construct the production management and monitoring of data pipelines

We’d like to review your application if you have…

Must-haves (minimum requirements):
Five years of experience in data management, data and environment provisioning, and test automation, using relevant Big Data technologies on Azure, AWS or Google platforms
A Bachelor’s degree or Masters in Computer Science, Computer Engineering, Software Engineering or a related technical field
Experience working in a cloud platform (e.g. Microsoft Azure, AWS, Google Cloud)
Experience in Extract, Transform and Load processes (ETL), SQL databases, data warehousing solutions, data modeling and scripting languages
Exceptional analytical and critical reasoning skills
Proven communication and social skills
Alignment with our values: safety above all else, stronger together, operational discipline, curiosity and lifelong learning, and act with integrity

Preference for:
Familiarity with analytical tools and languages such as Matlab, Python, R, SPSS
Familiarity with NoSQL databases

Where you’ll be working, your work schedule, and other important information:

You will work out of our Calgary head office, located in the Suncor Energy Centre at 150 – 6th Ave S.W.
This role can also be supported from one of our hub locations (e.g. Mississauga, Fort McMurray, Edmonton, Sarnia, Montreal)
One of our values is curiosity and lifelong learning – we challenge the status quo and learn from and support each other to make the world a better place
We are so invested in building advanced analytics skills within our organization that we've created the Analytics Academy to profide training to employees through instructor-led courses, e-learning, communities of practice, etc.

Why Suncor?

Supporting our people. Caring for our communities. Living our purpose.

With our operations declared an essential service, we are continuing to operate and are looking to fill business-critical roles at this time. We require qualified and safety-focused employees to help keep things running. In terms of our current recruitment process, we’re doing things a bit differently to adjust to our new ‘normal.’ We are using technology to conduct virtual interviews to adhere to physical distancing recommendations and we are well set up for remote onboarding and orientation.

We are bolstered by the unity across our community and the solidarity across the world. We continue to encourage you to support global efforts to limit the impact of COVID-19 with good hygience practices, physical distancing, and with care and consideration for the people around you. For more information on how we’re responding to COVID-19, click here. #StrongerTogether

We are Canada's leading integrated energy company with a business portfolio that includes oil sands development and upgrading, offshore oil and gas production, petroleum refining, and product marketing under the Petro-Canada brand. Our global presence offers rewarding opportunities for you to learn, contribute, and grow in a variety of career-building positions. We live by the value of safety above all else – if it isn't safe, we don't do it. Our strong track record of growth and a focus on sustainability mean tremendous potential for the future. Learn about our purpose and values.

In addition to rewarding job opportunities, we offer an attractive employee package, including:

Competitive base salary, compensation programs, and an annual incentive program
Flexible benefits package
Rewarding pension and savings plans

Stay connected to us:
Follow us on LinkedIn, Facebook and Twitter for the latest job postings and news
Visit our Report on Sustainability to see our progress on a number of environmental, social and economic topics and what we’re doing to position our company for the future
Join our Talent Community and sign up to receive customized job alerts
Read our Suncor Connections newsletter to see what we’re doing in the communities we live and work in

We are an equal opportunity employer and encourage applications from all qualified individuals. We are committed to providing a diverse and inclusive work environment where every employee feels valued and respected. We will consider accessibility accommodations to applicants upon request. Check out our social goal to learn how we are working to build greater mutual trust and respect with the Indigenous Peoples in Canada.

Please note that our job postings are typically open for two weeks, so don't delay, apply now.

JOB CATEGORY: Business Professionals",4.0,Suncor Energy Services,Calgary,"Calgary, Canada",10000+ employees,1967,Company - Public,Energy,"Oil, Gas, Energy & Utilities",$10+ billion (CAD),"Imperial Oil, Husky Energy",152.0,53,data engineer,na,0,1,0,0,0,1,0,1,1,1,0,0,0,0,0,6865,2
275,"Salary Mid-Point: $0

Location: Toronto ON

Job Type: Permanent

Job Title:Data Engineer

Location: Downtown Toronto

The individual our client seeks is highly analytical, self motivated, curious and has a track record of quantitative and qualitative analysis. If this sounds like you please apply below!

Our technology client is past the boot strapping stage of a start up and continues to grow at an accelerated rate. The environment is fast paced and at times both structured and unstructured. This organization will provide you with the challenges you are looking for and the continued growth for learning you are looking for in your career. The office environment is fantastic and the client is all about social change. Our client seeks a passionate and talented Data Engineer who is comfortable working in a very fast paced environment.

Responsibilities:
Help build, scale and maintain the data platform.
Play a key role in data infrastructure, analytics projects, and systems design and development.
Extract the data, transform the data and load the data into a database or data warehouse (ETL).
Introduce new technologies to the environment through research and POCs.
Ensure high quality standards are met (documentation is in place; quality checks are working and data in dashboards is updated according to data sources).
Will assure standards to be followed by the data analysts & data scientists in terms of analytical data gathering and transformations.
Delivering an enterprise data platform that will accelerate the delivery of business intelligence, machine learning and the ability to generate new insights.
You will focus on integrations and data modelling, ETL along with the automation of data sets.
Requirements:
BA/BS degree in Mathematics, Computer Science, Mathematics or related technical field, or equivalent practical experience.
Have a deep technical understanding, hands-on experience in distributed computing, big data, ETL, dimensional modeling, columnar databases and data visualization.
Experience working with data warehouses, including data warehouse technical architectures, infrastructure components, ETL and reporting/analytic tools and environments.
Experience with data modelling techniques for modern data architectures.
Hands-on implementation experience with cloud data platforms (e.g. Azure, GCP, AWS).
Experience in writing software in one or more languages such as Java, C++, Python, Go, Ruby and/or JavaScript.
Soft skills: High performer, polished/high work ethic, smart learner, flexible, organized, has initiative/fast producer.
Knowledge of Ruby on Rails, experience building data visualizations with D3 or in JavaScript / React and familiarity with Postgres would be a “Nice to have”
For consideration please email your resume to ""Eileen@ifgpr.com"" with ""Data Engineer"" in the subject line.",2.6,IFG Project Resourcing,Toronto,"Toronto, Canada",501 to 1000 employees,2006,Subsidiary or Business Segment,Staffing & Outsourcing,Business Services,$100 to $500 million (CAD),-1,152.0,14,data engineer,na,0,1,0,0,0,0,0,0,1,0,0,0,1,0,0,2843,0
276,"THE OPPORTUNITY

ZE is a global leader in the development of enterprise data management and analysis software. We design and develop ZEMA, a sophisticated suite of products that provide clients with powerful capabilities for data collection, process automation and business intelligence through web based analytical tools, services and dashboards. We will provide thorough training, a great work environment, a unique corporate culture and reward you for your good work.

RESPONSIBILITIES
Lead data collecting, data interpretation and development of technical report specifications based on established standards including logic and structure
Lead team to grow data domain expertise with a focus on the energy and commodity industry
Provide high level of support to field Issue investigations as it pertains to data, report design changes or updates, and to troubleshoot to root cause when necessary
Provide solution for data extraction, transformation and load (ETL) processes
Support Market Data Services, and Software Development teams to release and maintain the suite of ZE Processors
Support clients with regard to their requests scoping data needs against the ZE data universe
Support data centric tasks for business, product development, and operational teams
Identify patterns and trends in data sets and work alongside the business and management team to establish business needs
Design data automation framework to improve data quality and efficiency
YOU SHOULD HAVE
An accredited Engineering, Computer Science, Database, Data Science degree or equivalent experience
At least 5 years of working experience in IT support and Data Analysis
Strong understanding of relational databases and SQL programming
Knowledge of software development life cycle
Competence around computer servers, databases, and web services
COMPETENCY AND SKILL SET
Communicates clearly and competentl
Strong initiative and ability to work with minimal supervision
Great interpersonal, collaboration, and facilitation skills
Excellent ability to work in a team environment
ABOUT US
ZE PowerGroup Inc. (ZE) is a global leader in the development of data management, analysis, and business automation software. ZEMA is our enterprise-level suite of products. ZEMA enables users to capture, transform, manipulate, analyze, report and visualize data quickly and easily. We work with world-class companies in energy, commodities, and finance to serve users in trade, risk management and IT. Our head office is in Vancouver, BC, and we have operations in Houston, Raleigh, London, and Singapore.",2.6,ZE Power Engineering,Richmond,"Richmond, Canada",1 to 50 employees,2001,Company - Private,Architectural & Engineering Services,Business Services,$1 to $5 million (CAD),-1,152.0,19,data analyst,senior,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2570,0
277,"Big Data Engineer

Location: Toronto, Montreal, Ottawa
We Are:

Applied Intelligence, the people who love using data to tell a story. Were also the worlds largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anythingspark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds? Visit us here to find out more about Applied Intelligence.
You Are:

A Big Data consulting prosomeone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. Youre passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues dont faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.
The Work:

Data and Analytics professionals define strategies, develop and deliver solutions that enable the collection, processing and management of information from one or more sources, and the subsequent delivery of information to audiences in support of key business processes.

Big Data professionals use Big Data methodologies, solutions and tools to help organizations optimize their business performance by managing, sorting and filtering volumes of data as well as extracting meaningful value from these large volumes of data.

A professional at this position level within Accenture has the following responsibilities:
Design and build robust data pipelines using scalable tools and techniques (yes, were talking big data) to produce high quality data structures
Implement quicker data processing methods and integrate complex business logic compatible with daily or real-time/streaming frameworks
Increase automation and scaling of complex data sets based on the customers analytic use case, such as structured data delivery for business analysis, daily extraction of mission enabling data for data mining/exploration, and transforming data for applied intelligence to power impactful data visualizations

Heres What You Need:

Qualifications:
Minimum 3years of designing, building and operationalizing large scale enterprise data solutions and applications using one or more of Azure / AWS / GCP data and analytics services in combination with custom solutions - Spark, Azure Data Lake, HDInsights, SQL DW, DocumentDB, Search, Elastic Pool etc.
Minimum 3years of hands-on experience analyzing, re-architecting and re-platforming on-premise data warehouses to data platforms on Azure / AWS / GCP using AZURE/customservices.
Minimum3 years of designing and building production data pipelines from ingestion to consumption within a hybrid big data architecture, using Java, Python, Scala etc.
High emphasis on consulting/client facing experience, this is a must have.
Minimum 3 years of architecting and implementing next generation data and analytics platforms on Azure / AWS / GCP.
Minimum 3 years of designing and implementing data engineering, ingestion and curation functions on Azure / AWS / GCP using AZURE native or custom programming.
Minimum 3years experience in performing detail assessments of current state data platforms and creating an appropriate transition path to Azure / AWS / GCP.
Hands-on Azure / AWS / GCP experience with a minimum of 1 solutions designed and implemented at production scale.
Candidate should be eligible for Reliability/Government Secret Clearance (Spent at least the past 5 years in Canada as a permanent Resident or a Canadian Citizen)

Bonus Points if:
Bachelor's degree in Computer Science, Engineering, Technical Science or 3+ years of technical architecture and build experience with large scale solutions.
Minimum 3 years of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders.
3 years of hands-on experience designing and implementing data ingestion solutions on Azure / AWS / GCP using custom approaches.
3 years of hands-on experience architecting and designing data lakes on Azure / AWS / GCP cloud serving analytics and BI application integrations.
3 years of experience in designing and optimizing data models on Azure / AWS / GCP
3 years of experience integrating AZURE security services with Azure / AWS / GCP data services for building secure data solutions.
Minimum 3years experience introducing and operationalizing self-service data preparation tools (e.g. Trifacta, Paxata) on AZURE.
Minimum 3 years of architecting and operating large production Hadoop/NoSQL clusters on premise or using Cloud services.
Minimum 3 years architecting and implementing metadata management on Azure / AWS / GCP.
Architecting and implementing data governance and security for data platforms on Azure / AWS / GCP.
Designing operations architecture and conducting performance engineering for large scale data lakes a production environment.
Craft and lead client design workshops and provide tradeoffs and recommendations towards building a solutions.
Author blog entries and whitepapers on AZURE data solutions, architecture and strategic topics.

Accenture Overview

We are a global collective of innovators applying the New every day to improve the way the world works and lives. Help us show the world whats possible as you partner with clients to unlock hidden value and deliver innovative solutions. Empowered with innovative tools, continuous learning and a global community of diverse talent and perspectives, we drive success in a new business architecture that disrupts conventional practices. Our expertise spans 40+ industries across 120+ countries and impacts millions of lives every day. We turn ideas into reality.

Important information

To learn more about Accenture, and how you will be challenged and inspired from Day 1, please visit our website at accenture.ca/careers.https://accntu.re/2Hcjdtn

It is currently our objective to assign our people to work near where they live. However, given the nature of our business and our need to serve our clients our employees must be available to travel when needed.

Accenture does not discriminate on the basis of race, religion, color, sex, age, non-disqualifying physical or mental disability, national origin, sexual orientation, gender identity or expression, or any other basis covered by local law. Accenture is committed to providing employment opportunities to current or former members of the armed forces.

We are committed to employment equity. We encourage all people, including women, visible minorities, persons with disabilities and persons of aboriginal descent to apply.

Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions underpinned by the worlds largest delivery network Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 469,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us at www.accenture.com.",4.0,Accenture,Toronto,"Dublin, Ireland",10000+ employees,1989,Company - Public,Consulting,Business Services,$10+ billion (CAD),"Cognizant Technology Solutions, EY, McKinsey & Company",152.0,31,data engineer,na,0,1,0,0,0,1,1,1,1,0,0,0,1,0,0,7715,3
278,"Infoblox is looking for a Staff Data Engineer to augment our growing Cyber Security Software Development Team. This growing team supports the Infoblox mission to thwart cybersecurity threats in our customer’s networks. This is an opportunity to work closely with data scientists and threat analysts to curate the data that makes this mission possible.

The ideal candidate is a savvy software engineer with experience in data engineering and a solid background in Spark and Python. Preferably you know that countMinSketch is not a children’s game. You are comfortable wearing several hats in a small organization with a wide range of responsibilities and have worked in a cloud environment, such as Amazon EMR. You know that Big Data is both a blessing and a curse; without good data engineering, it loses its potential. You are passionate about the nexus between data and computer science-driven to figure out how best to represent and summarize data in a way that informs good decisions and drives new products. When someone says, “my Spark job failed”, your first question is “what’s the skew?”. Come join our growing Cyber Threat Intelligence team and help us build world-class solutions!

Responsibilities:
Curate very large-scale data from a multitude of sources into appropriate sets for research and development for data scientists, threat analysts, and developers across the company.
Design, test, and implement storage solutions for various consumers of the data.
Design and implement mechanisms to monitor data sources over time for changes using summarization, monitoring, and statistical methods.
Leverage computer science algorithms and constructs, including probabilistic data structures, to distill large data into sources of insight and enable future analytics.
Convert prototypes into production data engineering solutions through disciplined software engineering practices, Spark optimizations, and modern deployment pipelines.
Collaborate on the design, implementation, and deployment of applications with the rest of software engineering.
Support data scientists and threat analysts in building, debugging and deploying Spark applications that best leverage data.
Build and maintain tools for automation, deployment, monitoring, and operations.
Create test plans, test cases, and run tests with automated tools.
Requirements:
7+ years of experience with Python3, and 2+ years experience with Spark. Scala experience is helpful.
5+ years of experience in data engineering, data science, and related data-centric fields using large-scale data environments.
3+ years of experience in using SQL and working with modern relational databases, including MySQL or PostgreSQL
3+ years of experience with developing ETL pipelines and data manipulation scripts
Proficient in Object-Oriented Design and S.O.L.I.D principles.
Strong emphasis on unit testing and code quality.
Proficient with AWS products (EMR S3, Lambda, VPC, EC2, API Gateway, etc).

Preferred Experience:
Very strong Python and PySpark experience.
Very strong back end development experience.
Strong experience with cloud deployments and CI/CD.
Experience with virtualization, containers, and orchestration (Docker, Kubernetes, XEN).
Experience with NoSQL Non-Relational databases (AWS DynamoDB).

Education:
MS or BS in Computer Science or a related field, or equivalent work experience required.
Perks:
Work with a world-class technology team in a rapidly growing company
A career path with opportunities to grow
Boutique office space with state of the art amenities, located in the heart of Metro Vancouver area; steps from SkyTrain and Metrotown Mall
Cross-functional break room stocked with snacks and beverages
And many, many more perks!
It’s an exciting time to be at Infoblox. We are the market leader in technology for network control. Our success depends on bright, energetic, talented people who share a passion for excellence in building the next generation of networking technologies—and having fun along the way. Infoblox offers a fast-paced, action-oriented environment. We promote a culture that embraces innovation, change, teamwork, and strong partnerships. Join the winning Infoblox team—our future looks bright, and so will yours. To check out what it’s like to be a Bloxer click here.

#LI-AB1",4.2,Infoblox,Burnaby,"Santa Clara, CA",1001 to 5000 employees,1999,Company - Private,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (CAD),-1,152.0,21,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,1,0,0,0,4291,0
279,"// ENGLISH VERSION WILL FOLLOW ...//

Poste: Analyste de données

Relève de: BI Manager

Fonctions:
Déterminer les besoins de l’équipe de jeu au niveau analytique;
Définir les spécifications de la collecte d’information;
Apporter du support aux programmeurs lors de l’implémentation du système de collecte de données;
Participer au processus de vérification de qualité des données en collaboration avec l’équipe QA;
Créer des modèles analytiques et tableaux de bord personnalisés;
Générer des rapports d’analyse personnalisés;
Présenter, sous forme de story telling, les insights générés au travers des analyses, à tout type d’audience;
Fournir des recommandations opérationnelles en termes de design et de monétisation;
Participer à l’amélioration continue des processus décisionnels au sein de l’équipe de production;

Expérience et qualifications:
3 ans d’expérience pertinente ou équivalente dans le domaine du jeu mobile ou connexe.
Expérience de production d’une application mobile est un atout majeur.
Expérience avancée avec des plateformes analytiques tel que deltaDNA ou Amplitude.
Expérience pertinente avec des outils de reporting tel que Looker, PowerBI ou Tableau.
Compétent au niveau statistique et data mining.
Capacité de générer des connaissances poussées à partir de jeu de données multidimensionnel.
Bonne compréhension des concepts de Game Design, Economic Game Design et monétisation pour un jeu mobile.
Expérience en programmation SQL : un atout important.
Connaître d’autres langages de programmation tels que R et Python sont des plus.

Qualités interpersonnelles:
Grandes habiletés pour expliquer des phénomènes complexes et interreliés de façon claire et concise à tout type d’audience (anglais et français).
Axé sur l’impact opérationnel, débrouillard et capable de prendre de l’initiative.
Excellentes compétences relationnelles, capable de collaborer avec différents intervenants qui ont des objectifs différents et potentiellement contradictoires.
Faire preuve de pragmatisme et de rigueur dans les approches méthodologiques.
Être capable de s’adapter dans un environnement où les priorités peuvent changer régulièrement.
Être capable de faire preuve d’humilité et d’aider à faire progresser l’équipe

Motivation et intérêts:
De l’ambition et de la passion pour les jeux vidéo sont essentiels!
Title: Data Analyst
Reports to: BI Manager

Duties:
Determine the development team’s needs at an analytical level;
Define the specializations of the information collected;
Provide support to the developer when implementing the data collection system;
Participate in the verification process of the data quality in collaboration with the QA team;
Create analytical models and personalized dashboards;
Generate personalized analytical reports;
Present in a story telling format the insights generated through analyzes, to all types of audiences;
Provide operational recommendations in terms of design and monetization;
Participate in the continuous improvement of decision-making processes within the production team.

Experience and qualifications:
3 years of pertinent experience or equivalent in the mobile game field or related;
Production experience of a mobile application is a major asset;
Advanced experience with analytical platforms such as deltaDNA or Amplitude;
Pertinent experience with reporting tools such as Looker, PowerBI or Tableau;
Competent at a statistical and data mining level;
Capacity to generate advanced knowledge from multidimensional game data;
Good understanding of Game design concepts, Economic Game design and monetization for a mobile game;
Experience in SQL programming: an important asset;
Knowledge of other programming languages such as R and Python are a plus.

Interpersonal qualities:
Strong ability to explain complex and interrelate phenomena in a clear and concise manner to any type of audience (English and French);
Focused on the operational impact, resourceful and able to take initiative;
Excellent interpersonal skills, able to collaborate with different stakeholders that have different objectives and that are potentially contradictory;
Demonstrate pragmatism and rigor in methodological approaches;
Able to adapt in an environment where priorities can regularly change;
Able to be humble and help the team to move forward.

Motivation and interests:
Passion and ambition for video games are essential!",3.2,Square Enix Montreal,Montreal,"Tokyo, Japan",1001 to 5000 employees,1975,Company - Public,Video Games,Media,Unknown / Non-Applicable,"Electronic Arts, Activision, Infogrames",152.0,45,data analyst,na,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,4378,3
280,"Closing Date: August 31, 2020

Teck Resources Ltd. is Canada’s largest diversified natural resource company with a strong history of innovation over the last 100 years. The RACE21™ team is leading the charge in a company-wide renewal of technology and infrastructure, transforming mining for the next generation.

With financial backing and commitment from leadership, Teck envisions a fully integrated, agile, digital platform that will Renew, Automate, and Connect materials, processes, equipment flows, and data systems to expand and enable a broad application of advanced analytics, robotics, and artificial intelligence. As well as Empower employees to unleash their creativity and innovation at work, increasing sustainability, safety, and performance in real time, unlocking resource base knowledge, and improving planning for optimal resource extraction.

Reporting to the Manager of Data Science as part of the RACE21 digital transformation team, the Lead Data Scientist will design, plan, develop, and deliver advanced analytics solutions as part of an integrated team to improve performance of Teck’s coal and base metals operations.

You will work closely with a variety of business and technical stakeholders to define technical problems and corresponding hypotheses, develop efficient and accurate analytical models, perform regular testing and maintenance of analytical models to improve efficiency and ensure alignment with changing business needs. This will require data exploration and preparation, modelling, implementation of the advanced analytical tools and integration into a suite of products to achieve business value.

Who You Are
You are a highly effective and customer-obsessed advanced analytics professional
You are passionate about product innovation and creating a step change leveraging the power of cloud, big data and advanced analytics
You have experience working on data-intensive projects, using modern data platforms and tools and advanced analytics methods and approaches
You are comfortable working with minimal direction and exercising considerable latitude in determining objectives and leading other data scientists
Responsibilities:
Be a courageous safety leader, adhere to and sponsor safety and environmental rules and procedures
Actively seek and assess opportunities to apply advanced analytics to optimize performance across Teck’s operations in North and South Americas
Partner with and elevate a team of data scientists, providing leadership through consulting and coaching on a regular basis
Lead end-to-end design and implementation of Machine Learning and Data Analytics solutions for 2-3 use cases at a time to optimize productivity, safety and sustainability:
Work with a variety of business stakeholders to identify and prioritize use cases
Identify, profile and analyze large, complex, multi-dimensional datasets with a variety of tools to draw relevant insights
Use data science techniques to find data patterns, anomalies and optimization opportunities through analytical solutions
Solve complex business problems by designing, developing and implementing sustainable advanced analytics solutions
Plan model operationalization and rollout of solutions to business users
Plan projects and communicate project status, emerging issues, and next steps to relevant stakeholders in the organization
Identify new ways of piloting models, actively sourcing and incorporating feedback with learnings from the field
Provide expert guidance on Teck’s data, systems and environment to external partners and vendors providing data science and data engineering services
Write highly optimized and reusable code extending our internal data science toolkit and contributing to an enterprise-wide platform for advanced analytics called Galileo
Support hiring and onboarding of new data scientists in collaboration with Manager of Data Science and HR team
Willingness to travel up to 40% of the time to Teck’s operations across North and South Americas
Key Competencies:
PhD or Master’s degree in the field of Computer Science, Machine Learning, Applied Statistics, Mathematics or equivalent
7+ years of relevant industry work experience developing advanced analytics solutions
A deep understanding of a variety of statistical modelling and machine learning approaches and ability to apply them to business problems
Demonstrated proficiency with programming languages such as Python, R, SQL
Experience with popular machine learning frameworks, libraries and utilities
Experience with popular optimization framework and libraries (Gurobi, IBM Cplex, etc.)
Experience working with large data sets and distributed computing tools
Experience with a wide range of data collection systems including edge computing technologies
Working knowledge of at least one enterprise-grade cloud computing platforms such as Microsoft Azure, Amazon Web Services or Google Cloud Platform
Exceptional organizational and time management skills with the ability to meet deadlines and balance multiple projects
Excellent analytical and critical thinking skills, combined with the ability to present your ideas clearly and compellingly to both technical and non-technical audiences
Demonstrated ability to work well as part of agile, multidisciplinary teams
Strong interpersonal skills and previous experience coaching and mentoring data scientists
Interest in gaining the knowledge of mining industry and systems used in engineering, operations, process control and maintenance functions
Experience or education in mineral processing, maintenance, process control or supply chain would be an asset
Experience with real-time systems that support Asset Health, Dispatch and/or Processing workflows would be an asset
At Teck, we value diversity. Our teams work collaboratively and respect each person’s unique perspective and contribution.

Qualified applicants interested in joining a dynamic team are encouraged to submit a resume and cover letter electronically.

We wish to thank all applicants for their interest and effort in applying for the position; however, only candidates selected for interviews will be contacted.

Your application to this posting is deemed to be your consent to the collection, use and necessary disclosure of personal information for the purposes of recruitment. Teck respects the privacy of all applicants and the confidentiality of personal information.

Teck is a diversified resource company committed to responsible mining and mineral development with major business units focused on copper, steelmaking coal, zinc and energy. Headquartered in Vancouver, Canada, its shares are listed on the Toronto Stock Exchange under the symbols TECK.A and TECK.B and the New York Stock Exchange under the symbol TECK.

The pursuit of sustainability guides Teck’s approach to business. Teck is building partnerships and capacity to confront sustainability challenges within the regions in which it operates and at the global level. In 2019, Teck was named to the Dow Jones Sustainability World Index (DJSI) for the tenth straight year, indicating that Teck’s sustainability practices rank in the top 10 per cent of the world’s 2,500 largest public companies in the S&P Global Broad Market Index.

Learn more about Teck at www.teck.com or follow @TeckResources

#LI-AMN",3.7,Teck Resources Limited,Vancouver,"Vancouver, Canada",5001 to 10000 employees,-1,Company - Public,Mining,Mining & Metals,$10+ billion (CAD),-1,152.0,-1,data scientist,senior,0,1,0,0,0,1,0,1,1,1,0,0,1,0,1,7308,0
281,"Full-time, Contract

Position / Purpose:

We are looking for a CRM campaign manager and analyst. This is a contract role that reports to the marketing and communications, working closely alongside the 7Rewards loyalty program team!

Key Duties:

Maintain and update email preferences and customer segmentation

CRM campaign execution, including scripting for dynamic data integration within campaigns. The role does not include the creation of creative content

Support with audience criteria design including creation of data extensions

Track and conduct analyses on campaign performance

Performs other duties and responsibilities as requested by management.

Education/ Experience:

A minimum of 3 years with similar key duties

A minimum of 5 years of post-undergrad analytical experience

Specific Knowledge / Skills:

- Executing email, SMS and push notification campaigns (ad hoc, triggered and recurring)

- Bring together customer data to build personalized messaging and trigger customers on journeys

- Test/Control and AB testing design and analysis within a campaign

- Comprehensive knowledge working with Salesforce Marketing Cloud

- Experience with data visualization and analytics platform such as PowerBI or Tableau

Job Type: Contract

Job Types: Full-time, Contract

Job Types: Full-time, Contract, Freelance

Schedule:
8 Hour Shift
Experience:
analytics: 4 years (Preferred)
marketing : 4 years (Preferred)
Work remotely:
Temporarily due to COVID-19",3.2,7-Eleven Canada,Surrey,"Dallas, TX",10000+ employees,1927,Subsidiary or Business Segment,Other Retail Shops,Retail,$2 to $5 billion (CAD),"Hess Corporation, QuikTrip, Couche-Tard",152.0,93,data analyst,na,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1472,3
282,"Data Analyst Citis Innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to Citis Capital Markets, Securities Services and Banking lines of businesses. Our Mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurship spirit. We are currently looking for an excellent data analyst to join one of our cutting edge trade surveillance solutions. It is a highly advanced trade monitoring and analytics product used globally among Citis trading desks. Job Description Explore and analyze datasets to develop new robust controls Work with business partners to design new workflows to transform business requirements into concrete insights Onboard data across the various financial markets via multiple consumption methods (Message buses, SFTP, SQL connectors) Develop automated procedures to improve and optimize existing controls Work together with the R&D team to help guide the Platform roadmap Experience & Qualifications Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to details and accuracy Solid experience in working with data and relational / non-relational databases Hands-on experience in Scripting Languages (Python / R) Experience in troubleshooting code and logs Experience with parsing messages (ex: JSON, XML) and performing multiple data manipulations/ calculations Advantage Experience in Linux Advantage Excellent interpersonal and communication skills in English. BS/BA in Software Engineering or Computer Science advantage, or in Industrial Engineering, Mathematics, Statistics or Economics Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - CA ------------------------------------------------------ Time Type : ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.8,Citibank,Mississauga,"Irving, TX",1001 to 5000 employees,-1,Company - Private,Lending,Finance,Unknown / Non-Applicable,-1,49.0,-1,data analyst,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,3143,0
283,"NBCC is currently seeking a dynamic and competent Individual for the position ofInstitutional Research Data Analyst.

Our College is committed to transforming lives and communities. When you work at NBCC, you are a valued team member of a community of leaders who are driven by learning excellence and by our important role in social and economic development.

Reporting to the Manager of Institutional Research, as a member of the Institutional Research team, you will be primarily responsible to respond to the needs of the academic and student enrolment units of the organization; and help deliver data warehousing technology which converts College data contained within enterprise resource planning (ERP) systems to information useful to stakeholders for decision making. This role enhances timeliness, accuracy, consistency and accessibility of reported data and develops procedures and documentation in support of this function.

Responsibilities
Leading and/or participating in consultative gathering of reporting requirements within a multi-stakeholder environment (receiving, prioritizing, assessing and clarifying information requests with internal and external stakeholders.).
Develop and implement databases, data collection systems, data analytics and other strategies that optimize efficiency and quality.
Acquiring data from primary or secondary data sources and maintaining databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Build data validation automation to catch potential issues and perform Quality Assurance analysis within datasets
Interpret data, analyze results and provide regular/ad-hoc reports and dashboards to support decision-making on achievement of targets, in-year decisions and associated impacts, and proactive identification of potential data risks
Developing and reviewing existing processes, procedures, analysis methodology(s), tools and data definitions to streamline the collection and validation of College data.
Qualifications

Required qualifications for this opportunity include a Diploma and/or Bachelor degree in a relevant specialization (Computer Science, Statistics, Information Management, Economics, Mathematics, etc.) with demonstrated recent and related experience.

Related experience and technical skills must include technical expertise regarding data models, relational databases, database design development and ETL techniques; strong knowledge of and experience with databases (SQL server, Oracle, ) and reporting tools; advanced skills in Excel (Pivots, Macros, ); and knowledge of BI and Data Visualization tools (Tableau, Power BI, OBI, etc.).

Candidates must clearly demonstrate how they meet these qualifications on their resumes.

Preference may be given to candidates who demonstrate they have training or experience in one or more of the following: knowledge of statistics and using statistical packages for analyzing datasets; knowledge of R or Python Statistical Programming; machine learning; and previous experience in post-secondary education data analysis

Other combinations of education and experience may be considered as equivalent. Subject to competition response, the minimum qualifications may be raised.

Skills
Microsoft Excel
Database Administration
Business Analytics
Analytics
Analysis
About New Brunswick Community College (NBCC)

With six Campuses across the province, New Brunswick Community College (NBCC) transforms lives and communities across New Brunswick and contributes to the social and economic prosperity of our province.

Why work with NBCC?
You want to make a difference. By working at NBCC, you can support students in achieving their educational and career aspirations, help meet the needs of employers and contribute to stronger communities across New Brunswick.
You want to belong to something bigger. NBCC welcomes the individual experiences and perspectives of our learners, our staff and our partners. We nurture a culture of belonging where everyone feels valued and has opportunities to add value. NBCC is an equal opportunity employer building a dynamic team that is representative of the communities and industries that we serve.
We're one of the best places to work in Atlantic Canada. For five years in a row, we have been named one of Atlantic Canada's Top Employers because of our commitment to families, community service and employee engagement. This includes, paid time off to volunteer, comprehensive benefits packages and professional development opportunities.
Are you interested?

NBCC offers a comprehensive compensation and benefits package, that includes a competitive salary for this position ranging $44,954-$62,842.

All applicants must be eligible to work in Canada at the time of application. This competition may be used to fill future vacancies at the same level. We promote an equal opportunity work environment.

All interested candidates must submit a detailed application and resume online, by August 12, 2020. All applications will be acknowledged upon receipt.",4.0,New Brunswick Community College (NBCC),Moncton,"Fredericton, Canada",501 to 1000 employees,1973,College / University,Colleges & Universities,Education,$50 to $100 million (CAD),-1,49.0,47,data analyst,na,1,1,1,1,1,1,0,0,0,0,0,0,1,0,1,5046,0
284,"You are as unique as your background, experience and point of view. Here, you’ll be encouraged, empowered and challenged to be your best self. You'll work with dynamic colleagues - experts in their fields - who are eager to share their knowledge with you. Your leaders will inspire and help you reach your potential and soar to new heights. Every day, you'll have new and exciting opportunities to make life brighter for our Clients - who are at the heart of everything we do. Discover how you can make a difference in the lives of individuals, families and communities around the world.

Job Description:

Role Summary

Be part of an exciting and challenging opportunity by helping to accelerate the growth and application of data analytics capabilities at Sun Life Canada. As part of the Distribution Analytics team within Sun Life Canada's Individual Insurance & Wealth line of business, you will have an opportunity to be at the forefront of applying data and analytics to tackle business problems and helping Sun Life use analytics to deliver on our purpose of helping our Clients achieve lifetime financial security and live healthier lives. As a Distribution Data Analyst, your focus will be working with a team of analytics professionals and other partners to source, manipulate, and transform data, develop enhanced reporting, produce innovative and effective analyses of data, contribute to an ethical and robustly managed best-practice team environment, and, most importantly, drive impact that matters to shareholders, employees, advisors, and clients.

Given the mandate of the role, the Distribution Data Analyst must possesses a breadth of analytical and data skills. The Candidate must have ability in the following areas:
Data sourcing, manipulation, and transformation
Insightful analysis of data
Reporting and business intelligence
Effective communication
Collaboration and self-management
Working in a compliant and well-governed environment
This is a 6 months contract position with possibilities of extension.

What will you do?

Data Sourcing, Manipulation, and Transformation
Source large quantities of data and help create value for a variety of business functions
Perform various investigative and analytical functions
Documentation of new and existing foundational data sources to ensure EUC compliance
Development of robust, business friendly self-serve data sources to help enable partners within distribution to be more self-sufficient and capable in using data to inform initiatives and projects
Insightful Analysis of Data
Conduct ad hoc audits of advisor blocks of business analysis using a variety of descriptive and predictive statistical methods
Conduct analyses that identify / assess business opportunities and address key business challenges
Identify, verify, evaluate, and validate hidden patterns in client and advisor data
Effectively translate business problems into analysis problems
Reporting & Business Intelligence (20%)
Prepare / compile ongoing trend reporting as required, daily, weekly, and monthly
Implement and report on performance metrics to support initiative measurement, analysis, and reporting, and measure effectiveness of predictive modelling efforts
What will you need to succeed?

Coding & Technical Skills
Proven experience in SQL as well as advanced Excel functions to mine large quantities of data
Keen aptitude for learning new programs and programming languages quickly
Ability to design and complete meaningful business analyses
Problem Solving
Proven balance of analytical and creative problem solving skills
Able to think with agility in meeting business partners' demanding deadlines
Ability to move with minimum effort from detailed diagnostic thinking to higher level, opportunity-oriented thinking and to integrate the best from both into contributions and deliverables
Communication
Must be able to effectively communication complex results to a business audience not familiar with complex data and analytics
Effective writing and verbal communication skills
Ability to distill complex technical information into the key points that matter to the audience
Collaboration
Proven ability to work well independently and also function in a team environment, with frequent contract with individuals and teams at all levels of the Sun Life Canada organization
Demonstrate an owner's mindset when approaching work, including prioritizing efforts, owning the work plan, and keeping key stakeholders informed
Education & Experience
A suitable academic background, such as mathematics, statistics, economics, engineering, or computer science etc.
What will be nice to have?

Industry Experience & Knowledge
Past experience in life insurance / wealth management, other financial services industry components (e.g., retail banking, credit card, properly and casualty insurance), or distribution
Working knowledge of one or more SLF Canada business units
Past experience in data and analytics
Software Experience
Good working knowledge of data presentation software such as Tableau, SAS Visual Analytics, etc.
Experience with statistical software such as R and/or python
Working knowledge of PowerPoint, Memos, and other forms of data and insights communication
Strong Microsoft Office skills
What's in it for you?
A friendly, collaborative and inclusive culture
Being part of our Analytics community, where we share best practices and broaden skill-sets
A ‘dress for the day’ dress code, where you dictate how you dress based on your day
The Base Pay range is for the primary location for which the job is posted. It may vary depending on the work location of the successful candidate or other factors. In addition to Base Pay, eligible Sun Life employees participate in various incentive plans, payment under which is discretionary and subject to individual and company performance. Certain sales focused roles have sales incentive plans based on individual or group sales results.

Diversity and inclusion have always been at the core of our values at Sun Life. A diverse workforce with wide perspectives and creative ideas benefits our clients, the communities where we operate and all of us as colleagues. We welcome applications from qualified individuals from all backgrounds.

Persons with disabilities who need accommodation in the application process or those needing job postings in an alternative format may e-mail a request to thebrightside@sunlife.com.

We thank all applicants for showing an interest in this position. Only those selected for an interview will be contacted.

Salary Range:

49,400/49 400 - 80,800/80 800

Job Category:

Advanced Analytics

Posting End Date:

31/07/2020",3.7,Sun Life,Waterloo,"Toronto, Canada",10000+ employees,1865,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),-1,49.0,155,data analyst,na,1,1,0,1,0,1,0,0,0,0,0,0,0,0,1,6663,0
285,"Country:
Canada

Cities:
Toronto

Area of expertise:
Analytics

Job Description

Do you enjoy making sure that information is accessible and easy to use? So do we.
You’re a data designer who knows how to find, store and present a range of information from different sources so that everyone can access what they need quickly and simply, and use it effectively.
About you
You draw on your considerable experience in bringing data and statistics to life to solve sometimes complex problems, and you’re comfortable looking after several projects at once. You’re able to make your own decisions while at the same time supporting more junior team members.
About the job
As a Consultant, Data Engineering, you know the importance of data to business. You design and set up projects that bring together information from a variety of sources, to enable analysis and decision-making. You make sure that data is accessible and easy to use, so that it can be used for routine and ad-hoc analysis.
Day to day, you will:
Use your knowledge to plan and deliver data warehouse and storage
Take part in designing and running bespoke data services for individual projects
Stay up to date with business best practice in using and retrieving data
Design, develop, adapt and maintain data warehouse architecture and relational databases that support data mining
Customize storage and extraction, metadata, and information repositories
Create and use effective metrics and monitoring processes
Help to develop business intelligence tools
Support deal teams by providing subject knowledge and solutions for client proposals
Author reports that include key performance indicators, show where current operations can be improved, and identify the causes of any problems
Create and maintain report forms and formats, information dashboards, data generators and canned reports, as well as other information portals and resources
Travel as required.
Your skills
You’re got great experience in data and analysis, and how to source, store and share information. You’re a problem solver who’s happy to work autonomously and to share their knowledge and skills, as well as guiding other team members.
Your skills and experience include:
Database, storage, collection and aggregation models, techniques and technologies and how to apply them in business
Employing statistical and data visualization tools and techniques
Experience in structured problem solving
Great project and people management
Using SharePoint, PowerPivot, SRRS, Excel – including pivot tables and macros
Working with SQL.

You’re likely to have a Bachelor’s degree in Applied Mathematics, Statistics or another relevant field, or an equivalent combination of education and experience. You also have three to five years of relevant professional experience.

Apply now",3.9,AVANADE,Toronto,"Seattle, WA",10000+ employees,2000,Company - Private,IT Services,Information Technology,$2 to $5 billion (CAD),"Slalom, Cognizant Technology Solutions, Deloitte",49.0,20,data engineer,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,2804,3
286,"Are you passionate about building tools that have an immediate impact on your customers?

Do you want to help build some of the most sophisticated data-driven products in the eCommerce industry?

Do you want to help collect, store and manage TBs of data per day?

Do you thrive when you're contributing to a high-performing, humble team?

Amazing, then youre the type of person were looking for!

At Jungle Scout, we are on a mission to empower entrepreneurs to be successful Amazon sellers. We work hard, keep it real and do it all for our customers by providing industry-leading tools, education and content.

Were growing and we are looking to add a Big Data Data Engineer to our fast-paced and customer-oriented team.

Where would this person be located? Great question! We have hubs in Vancouver, BC, Austin, TX and Shenzhen, CN. So if youre located in one of these cities - you're welcome to work in our offices! Jungle Scout started remotely and we want to stick to our roots, so we are open to hiring the right candidate remotely as well.

Interested in learning more? Lets get into the details:

What you will be doing:
Architect and build. You will help collect, manage and transform data for our engineering teams to enable the development of cutting edge, data-driven features in the Amazon space
Build and Maintain tools. You will help build and maintain various internal tools and dashboards that allow us to continually deliver high quality data to our customers
Eye for Detail. Youll use your eye for details to QA the data flowing in from our various apps to ensure accuracy and completeness. You know how to design effective monitoring for high-performance systems so we can proactively tweak our applications.
Make recommendations. You will play an active role in the way we make decisions around technologies to be used for new applications and improvements on existing applications
Scale, maintain, and improve. As we continue to grow, youll anticipate challenges before they happen by maintaining existing codebases and system infrastructures, as well as enhancing the development, staging and production environments of our applications.
Participate and contribute. Youll have an active hand in code reviews, as well as in project planning and management. Youll also provide input for ongoing improvement of engineering practices and procedures.
Passionate mentor. We are firm believers in knowledge sharing and supporting team development. You will coach other developers on programming and infrastructure best practices.
If you are thinking heck yeah!, please read on.

Who you are:
Done this before. We believe experience is best measured in results and intensity (not years), but you need to have been in this software development game a while. You also need to have experience with some subset of our primary tech stack: Ruby on Rails, Node, Python, Postgres, DynamoDB, Elasticsearch and Redshift.
Big Data Wizard. You have real-world experience using some of the following big-data tools: Hadoop, Spark, Flink, Storm, and Kafka
Heavy toolbelt. You know your way around working with SQL, know when to import a library or write code yourself for that Node project. You understand how your tools work in detail, and can show your team a thing or two.
AWS Cloud master. Youre an expert with AWS services, you can deep dive on any of the following tools: EC2, RDS, DynamoDB, Elasticsearch, ElasticBeanstalk, Lambda, Cloudwatch, SQS and SNS
Who we are:

Jungle Scout is the leading all-in-one tool for selling on Amazon, with the mission of providing powerful data and insights to help entrepreneurs and brands grow successful Amazon businesses.

The Jungle Scout team is a group of smart, motivated, and fun-loving professionals working hard to help our customers achieve success. We have a remote-first culture with employees across the world as well as in our hub offices in Austin TX, Vancouver BC and Shenzhen China. We believe team members should have the opportunity to choose the work environment that works best for them. Team members have the option of working from home, at one of our hub offices, or from a co-working space.

We offer workplace flexibility, competitive compensation packages, 401K/RRSP matching, generous vacation, and professional development to help you thrive in your career. The entire Jungle Scout team also gathers for annual all-expenses-paid retreats past locations have included Bali, Bangkok, Vietnam, Budapest, Mexico, Colombia, and Costa Rica. Check us out!

Powered by JazzHR",4.1,Jungle Scout,British Columbia,"Austin, TX",51 to 200 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,49.0,4,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,4540,0
287,"Job Title
Machine Learning Engineer (Layer 6)

27-Jul-2020

TD Description

Tell us your story. Don't go unnoticed. Explain why you're a winning candidate. Think ""TD"" if you crave meaningful work and embrace change like we do. We are a trusted North American leader that cares about people and inspires them to grow and move forward.

Stay current and competitive. Carve out a career for yourself. Grow with us. Here's our story: jobs.td.com

Auto req ID
282364BR

Department Overview

Customer Accountabilities:
Leverage deep technology expertise for own area of specialization to deliver and ensure that all areas across the organization that provision, manage and support various technologies have the necessary tools, processes and documentation required to effectively execute on their respective mandates
Execute on Engineering strategy as it relates to the introduction of tools and the automation of build, test, release and configure activities across Application, Platform and Infrastructure
Partner with the Operations team to automatically integrate with appropriate tools and processes as part of automated/self-serve Application, Platform or Infrastructure releases
Work with partners across Technology and apply in-depth understanding of relevant business needs to identify and leverage synergies across the various areas
Act as the expert or lead innovator and agent of change for the programs and services under management
Work with other teams to implement best practices for engineering and management
Work with vendor platform providers and engineering peers to keep abreast of trends, products, frameworks, and applications
Identify and effectively manage stakeholder engagement and impacts across the enterprise
Interpret client needs, assess engineering related requirements and identify solutions to non-standard requests
Shareholder Accountabilities:
Apply best practices and knowledge of internal / external business issues to improve products or services in own discipline
Monitor and control costs within own work
May interact with governance and control groups, (e.g. regulatory / operational risk, compliance and audit) to provide subject matter expertise and consult on risk issues / items related to Engineering technology and tools
May develop and/or contribute to negotiations of third party contracts/agreements
Maintain knowledge and understanding of external development, engineering and emerging solutions, market conditions and their impact
Proactively identify emerging technologies and innovative solutions for building more robust platform domains
Country
Canada

Job Requirements

Experience and/or Education:
University or post-graduate degree
Strong academic background (e.g., computer science, engineering)
7 + years relevant experience
Hours
5
Job Description

Employee/Team Accountabilities:
Continuously enhance knowledge/expertise in own area and keep current with emerging industry trends, new technologies and best practices in the external market that can contribute to delivering effective client solutions
Prioritize and manage own workload in order to deliver quality results and meet timelines
Support a positive work environment that promotes service to the business, quality, innovation and teamwork and ensure timely communication of issues/ points of interest
Participate in knowledge transfer with senior management, the team, other technical areas and business units
Work effectively as a team, supporting other members of the team in achieving business objectives and providing client services
Identify and recommend opportunities to enhance productivity, effectiveness and operational efficiency of the business unit and/or team
Breadth and Depth:
Expert knowledge of specific domain or range of engineering frameworks, technology, tools, processes and procedures, as well as organization issues
Expert knowledge of TD applications, systems, networks, innovation, design activities, best practices, business / organization, Bank standards, and may fulfill a governance role
Expert knowledge and experience in own discipline; integrates knowledge of business and functional priorities
Acts as a key contributor in a complex and critical environment
May provide leadership to teams or projects; shares expertise
Applies in-depth skills and broad knowledge of the business to address complex problems and non-standard situations
Generally reports to a Senior Manager or above
Inclusiveness

At TD, we are committed to fostering an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of our customers and communities in which we live and serve. If you require an accommodation for the recruitment/interview process (including alternate formats of materials, or accessible meeting rooms or other accommodation), please let us know and we will work with you to meet your needs.

{""QuestionName"":""Additional Information"",""AnswerValue"":""

We are looking for world-class engineers to help us develop a system that will serve as the main interface to our machine learning platform. The goal of this system is to help in all stages of model development, from feature engineering all the way to production monitoring.

We empower our data scientists to build better models by helping them understand the data and trained models. We also provide the tools necessary for analyzing and visualizing machine learning algorithms in an effort to extract valuable business insights in a transparent and comprehensive manner.

As front-end engineer at Layer 6, you will learn about different machine learning algorithms and ways to analyze them. Using that knowledge, you will build intuitive interfaces to visualize data and answer questions about machine learning models. You will work with backend engineers to design web APIs. You will also work with the engineering team to solve challenges of developing high performance, robust and scalable systems.

# Requirements

- You have experience in designing and building a large single-page web application

- Mastery of at least one front end application framework. (e.g. Elm, React/Redux)

- Experience with JavaScript-based data visualization libraries like D3.js

- You value good software design and sweat over details in user experience and also in code

- You enjoy learning new technology and also educating others

- You strive to communicate clearly and with empathy

- You take great personal pride in building robust, scalable software

- You are highly accountable and have a strong sense of ownership

- Ability to do detailed code reviews and give thoughtful feedback

# Nice to have

- Experience with Elm for building front-end applications

- Experience with functional programming

- Experience with data analysis and visualization

- Knowledge of machine learning algorithms

- Comfortable with math (linear algebra, calculus)

Apply",3.9,TD Bank,Canada,"Toronto, Canada",10000+ employees,1855,Company - Public,Banks & Building Societies,Finance,$10+ billion (CAD),"Chase, BB&T, SunTrust",49.0,165,machine learning engineer,na,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,6972,3
288,"Posted: July 21, 2020

Region: CAN - NB - Saint John

Application deadline: August 04, 2020
Permanent Full-Time

Reporting to the Senior Manager, Donation Processing, or their designate, the Senior Data Analyst - Finance is responsible for understanding the finance transactions as they relate to Donation Processing. This position is a key resource supporting data management, identifying areas for process improvement, coordinating change management, creating and maintaining process documentation, and ensuring the integrity of the various data systems such as philanthropy, accounting, etc.

You will enjoy:
Culture: an organization that is guided by our fundamental principles of humanity, impartiality, neutrality, independence, voluntary service, unity and universality.
Opportunity: to work with the best and brightest in the non-profit field, in an environment that promotes continuous learning, creativity and collaboration.
Flexibility: alternative work arrangements and paid time off for those “life happens” moments.
Employee Benefits: comprehensive health and dental plan, pension plan with matching contributions and competitive vacation entitlements.
Meaningful Work: you will be part of a team that supports Canadians within your provinces as well as from across the country.
In this role you will:
Develop and sustain a strong relationship between Philanthropy and Finance, ensuring the processing and analytical departments get satisfaction across all the relevant finance processes and services.
Stay abreast of new technologies and their ability to provide a competitive edge by partnering with Philanthropy counterparts, attending relevant workshops and participating in training activities provided by service providers and others.
Look for opportunities to leverage technology to achieve business unit objectives.
Be responsible for understanding the Finance Donations Processing Operations, assisting in the prioritization of projects and working with the Finance Manager and Director, Information Management strategy in support of the overall strategy.
Reconcile and analyze System Parity between the Philanthropy system and Financial System, ensuring all unreconciled items are brought forward to Finance Manager for investigation.
Participate in the planning and scheduling of project timelines and milestones using appropriate tools.
Employees and Volunteers at every level are responsible for safe work practices and to adhere to practices outlined in their applicable provincial Occupational Health and Safety Act.
Support other Red Cross initiatives, as needed, to provide for a coordinated team effort to meeting the needs of the most vulnerable in the community.
We’re looking for:
Completion of post-secondary education in Business Administration with a concentration in Accounting or Information Technology or a related field, as well as, five to seven years of related experience, or an equivalent combination of education and experience.
Minimum of 7 years proven experience with financial, operational, statistical, and system analysis.
Strong communication skills in English, written and oral are required.
Competent and proficient in understanding of platforms and internet technologies such as CRM databases, Microsoft SharePoint and Dynamics AX.
Ability to bring projects to successful completion through competing priorities.
Ability to effectively prioritize and execute tasks in a high-pressure environment is crucial.
Ability to elicit cooperation from a wide variety of sources, including upper management, clients and other departments.
Ability to understand and communicate complex business requirements to the technology teams.
Strong conflict resolution skills.
Position requires a very high level of technical know how:
Mapping and SQL coding.
Crystal Reports/SSIS reporting.
Strong attention to detail and accuracy.
Demonstrated computer proficiency and advanced Excel skills.
A satisfactory criminal record check is required.
The Canadian Red Cross is committed to gender equality and social inclusion in our workplace. All qualified applications will receive consideration without regard to sex, gender identity, gender expression, sexual orientation, race, ethnic origin, color, religion, nationality, disability, age, or any other characteristic protected by applicable law. We encourage all qualified persons to apply particularly Indigenous peoples, persons with disabilities, ethnic minorities, visible minorities, and others who share our values and contribute to fostering an inclusive and diverse workplace.

Please notify us as soon as possible of any adaptive measures you might require at any stage of the recruitment process.

To apply for this position, click here",4.2,Canadian Red Cross,Saint John,"Ottawa, Canada",10000+ employees,1896,Non-profit Organisation,Charitable Foundations,Non-Profits,Unknown / Non-Applicable,-1,49.0,124,data analyst,senior,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,4733,0
289,"Data Analyst (and Insights Mastermind) – Kelowna, Canada

Are you a data junkie? Do you love the idea of challenging the way that people use visual interpretations of data to transform the way Canadians interact with our favourite brands? Do you enjoy working in an entrepreneurial environment, where quick decision-making enables meaningful and measurable progress? Does the prospect of joining a well-funded, early stage business, with tons of potential, excite you?

If you answered yes to the questions above, then we’d love to hear from you!

About 7X

7X was founded on the basic premise that most third-party contact centres suck, resulting in painful client interactions with some of the world’s most recognized consumer brands. 7X has set out to reinvent the industry, shifting focus towards co-creating delightful experiences to drive brand affinity, loyalty and adoption, for our clients. To achieve this, the company’s unique engagement model involves a more customized and collaborative approach to designing, building and operating omnichannel contact centres for some of the world’s most recognizable brands.

As part of this unique approach, 7X has recently partnered with a top-tier North American Telco, to build a world-class sales organization. Delivering a world-class experience requires that we look at the world in a whole new way. Using insights gleaned from rich data, we can create exceptional, fully customized, experiences that go beyond what anyone has thought possible.

This role offers an opportunity to work remotely (for the right candidate).

Key Responsibilities

Create unique, mind-blowing visuals that will help interpret complex data for internal and external stakeholders
Finding new ways of presenting data so that it is interesting and captivating
Mining for nuggets of insights that can inform and transform our clients’ business strategies
Use data to challenge the old way of doing things
Help us take calculated risks to ensure we are going where others think they can’t and that that we’re successful at it.
Sweat the details – present your findings in an easy-on-the-eyes and easy-on-the-mind kind of way.

Required Qualifications & Experience

2+ Years with either Microsoft Power BI or Tableau, is a requirement.
SQL query writing is strongly preferred.
ETL Tools such as SSIS and SSRS would also be a benefit.
A collaborative team member that has a positive outlook, and can-do attitude
Ability to effectively multi-task in a fast-paced environment.
Must have a good visual eye and care about how data is presented
A creative mastermind that is comfortable working in an agile development environment

Job Types: Full-time, Permanent

Benefits:
Dental Care
Paid Time Off
Vision Care
Wellness Program
Experience:
Microsoft Power BI or Tableau: 2 years (Required)
Work remotely:
Temporarily due to COVID-19",5.0,7x Powered Inc.,Kelowna,"Calgary, Canada",51 to 200 employees,-1,Unknown,-1,-1,Unknown / Non-Applicable,-1,49.0,-1,data analyst,na,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,2857,0
290,"ZeniMax understands the importance of privacy. Please review the “Applicant Privacy Notice” section below, which explains how we process the personal information we collect about you when you apply for a job or submit information to us through this job portal. BY APPLYING FOR THIS JOB, SHARING THIS JOB OR OTHERWISE PROVIDING US WITH YOUR PERSONAL INFORMATION THROUGH THIS JOB PORTAL, YOU ACKNOWLEDGE THAT YOU HAVE READ AND UNDERSTOOD THE APPLICANT PRIVACY NOTICE , WHICH IS SET FORTH IN THE “APPLICANT PRIVACY NOTICE” SECTION BELOW.

Bethesda Game Studios recherche un talentueux Spécialiste en analyse de données, très autonome avec de fortes compétences d’analyse, pour rejoindre l’équipe qui dépasse les standards et repousse les limites du développement de jeux AAA sur les plateformes mobiles. L'analyste doit posséder des connaissances et de l'expérience dans l'exploration et l'analyse de données pour créer des rapports et des tableaux de bord standard et ad hoc, et être en mesure de déterminer les tendances qui donnent lieu à des perspectives exploitables. Doté d’une solide compréhension des méthodologies avancées en statistiques, vous souhaitez vous impliquer dans un nouveau challenge.
Bethesda Game Studios is looking for talented and self-driven Data Analyst with strong analytical skills to join the team that is pushing the bleeding-edge AAA game development for mobile platforms. The Analyst must have knowledge and experience in data exploration and analysis to create standard and ad-hoc reports and dashboards, as well as being able to determine trends that result in actionable insights. With a deep understanding of advanced statistical methods, you want to be part of a new challenge.

Produire régulièrement des rapports sur les métriques clés dans le jeu;
Concevoir, développer et maintenir des rapports, des visualisations et des tableaux de bord des KPI et des métriques pour le personnel interne et les dirigeants;
Identifier et développer de nouvelles mesures pour aider à déterminer ce qui est amusant ou non dans le jeu, identifier les déséquilibres du jeu, identifier les stratégies optimales de monétisation, etc. sur une base régulière;
Analyser les données pour mieux comprendre, modéliser, prédire, segmenter et monétiser les joueurs de Bethesda;
Créez des modèles pour prévoir les métriques clés et optimiser la monétisation du jeu;
Exploiter et explorer des ensembles de données multidimensionnelles;
Collaborer avec les intervenants et les équipes départementales pour obtenir et documenter les besoins en matière de rapports et d'analyses qui peuvent les aider;
Travailler avec les programmeurs et les concepteurs de jeux pour s'assurer que le suivi de l'implémentation dans le jeu répondra aux exigences;
Agir à titre d'expert en la matière et de ressource pour accéder aux données et les analyser;
Aider à définir et valider les métriques dans le jeu;
Rédiger des requêtes SQL ainsi que des scripts complexes en Python afin d’extraire et d’analyser des ensembles de données massives, complexes et multidimensionnels avec des outils de modélisation statistique et de visualisation (Matplotlib, Seaborn, Tableau).

Production of regular reports on key in-game metrics;
Design, develop, and maintain reports, visualizations and dashboards of KPIs and metrics to internal staff and executives;
Identify and develop new metrics to help determine what is fun/not fun in the game, identify game imbalances, identify optimal strategies for monetization, etc. on a recurring basis;
Analyze data to further understand, model, predict, segment, and monetize Bethesda’s players;
Create models to forecast key metrics and optimize the monetization of the game;
Mine and explore multi-dimensional datasets;
Partner with stakeholders and departmental teams to elicit and document reporting and analytics requirements that can help them;
Work with game programmers and game designers to ensure tracking implementation in the game will support requirements;
Serve as a subject matter expert and resource for accessing and analyzing data;
Write complex set of SQL queries and Python scripts in order to extract and analyze big, multi-dimensional datasets with statistical modelling and visualization tools (Matplotlib, Seaborn, Tableau).

Passion pour les jeux vidéo;
Minimum de 2 à 4 ans d'expérience dans un poste similaire à développer des rapports, des visualisations et des tableaux de bord en utilisant Tableau Desktop ou similaire;
Expérience de l'analyse quantitative, de la modélisation statistique et de la statistique appliquée, avec des recommandations à l'intention des intervenants - idéalement dans l'industrie du jeu vidéo;
Expérience avec l'extraction de données, la manipulation et wrangling;
Excellentes compétences SQL avec la connaissance des fonctions statistiques, d'agrégation et de windowing;
Solides connaissances sur Excel et/ou d’un progiciel statistique;
Connaissance de Python ou d'autres langages de programmation;
Connaissance approfondie de la conception logique des bases de données, des bases de données relationnelles et des principes de l'entrepôt de données;
Très bonnes habiletés en communication et en travail d’équipe.
Passion for video games;
Minimum 2-4 years of experience on a similar role developing reports, visualizations, and dashboards using Tableau Desktop or similar;
Experience in performing quantitative analysis, statistical modelling and applied statistics, providing recommendations for stakeholders – ideally in the video game industry;
Experience with data extraction, manipulation, and wrangling;
Excellent SQL skills with the knowledge of statistical, aggregate, and windowing functions;
Strong knowledge of Excel and/or statistical packages;
Knowledge of Python or other programming languages;
Strong knowledge of logical database design, relational databases, and data warehouse principles;
Strong communication and teamwork skills.

Baccalauréat en informatique, en mathématiques, en statistique, en économie d'entreprise, en génie ou en BI avec une expérience supplémentaire appropriée;
Expérience dans l'industrie du jeu vidéo serait un grand plus;
Bonne compréhension des systèmes de jeu gratuit et de l'économie de jeu;
Expérience générale en programmation serait un atout;
Expérience précédente de travail avec Apache Spark et Spark SQL;
Expérience précédente de travail dans un environnement AWS, y compris l'expérience de l'utilisation de Redshift;
Expérience précédente avec les modèles prédictifs / Machine learning.
BS degree in Computer Science, Math, Statistics, Business Economics, Engineering, or BI with appropriate additional experience;
Experience in the video game industry would be a big plus;
Good understanding of free-to-play systems and economy-in-game;
General programming experience would be an asset;
Prior experience working with Apache Spark and Spark SQL;
Prior experience working in an AWS environment preferred including experience using Redshift;
Prior experience with predictive models / Machine learning.

Applicant Privacy Notice",3.4,"ZeniMax Media, Inc.",Montreal,"Rockville, MD",201 to 500 employees,1999,Company - Private,Video Games,Media,Unknown / Non-Applicable,-1,49.0,21,data analyst,na,0,1,0,1,0,1,1,1,0,0,0,0,1,0,1,7057,0
291,"About Behavox


We are a fast-growing and pioneering people analytics company that is transforming the financial workplace. We use cutting-edge software and machine learning to generate previously unidentifiable insights into employee behavior and performance. We have been recognized by renowned companies such as Amazon Web Services and Google Cloud for our achievements in AI, big data analytics, and machine learning. We have also been included in the Forbes FinTech 50, CB Insights AI 100, and Tech Nation's prestigious Future 50 program.

Our goal is to help businesses achieve better outcomes by developing and delivering data-driven solutions for compliance, CRM, HR, and workplace productivity. We also aim to rapidly expand our worldwide customer base to include companies across all major industries.

About the Role


Behavox Platform daily processes massive amounts of highly unstructured data and converts it to structured information (clean text, classification, artifacts, topics of interest, etc.) for further analysis.

The Data Analytics Team creates applications that leverage tools provided by the Behavox Platform to give clients insights into their data. These applications are available to all our clients via the Behavox CRX (Conduct Risk Exchange), which is an online library of scenarios, reports, and widgets. Each application is a small product itself - with its context, objectives, approach, means.

As a Senior Analyst, you'll be in charge of designing and developing applications for Behavox CRX to effectively aggregate, analyze and represent data, find patterns, outliers and generate insights. You'll work in close collaboration with other analysts, linguists, developers, and experts. You'll be the owner of the products you create and these applications will run daily on Big Data and help our clients to make important decisions.

This is a unique opportunity to work with real data on challenging and diverse tasks in a very dynamic environment and make a real impact on the largest global businesses.

.Responsibilities
Design, development, and ownership of complex applications (our DSL / Groovy);
Understanding business needs related to your area of ownership, proactively analyzing gaps in current applications, formulating requirements, designing and creating corresponding solutions;
Effective collaboration with cross-functional teams (Engineering, ML, PM, etc) and clients: detecting problems in current approaches/tools, providing feedback, proposing solutions for the roadmap.
Ideal Candidate Profile
5+ years of experience in a similar role (data analysis / applied linguistics / NLP / statistics);
Strong programming skills with an overall 3+ years of production experience (Python / Groovy / Java);
Experience in text/language data analysis (semantics, syntax, sentiment, etc);
Subject matter expertise in the financial / compliance / fraud detection domains is an advantage;
Ability to take full ownership of the task, communicate clearly, and solve the problems creatively.
What We Offer
Passionate team applying cutting-edge tech to data and analytics;
Competitive salary;
Fully covered health benefits for employee and family;
Generous time-off policy; and
Flexible work schedule.
Selection Process
HR phone interview to discuss your skills, experience, and interests;
Interview with the hiring manager;
Take-home technical task; and
Final on-site interview with Data Analytics Team members and Chief Data Scientist.",5.0,Behavox,Montreal,"New York, NY",51 to 200 employees,2014,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,-1,49.0,6,data analyst,na,0,1,0,0,0,0,0,1,0,1,0,0,1,0,1,3473,0
292,"Company Description

We’re a technology company working in the loyalty e-commerce industry. Our solutions enhance the management and monetization of loyalty currencies for more than 50 of the world’s largest loyalty brands, from frequent flyer miles and hotel points to retailer and credit card rewards. Supported by our unparalleled loyalty industry experience and technological expertise, we bring state-of-the-art loyalty commerce platforms and products to individuals and businesses in today’s loyalty marketplace.

Our casual, collaborative office is where our strong workplace culture begins. Our people are what make us great, so we empower them with the freedom to think big and the resources to make things happen. We communicate directly, lead by example, and make sure our team members know how much they are appreciated. Passion for life and work is important to us, and we want to see it in you, too!

Job Description

Points is looking for a Data Engineer to join our Data Engineering team for a permanent position in our downtown Toronto office.

We’re an industry-leading web-based organization that is continuously reshaping how consumers interact with their loyalty programs. We work with the world’s largest airline, hotel, financial, and retail rewards programs, to tackle complex challenges and come up with innovative e-commerce solutions. If you’d like to be a part of it, we’d love to hear from you.

Reporting to the Team Lead, Data Engineering, you will:
Work in a scrum based team that is passionate about data.
Design and develop scalable pipelines for data consumption by downstream applications and for reporting purposes.
Improve upon existing ETL processes and monitoring to maintain data integrity and accuracy.
Automate the boring manual stuff, preferably using Python.
Support production systems to ensure a high degree of data availability.
Qualifications
Experience using GUI ETL tools (we use Talend).
Strong knowledge of SQL.
Experience with pub/sub architectures, such as Kafka.
Experience with containers and related infrastructure, such as Docker and Kubernetes.
Self-discipline and willingness to learn.
Nice to haves
Good knowledge of general software engineering principles and practices.
Experience with columnar-oriented databases, such as Vertica.
Experience integrating with services, such as Dataiku and NetSuite.
Working knowledge of Continuous Integration and Continuous Deployment concepts.
Additional Information

Building a great company culture is as vital to us as building a great business. Over the last 5 years Points has been the recipient of the following awards:
Best Workplaces (Medium) in Canada
Best Workplaces for Women.
Canada’s Top Small and Medium Employers
Greater Toronto’s Top Employers
Here are some of the perks that are included in our Points culture:
Central downtown location in the Financial District
Connected to the PATH network of shops/restaurants
We want to celebrate with you: all employees get an extra day off for their Birthdays!
Flexible work hours and casual dress every day
Marvelous Snack Cart Fridays: free refreshments and snacks!
Free coffee, tea, juice, pop, and snacks
Monthly subsidized lunch program
Green commuter and fitness subsidies
Secure bike storage with showers and towel service
Company-sponsored activities: bowling, movies, sports, paintball, and more!
Points is an equal opportunity employer and is committed to providing an accessible recruitment process. Upon request we will provide accommodation for applicants with disabilities.

All your information will be kept confidential.

No agencies please.",3.7,Points International,Toronto,"Toronto, Canada",201 to 500 employees,2001,Company - Public,Internet,Information Technology,$100 to $500 million (CAD),-1,49.0,19,data engineer,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,3614,0
293,"Sustainability Impact Data Analyst

Green Economy Canada is a national non-profit working to accelerate Canada’s transition to a vibrant and sustainable low carbon economy. We do this in three ways: 1.) We work with community organizations to launch and grow Green Economy Hubs, which bring together, support and celebrate local businesses (Green Economy Leaders) in setting and achieving sustainability goals. 2.) We share success stories of businesses going green to inspire others to follow suit and build public support for the green economy. 3.) We work with policymakers and experts to inform green policies and investments that will accelerate action on climate change and other sustainability challenges.

With seven Ontario-based Hubs and the Edmonton Corporate Climate Leaders Program, our network is engaging over 300 organizations of all sectors and sizes in demonstrating a more sustainable economy is possible. Two new Hubs are in development in Ontario and New Brunswick. By 2024, our goal is to support a network of 20 Green Economy Hubs across Canada engaging thousands of organizations in changing business-as-usual.

Position Overview

The Sustainability Impact Data Analyst will play a key role across three exciting data-focused projects to support us in achieving our impact goals:
*
Managing our Excel-based carbon accounting tool and developing GHG inventories to support our growing network of Green Economy Leaders in effectively measuring and managing their GHG emissions;
Analyzing GHG data and synthesizing findings for an innovative project focused on what it will take to get small and medium-sized manufacturers to net zero emissions; and
Identifying opportunities to improve our overall data systems & processes with an eye to scale.
The ideal candidate is a data savvy systems thinker. They have experience with carbon accounting/energy management, and are an expert in Excel. They are highly organized and detail-oriented, with strong communication and interpersonal skills. This position works closely with the Senior Communications Manager, Special Projects Lead, Network Engagement Manager, and Program Manager for the City of Edmonton’s Corporate Climate Leaders Program.

Ideal Start Date: August 4th, 2020

Term: 1 year contract with potential to become a permanent position

Annual Compensation: $62,700 + $1500 health and wellness allowance

Location: Ontario preferred, though Green Economy Canada is primarily a remote team

Reports to: Senior Communications Manager

Interviews begin: Week of July 20, 2020 and will be rolling until the position is filled.

What does the Sustainability Impact Data Analyst Do?

Carbon Accounting Tool & GHG Inventories (40%)
Manage Green Economy Canada’s Excel-based carbon accounting tool, updating emission factors annually and processing business data efficiently and carefully to develop GHG inventories and business-facing inventory reports in line with the GHG Protocol Corporate Standard
Evaluate the performance of the tool with internal and external user feedback and identify improvements to functionality, usability, and reporting for future releases
Develop systems to ensure business data inputted and processed can be analyzed and housed securely and at scale
SME Net Zero Project (20%)
Support the data collection and inventory development for 10-12 participants in our SME Net Zero Manufacturing project
Analyze participant data to uncover key insights for emissions reductions, and compile findings to feed into a roundtable with policymakers and a public report in partnership with the Pembina Institute
Network Data & Communications (40%)
Lead data collection from Green Economy Hubs quarterly, performing completeness and quality checks
Improve and document our overall data collection systems and processes
Maintain and update data in our internal database, website, and intranet dashboard
Analyze results to identify key insights, trends, gaps and potential case studies to inform network strategy and external communications on network impact
Produce visualizations as needed to share back data with Hubs and Green Economy Leaders on the network’s impact
Key Skills and Characteristics Required to Succeed in this Role:
Combination of at least 5 years of relevant education, work and life experience in business, sustainability or a related field. Has knowledge and experience creating GHG inventories in accordance with the World Resource Institute’s GHG Protocol Corporate Standard. Energy Manager certification or equivalent is a major asset.
Advanced knowledge of Excel (e.g. Index Match, And / Or), pivot tables, and Power Query is a requirement. Major assets include: knowledge of the basic principles of database design, MySQL, Wordpress CMS, and data visualization tools like Power BI.
Excellent interpersonal and communication skills (oral and written).
Conscientious and highly detail-oriented. Strong at quality assurance, and builds trust that work is completed with quality and care.
Takes initiative to identify necessary improvements and strategic priorities and is proactive in bringing recommendations forward with clear rationale.
Strong critical-thinking and analytical skills. Adept at getting to the heart of a challenge and is goal and results-oriented in arriving at solutions.
Proven track-record managing significant projects from conceptualization through to implementation; organized, manages time well, can manage logistics and “pull-up” to achieve the desired outcomes.
Life long learner who values continuous improvement and can pick up new skills and knowledge quickly to further their growth and development.
Thrives in a fast-paced, evolving environment working alongside high performing team members who are passionate about accelerating Canada’s transition to a low-carbon economy.
To Apply:

Please send a resume and cover letter to Priyanka Lloyd, Executive Director. Please also indicate in your email how you learned about this opportunity. Applications will be accepted on a rolling basis until the position is filled, and interviews will begin the week of July 20th. We sincerely thank all applicants, however, we will only be able to personally contact those selected for an interview.

Green Economy Canada is an equal opportunity employer where a diverse mix of talented people do their best work because of, not in spite of, our differences. We are committed to providing an inclusive and welcoming environment for all staff, volunteers, members, subcontractors, and vendors in all our activities and operations, regardless of race, color, religion (creed), gender identity, gender expression, age, national origin (ancestry), dis/ability, marital status, or sexual orientation.

What’s it Like Working at Green Economy Canada?

At Green Economy Canada, we seek to blend the nimbleness and autonomy of a small team with the influence and opportunities afforded to a national network.
We are bold, ambitious and optimistic. Our vision is for an economy that makes environmental sustainability, human well-being, and business success synonymous.
We care about what we each accomplish, not where we work from or how many hours we put in.
We want working together to feel effortless and the ways we work together to be intuitive.
We embrace innovation: we’re willing to take risks, we know we’ll make mistakes along the way, and we push ourselves to apply what we learn each time. At Green Economy Canada, it’s okay to fail.
We have fun, enjoy working together, and laugh often.
We’re not satisfied with the status quo: we don’t think “because that’s how it’s always been done” justifies a course of action. We challenge each other, think critically, and strive for objective decision-making.
Together with our network of Hubs and partners, we’re demonstrating a more sustainable economy is possible,

Learn More About Green Economy Canada
Visit www.greeneconomy.ca
Join the conversation on Twitter @greeneconomyca
Application deadline: 2020-07-24

Expected start date: 2020-08-04

Job Types: Full-time, Contract

Salary: $31.00 per hour

Benefits:
Casual Dress
Flexible Schedule
Paid Time Off
Work From Home
Schedule:
Monday to Friday
Experience:
relevant work, life and/or educational: 5 years (Preferred)
Work remotely:
Yes",-1.0,Green Economy Can,Remote,"Syracuse, NY",1 to 50 employees,-1,Non-profit Organisation,-1,-1,Less than $1 million (CAD),-1,49.0,-1,data analyst,na,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,8270,0
294,"The OneHSN Childcare Data Analyst resides in the Customer Relations department. The Childcare Data Analyst plays a critical role in supporting and facilitating the customer base in the usage of the OneHSN platform and tool sets. Our Childcare Data Analyst interprets data and turns it into information which can offer value to our customers who desire to improve the childcare service model, thus affecting policy and investment decisions. You will identify and gather information from various sources, including our Childcare Connect Platform, identify and interpret patterns and trends that support the building and sustainment of a healthy childcare service ecosystem. Once data has been gathered and interpreted, the Childcare Data Analyst will report back what has been found in a comprehensive study to the wider business/relevant colleagues.

Overall complexity of responsibilities is intermediate to advanced.

Position will be based in Canada.

Childcare Data Analyst responsibilities include:

· Conducting full life cycle analysis to include requirements, activities and design reporting capabilities

· Interpret data, analyze results using statistical techniques and provide ongoing reports

· Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality

· Acquire data from primary or secondary data sources and maintain databases/data systems

· Identify, analyze, and interpret trends or patterns in complex data sets

· Design and develop data queries via Open Data Connectivity (OData)

· Design and develop PowerBI reports and visual presentations for our clients

· Work with management to prioritize business and information needs

Key skills for a data analyst:

· A high level of mathematical ability

· Data query design and development in Microsoft SQL

· Microsoft PowerBI report and visual presentation development

· Technical expertise regarding data models, database design development, data mining and segmentation techniques

· Problem-solving skills

· A methodical and logical approach

· The ability to plan work and meet deadlines

· Accuracy and attention to detail

· Interpersonal skills

· Teamworking skills

· Written and verbal communication skills

Reference ID: OneHSN-2020-003

Contract length: 6 months

Job Types: Full-time, Contract

Salary: $45,000.00-$60,000.00 per year

Benefits:
Casual Dress
Dental Care
Disability Insurance
Extended Health Care
Flexible Schedule
Life Insurance
Vision Care
Work From Home
Schedule:
8 Hour Shift
Experience:
Microsoft PowerBI: 1 year (Preferred)
data analytical: 1 year (Preferred)
SQL query development: 1 year (Preferred)
Work remotely:
Yes",-1.0,One Human Service Network (OneH,Sault Ste. Marie,-1,-1,-1,-1,-1,-1,-1,-1,49.0,-1,data analyst,na,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,2712,0
295,"Data Analyst Team Lead Citis Innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to Citis Capital Markets, Securities Services and Banking lines of businesses. Our Mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurship spirit. We are currently looking for an excellent data analyst team lead to join one of our cutting edge trade surveillance solutions. It is a highly advanced trade monitoring and analytics product used globally among Citis trading desks. Job Description Recruit and Manage a team of talented data analysts Explore and analyze datasets to develop new robust controls Work with business partners to design new workflows to transform business requirements into concrete insights Onboard data across the various financial markets via multiple consumption methods (Message buses, SFTP, SQL connectors) Develop automated procedures to improve and optimize existing controls Work together with the R&D team to help guide the Platform roadmap Experience & Qualifications Experience managing data/business analysts 2+ people management and 5+ years total experience is required Strong leadership and management skills Ability to manage senior stakeholder relationships Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to details and accuracy Solid experience in working with data and relational / non-relational databases Hands-on experience in Scripting Languages (Python / R) Experience in troubleshooting code and logs advantage Experience in Linux Advantage BS/BA in Software Engineering or Computer Science advantage, or in Industrial Engineering, Mathematics, Statistics or Economics Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - CA ------------------------------------------------------ Time Type : ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,Citi,Mississauga,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,$10+ billion (CAD),-1,49.0,208,data analyst,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,3245,0
296,"Hey, it’s so nice to meet you!

We’re Nude Solutions – and our team is on a mission to empower insurance with our cloud-based, API-driven platform that is (positively!) disrupting the industry as we know it. We’ve developed a simple, but powerful, solution that allows brokers, agents, managing general agencies, mutuals, and insurers to transform their businesses and achieve their vision of delivering the best insurance experience in the world.

Being a data informed company allows us to provide our clients with a world-class experience and provide our own team the insights that help build an even more kick-ass product. Our Business Intelligence Team is made up of passionate, collaborative, and downright awesome misfits that fit – so we know that you’re going to fit right in. As a Nude Solutions Data Engineer, you’ll be the whiz who builds and maintains our data warehouse and pipelines. With your amazing development skills, your wicked business acumen, and your love for crafting innovative solutions and ideas, we’re already so excited about all the amazing things we’re going to accomplish together.

What you’ll do:
Create data marts – physical and logical models
Create/Test/Maintain Data Warehouse
Create/Maintain reports in Power BI
Work closely with Data team to perform all the above tasks
Collaborate with the team to identify and document process for improvements
Support data team with everyday tasks
What you’ll need to succeed:
Advanced knowledge of MSSQL or other TSQL language is a requirement
Understanding of data warehousing and ETL procedures (extract/transform/load)
Experience with Power BI
You’re going to love it here.

We’re more than just a workplace. We’re a community. At any given time, you can find our team zipping around the office on scooters, finding quiet time with puzzles in our Cantina, reading a book from our library, or coloring on our walls (seriously - we have a gigantic coloring wall). Nude Solutions is a place where you can be who you want to be, work on projects you’re passionate about, and grow organically into your dream career with the support of an amazing team cheering you on every step of the way. If all that isn't enough, here are just a few more fabulous things we offer:
Team building and bonding events
Extended health, dental, vision benefits
Professional development allowance
Community and charity partners we volunteer with
A deliciously stocked beverage fridge
That's it! If you like what you see, you know what to do (hint, apply) - we can’t wait to meet you!",-1.0,Nude Soluti,Calgary,-1,-1,-1,-1,-1,-1,-1,-1,49.0,-1,data engineer,na,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,2539,0
297,"If you are looking to join one of Canada’s fastest growing companies, goeasy Ltd. is the place for you! Recognized as one of Canada’s Most Admired Corporate Cultures, one of Canada’s Top 50 Fintech’s and one of North America’s Most Engaged Workplaces, we want the best and brightest to join our team.

We are a publicly traded company on the TSX with over 4000% shareholder return since 2001, goeasy operates two main business units. easyfinancial is our consumer lending business that offers secured and unsecured installment loans of up to $35,000 and easyhome is Canada’s largest merchandise lease-to-own company. It is our mission to provide everyday Canadians the chance for a better tomorrow, today by giving them access to the credit they need and by offering them a second chance when they have been turned down by banks and traditional lenders. With a retail network of nearly 400 locations across Canada and over 1900 employees, we are able to build lasting relationships with our customers as we help them rebuild their credit and graduate towards prime rates and a brighter financial future.

The Data Engineer on the Data Science and Business Insights team will build, integrate data from various resources, manage data in goeasy operational data store and enterprise data warehouse. This position will develop ETL (Extract, Transform and Load) with various tools on large datasets to ensure data is easily accessible, works smoothly, as well as maintain and expand the data warehouse for reporting and analysis. The Data Engineer will also work closely with the data architect on the design and architecture of our enterprise data warehouse.

Responsibilities:
Develop data set processes for data modeling, mining and production
Develop and maintain ETL processes using SSIS, Scripting and data replication technologies
Participate in development of datamarts for reports and data visualization solutions
Research opportunities for data acquisition and new uses for existing data
Integrate new data management technologies and software engineering tools into existing structures
Support the translation of business requirements for data acquisition/manipulation and provide detailed specifications that can be passed downstream for use
Develop detailed technical specifications and operational support documentation in collaboration with Business Systems Analysts, BI Engineers and Architects.
Identify and communicate technical problems, process and solutions
Create Ad-Hoc queries and reports as needed along with providing on-going analytical support for these requests
Assist in the collection and documentation of user’s requirements
Ensure that existing business processes dependent on the ODS/EDW are monitored and respond quickly to bug fixes, enhancement requests and production ETL related issues.
Dealing with the database users on a daily basis to ensure that problems are dealt with promptly and that appropriate fixes are made to resolve any problems.
Recommend ways to improve data reliability, efficiency and quality
Ensure systems meet business requirements and industry practices
Work effectively with the Business Intelligence and Data Solutions Architects, Data and BI Engineers to ensure that all approved development and deployment procedures are followed.
Qualifications:
Bachelor’s Degree in Computer Science, MIS, Computer Engineering or other Information Technology related degree
4+ years working with SQL Server or comparable relational database system
3+ years of extensive ETL development experience with SSIS and/or ADF
4+ years of experience troubleshooting within a Data Warehouse environment
Expert domain knowledge & experience in Data warehousing, encompassing data model design, dimensional modeling, naming conventions, cross-cutting concerns, common integration technologies, patterns & standards and emerging technologies.
Expert Knowledge of SQL skills to build, debug, and optimize (developing procedures, functions, SQL queries, etc.) and working with large data sets and to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
2+ years SQL Server Database administration experience
Cloud experience (Azure) is highly preferred
Exposure and experience with Python, R, Hadoop, Azure, other Big data and advanced analytics
Knowledge of AI and ML developments/solutions/implementations
Experience with multiple programming languages (PowerShell scripting, C#, others) with basic scripting skills.
High level of technical aptitude
Inclusion and Equal Opportunity Employment

goeasy is an equal opportunity employer. In addition, goeasy is committed to providing accommodations for applicants upon request at any stage of the recruitment process in accordance with all legislative requirements throughout Canada. Please let us know if you require an accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.

Additional Information:

All candidates considered for hire must successfully pass a criminal background check, credit check, and validation of their work experience to qualify for hire. We thank all interested applicants, however we will only be contacting those for interview who possess the skills and qualifications outlined above.

Why should you work for goeasy?

To learn more about our great company please click the links below:

PAID1234",4.4,goeasy,Mississauga,"Mississauga, Canada",1001 to 5000 employees,1990,Company - Public,Lending,Finance,$1 to $2 billion (CAD),"Fairstone, Mogo (Canada), Money Mart Financial Services",49.0,30,data engineer,na,0,1,0,0,0,1,0,0,1,0,0,0,0,0,0,5479,3
298,"Posted: Jul 30, 2020
Weekly Hours: 37.5
Role Number:
200183612
When this team introduced the App Store, it launched a cultural and economic phenomenon that changed the way people live, work, and play. These engineers continue to innovate the platform, now home to over 1.5 million apps — each created using the team’s own software development kit and related services. All those apps mean the store takes billions of requests from more than 500 million visitors every week, across iOS, macOS, tvOS, iPadOS, and watchOS.

To deliver such a rich experience at this scale, the engineers build high- performance systems backed up by persistent systemwide A/B testing. And to help people discover apps they love, the team uses machine learning techniques that include natural language processing to develop new algorithms for personalization, search, and recommender systems. In a world where apps have become essential in people’s daily lives, the App Store team has become essential to Apple’s business.
Key Qualifications
5+ years of programming experience
Proven understanding on the following distributed data processing platforms: Spark, Hadoop
Solid understanding of HBase, Kafka, Java Map Reduce or Scala
Experience developing new algorithms and data structures to process large scale data efficiently
Distributed Algorithms to process and mine data, e.g. Map Reduce Algorithm
Able to gather multi-functional requirements and translate them into practical engineering tasks
Graph, Data classification and clustering algorithms in distributed environment
Good debugging, critical thinking, and interpersonal skills
Knowledge in engineering machine learning, feature engineering systems is desired
Ability to stay focused and prioritize a full workload while achieving extraordinary quality
Description
The Apple Mediate Products Analytics team is responsible for collecting, analyzing, and reporting on customer experience data. From this data we generate insights into how customers interact with our products, and use these insights to drive improvements to user-facing features.

As a member of the Data Engineering team, you will have significant responsibility and influence in shaping its future direction. This role is inherently cross-functional and the ideal candidate will work across disciplines. We are looking for someone with a love for data and ability to iterate quickly on all stages of data pipeline.

This position involves working on a small team to develop large scale data pipelines and analytical solutions using Big Data technologies. Successful candidates will have strong engineering skills and communication, as well as a belief that data driven processes lead to phenomenal products.
Education & Experience
Bachelors or masters degree in Computer Science, related field or equivalent experience.

Apple is an equal opportunity employer and value diversity at our company. Apple does not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",4.1,Apple,Vancouver,"Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (CAD),"Google, Microsoft, Samsung Electronics",49.0,44,data engineer,senior,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,3072,3
299,"SOTI is committed to providing its employees with endless possibilities; learning new things, working with the latest technologies and making a difference in the world.


Job Title:

Senior Data Engineer

Location:

Mississauga

Who We Are

At SOTI, we are committed to delivering best in class mobile and IoT device management solutions. We are looking for out of the box thinkers that appreciate the art of creating great software. To us, being visionary is more important than doing things the way they’ve always been done.

What’s in it for you?

The People - From our humble origins in our founder’s basement, to our industry leading position today, SOTI has worked hard to foster a company culture that we can all believe in. A culture that emphasizes personal growth, continuous innovation and fun.

The Growth - Our environment fosters new ideas, fresh perspectives, and the ability to take them over the goal line. SOTI is a fast-paced environment with a global reach that encourages you to make your mark and be part of something big!

The Technology - You’ll get the chance to work with leading edge technologies and take on complex and interesting projects, as part of highly collaborative and agile teams. You will work alongside SOTI’s partners which include leading tech giants that will keep you on the cusp of emerging technologies.

What You’ll Do
Ability to translate and document business requirements into technical documentation, supporting document management and knowledge sharing
Ensure assigned deliverables are within business / audit control requirements
Take ownership of end to end design and all aspects related to development and ensure design and development standards and followed
Create project documentation (Detailed design, Source-to-target mappings, Implementation plans, etc.)
Develop data and database-oriented solutions in order to solve complex business problems leading to data driven decision making
Develop data integration processes to integrate disparate data sets into a cohesive data model in support of BI and analytical requirements
Works closely with data architecture to ensure proper adherence to architectural guidelines and principles
Experience You’ll Bring:
7+ years of hands-on advanced experience designing and developing BI Solutions and providing technical expertise
7+ years hands-on advanced experience using MS SQL
7+ years of experience with MS SQL Business Intelligence Stack (SSAS, SSIS, and SSRS)
5+ years hands-on advanced experience using Power BI or similar BI platforms
Experience using Cloud architecture, NoSQL databases and R/Python
Experience using building data pipelines to integrate with unstructured data sources
Experience in designing and building unstructured data stores using Azure or AWS technologies
Experience with Data Warehouse concepts, including the use of Extract, Transform, and Load (ETL) tools
Excellent analytical, troubleshooting, problem-solving and research skills
Must be able to multitask and have experience with interacting within a diverse user/customer base
Excellent written, verbal, and interpersonal communication skills
About SOTI

SOTI is the world's most trusted provider of mobile and IoT management solutions, with more than 17,000 enterprise customers and millions of devices managed worldwide. SOTI's innovative portfolio of solutions and services provide the tools organizations need to truly mobilize their operations and optimize their mobility investments. SOTI extends secure mobility management to provide a total, flexible solution for comprehensive management and security of all mobile devices and connected peripherals deployed in an organization.

At SOTI, we celebrate the uniqueness of our global teams and are proud to be an equal opportunity workplace. We are curious problem solvers who are committed to bringing the best mobile and IoT management solutions to market. We offer careers with #EndlessPossibilities.

What are you waiting for? Apply today: https://www.soti.net/careers

If you want to bring your ideas to life, apply at SOTI today.
We are committed to providing accessible employment practices that are in compliance with the requirements under the Human Rights Code and the Accessibility for Ontarians with Disabilities Act (AODA). If you require accommodation during any stage of the recruitment process, please notify People & Culture at careers@soti.net.


Please note that SOTI does not accept unsolicited resumes from recruiters or employment agencies. In the absence of a signed Services Agreement with agency/recruiter, SOTI will not consider or agree to payment of any referral compensation or recruiter fee.",3.1,SOTI,Mississauga,"Mississauga, Canada",1001 to 5000 employees,1995,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,MobileIron,49.0,25,data engineer,senior,0,1,1,0,0,1,0,1,1,0,0,0,0,0,0,4665,1
300,"Vendasta is seeking a Senior Data Analyst to help propel meaningful analyses that drive our growth & success as a company!

As a Senior Data Analyst, you will work closely with key members of our business intelligence & analysis team to help tackle robust research questions and contribute to key aspects of the data analysis process—including: pulling, exploring, and cleaning data; modelling, interpreting, communicating results; and measuring their implementation. Finally, you will leverage the interdepartmental analyst group to review, develop, and share information or analyses that help one another learn and grow in data & business intelligence, as well as help the company grow and evolve. The selected candidate must enjoy coordinating with interdisciplinary teams, learn quickly, and be comfortable working independently!

Responsibilities
Respond to ad hoc requests from various stakeholders; seek to understand the requirements and determine the data needed to find the right solutions
Work with members of the business intelligence & analysis team to contribute to relevant aspects of Vendasta’s analysis workflow, such as:
Building ETLs: Building analytics pipelines
Exploratory Data Analysis: Gather, clean, and explore large data sets
Model Building: Create a visual and/or mathematical representation of the real world
Build, maintain & monitor internal dashboards to track key metrics in relation to areas such as productivity, revenue, expenses, efficiency, and more
Participate in process improvement initiatives and assist in automating processes currently requiring manual efforts
Provide prompt reports on monthly, quarterly, and yearly information
Develop and foster a working relationship with other analysts, software developers, product managers, sales, marketing, and executive
Become the expert in multiple data sources and create/implement innovative and sustainable solutions

Skills & Qualifications
4+ years experience in gathering, cleaning, and conducting data analysis
Demonstrated expertise with databases and various querying techniques (SQL, NoSQL, API)
Demonstrated ability to retrieve and clean data by whatever means is necessary
Proven ability to analyze and report information
Well developed communication and presentation skills
Ability to engage in multiple initiatives simultaneously while working in a dynamic environment subject to impromptu changes in schedules and priorities
Strong initiative – establish goals and take responsibility for meeting them within defined timelines",4.3,Vendasta Technologies,Saskatoon,"Saskatoon, Canada",201 to 500 employees,2008,Company - Private,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (CAD),-1,49.0,12,data analyst,senior,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2530,0
301,"Company Description

About Huawei
Huawei is a leading global provider of information and communications technology (ICT) infrastructure and smart devices. With integrated solutions across four key domains – telecom networks, IT, smart devices, and cloud services – we are committed to bringing digital to every person, home and organization for a fully connected, intelligent world.

At Huawei, innovation focuses on customer needs. We invest heavily in basic research, concentrating on technological breakthroughs that drive the world forward. We have more than 180,000 employees, and we operate in more than 170 countries and regions. Founded in 1987, Huawei is a private company fully owned by its employees.

About Huawei Canada
Huawei Canada helps connect Canadians to world-leading high-speed wireless Internet – and supplies them with cutting-edge smart devices. In partnership with Canadian telecommunications providers, we work to bring the benefits of a reliable and secure digital experience to every person, home and organization, including those in rural and remote areas of the country. Huawei first came to Canada in 2008. Today, the company employs more than 1,100 Canadians in research and development, IT, sales and other fields. Huawei Canada is an active supporter of many charitable and community initiatives from coast to coast.

Job Description

Our Team

The Wireline Application and Testing team is looking for a dynamic and energetic software programmer to join our team to develop software applications for ultra-high speed wireline semiconductor devices. This is an opportunity to be part of a fast moving, enthusiastic, and motivated team made up of world class mixed signal, system, and application engineers.

Position Overview

The individual will be responsible to lead the develop of software programs with GUI and/or command line capability for our device testing environment, including post data analysis toolsets, database development, and automation scripts for validation and characterization testing. General requirements will be provided, however, the opportunity to impart programming creativity and GUI experience is highly encouraged.

Responsibilities
Develop database solution to store test results and develop post data analysis toolsets / widgets to data mine, plot, and/or tabularize these results
Integrate test code using MatLab / Python into an automated test environment and collaborate with teams to drive test plans / strategy
Provide support and cooperate with application, design, and architecture teams on software definition, features, and specifications
Create and maintain documentation, such as user guides, application notes etc.
Review, track, and document results and observations
Qualifications
5+ years of hands on experience developing database solutions
5+ years of experience in statistical data analysis & development of statistical analytical toolsets
Hands on experience in GUI design
3+ years of experience in python
Hands on experience with matlab & C# / .NET programming using Visual Studio would be highly desirable
Lab experience using equipment such as power supplies, oscilloscopes, and BERTs is desirable but not required
Semiconductor knowledge, particularly SerDes device, is an asset, but not required
Knowledge and implementation of database software as well as on-line test / debug data acquisition is a valuable asset
Proven team player with strong communication skills and ability to work under time pressure
Key Words

Software programmer, SerDes, analog, IC, analog IC, IC design, statistical analysis, Application engineer, validation test engineer, CMOS, FinFET, high speed",3.6,"Huawei Technologies Canada Co., Ltd.",Ottawa,"Shenzhen, China",10000+ employees,1987,Company - Private,Telecommunications Services,Telecommunications,$10+ billion (CAD),"Ericsson-Worldwide, Cisco Systems, Apple",81.5,33,data engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,3665,3
302,"Data Analyst (Data Engineer)


Eagle is currently seeking a Data Analyst (Data Engineer) for a four (4) month contract opportunity, scheduled to begin immediately.

Key Responsibilities

The successful candidate will be responsible for:
Identifying patterns and trends in data sets;
Working alongside teams within the business or the management team to establish business needs; and,
Defining new data collection and analysis processes.
Skills and Qualifications

The qualified candidate must have:
Experience in data models, collecting, and interpreting data;
The ability to analyze large datasets;
The ability to write comprehensive reports;
Excellent problem solving and analysis skills;
Spark / Python development experience;
Experience with Azure (Data Lake Gen2, Data Factory, Event Hub, Azure Data Warehouse);
Experience with Databricks; and,
ETL / Data experience.
Don’t miss out on this opportunity, apply online today!

Eagle is an equal opportunity employer and will provide accommodations during the recruitment process upon request. We thank all applicants for their interest; however, only candidates under consideration will be contacted. Please note that your application does not signify the beginning of employment with Eagle and that employment with Eagle will only commence when placed on an assignment as a temporary employee of Eagle.

JOB#67256",4.0,Eagle Professional Resources,Calgary,"Ottawa, Canada",51 to 200 employees,1996,Company - Private,Staffing & Outsourcing,Business Services,$100 to $500 million (CAD),"S.i. Systems, Procom, Veritaaq",81.5,24,data analyst,na,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,1367,3
303,"Vous êtes unique, comme le sont votre parcours, votre expérience et votre façon de voir les choses. Ici, on vous encourage et on vous motive donner le meilleur de vous-même, et on vous donne les moyens de le faire. Vous travaillerez avec des collègues dynamiques experts dans leur domaine qui sont impatients de partager leurs connaissances avec vous. Vous aurez des gestionnaires inspirants qui vous aideront développer votre potentiel et atteindre de nouveaux sommets. Chaque jour, vous aurez de nouvelles occasions de rendre la vie de nos Clients plus radieuse ils sont au cœur de tout ce que nous faisons. Découvrez comment vous pouvez faire une différence dans la vie des gens, des familles, des collectivités ici et partout dans le monde.

Description de poste:

Role Summary

Be part of an exciting and challenging opportunity by helping to accelerate the growth and application of data analytics capabilities at Sun Life Canada. As part of the Distribution Analytics team within Sun Life Canada's Individual Insurance & Wealth line of business, you will have an opportunity to be at the forefront of applying data and analytics to tackle business problems and helping Sun Life use analytics to deliver on our purpose of helping our Clients achieve lifetime financial security and live healthier lives. As a Distribution Data Analyst, your focus will be working with a team of analytics professionals and other partners to source, manipulate, and transform data, develop enhanced reporting, produce innovative and effective analyses of data, contribute to an ethical and robustly managed best-practice team environment, and, most importantly, drive impact that matters to shareholders, employees, advisors, and clients.

Given the mandate of the role, the Distribution Data Analyst must possesses a breadth of analytical and data skills. The Candidate must have ability in the following areas:
Data sourcing, manipulation, and transformation
Insightful analysis of data
Reporting and business intelligence
Effective communication
Collaboration and self-management
Working in a compliant and well-governed environment
This is a 6 months contract position with possibilities of extension.

What will you do?

Data Sourcing, Manipulation, and Transformation
Source large quantities of data and help create value for a variety of business functions
Perform various investigative and analytical functions
Documentation of new and existing foundational data sources to ensure EUC compliance
Development of robust, business friendly self-serve data sources to help enable partners within distribution to be more self-sufficient and capable in using data to inform initiatives and projects
Insightful Analysis of Data
Conduct ad hoc audits of advisor blocks of business analysis using a variety of descriptive and predictive statistical methods
Conduct analyses that identify / assess business opportunities and address key business challenges
Identify, verify, evaluate, and validate hidden patterns in client and advisor data
Effectively translate business problems into analysis problems
Reporting & Business Intelligence (20%)
Prepare / compile ongoing trend reporting as required, daily, weekly, and monthly
Implement and report on performance metrics to support initiative measurement, analysis, and reporting, and measure effectiveness of predictive modelling efforts
What will you need to succeed?

Coding & Technical Skills
Proven experience in SQL as well as advanced Excel functions to mine large quantities of data
Keen aptitude for learning new programs and programming languages quickly
Ability to design and complete meaningful business analyses
Problem Solving
Proven balance of analytical and creative problem solving skills
Able to think with agility in meeting business partners' demanding deadlines
Ability to move with minimum effort from detailed diagnostic thinking to higher level, opportunity-oriented thinking and to integrate the best from both into contributions and deliverables
Communication
Must be able to effectively communication complex results to a business audience not familiar with complex data and analytics
Effective writing and verbal communication skills
Ability to distill complex technical information into the key points that matter to the audience
Collaboration
Proven ability to work well independently and also function in a team environment, with frequent contract with individuals and teams at all levels of the Sun Life Canada organization
Demonstrate an owner's mindset when approaching work, including prioritizing efforts, owning the work plan, and keeping key stakeholders informed
Education & Experience
A suitable academic background, such as mathematics, statistics, economics, engineering, or computer science etc.
What will be nice to have?

Industry Experience & Knowledge
Past experience in life insurance / wealth management, other financial services industry components (e.g., retail banking, credit card, properly and casualty insurance), or distribution
Working knowledge of one or more SLF Canada business units
Past experience in data and analytics
Software Experience
Good working knowledge of data presentation software such as Tableau, SAS Visual Analytics, etc.
Experience with statistical software such as R and/or python
Working knowledge of PowerPoint, Memos, and other forms of data and insights communication
Strong Microsoft Office skills
What's in it for you?
A friendly, collaborative and inclusive culture
Being part of our Analytics community, where we share best practices and broaden skill-sets
A dress for the day dress code, where you dictate how you dress based on your day
Léchelle du salaire de base est pour lemplacement principal du poste affiché. Elle peut varier selon lemplacement du candidat sélectionné et dautres facteurs. En plus du salaire de base, les employés admissibles de la Financière Sun Life participent différents programmes de rémunération incitative, dont le montant octroyé est discrétionnaire et dépend du rendement de lemployé et de la compagnie. Certains postes de vente participent des programmes de rémunération incitative basés sur les résultats de vente individuels ou de groupe.

Depuis toujours, la diversité et l'intégration sont au cœur des valeurs de la Financière Sun Life. Nous croyons qu'un effectif diversifié ayant des points de vue variés et des idées créatives est avantageux pour nos clients, pour les collectivités où nous exerçons nos activités, ainsi que pour nous tous, en tant que collègues. Nous accueillons avec enthousiasme les candidatures de personnes compétentes provenant de tous les horizons.

Les personnes handicapées ayant besoin de mesures d'adaptation pour présenter leur candidature et celles qui doivent consulter les offres d'emploi sur un support de substitution peuvent envoyer leur demande par courriel l'adresse thebrightside@sunlife.com.

Nous remercions tous les candidats de l'intérêt manifesté pour ce poste. Nous ne communiquerons qu'avec les personnes qui auront été retenues pour passer une entrevue.

Échelle salariale:

49,400/49 400 - 80,800/80 800

Catégorie d'emploi:

Advanced Analytics

Fin de l'affichage:

31/07/2020",3.7,Sun Life Financial,Waterloo,"Makati, Philippines",201 to 500 employees,-1,Company - Private,Insurance Operators,Insurance,$2 to $5 billion (CAD),-1,81.5,-1,data analyst,na,1,1,0,1,0,1,0,0,0,0,0,0,0,0,1,7188,0
304,"MC04 Senior Data Analyst
Full Time Posting Date: 04/14/2020 Closing Date: 05/14/2020 • Strong understanding with data infrastructure, data warehouse, or data engineering
• Coordinate with business planners and decision makers to translate business questions into verifiable data models requirements and hypothesis
• Strong knowledge of and experience with reporting and analytics packages, databases.
• Knowledge of statistics and experience using statistical packages for analyzing datasets (Excel, Tableau, R, etc.)
• Experience in visualization (Tableau), machine learning, analytic data models, data mining.
• Experience in one or more scripting languages, such as Python
• Experience working with complex analytical tools, such as R
• Experience in statistical techniques such as Regression, Clustering & Time Series Forecasting, etc.
• Ability to create visual models that support analyses, such as workflow diagrams or wireframe prototypes (Visio, Tableau)
• Technology background including programming skills in SQL, Python, R, as well as data storage such as RDBMS (Oracle), big data skills (Hadoop)
• Creative and innovative with strong analytical and problem solving skills including the ability to frame complex problems and develop recommended solutions
• Strong technology insights with demonstrated ability to work across business lines Toronto, ON Canada Apply",3.8,Maxima Consulting,Toronto,"Wakefield, MA",51 to 200 employees,-1,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (CAD),-1,81.5,-1,data analyst,senior,0,1,0,1,0,1,0,0,0,0,0,0,1,0,1,1376,0
305,"Senior Data Analyst
Research Officer R24

This position may be performed from either Victoria or Vancouver.

An eligibility list may be established.

Your skills, confidence and initiative will be valued in this challenging role

The Employment and Labour Market Services division delivers employment services to unemployed individuals who are eligible to work in British Columbia through contracts with service delivery organizations. The Divisional Services Branch is responsible for the overall program and service quality through strategic planning, policy, financial, governance, and quality assurance. The Branch supports ongoing program improvement through analysis, performance measurement, program evaluation, economic modelling and forecasting to create effective evidence-based decisions.

The Senior Data Analyst resides in the Analytics business unit and reports to the manager of Analytics. The position is responsible for providing technical and analytical support, advice and training to both internal and external clients on the application of data science techniques, including design, development, and management of complex data science projects, preparation of datasets for analysis, validating, reconfiguring, documenting and archiving standard inventory and analysis data, conducting detailed statistical analysis and data visualizations, and developing systems and documentation for distribution of data. This role is a critical lever to elevate the division’s capability, and capacity, to proactively analyze, predict and adjust program variables to the shifting economic landscape within BC and more effectively support WorkBC clients.

The Senior Data Analyst is the leading expert in statistical methods, predictive analytics and data science. Outputs from this position are used for informing development of science-based policy, standards and guidelines, strategic planning and decision-making.

To learn more about these B.C communities you can click on the Hello BC link here!

The BC Public Service is an award winning employer and offers employees competitive benefits, amazing learning opportunities and a chance to engage in rewarding work with exciting career development opportunities. For more information, please see What We Offer.

The BC Public Service is committed to creating a diverse workplace to represent the population we serve and to better meet the needs of our citizens. Consider joining our team and being part of an innovative, inclusive and rewarding workplace.

For complete details about this opportunity, including accountabilities, please refer to the attached job profile. For specific position related enquiries, please contact Ada.Litvinov@gov.bc.ca DO NOT SEND YOUR APPLICATION TO THIS EMAIL ADDRESS. For more information about how to complete your job application, add/edit your resume and for more useful tips when applying for jobs, please refer to the Your Job Application page on the MyHR website. If you are still experiencing technical difficulty applying for a competition, please send an e-mail to BCPSA.Hiring.Centre@gov.bc.ca before the stated closing time, and we will respond as soon as possible to assist you.

NOTE: Applications will be accepted until 11:00 pm Pacific Standard Time on the closing date of the competition.

Job Requirements:
In order to be considered for this position, your application must clearly demonstrate how you meet the education and experience as outlined below:
Degree in a related field and a minimum 2 years related experience; OR
Diploma in a related field and a minimum 3 years related experience; OR
Certificate from a recognized institution in a related field and a minimum 4 years related experience; OR
Any other education in an unrelated field and a minimum 5 years related experience.
Related Education fields may include: Data Science, Computer Science, GIS, statistics, mathematics, or other relevant specialty education as designated by program requirements.

Related experience must include:
Experience at leveraging structured and unstructured data sources to conduct quantitative analysis.
Experience determining appropriate use of various problem structuring methods and statistical methods for sampling, distribution assessment, bias and error.
Experience creating and delivering executive-level presentations for the purpose of decision making.
Willingness Statements:
Willing to keep up to date with cutting-edge techniques in machine-learning and big data analytics and find ways to advance the organization’s capabilities in analytics.
Willingness and ability to learn new technologies on the job.
Applicants selected to move forward in the hiring process may be assessed on the Knowledge, Skills, Abilities and Competencies as outlined in the attached Job Profile located in the Additional Information section at the bottom of the posting.

A Criminal Record Check (CRC) will be required.

APPLICATION REQUIREMENTS:

Cover letter: NO - Please do not submit a cover letter as it will not be reviewed.

Resume: YES - A resume is required as part of your application; however, it may not be used for initial shortlisting purposes.

Questionnaire (COMPREHENSIVE): YES - As part of the application process, you will be prompted to complete a comprehensive online questionnaire to demonstrate how you meet the job requirements. Please allot approximately 60 minutes to complete the questionnaire.

IMPORTANT: Comprehensive questionnaire responses will be used to shortlist applicants against the job requirements. Please ensure you include all relevant information about your educational accomplishments and employment history including job titles, start and end dates (month and year) of your employment, and your accountabilities and accomplishments.",3.8,Government of British Columbia,Victoria,"Victoria, Canada",10000+ employees,1858,Government,Government Agencies,Government,$10+ billion (CAD),-1,81.5,162,data analyst,senior,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,5774,0
306,"We are looking for a Senior Data Scientist who is enthusiastically driven to generate actionable insights and create new growth opportunities. You must have proven leadership skills to grow and foster a highly effective team capable of rapid learning and application. You will lead a team conducting research experiments, advanced statistical modelling and develop data-driven products across several domains including infrastructure optimization, logistics efficiency, and data visualization. This is a unique opportunity to apply your leadership skills in a growing company and lead our next generation products.

REQUIREMENTS
M.Sc. or Ph.D. in a quantitative field (e.g., Computer Science, Statistics, Financial Economics, Applied Mathematics, Computer Engineering, or other related discipline).
Significant experience solving problems with the required the use of advanced statistical modelling techniques.
Proven programming skills including experience conducting modelling and statistical analysis (e.g., R, Matlab), object-oriented software development (e.g., Python, Scala), and massive parallel processing (e.g., Spark, Apache Hadoop).
Excellent communication skills and ability to describe and present complex technical concepts in clear language.
Ability to lead teams and create an environment of continuous learning and open communication.
Ability to structure and lead a project from idea to experimentation to prototype to delivery.
WHAT WE EXPECT?
Self-starter that is focused and driven with amazing follow-through.
Enthusiastically tackling problems with a love for teaching and celebrating the successes of others.
Ability to synthesize information, evoke good conversation and consider problems from new perspectives.
Desire to share information with others and contribute to our top-notch learning environment.
Driven to delivery quality solutions.",-1.0,Temet,Ottawa,-1,-1,-1,-1,-1,-1,-1,-1,81.5,-1,data scientist,senior,0,1,0,0,0,0,1,0,0,0,0,0,0,0,1,1869,0
307,"GAL AeroStaff., which provides specialized staffing and recruiting services is presently seeking a GCP Data engineer with Dataproc + Big Table for a contract based anywhere in Canada (Remote work)Responsibilities:

Working with GCP team for various GCP Cloud programs including Certifications, Partner engineering, Marketplace and other Cloud platform solutions.
Educating GCP / ISVs customers on best practices
Stakeholders management / Communication: Google, ISVs, Project Teams
Program Management and Execution
Managing the teams on different projects
Reporting and Project Communications
Advocating the customer's perspective during product and architecture planning.
Create and maintain a library of reusable container images
Awareness of Business P&L and Goals aligned to technology and revenue

Certifications:

GCP Cloud Certification is Must
Google Cloud Certified Professional Data Engineer
Google Cloud Certified Professional Cloud Architect

Technical Skills:

Experience with private, hybrid or public cloud technology
Possess Strong Cloud Implementation Experience in Cloud architecture/design, compute/storage services.
Understand multi-Cloud/multi-zone based designs.
Compute: Docker Apps, Lambda/ serverless, UserData customization
Preferred: Cluster/HA-based parallel design/multi-region approach
Cloud automation: Ansible, YAML, CloudFormation
Containers: Docker; Preferred: Container orchestration - Mesosphere, Kubernetes, ECS
Familiarity with functional operations of server, storage, and network functions.
Experience migrating Windows or Linux
Virtualization experience (VMware, Xen, HyperV)
Databases understanding: Oracle, DB2,MySql; Preferred: NoSql DB, MongoDB, Cassandra, DynamoDB
Program Management experience from Planning to execution
Having experience of Managing teams of moderate size
Strong communications skill and multiple stakeholder(TM)s management
Experience in implementing cloud solutions",4.0,GAL Aerostaff,Remote,"Vaudreuil-Dorion, Canada",1 to 50 employees,2011,Company - Private,Aerospace & Defence,Aerospace & Defence,Unknown / Non-Applicable,-1,81.5,9,data engineer,na,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1931,0
308,"Data Engineer or Scientist - Product Owner-MON16974

Description

BOMBARDIER

At Bombardier, our employees work together to evolve mobility worldwide - one good idea at a time. If you have a good idea, we’ll provide the environment where it will thrive and grow into a great product or customer experience. Your ideas are our fuel.

In your role, you will:
Integrate internal A.I. solutions within evolving Business Unit needs;
Nurture strong working networks with internal and external stakeholders to identify business opportunities for enhanced A.I. value creation;
Challenge status-quo for business ecosystem and collaboratively innovate solutions to enable A.I. across teams;
Support A.I. teams across multiple business areas by managing the pipeline of A.I. initiatives;
Govern day-to-day operations aligning with business owners across all functions and senior management; and
Articulate business opportunities created by A.I. solutions to non-practitioners.
Qualifications

As our ideal candidate,
At least 3 years of work experience designing and implementing AI/data science algorithms/systems and managing the associated data by leveraging, connecting and operationalizing large scale enterprise data solutions and applications using best-known data management and analytics platforms (e.g. Azure / AWS / GCP).
Experience working in an Agile development environment implementing AI/data science algorithms leveraging state-of-the-art programming languages and libraries (e.g. Python, R, Tensorflow, pytorch, mxnet, pandas) and understanding of development and service delivery/management frameworks (e.g. DevOps).
Masters and/or PhD credentials in data science related fields and business administration background is desired.
Experience deploying A.I. solutions within business functions to improve business competitiveness.
Proven results while navigating through global organizational environments.
Organizational savviness and good communications skills.
Bombardier is an equal opportunity employer and encourages women, Aboriginal people, persons with disabilities and members of visible minorities to apply.

Whether your candidacy is moving on to the next step of the hiring process or not, we will keep you informed by email or by phone. Join us at careers.bombardier.com

Your ideas move people.

#LI-RK1

Job: System Integration
Primary Location: CA-QC-Montreal Dorval
Organization: Aerospace
Schedule: Full-time
Employee Status: Regular

Job Posting: 05.02.2020, 10:02:22 AM

Unposting Date: Ongoing",3.3,Bombardier,Montreal,"Montreal, Canada",10000+ employees,1942,Company - Private,Transportation Equipment Manufacturing,Manufacturing,$10+ billion (CAD),-1,81.5,78,data engineer,na,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,2521,0
309,"Tu es mordu des données massives?
Tu as une très bonne connaissance des bases de données Oracle / Unix?
La sécurité des données de nos clients fait partie de tes gènes?

Léquipe Expérience Client et données recherche deux Data Analystes / développeurs pour joindre son équipe. Nous recherchons des candidats laise travailler avec des équipes multidisciplinaires, qui démontrent un bon esprit danalyse et de synthèse et qui excellent concevoir des solutions technologiques de qualité.

Ton rôle :
À titre dexpert en données, participer des projets majeurs en accompagnant et en développant des solutions visant répondre aux besoins de multiples lignes daffaires
Comprendre les règles daffaires régissant les données clients et transactionnelles
Assurer le bon fonctionnement et la maintenance des bases de données stratégiques de lorganisation
Mettre en place les requis de sécurité selon les recommandations de la banque
Définir et prendre en charge les activités visant la mise niveau des plateformes technologiques
Collaborer la résolution dincidents et procéder aux corrections reliées aux problèmes de production
Travailler en fonction des priorités de livraison convenues en équipe, centré sur la valeur daffaires, lexcellence opérationnelle et les risques
Accompagner la livraison et lamélioration continue en occupant un ou plusieurs rôles selon contexte et priorités.
Diplôme d'études collégiales, connexe au secteur d'activité, et quatre années d'expérience pertinentes
Expérience démontrée comme Data analyste / développeur dans une organisation complexe
Expérience en processus opérationnels (Incidents, Changements, Problèmes, SLA, Gestion daccès, etc)
Connaissance avancée en utilisation des systèmes Unix
Connaissance avancée en base de données Oracle
Connaissance en utilisation du langage SQL pour linterrogation de bases de données relationnelles
Capacité influencer et mobiliser positivement les parties prenantes
Autonomie, initiative et grande capacité dapprentissage
Esprit de synthèse et danalyse
Aptitude au travail déquipe et la résolution de problèmes
Capacité travailler sous pression
Démontrer nos valeurs de complicité, dagilité et de pouvoir dagir
Bilinguisme (parlé/écrit) français et anglais
Nous travaillons demeurer une entreprise inclusive qui valorise tous ses employés. La Banque Nationale se démarque par ses nombreuses initiatives en matière d'inclusion ce qui fait d'elle une des meilleures organisations en diversité au Canada.",4.1,Banque Nationale du Canada,Montreal,"Montreal, Canada",10000+ employees,1859,Company - Public,Banks & Building Societies,Finance,$10+ billion (CAD),-1,81.5,161,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,2467,0
310,"Think insurance is boring? We did too. So we built a company that takes everything you think you know about buying insurance and turns it on its head.
At Cover, want to become the largest and most customer centric insurance company in the world.
Founded in 2016, Cover is a mobile-first insurance platform licensed in all 50 states, working with over 35 carriers. We were part of Y Combinator’s W16 batch, and have gone on to raise $27 million across three funding rounds backed by world class investors.
We’re growing fast. In the past year we’ve scaled the team across our San Francisco and Toronto offices. Across our diverse and multi-skilled team we’re working together to deliver a service that’s effortless to interact with, transparently priced, and built on a sustainable and long term footing.
We’re pushing hard to make our vision of insurance a reality and we want dedicated, inquisitive and collaborative people who are ready to play their part in achieving our goal.

We are looking for an experienced Senior Data Analyst to join the Cover Analytics team. This role will involve working with complex datasets to translate business needs into analytics and visualizations that provide actionable insights. You’ll partner with Product, Marketing, Sales and Engineering teams to help them make data-informed decisions.
Key Responsibility
Work with complex data sets to answer complicated questions and uncover new business insights.
Autonomously prioritize and execute Analytics projects and tasks in a fast-paced environment.
Identify the trade-offs between speed and quality of different approaches.
Build dashboards and reporting to measure progress in key initiatives.
Partner with executives, product managers, engineers and marketers to provide data-driven recommendations, support with ad-hoc analysis, and ensure stakeholders are asking the right questions.
Manage and develop our data analytics pipeline.
Contribute to improving data culture. Develop and improve data processes and best practices.
Requirements
3+ years of professional working experience in Analytics
Strong proficiency with SQL-based languages
An ability to write and troubleshoot complex SQL queries.Experience with data visualization tools (Tableau, Periscope, Looker, etc.)
Experience in analytical programming such as Python and R
Strong analytical problem-solving skills, able to transform data into business insights and actionable recommendations
Strong understanding of analytics and how to measure the non-obvious within the domains of user acquisition, product improvements/optimizations, and sales operations
Strong business acumen, including communication and interpersonal skills
Ability to thrive in fast-paced work environments and manage and prioritize multiple projects.
Nice to Have
Experience working on ETLs/data pipelinesExperience in A/B testing, designing and measuring experiments
Experience developing machine learning / predictive models to solve complex business problems
Experience in Technology and/or Insurance



We Believe in Equal Opportunity
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",2.6,Cover,Toronto,"San Francisco, CA",51 to 200 employees,2016,Self-employed,Insurance Agencies & Brokerages,Insurance,Unknown / Non-Applicable,-1,81.5,4,data analyst,senior,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,3303,0
311,"Machine Learning Engineer

Job Description:

Interset Software uses big data and advanced behavioral analytics to detect and prevent the theft of intellectual property...simply put, WE CATCH BAD GUYS WITH MATH!!!

Part of the Micro Focus group of companies, we are a fast-paced, all-hands-on-deck kind of environment where you are respected and listened to from day one. We have a start-up feel within the stability and structure of a large global company.

We are currently looking to fill a development position focused on extending the existing analytics platform and related capabilities to add unprecedented analytics flexibility for our customers. This will include enabling Data Scientists to manipulate and combine events and models to extend and customize the analytics in ways that provide unique value for each customer.

We’re looking for a software developer who’s passionate about what they do, takes a creative approach to problem solving and will be the champion for creating innovative machine learning hooks that deliver real value and perform in big data environments.

If you’re passionate about true machine learning and want to be part of a company building solutions that leverage the latest in big data technology, we want to talk to you!!

What you'll do:
Implement model data flows to support running cutting-edge machine learning techniques on massive amounts of data
Work with product managers and data scientists to turn new features and algorithms into beautiful, battle-tested code
Work with the technologies we use to analyze and identify cyber-security threats for our customers (Elasticsearch, Spark, HBase, Kafka, Vertica, NiFi, using Java and Scala)
Work side by side with some of the smartest minds in the fields of machine learning and behavioural analytics
Create efficient and robust cloud-based solutions, leveraging the best in cloud technologies.
Who you are:
Undergraduate or Masters’ degree in Computer Science or equivalent engineering experience
Strong interest in software design, distributed computing, and databases
Experience developing in a JVM environment (Java, Scala, Clojure)
At least two years of experience developing with or using Big Data & Analytics stacks/tools such as Hadoop, HBase, Spark, Presto and Vertica.
Experience implementing and using streaming platforms such as SparkSQL, Flink, Kafka, Storm, etc.
Experience with Kubernetes, Docker, Ansible or any other infrastructure or containerization management/automation platform.
Familiarity leveraging AWS EMR, Azure, GCP cloud technologies best practices to enable the distribution and analysis of big data on the cloud would be considered an asset.
Nice to haves:
Familiarity with data science or machine learning packages (pandas, R, TensorFlow, etc...)
Familiarity with virtualization technologies (VMWare ESX, Docker)
Contributions to open source software (code, docs or mailing list posts)
Interest in understanding and analyzing diverse types of data
Job:

Engineering

Micro Focus is proud to be an Equal Opportunity Employer. Prospective employees will receive consideration without discrimination because of race, colour, religion, creed, gender, national origin, age, disability, marital or veteran status, sexual orientation, genetic information, citizenship or any other legally protected status",3.3,Micro Focus,Ottawa,"Newbury, United Kingdom",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$2 to $5 billion (CAD),"SAP, Oracle",81.5,44,machine learning engineer,na,0,0,0,0,0,1,1,1,1,0,0,0,1,0,0,3325,2
312,"Job Type: Permanent
Primary Location: Montreal, Quebec, Canada
All Available Locations: Montreal

Be encouraged to deepen your technical skills…whatever those may be.

Be expected to share your ideas and to make them a reality.

Be part of a firm where you are valued for your unique strengths and where everyone feels a sense of belonging.
Do you dream about data? Do you speak SQL as well as your mother language? Are you motivated by solving complex problems by leveraging best-in-class data pipelines? We want to hear from you!
What will your typical day look like?
Everyday you will work with our clients to solve their toughest problems in data engineering, data acquisition, and data standardization. You will do so by leveraging leading technology to accomplish large-scale implementations. You will facilitate design sessions with business stakeholders to define key data definitions, consolidate findings, and work with technology teams to develop appropriate data models. Everyday, you will design and implement optimal data pipeline architecture that is auditable, redundant, scalable and high-performing. Since we know you are a great self-starter, you willm also build the cloud infrastructure and pipeline required for optimal extraction, transformation, and loading of data from a wide variety of data sources (structured and un-structured, streaming and batch).
About the team
Omnia AI, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

Our Canadian Delivery Centre (CDC) team within our Omnia AI group is based out of Montreal and helps multiple clients replace, upgrade or maintain their information systems. We deliver a breadth of solutions to solve our clients most challenging business problems. Our teams deliver “Big Data”, Robotic Processing Automation, Digital Content, Data Integration, and Analytical Solutions. Each one of these solutions leverages a different mix of new technologies to achieve a business outcome.

We have:
Leading methods and tools
Top professionals to coach and develop you
An open mind for new ideas
Opportunities to work with leading Canadian and global companies
Partnerships with top software providers
A dynamic and energetic workplace
Enough about us, let’s talk about you
With hands-on Microsoft Azure data ingestion experience, with at least 2 projects (minimum of 3 month each)
Who has leveraged at least 3 out of these 2 components: Azure Data Factory, Azure Event Hub, Databricks
With 1+ years of hands-on experience with data ingestion on Azure
With 3+ years of relevant technology consulting or industry experience in data & analytics delivery
With 2+ years of experience designing and developing data pipelines, data cleansing routines utilizing typical data quality functions involving standardization, transformation, rationalization, linking and matching
With Azure Data Engineer Certification

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:
You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.
The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.",3.9,Deloitte,Montreal,"New York, NY",10000+ employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (CAD),"Amazon, PwC, McKinsey & Company",81.5,170,data engineer,na,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,4566,3
313,"At Intact, insurance is not about things. Its about people. Its what we believe, and it shapes everything we do. Its why we strive to provide a second-to-none experience for our customers and create an inspiring workplace for our employees to thrive in.

As Canadas largest provider of property and casualty insurance, were not only leading our industry, but were redefining what it means to work for it. As a recognized top employer, were committed to living our values and supporting our dedicated people who bring their best to work each day because they know their work matters.
Your Job
Hiring Manager: Ionut Calacean

Workplace:Montreal (2020, Blvd. Robert-Bourassa) or Toronto (700 University)

Data is the most important asset in todays competitive world. We are the Data and Analytics department of the largest P&C insurer in Canada. Our mission is: Accelerate our data advantage by bringing to user analytical data ready to be consumed, at a proper level of trust and security.

Our team is using modern concepts, tools and technologies for data ingestion, acquisition and data consumption and work with Agile framework. We are structured into small, highly productive squads and working very close with the Data Lab team composed of Actuaries and Data Scientists.

You dream of exciting challenges at one of Canadas top 100 places to work? Join our team as Senior Data Engineer and contribute to the planning and execution of data pipelines for various machine learning projects.

You will:
Design, implement, and maintain large-scale batch and real-time scalable data pipelines with complex data transformations;
Perform data wrangling to transform and map data from raw data forms into formats more appropriate and valuable for analytics;
Write and optimize complex queries on large data sets;
Assemble large, complex data sets that meet functional / non-functional business requirements;
Work with stakeholders to assist with data-related technical issues and support their data infrastructure needs;
Experience working with business teams to translate functional requirements into technical requirements;
Conduct business and functional requirements gathering and provide projects estimates;
Experience supporting and working with cross-functional teams in a dynamic environment;
Develops workflows and tools that automate data loading processes and help ensure data quality and integrity.
Your Skills
You are:
Motivated and autonomous, you love learning and applying new technologies to solve complex problems;
Eager to understand how the business works and how your work impacts the business;
Comfortable working in complex environments and multidisciplinary teams;
Fast learner, versatile and a good team player;
Excellent communicator with good analytical skills.
You have:
A bachelors degree in computer science, Software Engineering or equivalent;
Hands-on experience with leading commercial Cloud platforms, including AWS and Azure;
Excellent SQL, Python and PySpark skills;
Strong experience with Apache Spark(Databricks or similar), Kafka and NiFi;
Hands on experience with Hadoop distributions (Cloudera, Hortonworks) and Hive;
Strong experience with relational SQL and NoSQL databases like PostgreSQL, Oracle, Cassandra, Mongo DB;
Hands on experience with Snowflake or Redshift, or similar cloud storage technologies;
Experience with ElasticSearch and Kibana is a big plus;
Experience with Alation and/or other data catalog tools (Azure, Informatica) is a big plus;
Experience with Kubernetes, Docker is a big plus;
Experience with Agile development methodologies;
Strong presentation, facilitation, verbal and written communication skills, including interpersonal skills.
Here are a few reasons why others have joined our team:
An award-winning, inspiring workplace that supports its people and recognizes great work
Stimulating, challenging projects and development opportunities to help you grow your skills and career
Flexibility in how and where you work
A comprehensive financial rewards program that recognizes your success
An extensive, flexible benefits package
An industry leading Employee Share Purchase Plan where we match 50% of net shares purchased
A casual dress for your day culture that encourages you to be yourself
A $350 annual wellness account that promotes an active lifestyle
Closing Statement
We are an Equal Opportunity Employer

At Intact, our values guide everything that we do. We celebrate our differences and appreciate our similarities. Thats why we are committed to building an inclusive and inspiring environment for all employees. If you need a specific accommodation during the recruitment process, please let us know and we will be happy to provide.

Background Checks

As an employer and publicly traded financial services company, the best interests of our customers, employees and shareholders are important to us. We want Intact to be a great place to work! This means that youll be asked to consent to background checks so we can learn more about you. Please note that for positions with access to financial data or funds, your credit must be in good standing.

Internal Candidates

For internal candidates, you can apply for a posted position if you have been in your current position for at least 12 months and are performing at a satisfactory level. Please note we may have identified other internal candidates through our Employee Development Program, and that the selection process may also be opened to external applicants.

Eligibility

Its important that you are legally eligible to work in Canada at the time an offer of employment is made. You may be requested to provide proof of eligibility at that time.
Referral Bonus
This role is eligible for employee referral bonus. #myReferrals3000
Glassdoor Sponsored
#GD-Quebec",4.1,Intact,Montreal,"Toronto, Canada",10000+ employees,-1,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),"Aviva Canada, RSA Group, Economical Insurance",81.5,-1,data engineer,senior,0,1,0,0,0,1,1,1,1,0,0,0,1,0,0,5797,3
314,"FreshBooks has an ambitious vision. We launched in 2003 but we're just getting started and there's a lot left to do. We're a high-performing team working towards a common goal: building an extraordinary online accounting application to help small businesses better handle their finances. Known for extraordinary product and customer service experiences and based in Toronto, Canada, FreshBooks serves paying customers in over 120 countries.

The Opportunity – Senior Analyst, Early Lifecycle

The senior analyst will enable FreshBooks to derive insight from campaign and customer interaction data to manage customers early lifecycle with us. You love to solve a problem and have a knack for translating data into insights and presenting that information to stakeholders. You will be collaborating with your manager and a team that includes other analysts, data scientists, marketers, financial analysts, and developers all working together to drive growth at FreshBooks.

What you'll do:
Organize and execute analyses relating to customer experience including but not limited to:
In trial and early lifecycle product usage, purchasing behavior, churn, etc.
Provide insights to drive key product usage and drive upsell/cross sell opportunities
Dashboards for core performance metrics
Consult directly with internal clients to gather requirements, scope & execute
Provide support for reporting and dashboarding to track core KPIs
Complete regular ad-hoc analyses by translating raw data into useable information and insights:
A/B testing for campaign treatments
Email Send, Open, CTR, CTA etc. review
Changes in usage behaviors (organically and due to marketing)
Profiling and trending of customer segments
Cohort based investigations tied to performance gains and losses
Plan selection and optimization
Designing, writing and implementing new reports, datasets and business intelligence tools to productionize ad-hoc analyses
Assist (with Business Operations) in the building, development and maintenance of data models, reporting systems and tools that support key business decisions
Ensure accuracy of data and deliverables of reporting
What you have:
Advanced knowledge of SQL & Python or similar
3-5 years in data analytics and/or business intelligence
Quantitative background with strong analytical skills
Experience using a dashboarding tool such as Periscope, Tableau, Looker, etc.
Experience using LOOKER is a huge plus
Experience in calculating and tracking LTV, CPA, ROI, churn, acquisition & related metrics
Knowledge of Google Analytics (or a similar web analytics tool)
Why Join Us

We're an ambitious bunch, with our eyes laser-focused on shipping extraordinary experiences to small business owners. You will be surrounded by hardworking team members who share a common vision for what an amazing software company could be, and have the opportunity to help build an elite one, right here in downtown Toronto.

Apply Now

Have we got your attention? Submit your application today and a member of our recruitment team will be in touch with you shortly!

FreshBooks is an equal opportunity employer that embraces the differences in all of our employees. We celebrate diversity and are committed to creating an inclusive environment for all FreshBookers. All applicants are evaluated based on their experience and qualifications in relation to this position.

FreshBooks provides employment accommodation during the recruitment process. Should you require any accommodation, please indicate this on your application and we will work with you to meet your accessibility needs. For any questions, suggestions or required documents regarding accessibility in a different format, please contact us at phone 416-780-2700 and/or accessibility@freshbooks.com.",4.2,FreshBooks,Toronto,"Toronto, Canada",201 to 500 employees,2003,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,81.5,17,data analyst,senior,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,3761,0
315,"TheIntermediate Data Engineer works in one of the agile BI teams.

The ideal candidate will be an experienced Data Engineer that demonstrates in-depth knowledge and understanding of data warehousing, data integration, reporting and business intelligence. Open-minded and flexible and prepared to work in a very dynamic environment, supporting multiple business units.

JOB RESPONSIBILITIES:

·Creating, supporting, and maintaining ongoing operational, managerial, and executive business intelligence infrastructure.

·Attention to detail, in particular as it relates to compliance and accuracy of data.

·Developing understanding of information sources and correct interpretation of data

·Gathering, documenting and analyzing requirements from stakeholders

·Meeting and interacting with all levels of management as needed to elicit, define, analyze and document requirements for new business intelligence initiatives.

·Designing the conceptual, logical and physical data models necessary to support new reporting and data analysis

·Developing data integration processes

QUALIFICATION:

·Minimum 3 years of related experience.

·Understanding of Data Warehouse lifecycle is a must.

·Good knowledge in cloud technologies (preferably GCP)

·Advanced knowledge in Python scripting language

·Good knowledge in Message Broker systems (Kafka, RabbitMQ, PubSub)

·Excellent proficiency in writing SQL queries.

·Advanced proficiency with Microsoft BI Suite - SQL Server 2014-2019, SSIS, SSRS.

·Understanding relational and dimensional data modeling concepts.

·Strong knowledge and comprehension of technology and data management used in the process of collecting, storing and retrieving data.

·Post-secondary education, preferably in Math/Statistics or Computer Science.

·Superior writing, editing, and communication skills, capacity to interact with all levels of the organization.

·Knowledge of latest Microsoft self-service BI tools – Power BI (both desktop and cloud) an asset.

·Experience with DAX an asset

·Experience and/or personal interest in the financial industry an asset.",4.3,Questrade,Toronto,"Toronto, Canada",501 to 1000 employees,1999,Company - Private,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1,81.5,21,data engineer,na,0,1,1,0,0,1,0,0,0,0,0,0,0,0,1,2090,0
316,"Data Engineer - Ottawa, Ontario
About Us

Backed by a 50-year legacy of engineering excellence, reliability and industry-leading customer service, Telesat has grown to be one of the largest and most successful global satellite operators. Telesat works collaboratively with its customers to deliver critical connectivity solutions that tackle the world’s most complex communications challenges, providing powerful advantages that improve their operations and drive growth.

In addition to our state-of-the-art global, geostationary satellite fleet, Telesat LEO, our Low Earth Orbit network scheduled to begin service in 2022, will revolutionize global broadband connectivity by delivering a combination of high capacity, security, resiliency and affordability with ultra-low latency and fiber-like speeds.

Telesat also provides industry-leading technical consultation and support services to satellite operators, insurers and other industry stakeholders around the globe.

Privately held and headquartered in Ottawa, Canada, with offices and facilities around the world, Telesat’s principal shareholders are Canada’s Public Sector Pension Investment Board and Loral Space & Communications Inc. (NASDAQ: LORL). For more information, visit www.telesat.com.

About the Role

The Data Engineer will be responsible for working with the LEO Prime to implementing the data warehouse, including an operational data analytics platform and Telesat’s LEO data warehouse. They will be primarily focused on the data extraction, ingestion and transformation of data from the various LEO segments and ensuring it is made available in the data warehouse for other teams and data analytics applications to use.

Main Responsibilities

The role has 2 primary responsibilities:

Operational platform & data warehouse: Working with the Data Analytics team, build out the operational data analytics platform and data warehouse on Telesats’ Cloud provider.

ELT: Extract, Load, Transform – working with Telesat’s LEO partner, build systems and processes to extract the data from the various segments, load it into the data warehouse(s), and transform it as required so that other systems, Data Scientists & Analysts and applications can use the data for operational, business and commercial purposes.

Education & Experience Required
2-5 years’ experience in implementation of data management, analysis and warehousing strategies that have positively impacted business objectives.
Bachelor's degree preferred - Computer Science with specialization in statistics, data analytics, or related discipline preferred.
Excellent communication (verbal, written, presentation) and interpersonal skills.
Communicates well with own team and across organizational boundaries to ensure the successful completion of shared goals.
You are advanced in the use of MS Excel to drive data driven reports to influence decisions. This would include creating/maintaining macros, pivot tables & charts.
Experience with various Data analytics tools (Scripting, R, Python, SQL, Power BI, Tableau, Databricks, and others)
Experience building data analytics systems based on cloud (GCP, AWS, Azure) technologies
In depth experience with storage management, including retention policy, security policy and backup management in a cloud environment
Agile development and Machine Learning experience considered a strong asset.
Decision Making & Supervision

Decision Making

In this role, the incumbent will have some influence on the architecture of the data storage, vendors involved, and infrastructure for the LEO program. They will need to make recommendations and decisions based on their experience.

Supervision Exercised

None

The successful candidate must be able to work in Canada and obtain clearance under the Canadian Controlled Goods program (CGP).",2.7,Telesat Holding,Ottawa,"GLOUCESTER, Canada",201 to 500 employees,-1,Subsidiary or Business Segment,"Cable, Internet & Telephone Providers",Telecommunications,$100 to $500 million (CAD),-1,81.5,-1,data engineer,na,0,1,1,1,1,1,0,0,1,0,0,0,1,0,1,3811,0
317,"Who We are

Founded in 2016, Skycope Technologies Inc. is a high tech company based in Burnaby, Canada. Applying the latest RF spectrum sensing technologies, we provide cutting-edge anti-drone solutions. Our technology can safely and effectively detect, identify, locate, and track rogue drones to prevent them from posing security threats in unauthorized areas.

Our team is a diverse collection of developers and scientists who enjoy attacking challenging problems. The team has varied levels of industry expertise in the fields of signal processing, machine learning, information theory, coding, and network security.

Job Description

The goal of the machine learning (ML) team at Skycope is to develop the foundations for applying ML techniques to the radio frequency (RF) wireless communication domain, and to develop practical applications for our products to address RF spectrum detection and analytics problems.

Traditionally, ML research has been focused on problems in the domains of image, audio, and language processing, as these are related to human abilities and intelligent behaviour. Progress in these areas has been significant in recent years. Although the RF environment presents familiar ground for ML researchers in some ways, there are important differences that make ML using RF data unique, and much more challenging than these traditional domains. We are looking for a Machine Learning Engineer who will do cutting-edge research in this field, and develop and scale solutions.

Responsibilities
Explore the application of ML, especially deep learning, in the RF communication domain. You will do research on solving open problems in the field.
Develop and scale our data-driven systems. You have interest and ability in both data science and engineering, since this is a hands-on role where you own the whole stack - from modelling to production.
You will be involved in a variety of projects: data collection, data analysis, algorithm design, and scaling up the system, working with engineers who specialize in machine learning, wireless, and software.
You will have substantial independence and responsibility from day one.
Required Qualifications
2+ years of industry experience in large-scale ML modelling and engineering, preferably in deep learning.
Expertise in software engineering at scale, along with proficiency in using industry-standard development tools such as Git, and being comfortable using Linux command-line tools.
Proficiency in Python development, and the usage of libraries such as NumPy, Pandas, and TensorFlow.
Proficiency in C (and familiarity with C++).
Understanding of basic signal processing concepts, such as signal statistics and the Fourier transform.
Ph.D. or M.S. in mathematics, physics, engineering, or another quantitative discipline.
Eligible to work in Canada
Preferred Qualifications
Exposure to database systems and familiarity with SQL.
Experience deploying ML models using libraries such as TensorRT.
We will consider candidates with qualifications that may differ from those above, depending on demonstrated capability in delivering successful ML applications.

What We Offer:
Competitive compensation
Comprehensive health, dental, and vision coverage
Opportunities for career advancement
A challenging adventure of working in an emerging industry with cutting-edge technologies
A fulfilling experience of teaming up with a group of top-talented people
Job Type: Permanent

Experience:
Machine Learning: 2 years (Required)
Python: 3 years (Preferred)
C/C++: 3 years (Preferred)",-1.0,Skycope Technologies ,Vancouver,-1,-1,-1,-1,-1,-1,-1,-1,90.0,-1,machine learning engineer,na,0,1,0,0,0,1,0,0,0,0,0,0,1,1,1,3549,0
318,"Role Purpose and Key Accountabilities:
The primary role of a Senior Security Data Scientist at Prevalent AI involves analyzing significantly large volumes of security telemetry data collected from various sources (application logs, network logs, database logs, cloud and perimeter security devices), implement complex Machine Learning algorithms and building advanced models, applying these concepts to real security data sets in single or clustered environments, drawing inferences from the collated data and preparing conclusions out of it, to analyse and assess security risk posture for enterprises.
This role also involves employing sophisticated analytics programs, data mining techniques, machine learning and statistical methods to prepare data for use in predictive and prescriptive modelling. Key accountabilities include:

▪ Developing a firm understanding of the essential business requirements through interaction with, and interrogation of, business SMEs and translating that understanding into models that address the requirements, using data science methods, including:

▪ Data assembly, cleansing, validation

▪ Data visualization

▪ Statistical modelling, supervised and unsupervised machine learning, mathematical programming

▪ Inspecting data to confirm that it is consistent with expectations, modifying designs as necessary.

▪ Communicating predictions and findings to the Organization through effective data visualizations and reports.

▪ Creating prototypes of key data manipulations, visualizations and mathematical modelling elements.

▪ Validating designs with business SMEs via discussions, examples, prototype demonstrations and documentation and iterating designs in response to negotiations with business SMEs.

▪ Conveying the designs to the development teams via discussion, documentation and prototype code.

▪ Developing an understanding of industry trends and best practices.

▪ Creating and follow personal education plan in the technology stack and solution architecture.

Experience & Skills
▪ Exposure to cyber security domain.

▪ Significant relevant experience in Data Science.

▪ Hands on experience in production deployment of ML models in large complex environments.

▪ Ability to learn quickly in a fast-paced environment.

▪ Excellent communication and team management skills.

▪ Self-motivated individual capable of working in a fast-paced environment.

▪ Great verbal and written communication skills.

▪ A strong analytical mind-set.

Knowledge:
▪ Good understanding and expertise in processing large datasets.

▪ Good working knowledge in implementation of various ML algorithms in big data environment

▪ Understanding of data visualization tools, such as Tableau, etc.

▪ Familiarity in working with Big Data and common data science tools such as Python, Spark etc. Proficiency in at least one.

▪ Familiarity with Scala, HIVE is desired.

▪ Good scripting and programming skills; SQL proficiency.

▪ Understanding of and proficiency in NLP.

▪ Understanding of a range of statistical and machine learning techniques and algorithms, such as logistic regression, KNN, decision trees, SVM, CNN, etc.

▪ Good understanding of the process workflow:

▪ Problem definition to hypothesis building

▪ Prototype model building using python/R

▪ Implementation of ML problems in big data.

▪ Performance Monitoring & Evaluation of System

Education:
▪ Master’s in Engineering, Science, or Mathematics",-1.0,Prevalent,Cochin,"Kochi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,90.0,-1,data scientist,senior,0,1,0,1,0,1,1,0,0,0,0,0,1,0,0,3445,0
319,"Posted: Jun 7, 2020
Weekly Hours: 37.5
Role Number:
200173885
The Apple Media Products Engineering team is one of the most exciting examples of Apple’s long-held passion for combining art and technology! These are the people who power the App Store, Apple TV, Apple Music, Apple Podcasts, and Apple Books. And they do it on a massive scale, meeting Apple’s high expectations with high performance to deliver a huge variety of entertainment in over 35 languages to more than 150 countries.

These engineers build secure, end-to-end solutions. They develop the custom software used to process all the creative work, the tools that providers use to deliver that media, all the server-side systems, and the APIs for many Apple services.

Thanks to Apple’s unique integration of hardware, software, and services, engineers here partner to get behind a single unified vision. That vision always includes a deep commitment to strengthening Apple’s privacy policy, one of Apple’s core values. Although services are a bigger part of Apple’s business than ever before, these teams remain small, forward-thinking, and cross-functional, offering greater exposure to the array of opportunities here.
Key Qualifications
Experience in high level programming languages such as Java, Scala, or Python.
Proficiency with databases and SQL is required.
Proficiency in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce.
Expertise in Hadoop related technologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig.
Expertise in developing big data pipelines using technologies like Kafka, Flume, or Storm.
Experience with large scale data warehousing, mining or analytic systems.
Ability to work with analysts to gather requirements and translate them into data engineering tasks
Aptitude to independently learn new technologies.
Description
As a senior member of the Data Engineering team, you will have significant responsibility and influence in shaping its future direction. This role is inherently cross-functional and the ideal candidate will work across disciplines. We are looking for someone with a love for data and ability to iterate quickly on all stages of data pipeline. This position involves working on a small team to develop large scale data pipelines and analytical solutions using Big Data technologies. Successful candidates will have strong engineering skills and communication, as well as, a belief that data driven processes lead to great products. You will need to have a passion for quality and an ability to understand complex systems.
Education & Experience
Bachelor's degree or equivalent work experience in Engineering, Computer Science, Business Information Systems.

Apple is an Equal Opportunity Employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, or other legally protected characteristics.",4.1,Apple,Vancouver,"Cupertino, CA",10000+ employees,1976,Company - Public,Computer Hardware & Software,Information Technology,$10+ billion (CAD),"Google, Microsoft, Samsung Electronics",90.0,44,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,3039,3
320,"About Us
AntiSocial Solutions is a full-service digital marketing agency made up of people who love to create. Our work spans industries; we produce cinematic media pieces and conceptual campaigns for great brands across the globe. As a division of Thinkingbox, we have offices located in Vancouver, Toronto, New York City, Salt Lake City, and Los Angeles. You’ll be joining a truly diverse, international, and supremely talented group of people who craft campaigns and provide solutions for the world’s top brands.

The Role
AntiSocial Solutions is searching for a Senior Marketing Data Analyst to join our growing team. The ideal candidate will be responsible for providing an in-depth analysis of marketing analytics to provide business insights that affect the growth of a company.

Responsibilities
Analyze the performance across multiple channels and deliver detailed insights to increase effectiveness, driving key performance metrics
Aggregate and analyze data across paid media platforms to develop hypotheses to optimize projects
Collaborate with our teams across all our offices to track performance, glean insights, and make informed decisions about optimizations
Provide insight on attribution to inform on touch points throughout the sales funnel
Advise cross functional teams to help with tagging campaigns and identifying patterns with web traffic and behaviors to improve tracking and reporting.
Leverage media platforms to conduct research and drive greater understanding of our audience.
Create data informed hypotheses for A/B testing and personalization.
Work with marketing software and tools such as Google Analytics, Tableau, Salesforce, Facebook Ads, Google Ads and LinkedIn Ads.
Define social influencer strategies, associated content approaches, and lead campaign ideation with broader account managers
Deploy successful SEM bidding strategies, placement mixes, and effective keyword management to hit target KPIs
Participate in cross-functional strategic planning that incorporates insights from the digital landscape, competitive intelligence, and data from our clients’ businesses together into impactful, integrated campaign proposals
Maintain a solid understanding of client objectives and draw a dotted line between digital media spend to marketing outcomes
Requirements
4+ years experience managing social campaigns in Facebook Business Manager, LinkedIn Ads, or DCM, experience with community management tools like Spredfast or Sprout a plus
2 years of experience managing search campaigns in Google Adwords required
Experience with SQL to extract, manipulate and discover insights in large data sets
Statistics and experimental methodology (e.g. A/B testing).
Ability to multitask and scale efforts across accounts, campaign objectives, and digital tasks
Previous experience documenting case studies that showcase campaign/project successes, ability to summarize learnings from client challenges to help better inform future work
To Apply
At Thinkingbox, we celebrate diversity both in our work and our people. We simply look for great talent and are dedicated to building a workplace where everyone feels valued and part of the Thinkingbox family.

Thank you for taking the time to apply for this opportunity. Please include your resume and links to your online portfolio with your application. Unfortunately, due to the number of applications we receive we are not able to contact everyone who applies. However, all applications are stored in our talent database and will be considered for future opportunities.",3.0,Thinkingbox,Vancouver,"Vancouver, Canada",1 to 50 employees,2010,Company - Private,Advertising & Marketing,Business Services,$1 to $5 million (CAD),-1,90.0,10,data analyst,senior,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,3549,0
321,"Position Overview
Our data aspiration is to unlock the power of connected data to deliver continuous value for our customers, our partners, and our company with trust and integrity. The position is central to our ability to do so. The Senior Data Analyst role is responsible for Advanced Analytics/Machine Learning application support executing in the Microsoft Azure Machine Learning (ML) Environment.
This role is to perform a combination of operations support and project work/enhancements associated with enabling Advanced Analytics. These activities will involve working with business teams, Data Scientists and Azure middleware teams.
Position Accountabilities
Work with business/application teams and data scientist to define and enhance data used for the execution of Advanced Analytics, production usage of the analytics models and supporting measurement metrics
Support data science teams in data extraction and preparation from multiple sources including files, data base tables, Data Lake (Hadoop), modelling the data for use for Advanced Analytics and business dashboards
Logical and physical data modeling of data to align with Business Intelligence/Advanced Analytics initiatives and includes definition of meta data, and the management of the data models using modeling tools (such as Erwin, Collabra)
Define and build data structures in supporting Advanced Analytics applications based on need/usage; relational (database) / non-relational (Hadoop) and dimensional structures
Ongoing refresh and enhancements of Advanced Analytics models, associated needs (include requirements/impact analysis, development to for problems/small enhancements, testing/validation and deployment
Manage issues with production incidents, problem items and service request for provisioning/security and change for operational enhancements
Work with an Azure middleware team to support the creation of Azure workspaces for Advanced Analytics
Support the business community and data scientists that utilize the Azure Machine Learning (ML) Environment
Support data science teams in the set-up/transition and ongoing support of Azure Machine Learning “applications”
Establish and support ongoing development, deployment and production processes associated with analytics model consumption in production in Azure landscape
Define and manage application security setup using Active Directory/Azure security, including access audit and access clean-up
Construct and manage application monitoring and coordinating any corrective actions required for Advanced Analytics applications in production
Author and curate Advanced Analytics application documentation
Build insights: complete data analysis and discovery to better understand the data and the story it is telling to drive actionable results
Influence Data Quality: complete data profiling of critical data elements, providing trending and insights that driven action to improve data quality across our customer base.
Loves teamwork and collaboration, collaborates daily with the core Analytics squad and business
Open to learning and sharing with others across the company, including senior leadership and community of practice participation
Recommend improvements to data engineering and governance practices across our company
Qualifications and Competencies:
5+ years of applied data management experience (Data & Analytics education an asset)
Expertise in SQL, Data Visualization Tools and working knowledge of R, Python, Zeppelin, PowerBI is considered an asset.
Excellent communication and presentation skills and strong organization skills
Agile, practical, customer service-oriented mindset (doesn’t over complicate processes)
Generally curious and excited to learn new things
Our Story
Canada Life is a leading insurance, wealth management and benefits provider focused on improving the financial, physical and mental well-being of Canadians. For more than 170 years, individuals, families and business owners across Canada have trusted us to provide sound guidance and deliver on the promises we’ve made.
As of January 1, 2020, Great-West Life, London Life and Canada Life became one company – Canada Life, and today, we proudly serve more than 13 million customer relationships from coast to coast to coast.
Discover your opportunity….Apply today!
Canada Life offers competitive compensation, great benefits such as medical, dental, life insurance, wellness account and personal days not to mention onsite cafeteria and fitness in our head office facilities.  If you’d like to join our team submit your information online and introduce yourself.
Canada Life serves the financial security needs of more than 13 million people across Canada, with additional operations in Europe and the United States. As members of the Power Financial Corporation group of companies, we’re one of Canada’s leading insurers with interests in life insurance, health insurance, investment and retirement savings. We offer a broad portfolio of financial and benefit plan solutions for individuals, families, businesses and organizations.
We are committed to providing an inclusive, accessible environment, where all employees and customers feel valued, respected and supported. We are dedicated to building a workforce that reflects the diversity of the communities in which we live, and to creating an environment where every employee has the opportunity to reach their potential.
Canada Life would like to thank all applicants, however only those who qualify for an interview will be contacted",3.5,Canada Life Assurance Company,Winnipeg,"Toronto, Canada",10000+ employees,1847,Company - Public,Insurance Operators,Insurance,$10+ billion (CAD),-1,90.0,173,data analyst,senior,0,1,1,0,0,1,0,0,1,0,0,0,1,0,0,5529,0
322,"The recruitment team at Myticas Consulting is looking for an experienced Machine Learning / Data Analytics Consultant who would be interested in a full-time permanent opportunity within the Ottawa, Ontario region.

Qualifications:
At least 6-8 years of professional experience including Systems Engineering and/or system architecture in the respective areas.
Experience with programming in Python & ML frameworks (i.e. Tensorflow, Keras, PyTorch) and versioning tools.
Expertise in one or more of the following machine learning domains: Image Processing, Computer Vision, Natural Language Processing (NLP), Speech/Signal processing.
Advanced knowledge in deep learning algorithms.
Experience in data visualization tools and methods.
Good understanding and hands-on experience in software architecture, virtualization, cloud-native principles, microservices, containers.
Duties:
Driving product architecture / new function definition to enrich product with machine learning / deep learning capabilities to be used with existing and new product functions.
Cooperation with Product Managers, Product Architect, System Engineers, CTO and Development Teams on defining of product roadmap, feature definitions and backlog prioritization.
Identification of product gaps and weaknesses toward competition, addressing them into enhancements/ roadmap, for their respective areas.
Supporting design, implementation, test, sales and maintenance of product with the relevant teams.
Documenting and presenting product capabilities internally and externally (documentation/ publications and presentations).
Job is also known as: Machine Learning / Data Analytics Consultant, Machine Learning Consultant, Data Analytics Consultant",5.0,Myticas Consulting,Ottawa,"Ottawa, Canada",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Modis, excelHR, Robert Half",90.0,-1,machine learning engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,1714,3
323,"MavTek is proud to be a an equal opportunity workplace dedicated to hiring and nurturing a diverse workforce.

Machine Learning Engineer - Intermediate, and Senior

As a passionate ML Engineer, you will design and build machine learning systems, tools, and validation strategies to support new machine learning applications. You should have a proven history of bringing machine learning initiatives into production, and in generating new ML ideas. You will have the ability to influence your peers, and leadership can enable others to adopt your vision. As an ML Engineer, you will collaborate with other Machine Learning Engineers and Data Scientists.
Why MavTek
Since entering Montreal’s tech scene 6 years ago, MavTek continues to grow rapidly while the team forges ahead on a path of inventing change and creating real impact for our customers. We’re looking for a Machine Learning Engineer who is innovative, eager to own their success and energized by the opportunity to pursue a career that’s as challenging as it is rewarding. At MavTek, we empower you to raise your voice, make a real impact not just within our fast growing company, but in everyday lives of tens of thousands of our customers.
What your day to day looks like:
- Develop and deploy ML/DL models from raw data
- Design ML/DL applications that demonstrate the technology's real-world potential
- Use best SW Engineering methodologies to implement the applications
- Deploy the applications on Cloud to release their full power
- Drive your ML/DL projects from proposal to production

Are you right for the role?
Technical Skills:

- Good understanding of machine learning theory and mathematical modeling
- Ability to develop machine learning models on large and complex data
- Practical experience with ML/DL libraries, like Keras/TensorFlow, Torch, Scikit-learn
- Intermediate/Advanced programming skills in Python (3+ years), or any other popular programming languages like Java or C++
- Good knowledge in Database/Datawarehouse and proficiency in using SQL
- Experience with Cloud Computing (1-2 years), like AWS, GCP, Azure
- Knowledge in developing micro-service
- Data driven mindset
- Passionate to design high reliability & high-performance solutions

Personal Skills:
- Ability to work both independently and as a member of a team
- Good communication skills and initiative is a must
- Self-driven individual and able to engage with different teams
- Fast learner, high capacity for abstract thinking with hands-on mentality
- Curious about new tech and advances in the industry, think further than the solution appears to require

Nice to Have:

- Any AWS certificates
- Experience in data processing, like using Spark or Flink for ETL jobs
- Container experience, like Docker or Kubernetes
- Familiar with Linux systems and Shell programming
- RESTful API and Webserver experience or knowledge
- Knowledge in GPU computing
- CI/CD knowledge or experience with Jenkins
- Good knowledge in GIT
- Agile experience
What’s in it for you ?
- Work alongside super talented and friendly people that like to drive innovation
- Competitive salary & vacation packages
- Complimentary breakfast and lunch daily prepared by our in-house chef
- Generous referral program
- Year-round events, from massive to casual and everything in between
- 50% off your Opus Transit subscription
- Beautiful office right near Namur metro

You’ll be Joining:
We’re DJ’s, video game heroes, photographers, movie buffs, musicians, grill masters and everything in between. We’re fiercely proud of our teammates, our work, and the impact we’re making to help tens of thousands of entrepreneurs who rely on our e-commerce platform to monetize their content. If you're inspired to do the best work of your life, then join the team.",4.6,MavTek,Montreal,"Montreal, Canada",51 to 200 employees,2014,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,"MindGeek, Shopify, Lightspeed",90.0,6,machine learning engineer,senior,0,1,0,0,0,1,1,1,1,0,0,1,1,0,0,3782,3
324,"DATA ENGINEER (SOPHI)

POSITION CODE: 2020-063
LOCATION: The Globe and Mail, Toronto
SALARY: Commensurate with qualifications and experience

POSITION OVERVIEW:

Were looking for experienced individuals with deep knowledge of data streaming, serialization, databases and distributed systems, and proficient in writing custom libraries but also know when to use off-the-shelf solutions when necessary. Ideal candidates are self-motivated engineers with a passion for both business and technology innovation, more importantly they quickly adapt with changing technologies. We value people who are passionate about system design and have an eye for improving product quality. We currently work with Scala, Kotlin, Java, Python, NodeJS, Postgres, Go, Kafka, and Flink.

As a Data Engineer you will:

Develop and optimize system components for maximum performance and scalability across a vast array of environments
Have a commitment to collaborative problem solving, sophisticated design, and product quality
Ensure that system components and the overall application are robust and easy to maintain
Contribute to backlog reviews, technical solutions design and implementations
Be disciplined in implementing software in a timely manner while ensuring product quality isnt compromised
MINIMUM QUALIFICATIONS:

Strong analysis and problem solving skills
Deep understanding of good programming practices, design patterns, Functional Programming, and Object Oriented Analysis and Design
Successfully implemented and released a large number of data pipelines and web services using modern engineering frameworks in the past 3 years
Formal training in software engineering, computer science or computer engineering.
Worked as part of a mature engineering team
IDEAL CANDIDATE:

Have strong working knowledge with Scala and/or Kotlin.
Understands reactive programming, Threads and Futures.
Successfully implemented realtime and batch analytics using Kafka, Flink, Apache Beams and/or Google DataFlow.
Strong working knowledge of data warehouses include Redshift, Snowflake, and/or Apache Druid.
Have a working knowledge with containerization and build pipelines
Successfully implemented data systems for very large data volumes such as click streams and/or IoT sensors data.
THE GLOBE AND MAIL INC. IS DEDICATED TO EQUITY IN THE WORKPLACE
At The Globe and Mail, we are committed to fostering an inclusive, accessible work environment, where all employees feel valued, respected and supported. The Globe and Mail offers accommodation for applicants with disabilities as part of its recruitment process. If you are contacted to arrange for an interview, please advise us if you require an accommodation.",3.6,The Globe and Mail,Toronto,"Toronto, Canada",501 to 1000 employees,-1,Company - Private,Publishing,Media,$100 to $500 million (CAD),-1,90.0,-1,data engineer,na,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,2690,0
325,"Job Requisition ID #
20WD40730
Job Title
Senior Data Analyst
Job Description
Senior Data Analyst

Location: Montreal- Canada

Job ID: 20WD40730

Position Overview

Autodesk is seeking an experienced data analyst to join the Data Science team in our Data Platform and Insights group. The Data Platform and Insights group is chartered with building innovative data products and analytics solutions for Autodesk’s strategy, marketing, sales and customer support teams.

Data Analysts will play a critical role in discovering and communicating data-driven insights to inspire product improvements.

Responsibilities
Leverage Data Mining techniques to find key business insights
Partner with Data Scientists to improve Data Science models
Collaborate with Product Managers to explore new product ideas or enhancements
Build reporting to measure progress in key initiatives
Become an expert in Autodesk data
Work as an individual contributor with opportunities for management as we grow the team
Minimum Qualifications
2+ years in an Analyst role
Strong SQL coding skills and comfortable using it everyday
Experience working in Python or R
Experience building Data Visualizations via Python/R or a Business Intelligence tool
Preferred Qualifications
Familiarity with Data Science concepts
Experience working in Git
Experience using big data platforms (Hadoop, Spark, Hive)
A/B Testing Experience
The Ideal Candidate
Interested in learning about Data Science
Have a strong attention to detail and care deeply about data quality
Proactively reach out to stakeholders to understand data better
Enjoy collaborating with team members to drive impact
Are a strong communicator; you can adjust communication for technical stakeholders and non-technical stakeholders

At Autodesk, we're building a diverse workplace and an inclusive culture to give more people the chance to imagine, design, and make a better world. Autodesk is proud to be an equal opportunity employer and considers all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender, gender identity, national origin, disability, veteran status or any other legally protected characteristic. We also consider for employment all qualified applicants regardless of criminal histories, consistent with applicable law.

Are you an existing contractor or consultant with Autodesk? Please search for open jobs and apply internally (not on this external site). If you have any questions or require support, contact Autodesk Careers.",3.7,Autodesk,Montreal,"San Rafael, CA",5001 to 10000 employees,1982,Company - Public,Computer Hardware & Software,Information Technology,$2 to $5 billion (CAD),-1,90.0,38,data analyst,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,2531,0
326,"SSENSE is looking for a Senior Data Engineer to join our rapidly growing technology team. The Senior Data Engineer will take complex features of the product roadmap, break them down into their required technical components, and develop them independently. They own at least one component of the SSENSE technical stack and hold accountability for its SLAs. The ideal candidate will actively contribute to knowledge dissemination within the organization, participate in the recruiting and onboarding of new employees, and mentor Junior Developers on the team.

RESPONSIBILITIES
Product delivery
Build, test and operate stable, scalable data pipelines that cleanse, structure and integrate disparate data sets into a readable and accessible format for end-user facing reports, data sciences and ad-hoc analyses
Develop a deep understanding of the product roadmap for the squad, including future features to be developed
Contribute to high-level estimation and participate in laying out the development sequences, challenging the product roadmap and identifying areas where technical debt can be reduced or avoided
Complete independently complex development tasks and actively contribute to pushing code to production
Write testable, efficient, and reusable code suitable for continuous integration and deployment, respecting best practices and SSENSE development standards
Review Unified Modeling Language (UML) diagrams and technical documentation

Ownership and accountability
Be accountable for code quality by conducting adequate testing
Be accountable for performance, reliability, scalability and resilience of at least one technical component owned by the squad through SLAs and monitoring
Solve complex technical problems and mentor/support other technical staff on data modeling and ETL related issues
Contribute to cross-squad initiatives, acting as a change agent amongst peers to foster adoption of new processes or technical solutions

Knowledge sharing and coaching
Review Pull Requests with the objective to guide and upskill other Data Engineers on various technical topics
Actively contribute to SSENSE University (the internal peer learning platform) to promote continuous learning
Participate in the onboarding of new Data Engineers

Architecture
Contribute to solution designs, challenging other members on technical decisions and explaining the technical design to junior developers so they can write documentation for the rest of the team

Recruiting
Participate in HR recruiting events, helping to identify and recruit top developers

REQUIREMENTS
Bachelor’s degree in Computer Science, Engineering, or a related technical field, Master’s degree an asset
A minimum of 5 years of Functional Programming and/or Object Oriented Programming (OOP) experience
A minimum of 3 years experience writing and optimizing SQL queries
A minimum of 3 years experience with Apache Spark for big data processing
Extensive knowledge of Python programming language and its data manipulation libraries (Pandas and Numpy)
Expertise in data modeling and an advanced understanding of data architecture
Expertise with RDBMS and NoSQL databases at scale
Experience with Apache Airflow or other similar data pipelining and workflow scheduling framework (Luigi, Azkaban)
Ability to use containers, orchestration frameworks, and other DevOps tools (Kubernetes, Terraform, Giant Swarm, etc.)
Proficiency with cloud resources (AWS/Google Cloud/Azure) with the ability to operate them for the components owned, Certification is an asset.
Knowledge of the AWS services (Redshift, Glue, Athena, S3, etc.) an asset
Knowledge of big data technology (Databricks, Hadoop, Hive, Pig, Presto) an asset
Familiarity with continuous integration and automated pipeline tools (Jenkins, Travis, etc.)
Proficiency in Git
Strong written and verbal communication skills in both English and French

SKILLS
Highly analytical and detail oriented
Ability to coach and mentor junior employees to achieve personal and professional goals
Team player with a high sense of accountability and ownership
Ability to influence and drive change
Solution-oriented mindset and can-do attitude to overcome challenges
Ability to thrive in a fast-paced environment and master frequently changing technologies and techniques

----------

SSENSE est à la recherche d’un ingénieur de données principal pour joindre son équipe technique en pleine croissance. La personne détentrice du poste analysera les fonctionnalités complexes de la stratégie produit pour déterminer les composantes techniques requises et les développer de façon indépendante. L’ingénieur de données principal est responsable d’au moins une composante de la pile technique SSENSE ainsi que des niveaux de service associés. Il participera activement au partage de connaissances au sein de l’entreprise ainsi qu’au recrutement et à l’intégration de nouveaux employés, en plus d’agir à titre de mentor auprès des ingénieurs de données.

RESPONSABILITÉS
Livraison produit
Construire, tester et mettre en opération des pipelines de données stables et adaptables pour épurer, structurer et intégrer des ensembles de données hétérogènes dans un format compréhensible pour les rapports destinés aux utilisateurs finaux, à la science des données et aux analyses ad hoc
Comprendre en profondeur la stratégie produit de l’équipe ainsi que les fonctionnalités à développer
Contribuer à l’estimation et à l’élaboration de séquences de développement, par la remise en question de la stratégie produit et l’identification des dettes techniques
Effectuer des activités complexes de développement de manière autonome et soutenir activement l’intégration du code dans la production
Mettre au point des solutions de code testables, efficaces et réutilisables, applicables à l’intégration et au déploiement continus, en phase avec les meilleures pratiques et les standards de développement SSENSE
Réviser les diagrammes de langage de modélisation unifié (UML) et la documentation technique correspondante

Engagement et responsabilité
Assumer la responsabilité de la qualité du code en réalisant les tests adéquats
Assumer la responsabilité du rendement, de la fiabilité, de l’évolutivité et de la résilience d’au moins une des composantes techniques complexes de l’équipe, au moyen de supervision et d’ententes de niveau de service
Résoudre des problèmes techniques complexes et mentorer d’autres membres du personnel technique quant à la modélisation de données et aux enjeux relatifs à l’extracto-chargeur (ETL)
Contribuer aux projets interéquipes par la promotion du changement et de l’adoption des nouveaux processus ou solutions techniques

Coaching et partage de connaissances
Réviser les Pull Requests afin d’orienter le perfectionnement des ingénieurs de données sur divers sujets techniques
Contribuer activement à SSENSE University, une plateforme d’apprentissage destinée aux employés, afin de promouvoir l’apprentissage continu
Participer à l’intégration de nouveaux ingénieurs de données

Architecture
Participer à la conception de solutions, questionner l’équipe quant à ses décisions techniques et expliquer le design technique aux développeurs afin qu’ils rédigent de la documentation pour le reste de l’équipe

Recrutement
Participer aux activités de recrutement des ressources humaines et soutenir la recherche et l’identification des meilleurs développeurs

EXIGENCES
Baccalauréat en informatique, ingénierie ou un dans un domaine technique connexe; maîtrise, un atout
Un minimum de cinq ans d’expérience en programmation orientée objet et/ou en programmation fonctionnelle
Un minimum de trois ans d’expérience en rédaction et optimisation de langage de requête structurée (SQL)
Un minimum de trois ans d’expérience avec Apache Spark pour le traitement de mégadonnées
Notions avancées du langage de programmation Python et des bibliothèques de manipulation de données (Pandas et Numpy)
Expertise en modélisation de données et connaissances approfondies en architecture de données
Maîtrise à grande échelle des bases de données relationnelles (SGBDR) et des systèmes de gestion de bases de données (NoSQL)
Expérience avec Apache Airflow et avec d’autres outils de pipelines de données et de gestion de flux de travail (Luigi, Azkaban)
Capacité à utiliser les conteneurs et les logiciels d’orchestration intégrés ainsi que d’autres outils de DevOps (Kubernetes, Terraform, Giant Swarm, etc.)
Maîtrise des ressources infonuagiques (AWS, Google Cloud, Azure) et habileté à les employer pour les composantes possédées; la détention d’une certification dans le domaine est un atout
Connaissance des services AWS (Glue, Athena, S3, Spark, etc.), un atout
Connaissance des technologies de mégadonnées (Databricks, Hadoop, Hive, Pig, Presto), un atout
Familiarité avec les outils d’intégration continue et de pipelines automatisés (Jenkins, Travis, etc.)
Maîtrise de Git
Excellentes habiletés en communication écrite et verbale tant en français qu’en anglais

COMPÉTENCES
Sens de l’analyse et souci du détail
Aptitudes en coaching des employés pour l’atteinte de leurs objectifs individuels et professionnels
Esprit d’équipe et fort sens de la responsabilité
Force d’influence et de changement
Esprit déterminé, positif et orienté vers la recherche de solutions pour surmonter les obstacles
Habileté à s’épanouir dans un environnement à rythme accéléré et à maîtriser les technologies web en évolution fréquente

Note: le masculin est employé dans le seul but d’alléger le texte et inclut par défaut tous les genres.",3.9,SSENSE,Montreal,"Montreal, Canada",501 to 1000 employees,2003,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1,90.0,17,data engineer,senior,0,1,0,0,0,1,1,1,1,1,0,0,0,0,0,9527,0
327,"Dimensional Strategies Inc. (DSI) is currently looking to expand its rapidly growing Data Analytics team. We Specialize in the development of solutions based on the Microsoft Data Platform. DSI is looking to add several resources to the team.

At DSI we value aptitude, work ethic, and a desire to learn amongst a team that believes collaboration is key. If this sounds like a place you might like to work and you feel that your experience matches the requirements below, we encourage you to contact us.

This is a full time / permanent role.

Essential skills of the Data Analytics Developer(s)

· Strong customer facing skills with the ability to conduct requirement workshops.

· Excellent team player, with demonstrated project leadership skills.

· 12 months - 2 years experience with Data Lake, HDInsight, Data Factory, building application in Azure

· 5-7 years experience using MSFT stack of tools: SSIS, SSAS, SSRS, SQL Server

· Experience with DAX and data Modeling

· Azure Analysis Services Tabular model experience

· Fluent with modern analytical development patterns and platforms.

· Expert in the Microsoft data platform including tabular modeling and PowerBI.

· A hands-on, roll up your sleeve’s developer, who is passionate about analytics.

· Great communication skills, written and spoken.

· Experience dealing with multiple clients and projects.

· Excellent verbal communication and the ability to understand and communicate a project in both business and technical terms is a must.

Nice to have skills for the Senior BI Developer:

· Experience with agile software development

· Experience in establishing BI governance, standards, practices, and methods with a good understanding of the relevance of the business change agenda when designing, implementing and communicating

· Ability to work in a fast-paced environment

All interested candidates should submit a copy of their resume with their application, submissions without will not be considered.

Job Types: Full-time, Permanent

Salary: $70,000.00 - $100,000.00 per year

Benefits:
Casual Dress
Dental Care
Disability Insurance
Discounted or Free Food
Life Insurance
On-site Parking
Paid Time Off
Profit Sharing
Vision Care
Work From Home
Schedule:

8 Hour Shift
Monday to Friday
COVID-19 considerations:
During COVID we give our employees the option of working from home full time.

Experience:
data analytics: 5 years (Preferred)
Work remotely:
Yes",-1.0,Dimensional Strategies Inc. (D,Mississauga,-1,-1,-1,-1,-1,-1,-1,-1,90.0,-1,data engineer,na,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,2438,0
328,"Faites une différence !

Workforce Edge aide les organisations du secteur de la santé à mettre en place des pratiques exemplaires de planification des horaires du personnel et de transformer les pratiques de gestion de la main-d’œuvre. Plus de 70 % des budgets de santé sont consacrés à la dotation en personnel, et les organisations dépendent de la présence d'une main-d'œuvre engagée et qualifiée pour fournir des soins de qualité à tous les Canadiens. Nos projets améliorent la vie professionnelle des employés, offre une plus grande mobilisation des employés, un meilleur contrôle sur les coûts de main d’œuvre, et la capacité de prodiguer des meilleurs soins aux usagers et leurs familles.

Nous sommes présentement à la recherche d’un conseiller/analystebilingue (français/anglais), qui possède une expérience dans la planification des horaires de modèles 24h/24, 7j/7 ou engagé dans les secteurs RH/RT de la planification des horaires du personnel. Il peut s'agir de postes antérieurs en tant que planificateur, coordonnateur, ou commis en planification des horaires ; analyste de la main-d'œuvre ; ou des postes similaires au sein des ressources humaines ou de la planification de la main-d'œuvre dans des secteurs tels que les soins de santé, les compagnies aériennes, le secteur manufacturier ou les technologies de l’information.

En tant que Conseiller Workforce Edge:

Nous avons toujours été une équipe qui travaille à domicile, et la plupart des jours seront consacrés en télétravail au sein d’une équipe répartie à travers le Canada et travaillant à distance avec nos clients (par téléphone, courriel et réunions en ligne). Dans ce rôle vous devrez analyser les données relatives aux salaires et aux horaires des clients et préparer des tableaux et des graphiques, à contribuer à l'examen des horaires et des pratiques de planification des horaires, à concevoir et à assurer la qualité des horaires, soutien l'amélioration des processus d'affaires et à préparer des projets de rapports et de présentations. Vous contribuerez également à l'amélioration continue de nos outils et méthodologies.

La participation aux réunions interne et avec des clients par téléphone / réunion en ligne sera nécessaire au quotidiennes pour clarifier les données, présenter et revoir les livrables, et soutenir les conseillers principaux en documenter les éléments de discussions, les plans d’action et les mesures à prendre. Occasionnellement, vous vous rendrez sur les sites des clients, en travaillant avec des conseillers principaux pour documenter les résultats des entrevues et des groupes de discussion, aider la conception de processus, soutien les activités de formation et mise en œuvre et participer à d'autres réunions et activités sur place. En moyenne, les voyages d'affaires durent de 3 à 4 jours et la plupart des conseillers effectuent entre 6 et 12 voyages par an (bien que pendant la pandémie COVID, nous ne demandons pas de déplacement sur les sites des clients).

Si ce poste vous intéresse:

Veuillez envoyer votre CV ainsi qu’une lettre de présentation en anglais qui comprends les éléments suivants :
Votre expérience avec la planification des horaires, les difficultés rencontrées et les solutions proposées.
Si vous avez déjà travaillé avec un système informatisé de gestion des horaires, puis décrivez ce système et ses fonctions principales.
Si vous avez une expérience du travail à domicile, décrivez comment vous aimez organiser votre travail pour rester productif dans un environnement de bureau à domicile.
Compétences requises pour ce poste:

Excellent Niveau:
Excel - Tableaux croisés dynamiques, graphiques, mise en forme conditionnelle, formule et programmation, fonctions de nettoyage des données.
Très bon Niveau:
Word - Mise en forme avec Styles
Microsoft Outlook
Power Point
Agréable d'avoir:
Visio
Statistiques - Probabilité, conception de l'étude, inférence et association
Analyse d’affaire - conception de processus, la configuration système requise
Travailler à domicile

Voyage d'affaires - Occasionnel, 6 à 12 voyages par an. (Bien que pendant la pandémie COVID-19, nous ne demandons pas de déplacement sur les sites des clients)

Nous apprécions votre intérêt pour ce poste. Nous répondrons à tous les candidats qualifiés. Toutefois, nous vous demandons d’être patient car l'examen de votre candidature peut prendre un certain temps. Seuls les candidats qualifiés seront retenus pour le processus de recrutement, qui comprendra des entretiens dans les deux langues officielles, test de compétences Excel et la vérification des références.

-----------------------------------------------------

Bilingual Consultant, Data Analyst

Make a difference!

Workforce Edge helps our healthcare clients implement effective staff scheduling practices. Over 70% of healthcare budgets are spent on staffing, and organizations depend on having an engaged and skilled workforce to deliver quality patient care for all Canadians. Our projects improve the working life for employees and reduce the cost of delivering care.

We are looking for a Consultant & Data Analyst who is bilingual (English/French) and has past experience scheduling for a 24/7 workforce or involved in the HR/LR aspects of staff scheduling. This could include past positions as a scheduler, scheduling clerk, scheduling analyst, workforce analyst, or similar positions in HR or workforce planning in industries such as health care, airlines, manufacturing, or IT.

As a Workforce Edge Consultant:

We have always been a remote team, and most days will be spent working at your home office, connecting with consultants across Canada and with client contacts by phone, email, and online meetings. Your normal activities will be to analyze client payroll and schedule data and prepare tables and charts, contribute to reviews of schedules and scheduling practices, design and QA schedules, support business process improvements, and prepare draft reports and presentations. You will also contribute to continuous improvements of our tools and methodologies.

Attendance at internal and client meetings by telephone/online meeting will be required daily to clarify data, present and review draft deliverables, record client input, and support senior consultants by documenting discussion items and action items. Occasionally, you will travel to client sites, working with senior consultants to record the results of interviews and focus groups, support process design, training and implementation activities, and participate in other on-site meetings and activities. On average, business travel is 3-4 days duration and most consultants complete between 6-12 trips per year (although during the COVID pandemic, we are not requiring travel to client sites).

If this position interests you:

Please send your CV and a cover letter in English that includes the following:
Your experience with scheduling, the difficulties encountered and the proposed solutions.
If you have ever worked with a scheduling software system, please describe this system and its main functions.
If you have experience working from home and how you like to organize your work to stay productive in a home office environment.
Skills required for this position:

Excellent Skill Level:
Excel – Pivot tables, charts, conditional formatting, formula and programming, data cleanup functions
Very Good Skill Level:
Word – Formatting using styles
Microsoft Outlook
Power Point
Visio
Nice to Have:
Statistics– Probability, Study Design, Inference and Association
Business Analysis – business processes, system requirements
Required: Work from home office

Business travel: Occasional (6-12 trips per year - although during the COVID pandemic, we are not requiring travel to client sites).

We will respond to all qualified applicants, but please be patient as it may take time to review your application. Only qualified candidates will move forward with the recruiting process which will include interviews in both official languages, Excel skills testing, and reference checks.

Type d'emploi : Temps Plein, Permanent

Horaire :

Du Lundi au Vendredi
Mesures COVID-19:
Pendant la pandémie COVID-19, nous ne demandons pas de déplacement sur les sites des clients.

Langue:
Français et Anglais (Requis)
Télétravail:
Oui",-1.0,Workforce Edge Consult,Toronto,-1,-1,-1,-1,-1,-1,-1,-1,90.0,-1,data analyst,na,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,8284,0
329,"IT/IQ Tech Recruiters is seeking a Machine Learning Engineer to join our client in Toronto, ON.

Why work with our client?
Certified Great Place to Work
Weekly delivery of groceries for the office
Competitive compensation
Responsibilities
Perform ETL with massive data from multiple applications and 300 M+ customers
Architect, design and evaluate novel approaches for handling high-volume real-time data streams in an inferencing environment
Own the development, training, optimizing, and deployment of machine learning systems
Develop measurement and feedback systems at web scale to improve the selection of features and/or algorithm design
Top Skills Required
Strong software development skills (+3 years working experience), with proficiency in Python or Scala preferred
Experience in building ETL pipelines to perform feature engineering on large-scale dataset using Big Data technologies such as Spark
Ability to explain and present analyses and machine learning concepts to a broad technical audience
Ability to initiate and drive projects to completion with minimal guidance
Knowledge in advanced data structures and can use them to solve problems
You have a Masters degree or equivalent in Computer Science, Engineering, Mathematics or related field
Working knowledge of PyTorch, Tensorflow or other similar frameworks is a plus
Creative, collaborative, & product focused
Must be legally eligible to work in Canada
Why work with us?
Build a long-term relationship with an experienced recruitment expert
Access to the ‘hidden’ job market – opportunities across Canada that aren’t posted on job boards
Get a high-level understanding of market dynamics affecting your industry
Gain insight into the culture of the company you’re applying for before submitting your profile
About Us

IT/IQ Tech Recruiters provides contract and permanent IT recruitment services to employers across Canada. We have a specialized approach to recruiting, segmenting our recruitment teams into specialty practice areas focusing on Development, PMO, Infrastructure and BI/CRM/ERP skill sets.

This approach enables our recruiters to become specialists; they know the market and work hard to understand each candidates’ capabilities, goals, career ambitions and quickly present them with the best possible opportunities. We are committed to helping candidates develop their careers and to helping our clients grow their business and complete important projects successfully.

We create opportunities for IT Professionals to empower business.",2.8,IT IQ TECH RECRUITERS LTD,Vancouver,"Vancouver, Canada",1 to 50 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (CAD),"Randstad, TEKsystems, TEEMA Solutions Group",90.0,18,machine learning engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,2525,3
330,"Coursera is a leading online learning platform for higher education, where 64 million learners from around the world come to learn skills of the future. More than 200 of the world’s top universities and industry educators partner with Coursera to offer courses, Specializations, certificates, and degree programs. 2,500 companies trust the company’s enterprise platform Coursera for Business to transform their talent. Coursera for Government equips government employees and citizens with in-demand skills to build a competitive workforce. Coursera for Campus empowers any university to offer high-quality, job-relevant online education to students, alumni, faculty, and staff. Coursera is backed by leading investors that include Kleiner Perkins, New Enterprise Associates, Learn Capital, and SEEK Group.

Data Engineering is unique at Coursera. Our team doesn’t simply build reports on demand. Rather, we build the semantic infrastructure and products that empower our internal and external customers with the data to innovate and perform their jobs better.
We’re looking for a senior data engineer in Toronto who can help us drive data engineering efforts for our platform. In this role, you will work with cross-functional teams to design, develop, and deploy data solutions. Our ideal candidate is an independent, analytically-minded individual with strong data modeling and engineering skills, who shares our passion for education.
Your responsibilities
Architect scalable data models and build efficient and reliable ETL pipelines to bring the data into our core data lake
Design, build, and launch visualization and self-serve analytics products that empower our internal and external customers with flexible insights
Be a technical leader for the team; guide technical and architectural designs for the major team initiatives; mentor junior members of the team
Build data expertise, and partner with data scientists, product managers and engineers to define and standardize business rules and maintain high-fidelity data
Define and partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently
Work cross-functionally (eg: product managers, engineers, business teams) to support new product and feature launches
Your skills
5+ years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science
Strong data engineering skills and at least one scripting language (e.g., Python)
Proficient with relational databases and SQL
Familiarity and experience with big data technologies (eg: Hive, Spark, Presto) preferred
Ability to communicate technical concepts clearly and concisely
Independence and passion for innovation and learning new technologies

If this opportunity interests you, you might like these courses on Coursera -

Big Data Specialization

Big Data Essentials: HDFS, MapReduce and Spark RDD

Data Warehousing for Business Intelligence

Coursera is an Equal Employment Opportunity Employer and considers all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, age, marital status, national origin, protected veteran status, disability, or any other legally protected class.

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, please contact us at accommodations@coursera.org.

Please review our CCPA Applicant Notice here.",3.9,Coursera,Toronto,"Mountain View, CA",501 to 1000 employees,2012,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1,90.0,8,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,3526,0
331,"Reporting to the Technical Director, you will collaborate along side a team of other accomplished developers, delivering complex development projects for internal systems across a variety of products and technologies.

You will be challenged across several creative projects and responsibilities, including the opportunity to influence the future direction of the department and systems used across the business.

To apply for this role, you will have a strong technical capability and a proven track record in software development/ data engineering. You are motivated and experienced in taking responsibility and being on point for both departmental and business projects.

Key Responsibilities:
Design, model and maintain data sets to support reporting analytics and exploratory analysis
Can understand and contribute to the technical solution from design through to code level
Contribute to technical design and ongoing development of our custom ETL solutions and analytics platforms, and help improve overall design and delivery standards
Work with big data developers to build scalable and supportable infrastructure
Employ a variety of languages and tools (e.g. scripting languages) to marry systems together
Recommend and support the implementation available and latest big data technologies
Participate in reviews and meetings
Recommend ways to improve data, efficiency and quality
Work with data architects, modelers and IT team members on project goals
Contribute to post implementation reviews demonstrating success
Work on multiple projects involving the implementation of new and existing systems, solutions and processes
Desired Experience:
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Should also have experience using the following software/tools:
Experience with big data tools including: Hadoop, HDFS, Hive, Spark, Storm and Impala
Experience with relational query authoring (SQL) and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools such as Airflow
Experience with AWS cloud services: ECS, EKS, EMR, RDS, ELB, and Docker
Experience with Snowflake
Experience with object-oriented/object function scripting languages: Python, C#, SQL, NoSql and SnowSQL
Working knowledge of message queuing, stream processing, and scalable big data data stores
Experience working with unstructured datasets
Experience performing root cause analysis on all data and processes to answer specific fiscal questions while identifying opportunities for improvement
Experience in the physical and logical design of database architecture for relational databases, data warehouses and data lakes.
Experience with database optimization, data replication, database recovery and performance tuning.
Excellent personal organization
EA is an equal opportunity employer. All employment decisions are made without regard to race, color, national origin, ancestry, sex, gender, gender identity or expression, sexual orientation, age, genetic information, religion, disability, medical condition, pregnancy, marital status, family status, veteran status, or any other characteristic protected by law. EA also makes workplace accommodations for qualified individuals with disabilities as required by applicable law.",3.9,Electronic Arts,Vancouver,"Redwood City, CA",5001 to 10000 employees,1982,Company - Public,Video Games,Media,$2 to $5 billion (CAD),"Riot Games, Google, Activision Blizzard",90.0,38,data engineer,senior,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1,3429,3
332,"Join SADA as a Sr. Data Engineer!

Your Mission

As a Sr. Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring batch or streaming data pipelines, data lakes and data warehouses.

You will be expected to run point on whole projects, end-to-end, and to mentor less experienced Data Engineers. You will be recognized as an expert within the team and will build a reputation with Google and our customers. You will demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. You will also participate in early-stage opportunity qualification calls, as well as lead client-facing technical discussions for established projects.

Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our engineers know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.

Your success starts by positively impacting the direction of a fast-growing practice with vision and passion. You will be measured quarterly by the breadth, magnitude, and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, how well you collaborate with your peers, and the consultative polish you bring to customer interactions.

As you continue to execute successfully, we will build a customized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events. Due to the COVID-19 pandemic, travel has been temporarily restricted.

Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.

Training - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment
Required Qualifications:
Mastery in at least one of the following domain areas:
Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or customer-facing role
Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Experience operationalizing machine learning models on large datasets
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem
About SADA

Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA's values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.
Make them rave
Be data driven
Be one step ahead
Be a change agent
Do the right thing
Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!

Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match, professional development reimbursement program as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core:3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.",4.7,SADA,Toronto,"North Hollywood, CA",51 to 200 employees,2000,Company - Private,IT Services,Information Technology,$100 to $500 million (CAD),-1,90.0,20,data engineer,senior,0,1,0,0,0,1,1,0,0,1,0,0,1,0,0,5910,0
333,"Company Profile

TTT Studios is a digital innovation studio working for a global client list in multiple industries. Over the past eight years, we have built multiple applications and patented a portfolio of technologies. This experience puts us in a strong position to cater to larger accounts and launch our own products.

We are a family. We have fun. Design means everything to us and we have the technical chops to deliver what lesser programmers might describe as spooky magic. We expect amazing things from every TTT family member and drive each other to achieve greatness.

Role Summary - Big Data Engineer (Contractor)

We are looking for a talented and experienced big data engineer who is meticulous with designing and then developing data platforms for TTT Studios' client projects. The ideal candidate should have a deep understanding of best practices when it comes to building data pipelines and applications to stream and process datasets at low latencies.

Job Specifics
Big data platform architecture design.
Large dataset processing and migration.
Writing clean, readable, and testable code.
Ensuring the best performance and user experience of the application.
Seeing through a project from conception to finished product.
Work closely with the engineering team.
Documenting architecture and technical specs for a backend application.
Directly conversing with clients and stakeholders.
Skills and Qualifications
3+ years of experience in big data analytics platform.
Expertise in Spark, Akka, Kafka/Pulsar, AWS EKS
Experience in Cassandra database and Snowflake platform.
Proficient in Scala/Java programming language.
Experience writing technical documentation and software architecture.
Understanding of REST APIs, OOP, and related best practices.
Nice to have: Python, Ruby on Rails
Nice to have: Experience building CI/CD pipelines.
Hiring Process
Complete this application and include your resume or CV.
If your profile matches what we are looking for, we'll contact a you and setup a short phone call.
We will also setup an interview at our offices or via Zoom. We'll talk about your experience, what do you think about patterns, architecture, and some common situations while developing an app.
We will send you a challenge your way! You will be working with the team solving a specific task regarding an API and a backend service.
After finishing the code challenge, we'll come to a decision.
A Day at TTT Studios

The work culture at TTT is second to none. On arrival, head to the kitchen for your daily caffeine fix before joining the team in our open-plan office space. Once you've settled in, our engineering team will onboard you with our development processes and technical standards. Equipped with the tools you need, get ready to jump into action. Working from home is always an option.

Our clients operate across a wide range of industries that span from tourism to communications. For every project you take on, you’ll encounter intellectually stimulating and impactful technical challenges that keep you on your toes. For an idea of some of the projects we’ve taken on in the past, check out our case studies here.

As you work, keep your eyes peeled for our office dogs who will trot by and welcome you to the TTT family. To help combat work stress, our perks include work flexibility, monthly happy hours, weekly lunch & learns, yoga lessons twice a week, and a cozy massage chair overlooking Vancouver’s scenic waterfront. The team at TTT is passionate about creating software that impacts lives, and management does everything it can to plant the seeds that will propel you to greater heights.

More from Us

TTT Studios is an award winning digital innovation studio focused on empowering businesses through technology. #1 ranked Canadian custom software and mobile app developer. Our values are integrity, passion and excellence. We’re obsessed with delivering quality work. That’s why our team consists of designers and engineers of the highest calibre. We also strongly believe in empowering the community by being heavily involved in local and international events as speakers, educators, and sponsors. Whether you’re a developer, designer, management or co-op student, every single person here contributes to who we are as a company.",4.6,TTT Studios,Vancouver,"Vancouver, Canada",1 to 50 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Atimi Software, Dynamic Leap, Finger Food Advanced Technology Group",90.0,10,data engineer,na,0,1,0,0,0,0,1,1,0,0,0,1,0,0,0,4282,3
334,"Using our industry-leading game engine, we are creating a whole new line of products and services centered around running massively scaled simulations in the cloud. What we create will impact multiple industries such as Robotics and Autonomous Vehicles, and contribute to the advancement of the field of Artificial Intelligence.

The visual machine learning team in AI@Unity is focused on building robust tools to train, test, and validate autonomous systems using simulated environments. This requires visual content understanding, content generation, flexible yet accurate simulated sensors including LIDARs, cameras, and radars, and self-supervised learning.

We are looking for an exceptional Senior Machine Learning Engineer to push the boundaries of what is possible in the world of cloud-based simulations. If you're passionate about using synthetic data for computer vision, creating better autonomous vehicles and robots, and launching products from the ground-up, then we want to talk with you!

Responsibilities
Research and implement state of the art algorithms for domain adaptation and self-supervised learning
Implement state of the art models for a range of standard Computer Vision tasks to drive user engagement with the Unity simulation platform
Lead junior machine learning engineers with technical decisions to deploy models to the cloud and integrate them with new or existing services
Keep up to date with the latest in simulations, perception, and computer vision research
Requirements
B.Sc. in Data Science, Machine Learning, Statistics, Computer Science, Applied Math, or an experience in equivalent highly technical field
Hands-on experience in Computer Vision, Computer Graphics, or Machine Learning projects
Hands-on experience building production models with TensorFlow, PyTorch, or equivalent deep learning framework
Proven ability to ship quality software products and services
Bonus Points
Ph.D. in Data Science, Machine Learning, Statistics, Computer Science, Applied Math, or an equivalent technical field
Significant contributions to open-source software
Published research in areas of Machine Learning at major conferences and/or journals
Experience with Unity Engine, 3D simulators, game development and graphics
Excellent communication skills with the ability to build relationships across the company
About Unity Technologies

Unity is the world's leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity's platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company's 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com.

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

#LI-MH1 #SEN",4.9,Unity Technologies,Vancouver,"San Francisco, CA",1001 to 5000 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Epic Games, Electronic Arts, Zynga",90.0,15,machine learning engineer,senior,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,4042,3
335,"Role and Responsibilities

(English follows)

Lorsque vous prenez l’avion, peu importe la destination, il y a de fortes chances que le pilote ait été formé par CAE. Le point focal étant les clients, l’équipe Accélérateur numérique s’engage à rehausser l’expérience de formation afin de s’assurer que les pilotes soient les meilleurs possible.

Voici quelques raisons pour lesquelles les employés aiment travailler à CAE!
Travail significatif qui favorise le perfectionnement professionnel
Possibilité de travailler dans l’industrie technologique et de s’y épanouir
Environnement de travail axé sur la collaboration
Faire partie d’une équipe à haut rendement

Votre mission

À titre d’ingénieur des données, votre mission est d’améliorer l’expérience client en faisant la transformation des données dans un format pouvant être utilisées à des fins de prédiction. Cela sera accompli principalement par l’élaboration, l’entretien et la mise à l’essai d’infrastructures destinés à la production de données. Vous jouerez un rôle important dans la promotion de solutions d’architecture pour des projets de science des données et de modélisation avancée.

Votre rôle et responsabilités principales

Être le leader de la stratégie d’intelligence artificielle
Créer et maintenir une architecture de pipeline de données optimale et évolutive.
Assembler des ensembles de données complexes qui respectent les exigences opérationnelles fonctionnelles et non fonctionnelles.
Concevoir l’infrastructure requise pour l’extraction, la transformation et le chargement de données optimaux à partir d’une grande variété de sources de données et de technologies de « données massives ».
Définir, concevoir et mettre en œuvre des améliorations de processus internes : l’automatisation des processus manuels, l’optimisation de la transmission de données, la nouvelle conception de l’infrastructure pour une plus grande évolutivité, etc.
Mettre au point des outils d’analyse qui utilisent le pipeline de données pour fournir des perspectives applicables en matière d’acquisition de clients, d’efficacité opérationnelle et d’autres mesures clés du rendement opérationnel.
Maintenir les données séparées et en sécurité à travers les frontières nationales par l’entremise de plusieurs centres de données.
Travailler avec des experts en données et en analyse pour parvenir à une meilleure fonctionnalité de nos systèmes de données.
Être un contributeur-clé dans la transformation de l’entreprise
Travailler avec des intervenants, y compris les équipes de la direction, de l’expérience client et de la conception pour les assister dans la résolution de questions techniques liées aux données et le soutien de leurs besoins en infrastructure.
Être un collègue inspirant et motivant
Partager des connaissances avec les membres de l’équipe et prendre des initiatives de partage de connaissances hors de l’équipe de science des données
Être un agent de changement et un promoteur de la mentalité agile
Contribuer au milieu de travail collaboratif et stimulant
Être actif dans la communauté d'intelligence artificielle de Montréal et d'ailleurs pour trouver de nouvelles possibilités de collaboration et pour amener de nouvelles idées

Vos qualifications
Volonté de participer à tous les niveaux de l’exécution des travaux liés à un projet.
Excellentes aptitudes pour la communication verbale et écrite, en français et en anglais.
Compétences techniques
Baccalauréat en informatique, en ingénierie ou un domaine connexe.
Au moins trois (3) ans d’expérience dans l’industrie en matière de travail avec des données, de code, de création de scripts (Python/Java/Scala/SQL/JS/Bash), de conception, et de mise à l’essai.
Au moins trois (3) ans d’expérience en matière d’élaboration et d’administration de gros systèmes de données.
Solides connaissances des principes fondamentaux du soutien à la clientèle en matière d’algorithmes et de structures de données.
Expérience en soutien et en travail avec des équipes interfonctionnelles dans un environnement dynamique Expérience en utilisation d’outils de traitement de données massives : Hadoop, Spark, Kafka.
Expérience en utilisation de bases de données relationnelles SQL et NoSQL, y compris Serveur SQL et CosmosDb.
Expérience en utilisation de pipelines de données automatisées et d’outils de gestion du flux de travail : DevOps, ARM, Data Factory, Airflow.
Expérience en utilisation de services infonuagiques Microsoft : Azure, Databrick.
Expérience en utilisation de systèmes de traitement de flux : Storm, Spark-Streaming.
Ce que nous avons à offrir
Avantages sociaux : entièrement flexibles pour que vous puissiez choisir ce qui est important
Retraite : Régime de retraite à prestations déterminées et régime enregistré d’épargne-retraite (REER) collectif
Avantages financiers : Régime d’actionnariat et nombreux rabais d’entreprise
Programmes personnels et familiaux : Plan de bien-être physique et prestations de maternité complémentaires
Équilibre travail-vie personnelle : Horaires flexibles et « vendredis californiens » toute l’année
Plaisir au travail : Activités sociales et communautaires tout au long de l’année!

À CAE, il est très important de créer des liens avec les gens. Si vous avez des questions au sujet de cette possibilité de carrière, n’hésitez pas à communiquer avec Nadine Dubois, spécialiste, acquisition de talents (nadine.dubois1@cae.com), Marc-André Proulx, Spécialiste technique (marc-andre.proulx@cae.com) ou Sofiane Hocine, gestionnaire de produits numériques (sofiane.hocine@cae.com).

Joignez-vous au moteur de changement à CAE - notre prochain horizon de croissance passe avant tout par l’innovation numérique afin d’appuyer la réussite de nos clients.
***************************

If you’ve taken a plane to any destination in the world, chances are, your pilot was trained by CAE. With its strong customer focus, the Digital Accelerator team is dedicated to elevating the training experience to make pilots the best they can be.

Here are few reasons why folks love working at CAE!
Meaningful work that drives professional development
Ability to enter and grow within the technology industry
Work in a collaborative environment
Be part of a high-performance team

Your Mission

As a member of the Data Science team, your mission is to transform data into a format that can be consuming for other analytics stakeholders by developing, maintaining and testing infrastructure for data generation. You will also play an instrumental role enabling architecture solutions for Data Science and advance modelling projects.

Your Role & Main Responsibilities

Be a key contributor to the AI & Data Science Strategies
Create and maintain optimal and scalable data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and ‘big data’ technologies.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Keep data separated and secure across national boundaries through multiple data centers.
Be an active member of the business transformation
Work with stakeholders including the Executive, CX and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Be an inspirational and motivational colleague
Be an inspirational and motivational colleague
Share knowledge with team members & participate in various learning-sharing activities
Contribute to the collaborative and stimulating work environment
Be a change agent & Agile mindset promoter
Be connected to the industry to know tendencies and suggest innovative ideas
Your Qualifications

Softskills
Willingness to participate in all levels of project work when necessary.
Excellent English and French written and verbal communication skills.
Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.
Technical skills
Bachelor's degree in Computer Science, Engineering, or related field.
A minimum of 3 years industry experience working with data, coding and scripting (Python/Java/Scala/SQL/JS/Bash), design and testing.
A minimum of 3 years experience developing and administering large data systems.
Solid knowledge of CS fundamentals in algorithms and data structures.
Experience supporting and working with cross-functional teams in a dynamic environment. Experience with big data tools: Hadoop, Spark, Kafka.
Experience with relational SQL and NoSQL databases, including SQL Server and CosmosDb.
Experience with automated data pipeline and workflow management tools: DevOps, ARM, Data Factory, Airflow.
Experience with Microsoft cloud services: Azure, Databrick.
Experience with stream-processing systems: Storm, Spark-Streaming.
What we have to offer
Benefits: fully flexible for you to choose what is important
Retirement: Defined Benefits Retirement Plan & Group Registered Retirement Savings Plan (RRSP)
Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts
Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan
Work-Life Balance: Flextime & California Fridays all year
Fun at work: social and community events all-year round!

At CAE, connecting with people is very important. If you have any questions on this career opportunity, please do not hesitate to contact Nadine Dubois, Talent Acquisition Specialist (nadine.dubois1@cae.com), Marc-André Proulx, Technical Lead (marc-andre.proulx@cae.com) or Sofiane Hocine, Digital Product Manager (sofiane.hocine@cae.com).

Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.
Position Type

Regular

CAE thanks all applicants for their interest. However, only those whose background and experience match the requirements of the role will be contacted.

Equal Employment Opportunity

At CAE, everyone is welcome to contribute to our success. With no exception.

As captured in our overarching value ""One CAE"", we’re proud to work as one passionate, boundaryless and inclusive team.

At CAE, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age.

The masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.",3.9,CAE,Montreal,"Montreal, Canada",10000+ employees,1947,Company - Public,Aerospace & Defence,Aerospace & Defence,$2 to $5 billion (CAD),"Pratt & Whitney, Lockheed Martin",90.0,73,data engineer,na,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,10808,2
336,"@SYNNEX, we believe everyone has a story to tell. If you have a passion for advancing technology solutions, always putting customers first and want to become part of a team that embraces differences and creates trends, build your career story with us. We strive to create a work environment that is fun and inclusive with a sense of work-life balance and charitable giving.

Our recruiting experience is digital!

Technology is at the core of our business – we don’t just sell technology, we use it. The power of digital interviewing allows you the flexibility of using your computer or mobile device to record your interview on your own schedule in the comfort of your home. Our recruiting process allows you to tell your story in a stress-free way that is interactive and fun, so if you receive a link to Share your Story with us, we hope you have an awesome digital experience.

Business Systems Analyst (Data Analyst)


You will be the data analyst of SYNNEX IT, working with IT leadership, ERP business system analysts and the technical data management team utilizing report writing resources to help compile IT data relating to initiatives and strategies.

Get Inspired by the Work You’ll Do
Active member of our SYNNEX IT Digital Transformation task force
You will be working with SYNNEX global IT teams which includes US, Canada, China, Japan and LATAM
Responsible for data modeling and analytics using statistical techniques and provide ongoing reports
Identify, analyze, and interpret trends or patterns in complex data sets
Know how to analyze data, data modeling and data presentation
Locate and define new process improvement opportunities
Manage projects and resources (not a people manager)
Your passion is sparked by:
Bachelor of Science (BS or equivalent) in Mathematics, Economics, Computer Science, Information Management or Statistics coupled with 4-5 years of industry experience
Strong Power BI and related experience
Technical expertise regarding data modeling, mining and segmentation techniques
Proven working experience as a Data Analyst or Business Data Analyst
Experience of industrial data analysis. Supply chain industry experience is a plus
Strong analytical skill with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Demonstration of logical thinking, problem solving capability
Business Intelligence experience
Big Data experience – such as Vector or equivalent
SQL or equivalent experience
Project management experience
AI/ML knowledge or experience is a plus
We have Great Perks • 3-weeks’ vacation • Every day is Casual Day • Comprehensive Group Health Insurance plan • Profit Sharing Opportunity • Employee Referral Award program • Employee Purchase Plan/ Company Discounts • Out of Country travel assistance • Health/ Wellness initiatives • Paid Sick Days • Employee Assistance Program • Education Reimbursement • Milestone Service Awards • Community Involvement activities in partnership with Kids Help Phone • Employee of the Quarter awards • Group RRSP with Company Matching • Training Opportunities • Huang Leadership Development Scholarship • Bi-annual President’s Club • Annual Founders Award

Be Inspired In Your Career.


@ SYNNEX Corporation, we believe employees are our greatest asset and we empower them to make a difference in our business. Diversity and inclusion makes us all better. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, age, disability, protected veteran status, and all other protected statuses.

@ SYNNEX Canada Limited, we are committed to supporting accommodation and inclusivity for persons with disabilities throughout the recruitment process and employment lifecycle. If you require accommodation during the recruitment and selection process, please let us know; we will work with you to meet your needs.

Note: The preceding job description has been designed to indicate the general nature and level of work performed by employees with this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job.",3.3,SYNNEX,Toronto,"Fremont, CA",10000+ employees,1980,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (CAD),"Ingram Micro, Tech Data",90.0,40,data analyst,na,0,0,1,0,0,1,1,0,0,0,0,0,0,0,1,4301,2
337,"StackAdapt is the no. 1 performing native advertising platform helping brands accelerate customer engagement and acquisition. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience.

Ranking the highest in customer satisfaction and performance by G2 Crowd in the DSP category for the fourth time, we're one of the fastest growing companies in Canada and ranks 6th in Deloitte's Technology Fast 50 ranking and 23rd in Fast 500 in North America.

We're looking to add a Data Engineer to our data team! This team works on solving complex problems for StackAdapt's digital advertising platform. You'll be working directly with our data scientists, data engineers, Director of Engineering and CTO on building pipelines and ad optimization models. With access to over 500,000 data sets per second, there's no shortage of data and problems to tackle.

Learn more about our engineering culture here: https://www.stackadapt.com/artificial-intelligence-in-advertising

Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU
We'll be responding to applicants that have:
Proven experience architecting scalable ETL / machine learning pipelines (advertising technology experience preferred but not required)
Strong experience with Apache Spark
Strong programming skills in Scala (Golang and Python is a plus)
Experience in NoSQL databases such as HBase and Aerospike
Experience with data warehouse technologies such as Amazon Redshift, Hive
Experience with AWS, ElasticMapReduce, S3 and EC2 in particular
Experience working with small to mid-size teams, and a rapid development process
Experience with Airflow or other job scheduling libraries is a plus
Understanding of machine learning algorithms

StackAdapters enjoy:

Highly competitive salary
Full benefits from League on day one of employment
Coverage and support of personal development initiatives (conferences, courses, etc)
Fully stocked kitchen with healthy (and some not so healthy) snacks
Monthly presentations from global business leaders and innovators
An awesome parental leave policy
A weekly $15 lunch credit via Ritual
Our weekly Friday social events (sometimes on our 4000sq. ft. outdoor patio)
Quarterly team events like escape rooms, bubble soccer, obstacle courses, indoor skydiving, boat cruises, the list goes on…
About StackAdapt

StackAdapt is a self-serve programmatic advertising platform used by North America’s most exceptional digital marketers. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience. Ad buyers plan, execute, and manage data-driven digital advertising campaigns across all devices, inventory and publisher partners. Ranking a high performer by G2 Crowd in the DSP category for four consecutive years, StackAdapt is also recognized as a LinkedIn Top Startup in 2019.

Our office is located at King and Sherbourne near Toronto's historic Distillery District and the St. Lawrence Market. Our Walk, Bike and Transit Score are all over 90.

We've been recognized for our high performing campaign conversion rates, award winning customer service, and innovation by numerous industry publications including:

6th Fastest on Deloitte Technology's Fast 50 In Canada
StackAdapt’s New Chrome Extension Tackles Recruitment Bias
G2 Crowd's Highest Performing Demand Side Platform
The Globe and Mail 2019 Canada’s Top Growing Companies
Startup 50: The Complete Ranking of Canada’s Top New Growth Companies

StackAdapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. We are an equal opportunity employer and we are happy to work with applicants requesting accommodation at any stage of the hiring process. We welcome and encourage anyone and everyone to apply.",4.1,StackAdapt,Toronto,"Toronto, Canada",51 to 200 employees,2013,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1,95.0,7,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,3871,0
338,"Why We’re Rad (about us):
Rad Power Bikes is a leading consumer direct ebike manufacturer specializing in high quality yet affordable electric bikes for weekend warriors, hardcore commuters, and family cyclists.

Madly growing and located in Seattle, WA we are seeking a gifted Data Engineer to join our Vancouver team to help us design, build, and maintain the data-foundation that powers our warehouse and technologies that are central to Rad’s day-to-day operation, providing critical business value every day.

Our Data Engineer will be responsible for managing the interchange of data between systems, servers, employees and our Rad Riding customers. We are looking for someone who can architect, design and implement data processes that are crucial to Rad’s data-driven decisions. This role reports into our Director of Business Operations and Technology and is part of a cross-functional Technology department.
Why You’re Rad (about you):
5+ years of experience in a data engineering role, working with big datasets
Knowledge of professional software engineering practices & best practices for full software development life cycle, including coding standards, code reviews, source control management, continuous integration/deployments, testing and operations
Strong desire to work in a team environment
Ability to think and solve complex data engineering problems in a maintainable and scalable fashion
Desire to find new and better ways of doing things, generating original and imaginative ideas, products, and/or solutions
Desire to embrace documentation creation & maintenance
Ability to work independently and collaboratively with both local & non-local teammates
Strong problem solving and organizational skills
Impeccable written & oral communication skills with strong attention to detail
Additional Requirements:
Bachelor’s degree in Computer Science, Mathematics, Electrical Engineering or equivalent work experience
Expert knowledge and proficiency with SQL and no-SQL databases.
Familiarity with Big Data tools such as Google’s BigQuery
Experience with Visualization tools and libraries such as Power BI or Google’s Data Studio
Strong understanding of Dev Ops practices with a good understanding of AWS and Google Cloud infrastructure
You get bonus points for:
Experience working with Shopify’s systems and API
Experience with cloud-based ERPs and Warehouse Management Systems
Experience with NetSuite
Experience with GraphQL, BigQuery and Postgres
Open-source contributions or have personal projects you’ve shipped successfully
Project management experience
Had you been with us last month, you would have:
Developed business intelligence and reporting solutions
Utilized and built out the data warehouse foundation and set up the pipes for data sources
Managed the building of data and documentation across company wide systems
Worked cross functionally with all teams, including Supply Chain, Customer Experience, etc. to capture and report on inventory data
Evaluated the feasibility and effectiveness of proposed data solutions
Designed schemas, optimized data transformation, and managed deployments and maintenance of the data pipeline
Completed end-to-end administration and maintained tools, systems, pipelines and ETLs
Communicated designs, issues and trade-offs to stakeholders
Helped develop the foundational data stores that power our internal/external web apps and reporting systems
Dealt with 3rd party vendors, managing the relationships & troubleshooting high-level issues
Additional duties and overtime as required
Rad Power Bikes is proud to be an Equal Opportunity Employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.

If you need assistance or an accommodation due to a disability, you may contact us at 800-939-0310 or jobs@radpowerbikes.com.

Recruitment Agencies: Although we value the services you provide, at this time we are not leveraging external 3rd party recruitment resources for this search. Should those needs change, we will seek your assistance directly.",3.8,Rad Power Bikes,Vancouver,"Seattle, WA",201 to 500 employees,2007,Company - Private,Sports & Recreation,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1,95.0,13,data engineer,na,0,0,1,0,0,1,0,1,0,1,0,0,0,0,0,4348,0
339,"About Skillz:

Skillz is driving the future of entertainment by accelerating the convergence of sports, video games and media for an exploding mobile-first audience worldwide. The company's platform empowers mobile game developers and players with democratized access to fun, fair and skill-based competition for real prizes, shifting the paradigm to make eSports accessible to anyone, anywhere with a mobile device.

Skillz helps developers build multi-million dollar game franchises by turning content into competitive social gaming properties for the world's 2.6 billion gamers. The company has already worked with 13,000 game developers, leveraging its patented technology to host over 800 million tournaments for 18 million players worldwide.

This year, Skillz was recognized as one of Fast Company's Most Innovative Companies and CNBC Disruptor 50 (for the second time). In 2018, Skillz was listed as one of Forbes' Next Billion-Dollar Startups and Entrepreneur Magazine's 100 Brilliant Companies. In 2017, Inc. Magazine ranked Skillz the No. 1 fastest-growing private company in America.

The company is backed by leading venture capitalists, media companies, and professional sports luminaries, ranging from Liberty Global, Accomplice, Wildcat Capital, Telstra Ventures, and a founder of Great Hill Partners to the owners of the New England Patriots, Milwaukee Bucks, New York Mets, and Sacramento Kings.

Who we're looking for:

You're ready to take the next step in your Data Engineering career - to a fast-moving, successful company building out their next-generation streaming analytics infrastructure! You love data consistency and integrity. You consider yourself scrappy and a technologist, passionate about data infrastructure... with your attention to detail and insistence on doing things correctly, you know you can make a big impact on a small team! You're an excellent communicator and know that you grow faster from being able to mentor others.

What You'll Do:
Build new systems to provide real-time streaming analytics and event processing pipeline based on fast data architecture
Build enterprise grade data lake to support both business analytical needs and next generation data infrastructure
Building data integration toolkit for backend services
Support our data science team in deploying new algorithms for matchmaking, fraud and cheat detection
Find better ways to move massive amounts of data from a variety of sources to formats consumable by reporting systems and people
Improve monitoring and alarms that impact data integrity replication lag
Support our product development team in creating new events to measure/track
Your Skillz:

Basic Qualifications:
At least 4-5 years of experience in Scala/Java or Python programming
AWS data products (Data pipelines, Athena, Pinpoint, S3, etc)
Experience deploying data infrastructure
Experience with recognized industry patterns, methodologies, and techniques
Bonus:
Familiarity with Agile engineering practices
2+ years experience on Kubernete, Helm chart
4+ years of experience with Spark, Scala and/or Akka
4+ years of experience with Spark Streaming, Storm, Flink, or other Stream Processing technologies
2+ years of experience working with Kafka or similar data pipeline backbone
4+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python
3+ years' experience with NoSQL implementation (ElasticSearch, Cassandra, etc. a plus)
At least 4-5 years of experience with Unix/Linux systems with scripting experience
Familiarity with Alooma, Snowflakes
Familiarity with Kinesis, Lamda
Prior experience in gaming
Prior experience in finance
Skillz embraces diversity and is proud to be an equal opportunity employer. As part of our commitment to diversifying our workforce, we do not discriminate on the basis of age, race, sex, gender, gender identity, color, religion, national origin, sexual orientation, marital status, citizenship, veteran status, or disability status.",4.2,Skillz Inc.,Vancouver,"San Francisco, CA",201 to 500 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,95.0,8,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,3989,0
340,"About the Opportunity:

As part of the Data Hub team at AIR MILES, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flows and collection for cross functional teams. The pipeline needs to be scalable, repeatable, and secure. You will work with some of the largest and most varied data sets (both batch and real-time) in Canada. You will expand and develop the AIR MILES Cloud analytical platform that enables business users, data analysts and data scientists to make data driven decisions, build innovative data products and roll out advanced analytics.

What will you bring?
Ability and desire to work in our collaborative environment: open team room, pair programming and fluid interactions with all products and operations teams.
Focusing on building solutions utilizing an agile approach: close relationships with Product Managers, communicating and digesting real time feedback, and working smartly to build story cards on daily basis.
Passionate about Big Data and the latest trends and developments. We strongly believe in and encourage continuous learning.
You are self-driven, need minimal supervision and comfortable pushing your own projects and getting things done.
Experience with Python, Spark, and SQL
Experience building ‘big data’ pipelines, architectures, and datasets
Experience with Amazon AWS and other cloud platforms
Experience with Databricks
Experience with Agile methodologies as well as familiar with CI/CD tools (Jenkins, Travis, github)
Experience in ETL and Data Modeling preferred
Experience in designing and implementing streaming applications is preferred
Fully understand standard architecture methodologies, processes and best practices
About AIR MILES

Today, there are more ways than ever to engage shoppers. At AIR MILES, we believe that understanding the people behind the purchase is key to winning their hearts – and their wallets. For over two decades and from more than fifty locations around the globe, we have paired expertise in shopper behavior with advanced analytics to uncover the data-driven insights that drive successful loyalty, marketing and merchandising solutions. At AIR MILES, we know that in coming together we are at our strongest – and that together we can help shape the future for our clients, their shoppers and our communities. AIR MILES is an Alliance Data company. For more information, visit www.loyalty.com

About ADS

Alliance Data® (NYSE: ADS) is a leading global provider of data-driven marketing and loyalty solutions serving large, consumer-based industries. The Company creates and deploys customized solutions, enhancing the critical customer marketing experience; the result is measurably changing consumer behavior while driving business growth and profitability for some of today's most recognizable brands. Alliance Data helps its clients create and increase customer loyalty through solutions that engage millions of customers each day across multiple touch points using traditional, digital, mobile and emerging technologies. An S&P 500 and Fortune 500 company headquartered in Plano, Texas, Alliance Data consists of three businesses that together employ more than 16,000 associates at approximately 100 locations worldwide. For more information, visit www.alliancedata.com

Alliance Data is an Equal Employment Opportunity employer. Accordingly, we will make reasonable accommodations to respond to the needs of people with disabilities in accordance with legislation.

Alliance Data participates in E-Verify.

Check us out – AIR MILES on Stack Overflow | LinkedIn | Glassdoor | Facebook |Twitter | Blog | Instagram

Company: AIR MILES",-1.0,AIR MI,Toronto,"Toronto, Canada",501 to 1000 employees,1992,Company - Private,Advertising & Marketing,Business Services,$2 to $5 billion (CAD),-1,95.0,28,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,3691,0
341,"IT/IQ Tech Recruiters is seeking a Data Scientist to join our client in Victoria, BC.

Why work with our client?
Centrally located
Transit accessible
Competitive compensation
Responsibilities
Collaborates with team members, other IT teams, and customers to understand the organization’s business objectives, decisions and data in order to build the most effective analytical models
Uses statistical and mathematical techniques to undertake analysis including forecasting, segmentation and predictive modelling
Applies current and emerging techniques in deep learning, natural language processing and other machine learning areas
Designs, develops and conducts data science experiments and communicates the results to foster data and analytics literacy and adoption
Designs, develops and implements cloud-based AI and machine learning production pipelines
Ensures AI and machine learning production pipelines are scalable, repeatable and secure
Integrates structured and unstructured data from multiple sources for use in models and products
Collects, cleans, manages, analyzes and visualizes large sets of data using multiple data platforms, tools and techniques
Leads other internal resources on ad-hoc data and analytics requests, investigations, pilot studies, proofs of concept, and projects
Enhances data collection procedures to include information that is relevant to building advanced analytical models and provides input to other internal resources on the applications, databases and systems used to assess data quality
Communicates data science complexities in plain language to technical and non-technical audiences and develops reports and presentations
Keeps up to date with the latest technology trends and methods by staying abreast of state-of-the-art literature in the fields of deep learning, operations research, machine learning, statistical modeling, statistical process control and mathematical optimization
Identifies issues and risks, develops action plans, and takes corrective actions as needed
Undertakes special projects or assignments as required
Performs other related duties as required
Top Skills Required
Master’s Degree in Data Science, Statistics, Mathematics, Computer Science or a related discipline
A minimum of 5 years of experience as a Data Scientist or Data Analytics professional
Coding skills and deep proficiency with SQL, Python, R etc.
Competence at manipulating and analyzing complex, high-volume, high-dimensional data from varying sources
A flexible analytic approach that allows for results at varying levels of precision
Experience with version control systems (i.e. Git)
Demonstrated statistical, machine learning and other data science skills and capability for delivering effective modeling and analytics results
Must have excellent listening, communication, collaboration and problem-solving skills
Ability to understand business problems and bridge the gap between data analysis results and meaningful business insights
Must be legally eligible to work in Canada
Why work with us?
Build a long-term relationship with an experienced recruitment expert
Access to the ‘hidden’ job market – opportunities across Canada that aren’t posted on job boards
Get a high-level understanding of market dynamics affecting your industry
Gain insight into the culture of the company you’re applying for before submitting your profile
About Us

IT/IQ Tech Recruiters provides contract and permanent IT recruitment services to employers across Canada. We have a specialized approach to recruiting, segmenting our recruitment teams into specialty practice areas focusing on Development, PMO, Infrastructure and BI/CRM/ERP skill sets.

This approach enables our recruiters to become specialists; they know the market and work hard to understand each candidates’ capabilities, goals, career ambitions and quickly present them with the best possible opportunities. We are committed to helping candidates develop their careers and to helping our clients grow their business and complete important projects successfully.

We create opportunities for IT Professionals to empower business.",2.8,IT IQ TECH RECRUITERS LTD,Vancouver,"Vancouver, Canada",1 to 50 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (CAD),"Randstad, TEKsystems, TEEMA Solutions Group",95.0,18,data scientist,senior,1,1,0,0,0,1,0,0,0,0,0,0,1,1,1,4120,3
342,"(Senior) Principal Data Scientist

As a senior principal data scientist within our Personalized Health Care function you will work with partners throughout the global organization to use meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access. You would have the primary responsibility to design and implement analyses using a variety of data sources such as electronic medical records, insurance claims, patient registries, clinical trials, genomics, imaging and patient reported data (surveys, digital etc.). You will drive methodology development for use of real-world data for regulatory grade evidence generation and will partner with cross-functional teams and external organizations with considerable independence. This will require a deep understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical data science expertise.

Responsibilities
Drive methodology development for use of real-world data for regulatory purposes including but not limited to external controls, hybrid controls etc
Identify evidence needs & recommend data solutions: Ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.
Dive into data: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.
Produce high quality analyses: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to maximize impact and interpretability; implement and/or handle the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.
Collaborate & craft: Collaborate and contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaborations, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.
Minimum Qualifications:
MSc, PhD or similar qualification in a quantitative data science discipline (e.g., statistics/ biostatistics, epidemiology) with strong methodology focus
Consistent track record of developing and execution of data science research projects, patient-level data analyses (e.g., real world data, insurance claims, clinical trials, registries, surveys and digital health) with publications and presentations
Demonstrated experience with leading project scope and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges
Demonstrated strong collaboration skills and excellent communication skills; ambitious mindset and self-direction, ability to teach others and willingness to learn new techniques
Proficiency in English, both written and verbal
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Roche is an equal opportunity employer.

Research & Development, Research & Development > Biometrics",4.1,Roche,Welwyn,"Basel, Switzerland",10000+ employees,1896,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (CAD),"Novartis, AstraZeneca, Siemens Healthineers",95.0,124,data scientist,senior,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,3723,3
343,"What is Bold Commerce?
Named one of Canada’s fastest-growing tech companies by Deloitte, Bold Commerce is a software company specializing in innovative ecommerce apps and solutions for businesses of all sizes. We empower merchants both big and small by providing them with tools to make their ecommerce stores truly awesome.

Staples Canada, V-Dog and KONG Box are among the 90,000+ brands in over 170 countries around the world that trust Bold’s suite of ecommerce tools to power their online stores every day.

We're made up of more than 350 professionals (and growing) who live and breathe ecommerce, and truly give a shit about what we do. We call ourselves Builders. Here at Bold, we live by the BUILDERS Code, our shared set of practices, beliefs and values that help to shape this amazing company. We believe in challenging each other to create the best products and to constantly improve, all to ensure we deliver the best results to our merchants at all times.

Why work at Bold?
Our founders have worked to create and maintain a place that our employees look forward to coming to every day. A place where you can learn and grow, where your ideas are valued and where you can do cool things, all while contributing to the larger success of the company. At Bold we embrace and cultivate a culture of creativity, innovation, and collaboration in order to allow everyone to do their best work every day.

The Bold team is looking for a Senior Data Engineer to join the Data Analytics Team. This role will involve building out our cloud data warehouse to suit the needs of multiple business lines. In addition to building data pipelines, this role also includes building a clear data model, and documenting it in dbt. Additionally, the Senior Data Engineer will develop best practices for building data pipelines into Big Query that aggregate data from our applications for analytics purposes. The ideal candidate will have previously built a data warehouse (preferably Cloud) and will be able to confidently speak to best practices around warehouse design and data modeling. This person will also have the ability to communicate complex concepts to non-technical audiences.
Other key responsibilities include:
Designing, implementing, and maintaining large-scale batch and real-time scalable data pipelines with complex data transformations
Performing data wrangling to transform and map data from raw data forms into formats more appropriate and valuable for analytics
Writing and optimizing complex queries on large data sets
Assemble large, complex data sets that meet functional / non-functional business requirements
Developing workflows and tools that automate data loading processes and help ensure data quality and integrity
Evaluating new technologies and guiding the team through adoption
Providing feedback on projects owned by other members of the team
Contributing to a data-savvy culture
Here's what we need from you
Desire to get shit done
Belief in our core values
Bachelor’s Degree or higher in Computer Science or related discipline
5+ years of experience building data ingestion infrastructure
Expertise in designing, deploying, and automating data infrastructure frameworks in Python and SQL
Have taken a leading role in delivering complex software systems all the way from design to production
Experience working closely with business users and data analysts
Experience managing an entire data flow, ingesting data from a variety of sources including SQL, NoSQL, streams, and external APIs
Mastery of SQL and Python
Experience with cloud service providers, ideally GCP
Google Cloud Certified Data Engineer, a huge plus
Excellent verbal and written communication skills
Other skills that will get you far
Familiarity with Apache Kafka & Airflow
Experience with Salesforce
Being a generally awesome human being. We want someone cool to work with. It makes the office a better place for everyone. Impress us with anything else you can do! ­ Juggle knives, make a killer mixtape, or bake delicious pastries
At Bold, we work hard and we play hard! If you are a potential Builder and think you've got what it takes to be Bold, we encourage you to apply. We promise it will be a career like no other!

We get a lot of applicants, so we encourage you to do something that stands out. Go above and beyond when you apply so you don’t get lost in the mix. Talk about a cool project you’ve done, drop us a link to your github or portfolio if applicable, or just impress us with your personality.

Show us that you have what it takes to be Bold!",4.1,Bold Commerce,Winnipeg,"Winnipeg, Canada",201 to 500 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Ubisoft, SkipTheDishes, BigCommerce",95.0,8,data engineer,senior,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,4559,3
344,"You are a sharp, disciplined individual who has a passion for mobile games. Your experience helps to demonstrate your superior quantitative analytical skill and a scientific thought process. Your expertise paves the way for working with our game team to optimize every facet of player retention and monetization to ensure the continued success of our games. Large data sets are your playground and you can’t wait to join the fun!

Sound like a match? Kabam Vancouver is looking for a Senior Data Analyst to join us! We don’t just make games, we play and love them too.
You will contribute by:
Providing support to cross-functional teams across the organization to understand overall business goals, improve reporting, and assist with larger scale projects as needed
Finding answers to business questions via hands-on exploration of data sets using SQL, dashboards, statistical analysis, and data visualizations
Generating and maintaining a suite of dashboards and reports for teams throughout the organization
Creating and managing multiple A/B tests to gain valuable insights on KPIs including retention, acquisition, and monetization
Measuring the success of product features after release and optimize their performance through rapid, data-driven iteration
Aiding in task prioritization and general project management within the data team
Your background includes:
4+ years of industry data analysis experience, with solid knowledge of statistical methods
Bachelor’s Degree
Expert SQL skills and experience querying very large data sets
Proven ability to thrive using multiple mixed, varied, and inconsistent data sources
Fundamental knowledge of project management methodologies
Regular communication with stakeholders from other departments and drive actionable items for continuous improvement
It would be nice to have:
Experience with Google BigQuery, Tableau, JIRA and/or other project management software
Experience working for a social or mobile game developer
Understanding of game design concepts and principles
MBA or Master’s Degree
Together, we can create and support some of the best games ever made.

About Kabam
Kabam is a world leader of developing entertaining, immersive, and highly social multiplayer games for mobile devices. They merge consumer behaviour with the art of game design to create experiences that are enjoyed by millions of players across the globe. Each game has raised the benchmark in mobile gaming, bringing high-quality graphics, next-generation technology and revolutionary gameplay to the console in every player’s pocket.
Kabam has partnered with leading entertainment brands like Disney, Hasbro and Universal to create mobile games based on some of the world’s most iconic franchises.

Kabam’s games have generated hundreds of millions of downloads including Fast & Furious 6: The Game, Fast & Furious: Legacy, Marvel Contest of Champions, Transformers: Forged to Fight, Shop Titans and Mini Guns. These games have also received multiple awards such as Apple’s Editor’s Choice and Google Play’s Best Game of the Year.

Founded in 2006, Kabam has studios and offices in Vancouver, Montreal, Charlottetown, San Francisco and Austin. Kabam is a wholly-owned subsidiary of Netmarble Games.",4.1,Kabam,Vancouver,"Vancouver, Canada",501 to 1000 employees,2006,Company - Private,Video Games,Media,Unknown / Non-Applicable,"GREE, Electronic Arts, Glu Mobile",95.0,14,data analyst,senior,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,3231,3
345,"As a (Senior) Principal Data Scientist within our Personalized HealthCare function you will work with meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access.

You will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions. The data will be varied in type -- patient-level clinical data, supplemented with deep patient data such as omics (e.g. genomics, proteomic), imaging, digital health, etc. Source data will be diverse -- real-world data, including patient registries, electronic medical records, claims, biobanks, and clinical trials. The evidence and insights will be used to inform the research and development of our molecules, and support healthcare decisions by patients, physicians, health authorities, payers, and policy-makers. You will also contribute to functional, cross-functional, enterprise-wide or external initiatives that shape our business and healthcare environments. This will require a good understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical expertise in observational research. You will need strong strategic, collaboration and communication skills, as well as an entrepreneurial mindset, to transform the way we use data and analytics to develop and deliver medicines for our patients.

As (Senior) Principal Data Scientist you will typically be expected to contribute to the molecule/disease area for multiple or complex projects with minimal supervision. You will contribute to the development of new concepts, techniques, and standards using your expertise in epidemiology. We will look to you as a positive role model for peers and you will coach colleagues to improve in their role with both technical and interpersonal skills.

RESPONSIBILITIES
IDENTIFY EVIDENCE NEEDS & RECOMMEND DATA SOLUTIONS: Ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.
DEVELOP DATA STRATEGY & GAIN ACCESS TO DATA: Develop strategic plans to access fit-for-purpose data sources to support evidence generation, and gain access to data through collaboration or data generation.
DIVE INTO DATA: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.
BE AN EXPERT IN APPLYING METHODS: Stay current with and adopt emergent analytical methodologies, tools and applications to ensure fit-for-purpose and impactful approaches.
PRODUCE HIGH QUALITY ANALYSES: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to maximize impact and interpretability; implement and/or oversee the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.
INTERPRET AND SHARE RESULTS: Communicate findings to internal stakeholders, regulatory, health technology assessment (HTA) bodies and scientific communities; publish results; participate in external meetings and forums to present your insights (e.g. congress/conference).
COLLABORATE & SHAPE: Collaborate and contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaborations, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.
MINIMUM QUALIFICATIONS

We are looking for a professional with MSc or PhD in epidemiology, pharmacoepidemiology or biostatistics/public health (with focus on epidemiology/observational research) and minimum of 2 years working in a relevant department in pharmaceutical development. You will bring:
Demonstrated track record of developing and executing epidemiological or outcomes research projects, with publications and presentations
Demonstrated experience with managing project scope and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges
Demonstrated strong collaboration skills and excellent communication skills
Demonstrated entrepreneurial mindset and self-direction, ability to teach others and willingness to learn new techniques
Proficiency in English, both written and verbal
Track record of effectively working in a matrix environment with global, international team members coming from scientific, business and operational backgrounds, using influence without authority
PREFERRED/ADDITIONAL QUALIFICATIONS
PhD degree as listed in Minimum Qualifications
Relevant work experience especially with managing internal and external stakeholder collaborations
Proven ability to translate and communicate complex study design and findings to diverse audiences
Roche is an equal opportunity employer.

Research & Development, Research & Development > Modelling & Simulation",4.1,Roche,Welwyn,"Basel, Switzerland",10000+ employees,1896,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (CAD),"Novartis, AstraZeneca, Siemens Healthineers",95.0,124,data scientist,senior,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,5539,3
346,"Senior Data Engineer

Nomis is looking for an outstanding data expert to join our team. The Data Engineer will collaborate closely with our client services team to process critical data while working to power advanced analytics and enable the integration of data science across the company. You are ready to be flexible and nimble in your work, from constructing ETL pipelines for customer delivery to participating in exploratory data analysis with our Analytics team.

Who We Are & What We Build

We partner with Banks and FinTechs on their journey to best-in-class pricing technology and analytics so that they deliver more value to their customers, employees and shareholders. Our top-notch people, proven technology, and innovative analytics are tackling big data challenges at banks and lenders every day. We deliver market-leading cloud-based Pricing & Profitability Management solutions and insights for the Banking & Financial Services industry leveraging cutting-edge behavioral data science. We are a Blue Chip venture-backed company with the vision to transform the consumer banking landscape.

Responsibilities
Establish and maintain big data processing platform
Build data management applications and microservices on AWS
Design and implement Hive/Greenplum/RedShift distributed data warehouses and standard schemas
Design, develop, maintain cross-platform ETL processes and MapReduce/Hive/Spark data processing workflows
Manage and maintain reference data securely on S3 and other storage systems
Support client services teams by:
Manage, customize, and automate cloud-based (AWS) data processing supporting multiple clients
Administration of relational databases, capacity plans, infrastructure and storage design
Oversee and execute data migration from existing data stores
Application/implementation of custom analytics applications and datasets
Develop code standards, guidelines, and automated test suites to ensure highest data quality and integrity
Desired Skills and Requirement
Experience with building distributed systems, query processing, and the Hadoop ecosystem
Understanding of Data warehousing - architect and design data warehouse
Expertise with data schema - logical and physical data modeling
Knowledge of ETL processes and tools
Experience with AWS or a major cloud platform such as GCP
Proficiency in: Python, SQL, Java
Strong pluses:
Experience of Business Intelligence tooling such as Tableau
Experience with data mining techniques and analytics functions
Predictive analytics experience is a PLUS
Experience with Spark 2, Apache Airflow and other modern data engineering tooling a strong plus
Experience with streaming architectures and MPP databases such as Greenplum a strong plus
Up-to-date with the open-source community w.r.t. data engineering
Experience with the following services in AWS a strong plus: EMR, Lambda, Kinesis, Firehose, S3",3.8,Nomis Solutions,Toronto,"San Bruno, CA",51 to 200 employees,2004,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (CAD),-1,95.0,16,data engineer,senior,0,1,0,1,0,1,1,1,0,0,0,0,0,0,0,2883,0
347,"Description:
Skip, as a division of Just Eat- Takeaway, is searching for a Senior Data Engineer to join the Data Systems team. Youll have the opportunity to work with big data technologies, building scalable and reliable solutions to support real-time analytics, advanced data science and critical operational projects powered by data.

What We Do

The Data Systems teams role is to build a transformational data platform in order to democratize data in Just Eat. Our team is built on the following ideals:
Open Data: We ingest all data produced across Just Eat using batch and real-time pipelines and make it available to every employee in Just Eat. This data is then used to drive analytics, business intelligence, data science and critical business operations.
Self Service: We build tools, frameworks and processes to support self-service modelling and activation of data. Our goal is to empower our users to find, process and consume our data without barriers.
Single Truth: We build services that host all metadata about Just Eats data in a single store and promote governance, data culture and Single Source of Truth.
Intelligent Personalisation: We build and maintain a machine learning platform that supports data scientists in developing and deploying ML models at production scale. This allows us to deliver insights, personalization and predictions to our customers at scale.
How We Do It

Our team is built on the following tenets:
Innovate: We are always learning, growing, inquisitive and keen on new technologies and open source tooling. We love like-minded engineers with a passion to keep our code-base and infrastructure best in class.
Build for Scale: All our tools and components are built for scale and we use Kubernetes and other tools to help us scale automatically.
Cloud-based: We use serverless technologies where possible to simplify our estate, technologies like BigQuery, PubSub, Dataflow and Cloud functions allow us to move quickly. In addition, we run a Kubernetes cluster on GKE with many workloads including instances of Apache Airflow.
DevOps culture: Everyone in the team contributes to infrastructure, we have a CI/CD pipeline and we define our infrastructure as code. Our stack includes Terraform, Jenkins and Helm. Teams monitor their applications using Prometheus, Grafana and alert manager.
Collaboration & Ownership: All code is owned by the team and we have multiple avenues for collaboration - rotation, pairing and technical showcases. We also encourage team members to own their own code and promote self-governance.
Were looking for an enthusiastic engineer to join the Self Service Tools team within Data Systems

Self Service Tools

Our mission is to enable all employees to be self-sufficient with data so that data-driven decisions can be made quickly and easily. We build and maintain all of Just Eats data-centric tools.

We use engineering to simplify tasks, reducing the technical barrier of entry to navigate, explore and consume our data. Our tools use Airflow to unlock the tasks of transformation and egress of data, making these simple functions that can be undertaken by anyone.

We support over 200 active users across the business, building Airflow backed tools that run thousands of DAGs in multiple timezones. We manage and run our own Airflow clusters on Kubernetes. We work together as a team in three countries to produce innovative products and keep data flowing.

You should apply if
You love writing well tested, readable and performant code, capable of processing large volumes of data. You have mastery in Scala and/or Python.
You love working with Cloud technologies and have experience in working with AWS, Azure or Google Cloud. We use Google Cloud with a mix of services - Kubernetes, Dataflow, PubSub etc.
You can contribute to architecture discussions and influence peers and stakeholders to make better decisions.
You have the inclination to collaborate and the ability to communicate technical ideas clearly.
You understand the entire product development lifecycle, from coding to deployments, to monitoring, alerting etc... Our teams maintain all aspects of our product lifecycle, but we dont expect everyone to be an expert in all of it.
You understand the fundamentals of computing and distributed systems.
What Its Like To Work At Skip:

Picture this: you, dressed in your fave casual attire, amongst a team of friendly and passionate colleagues. You feel pride knowing your input and uniqueness is not only embraced, but makes an impact on a major Canadian company, and its satisfied customers. As the company grows, so do youyou meet and surpass new challenges every day.

This is just a taste of what its like to work at one of Canadas leading tech companies. If youre hungry for opportunity, growth, and something meaningful in a dynamic yet casual environment, wed love to hear from you.

Note: All employees will be asked to sign a Consent for Disclosure of Personal Information in order to complete a background check. Job offers will be conditional upon results that the Company determines to be satisfactory.",3.3,SkipTheDishes,Winnipeg,"Winnipeg, Canada",201 to 500 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,95.0,7,data engineer,senior,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0,5103,0
348,"SSENSE is looking for a Senior Data Engineer to join our rapidly growing technology team. The Senior Data Engineer will take complex features of the product roadmap, break them down into their required technical components, and develop them independently. They own at least one component of the SSENSE technical stack and hold accountability for its SLAs. The ideal candidate will actively contribute to knowledge dissemination within the organization, participate in the recruiting and onboarding of new employees, and mentor Junior Developers on the team.

RESPONSIBILITIES
Product delivery
Build, test and operate stable, scalable data pipelines that cleanse, structure and integrate disparate data sets into a readable and accessible format for end-user facing reports, data sciences and ad-hoc analyses
Develop a deep understanding of the product roadmap for the squad, including future features to be developed
Contribute to high-level estimation and participate in laying out the development sequences, challenging the product roadmap and identifying areas where technical debt can be reduced or avoided
Complete independently complex development tasks and actively contribute to pushing code to production
Write testable, efficient, and reusable code suitable for continuous integration and deployment, respecting best practices and SSENSE development standards
Review Unified Modeling Language (UML) diagrams and technical documentation

Ownership and accountability
Be accountable for code quality by conducting adequate testing
Be accountable for performance, reliability, scalability and resilience of at least one technical component owned by the squad through SLAs and monitoring
Solve complex technical problems and mentor/support other technical staff on data modeling and ETL related issues
Contribute to cross-squad initiatives, acting as a change agent amongst peers to foster adoption of new processes or technical solutions

Knowledge sharing and coaching
Review Pull Requests with the objective to guide and upskill other Data Engineers on various technical topics
Actively contribute to SSENSE University (the internal peer learning platform) to promote continuous learning
Participate in the onboarding of new Data Engineers

Architecture
Contribute to solution designs, challenging other members on technical decisions and explaining the technical design to junior developers so they can write documentation for the rest of the team

Recruiting
Participate in HR recruiting events, helping to identify and recruit top developers

REQUIREMENTS
Bachelor’s degree in Computer Science, Engineering, or a related technical field, Master’s degree an asset
A minimum of 5 years of Functional Programming and/or Object Oriented Programming (OOP) experience
A minimum of 3 years experience writing and optimizing SQL queries
A minimum of 3 years experience with Apache Spark for big data processing
Extensive knowledge of Python programming language and its data manipulation libraries (Pandas and Numpy)
Expertise in data modeling and an advanced understanding of data architecture
Expertise with RDBMS and NoSQL databases at scale
Experience with Apache Airflow or other similar data pipelining and workflow scheduling framework (Luigi, Azkaban)
Ability to use containers, orchestration frameworks, and other DevOps tools (Kubernetes, Terraform, Giant Swarm, etc.)
Proficiency with cloud resources (AWS/Google Cloud/Azure) with the ability to operate them for the components owned, Certification is an asset.
Knowledge of the AWS services (Redshift, Glue, Athena, S3, etc.) an asset
Knowledge of big data technology (Databricks, Hadoop, Hive, Pig, Presto) an asset
Familiarity with continuous integration and automated pipeline tools (Jenkins, Travis, etc.)
Proficiency in Git
Strong written and verbal communication skills in both English and French

SKILLS
Highly analytical and detail oriented
Ability to coach and mentor junior employees to achieve personal and professional goals
Team player with a high sense of accountability and ownership
Ability to influence and drive change
Solution-oriented mindset and can-do attitude to overcome challenges
Ability to thrive in a fast-paced environment and master frequently changing technologies and techniques

----------

SSENSE est à la recherche d’un ingénieur de données principal pour joindre son équipe technique en pleine croissance. La personne détentrice du poste analysera les fonctionnalités complexes de la stratégie produit pour déterminer les composantes techniques requises et les développer de façon indépendante. L’ingénieur de données principal est responsable d’au moins une composante de la pile technique SSENSE ainsi que des niveaux de service associés. Il participera activement au partage de connaissances au sein de l’entreprise ainsi qu’au recrutement et à l’intégration de nouveaux employés, en plus d’agir à titre de mentor auprès des ingénieurs de données.

RESPONSABILITÉS
Livraison produit
Construire, tester et mettre en opération des pipelines de données stables et adaptables pour épurer, structurer et intégrer des ensembles de données hétérogènes dans un format compréhensible pour les rapports destinés aux utilisateurs finaux, à la science des données et aux analyses ad hoc
Comprendre en profondeur la stratégie produit de l’équipe ainsi que les fonctionnalités à développer
Contribuer à l’estimation et à l’élaboration de séquences de développement, par la remise en question de la stratégie produit et l’identification des dettes techniques
Effectuer des activités complexes de développement de manière autonome et soutenir activement l’intégration du code dans la production
Mettre au point des solutions de code testables, efficaces et réutilisables, applicables à l’intégration et au déploiement continus, en phase avec les meilleures pratiques et les standards de développement SSENSE
Réviser les diagrammes de langage de modélisation unifié (UML) et la documentation technique correspondante

Engagement et responsabilité
Assumer la responsabilité de la qualité du code en réalisant les tests adéquats
Assumer la responsabilité du rendement, de la fiabilité, de l’évolutivité et de la résilience d’au moins une des composantes techniques complexes de l’équipe, au moyen de supervision et d’ententes de niveau de service
Résoudre des problèmes techniques complexes et mentorer d’autres membres du personnel technique quant à la modélisation de données et aux enjeux relatifs à l’extracto-chargeur (ETL)
Contribuer aux projets interéquipes par la promotion du changement et de l’adoption des nouveaux processus ou solutions techniques

Coaching et partage de connaissances
Réviser les Pull Requests afin d’orienter le perfectionnement des ingénieurs de données sur divers sujets techniques
Contribuer activement à SSENSE University, une plateforme d’apprentissage destinée aux employés, afin de promouvoir l’apprentissage continu
Participer à l’intégration de nouveaux ingénieurs de données

Architecture
Participer à la conception de solutions, questionner l’équipe quant à ses décisions techniques et expliquer le design technique aux développeurs afin qu’ils rédigent de la documentation pour le reste de l’équipe

Recrutement
Participer aux activités de recrutement des ressources humaines et soutenir la recherche et l’identification des meilleurs développeurs

EXIGENCES
Baccalauréat en informatique, ingénierie ou un dans un domaine technique connexe; maîtrise, un atout
Un minimum de cinq ans d’expérience en programmation orientée objet et/ou en programmation fonctionnelle
Un minimum de trois ans d’expérience en rédaction et optimisation de langage de requête structurée (SQL)
Un minimum de trois ans d’expérience avec Apache Spark pour le traitement de mégadonnées
Notions avancées du langage de programmation Python et des bibliothèques de manipulation de données (Pandas et Numpy)
Expertise en modélisation de données et connaissances approfondies en architecture de données
Maîtrise à grande échelle des bases de données relationnelles (SGBDR) et des systèmes de gestion de bases de données (NoSQL)
Expérience avec Apache Airflow et avec d’autres outils de pipelines de données et de gestion de flux de travail (Luigi, Azkaban)
Capacité à utiliser les conteneurs et les logiciels d’orchestration intégrés ainsi que d’autres outils de DevOps (Kubernetes, Terraform, Giant Swarm, etc.)
Maîtrise des ressources infonuagiques (AWS, Google Cloud, Azure) et habileté à les employer pour les composantes possédées; la détention d’une certification dans le domaine est un atout
Connaissance des services AWS (Glue, Athena, S3, Spark, etc.), un atout
Connaissance des technologies de mégadonnées (Databricks, Hadoop, Hive, Pig, Presto), un atout
Familiarité avec les outils d’intégration continue et de pipelines automatisés (Jenkins, Travis, etc.)
Maîtrise de Git
Excellentes habiletés en communication écrite et verbale tant en français qu’en anglais

COMPÉTENCES
Sens de l’analyse et souci du détail
Aptitudes en coaching des employés pour l’atteinte de leurs objectifs individuels et professionnels
Esprit d’équipe et fort sens de la responsabilité
Force d’influence et de changement
Esprit déterminé, positif et orienté vers la recherche de solutions pour surmonter les obstacles
Habileté à s’épanouir dans un environnement à rythme accéléré et à maîtriser les technologies web en évolution fréquente

Note: le masculin est employé dans le seul but d’alléger le texte et inclut par défaut tous les genres.",3.9,SSENSE,Montreal,"Montreal, Canada",501 to 1000 employees,2003,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1,101.0,17,data engineer,senior,0,1,0,0,0,1,1,1,1,1,0,0,0,0,0,9527,0
349,"Dimensional Strategies Inc. (DSI) is currently looking to expand its rapidly growing Data Analytics team. We Specialize in the development of solutions based on the Microsoft Data Platform. DSI is looking to add several resources to the team.

At DSI we value aptitude, work ethic, and a desire to learn amongst a team that believes collaboration is key. If this sounds like a place you might like to work and you feel that your experience matches the requirements below, we encourage you to contact us.

This is a full time / permanent role.

Essential skills of the Data Analytics Developer(s)

· Strong customer facing skills with the ability to conduct requirement workshops.

· Excellent team player, with demonstrated project leadership skills.

· 12 months - 2 years experience with Data Lake, HDInsight, Data Factory, building application in Azure

· 5-7 years experience using MSFT stack of tools: SSIS, SSAS, SSRS, SQL Server

· Experience with DAX and data Modeling

· Azure Analysis Services Tabular model experience

· Fluent with modern analytical development patterns and platforms.

· Expert in the Microsoft data platform including tabular modeling and PowerBI.

· A hands-on, roll up your sleeve’s developer, who is passionate about analytics.

· Great communication skills, written and spoken.

· Experience dealing with multiple clients and projects.

· Excellent verbal communication and the ability to understand and communicate a project in both business and technical terms is a must.

Nice to have skills for the Senior BI Developer:

· Experience with agile software development

· Experience in establishing BI governance, standards, practices, and methods with a good understanding of the relevance of the business change agenda when designing, implementing and communicating

· Ability to work in a fast-paced environment

All interested candidates should submit a copy of their resume with their application, submissions without will not be considered.

Job Types: Full-time, Permanent

Salary: $70,000.00 - $100,000.00 per year

Benefits:
Casual Dress
Dental Care
Disability Insurance
Discounted or Free Food
Life Insurance
On-site Parking
Paid Time Off
Profit Sharing
Vision Care
Work From Home
Schedule:

8 Hour Shift
Monday to Friday
COVID-19 considerations:
During COVID we give our employees the option of working from home full time.

Experience:
data analytics: 5 years (Preferred)
Work remotely:
Yes",-1.0,Dimensional Strategies Inc. (D,Mississauga,-1,-1,-1,-1,-1,-1,-1,-1,101.0,-1,data engineer,na,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,2438,0
350,"Faites une différence !

Workforce Edge aide les organisations du secteur de la santé à mettre en place des pratiques exemplaires de planification des horaires du personnel et de transformer les pratiques de gestion de la main-d’œuvre. Plus de 70 % des budgets de santé sont consacrés à la dotation en personnel, et les organisations dépendent de la présence d'une main-d'œuvre engagée et qualifiée pour fournir des soins de qualité à tous les Canadiens. Nos projets améliorent la vie professionnelle des employés, offre une plus grande mobilisation des employés, un meilleur contrôle sur les coûts de main d’œuvre, et la capacité de prodiguer des meilleurs soins aux usagers et leurs familles.

Nous sommes présentement à la recherche d’un conseiller/analystebilingue (français/anglais), qui possède une expérience dans la planification des horaires de modèles 24h/24, 7j/7 ou engagé dans les secteurs RH/RT de la planification des horaires du personnel. Il peut s'agir de postes antérieurs en tant que planificateur, coordonnateur, ou commis en planification des horaires ; analyste de la main-d'œuvre ; ou des postes similaires au sein des ressources humaines ou de la planification de la main-d'œuvre dans des secteurs tels que les soins de santé, les compagnies aériennes, le secteur manufacturier ou les technologies de l’information.

En tant que Conseiller Workforce Edge:

Nous avons toujours été une équipe qui travaille à domicile, et la plupart des jours seront consacrés en télétravail au sein d’une équipe répartie à travers le Canada et travaillant à distance avec nos clients (par téléphone, courriel et réunions en ligne). Dans ce rôle vous devrez analyser les données relatives aux salaires et aux horaires des clients et préparer des tableaux et des graphiques, à contribuer à l'examen des horaires et des pratiques de planification des horaires, à concevoir et à assurer la qualité des horaires, soutien l'amélioration des processus d'affaires et à préparer des projets de rapports et de présentations. Vous contribuerez également à l'amélioration continue de nos outils et méthodologies.

La participation aux réunions interne et avec des clients par téléphone / réunion en ligne sera nécessaire au quotidiennes pour clarifier les données, présenter et revoir les livrables, et soutenir les conseillers principaux en documenter les éléments de discussions, les plans d’action et les mesures à prendre. Occasionnellement, vous vous rendrez sur les sites des clients, en travaillant avec des conseillers principaux pour documenter les résultats des entrevues et des groupes de discussion, aider la conception de processus, soutien les activités de formation et mise en œuvre et participer à d'autres réunions et activités sur place. En moyenne, les voyages d'affaires durent de 3 à 4 jours et la plupart des conseillers effectuent entre 6 et 12 voyages par an (bien que pendant la pandémie COVID, nous ne demandons pas de déplacement sur les sites des clients).

Si ce poste vous intéresse:

Veuillez envoyer votre CV ainsi qu’une lettre de présentation en anglais qui comprends les éléments suivants :
Votre expérience avec la planification des horaires, les difficultés rencontrées et les solutions proposées.
Si vous avez déjà travaillé avec un système informatisé de gestion des horaires, puis décrivez ce système et ses fonctions principales.
Si vous avez une expérience du travail à domicile, décrivez comment vous aimez organiser votre travail pour rester productif dans un environnement de bureau à domicile.
Compétences requises pour ce poste:

Excellent Niveau:
Excel - Tableaux croisés dynamiques, graphiques, mise en forme conditionnelle, formule et programmation, fonctions de nettoyage des données.
Très bon Niveau:
Word - Mise en forme avec Styles
Microsoft Outlook
Power Point
Agréable d'avoir:
Visio
Statistiques - Probabilité, conception de l'étude, inférence et association
Analyse d’affaire - conception de processus, la configuration système requise
Travailler à domicile

Voyage d'affaires - Occasionnel, 6 à 12 voyages par an. (Bien que pendant la pandémie COVID-19, nous ne demandons pas de déplacement sur les sites des clients)

Nous apprécions votre intérêt pour ce poste. Nous répondrons à tous les candidats qualifiés. Toutefois, nous vous demandons d’être patient car l'examen de votre candidature peut prendre un certain temps. Seuls les candidats qualifiés seront retenus pour le processus de recrutement, qui comprendra des entretiens dans les deux langues officielles, test de compétences Excel et la vérification des références.

-----------------------------------------------------

Bilingual Consultant, Data Analyst

Make a difference!

Workforce Edge helps our healthcare clients implement effective staff scheduling practices. Over 70% of healthcare budgets are spent on staffing, and organizations depend on having an engaged and skilled workforce to deliver quality patient care for all Canadians. Our projects improve the working life for employees and reduce the cost of delivering care.

We are looking for a Consultant & Data Analyst who is bilingual (English/French) and has past experience scheduling for a 24/7 workforce or involved in the HR/LR aspects of staff scheduling. This could include past positions as a scheduler, scheduling clerk, scheduling analyst, workforce analyst, or similar positions in HR or workforce planning in industries such as health care, airlines, manufacturing, or IT.

As a Workforce Edge Consultant:

We have always been a remote team, and most days will be spent working at your home office, connecting with consultants across Canada and with client contacts by phone, email, and online meetings. Your normal activities will be to analyze client payroll and schedule data and prepare tables and charts, contribute to reviews of schedules and scheduling practices, design and QA schedules, support business process improvements, and prepare draft reports and presentations. You will also contribute to continuous improvements of our tools and methodologies.

Attendance at internal and client meetings by telephone/online meeting will be required daily to clarify data, present and review draft deliverables, record client input, and support senior consultants by documenting discussion items and action items. Occasionally, you will travel to client sites, working with senior consultants to record the results of interviews and focus groups, support process design, training and implementation activities, and participate in other on-site meetings and activities. On average, business travel is 3-4 days duration and most consultants complete between 6-12 trips per year (although during the COVID pandemic, we are not requiring travel to client sites).

If this position interests you:

Please send your CV and a cover letter in English that includes the following:
Your experience with scheduling, the difficulties encountered and the proposed solutions.
If you have ever worked with a scheduling software system, please describe this system and its main functions.
If you have experience working from home and how you like to organize your work to stay productive in a home office environment.
Skills required for this position:

Excellent Skill Level:
Excel – Pivot tables, charts, conditional formatting, formula and programming, data cleanup functions
Very Good Skill Level:
Word – Formatting using styles
Microsoft Outlook
Power Point
Visio
Nice to Have:
Statistics– Probability, Study Design, Inference and Association
Business Analysis – business processes, system requirements
Required: Work from home office

Business travel: Occasional (6-12 trips per year - although during the COVID pandemic, we are not requiring travel to client sites).

We will respond to all qualified applicants, but please be patient as it may take time to review your application. Only qualified candidates will move forward with the recruiting process which will include interviews in both official languages, Excel skills testing, and reference checks.

Type d'emploi : Temps Plein, Permanent

Horaire :

Du Lundi au Vendredi
Mesures COVID-19:
Pendant la pandémie COVID-19, nous ne demandons pas de déplacement sur les sites des clients.

Langue:
Français et Anglais (Requis)
Télétravail:
Oui",-1.0,Workforce Edge Consult,Toronto,-1,-1,-1,-1,-1,-1,-1,-1,101.0,-1,data analyst,na,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,8284,0
351,"Data Analyst Team Lead Citis Innovation labs is a global network of innovation centers focused on delivering cutting edge solutions to Citis Capital Markets, Securities Services and Banking lines of businesses. Our Mission is to create a competitive advantage for our clients, manifested as change in the way they operate, by providing innovative technological solutions with strong client engagement, from idea to production, and by leveraging the entrepreneurship spirit. We are currently looking for an excellent data analyst team lead to join one of our cutting edge trade surveillance solutions. It is a highly advanced trade monitoring and analytics product used globally among Citis trading desks. Job Description Recruit and Manage a team of talented data analysts Explore and analyze datasets to develop new robust controls Work with business partners to design new workflows to transform business requirements into concrete insights Onboard data across the various financial markets via multiple consumption methods (Message buses, SFTP, SQL connectors) Develop automated procedures to improve and optimize existing controls Work together with the R&D team to help guide the Platform roadmap Experience & Qualifications Experience managing data/business analysts 2+ people management and 5+ years total experience is required Strong leadership and management skills Ability to manage senior stakeholder relationships Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to details and accuracy Solid experience in working with data and relational / non-relational databases Hands-on experience in Scripting Languages (Python / R) Experience in troubleshooting code and logs advantage Experience in Linux Advantage BS/BA in Software Engineering or Computer Science advantage, or in Industrial Engineering, Mathematics, Statistics or Economics Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - CA ------------------------------------------------------ Time Type : ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.5,Citibank,Mississauga,"Elk Grove Village, IL",5001 to 10000 employees,-1,Subsidiary or Business Segment,Lending,Finance,$50 to $100 million (CAD),-1,101.0,-1,data analyst,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,1,3245,0
352,"Company Description
Do you know Techo-Bloc’s precious stones?

Headquartered on the south shore of Montreal, Techo-Bloc is the leader in product innovation in its industry. Our pavers, retaining walls and masonry materials are a model of beauty, quality and durability. As we strive for continuous improvement, we are constantly engaging in new challenges, products and niches to remain at the forefront of our industry.
Job Description
The primary role of the Data Analyst, Demand Planner is to develop a demand forecast for our finished goods using different data sources. Your primary role will be to collect data and apply statistical methods to provide insights to key stakeholders within the company. In addition, you will support our purchasing department by establishing and updating Min-Max inventory levels for products purchased, including resale, consumables etc.
Develop monthly rolling forecasts at multiple levels of aggregation and time horizons.
Collaborate with Sales & Marketing to ensure alignment of Production Forecasts with Sales Forecasts and company strategy.
Follow-up on weekly snapshots across the distribution network and assess trends.
Provide input in developing forecasts for new products.
Monitor alignment between Supply and Demand.
Manage Short-term and long-term forecasting & demand planning, involving complex modeling.
Study demand variability and external variables affecting our demand and deviations between actual orders and forecasts.
Develop safety strategies to account for forecast inaccuracy, lead time and other factors.
Perform data analysis, with a wide variety of statistical methods including cluster, regression, decision tree, random forest, time series, neural network and others.
Monitor demand and analyze forecast exceptions; perform root cause analysis to identify errors and take necessary corrective actions to drive continuous improvement in forecast accuracy.
Participate actively in the monthly Supply Planning Meeting and future S&OP meeting.
Establish strong relationships with peers and work cross-functionally with Supply Planning, Operations, Purchasing, Customer service, Replenishment, Sales and Marketing, and Finance teams.
Ad hoc analysis.

Qualifications
Bachelor’s degree in business, Engineering, Computer Science, Supply Chain Management, Statistics, Mathematics, or related field;
Minimum 2-3 years of experience in Demand Planning/data and analytics role;
Very high attention to details and commitment to meet deadlines;
Strong interest in data analytics, data transformation and problem-solving skills;
Advanced Knowledge: Microsoft Excel (Pivot tables, experience with cubes, data analysis tool pack, graphs etc.);
Advanced statistical and forecasting knowledge (hypothesis testing, linear regression, qualitative and quantitative forecasting methods);
Additional tools: Power BI, VBA, SQL, R, or Python (an asset);
Strong communication and presentation skills with a proven ability to understand key demand-planning concepts and to explain technical terms to a non-technical audience;
Ability to work under pressure, both individually and within a team environment;
Ability to work successfully with minimal direction in a fast-paced environment, handling multiple projects simultaneously in a dynamic environment;
Language requirements: Bilingual (French and English)

Additional Information
We offer an excellent compensation program
Competitive base pay
Bonus Program, Comprehensive Group Insurance
Working for the # 1 manufacturer in landscaping product innovation
Dynamic work atmosphere
We thank all applicants for their interest; however, only those under consideration will be contacted.

Indeed001
I'm interested
Cookies Settings",3.6,Techo-Bloc,Saint-Hubert,"Saint-Hubert, Canada",201 to 500 employees,1989,Company - Private,Industrial Manufacturing,Manufacturing,$100 to $500 million (CAD),-1,101.0,31,data analyst,na,0,1,1,0,1,1,0,0,0,0,0,0,0,0,1,3722,0
353,"IT/IQ Tech Recruiters is seeking a Machine Learning Engineer to join our client in Toronto, ON.

Why work with our client?
Certified Great Place to Work
Weekly delivery of groceries for the office
Competitive compensation
Responsibilities
Perform ETL with massive data from multiple applications and 300 M+ customers
Architect, design and evaluate novel approaches for handling high-volume real-time data streams in an inferencing environment
Own the development, training, optimizing, and deployment of machine learning systems
Develop measurement and feedback systems at web scale to improve the selection of features and/or algorithm design
Top Skills Required
Strong software development skills (+3 years working experience), with proficiency in Python or Scala preferred
Experience in building ETL pipelines to perform feature engineering on large-scale dataset using Big Data technologies such as Spark
Ability to explain and present analyses and machine learning concepts to a broad technical audience
Ability to initiate and drive projects to completion with minimal guidance
Knowledge in advanced data structures and can use them to solve problems
You have a Masters degree or equivalent in Computer Science, Engineering, Mathematics or related field
Working knowledge of PyTorch, Tensorflow or other similar frameworks is a plus
Creative, collaborative, & product focused
Must be legally eligible to work in Canada
Why work with us?
Build a long-term relationship with an experienced recruitment expert
Access to the ‘hidden’ job market – opportunities across Canada that aren’t posted on job boards
Get a high-level understanding of market dynamics affecting your industry
Gain insight into the culture of the company you’re applying for before submitting your profile
About Us

IT/IQ Tech Recruiters provides contract and permanent IT recruitment services to employers across Canada. We have a specialized approach to recruiting, segmenting our recruitment teams into specialty practice areas focusing on Development, PMO, Infrastructure and BI/CRM/ERP skill sets.

This approach enables our recruiters to become specialists; they know the market and work hard to understand each candidates’ capabilities, goals, career ambitions and quickly present them with the best possible opportunities. We are committed to helping candidates develop their careers and to helping our clients grow their business and complete important projects successfully.

We create opportunities for IT Professionals to empower business.",2.8,IT IQ TECH RECRUITERS LTD,Vancouver,"Vancouver, Canada",1 to 50 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (CAD),"Randstad, TEKsystems, TEEMA Solutions Group",101.0,18,machine learning engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,2525,3
354,"Job description:

Location: Toronto, ON or Montreal, QC

If working with billions of events, petabytes of data and optimizing for last millisecond is something that excites you then read on! We are looking for Data Engineers who have seen their fair share of messy data sets and have been able to structure them for building useful AI products.

You will be working on writing frameworks building for real time and batch pipelines to ingest and transform events(108 scale) from 100s of applications every day. Our ML and Software engineers consume these for building data products like personalization and fraud detection. You will also help optimize the feature pipelines for fast execution and work with software engineers to build event driven microservices.

You will get to put cutting edge tech in production and freedom to experiment with new frameworks, try new ways to optimize and resources to build next big thing in Fintech using data!

Requirements:
You have previously worked on building serious data pipelines ingesting and transforming > 10 ^6 events per minute and terabytes of data per day.
You are passionate about producing clean, maintainable and testable code part of real-time data pipeline.
You understand how microservices work and are familiar with concepts of data modelling.
You can connect different services and processes together even if you have not worked with them before and follow the flow of data through various pipelines to debug data issues.
You have worked with Spark and Kafka before and have experimented or heard about Flink/Druid/Ignite/Presto/Athena and understand when to use one over the other.
On a bad day maintaining zookeeper and bringing up cluster doesnt bother you.
You may not be a networking expert but you understand issues with ingesting data from applications in multiple data centres across geographies, on-premise and cloud and will find a way to solve them.
Proficient in Java/Scala/Python/Spark
Job #43631",3.6,Tundra,Montreal,"Toronto, Canada",201 to 500 employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,101.0,16,data engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,1969,0
355,"Coursera is a leading online learning platform for higher education, where 64 million learners from around the world come to learn skills of the future. More than 200 of the world’s top universities and industry educators partner with Coursera to offer courses, Specializations, certificates, and degree programs. 2,500 companies trust the company’s enterprise platform Coursera for Business to transform their talent. Coursera for Government equips government employees and citizens with in-demand skills to build a competitive workforce. Coursera for Campus empowers any university to offer high-quality, job-relevant online education to students, alumni, faculty, and staff. Coursera is backed by leading investors that include Kleiner Perkins, New Enterprise Associates, Learn Capital, and SEEK Group.

Data Engineering is unique at Coursera. Our team doesn’t simply build reports on demand. Rather, we build the semantic infrastructure and products that empower our internal and external customers with the data to innovate and perform their jobs better.
We’re looking for a senior data engineer in Toronto who can help us drive data engineering efforts for our platform. In this role, you will work with cross-functional teams to design, develop, and deploy data solutions. Our ideal candidate is an independent, analytically-minded individual with strong data modeling and engineering skills, who shares our passion for education.
Your responsibilities
Architect scalable data models and build efficient and reliable ETL pipelines to bring the data into our core data lake
Design, build, and launch visualization and self-serve analytics products that empower our internal and external customers with flexible insights
Be a technical leader for the team; guide technical and architectural designs for the major team initiatives; mentor junior members of the team
Build data expertise, and partner with data scientists, product managers and engineers to define and standardize business rules and maintain high-fidelity data
Define and partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently
Work cross-functionally (eg: product managers, engineers, business teams) to support new product and feature launches
Your skills
5+ years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science
Strong data engineering skills and at least one scripting language (e.g., Python)
Proficient with relational databases and SQL
Familiarity and experience with big data technologies (eg: Hive, Spark, Presto) preferred
Ability to communicate technical concepts clearly and concisely
Independence and passion for innovation and learning new technologies

If this opportunity interests you, you might like these courses on Coursera -

Big Data Specialization

Big Data Essentials: HDFS, MapReduce and Spark RDD

Data Warehousing for Business Intelligence

Coursera is an Equal Employment Opportunity Employer and considers all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, age, marital status, national origin, protected veteran status, disability, or any other legally protected class.

If you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, please contact us at accommodations@coursera.org.

Please review our CCPA Applicant Notice here.",3.9,Coursera,Toronto,"Mountain View, CA",501 to 1000 employees,2012,Company - Private,Colleges & Universities,Education,Unknown / Non-Applicable,-1,101.0,8,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,3526,0
356,"Reporting to the Technical Director, you will collaborate along side a team of other accomplished developers, delivering complex development projects for internal systems across a variety of products and technologies.

You will be challenged across several creative projects and responsibilities, including the opportunity to influence the future direction of the department and systems used across the business.

To apply for this role, you will have a strong technical capability and a proven track record in software development/ data engineering. You are motivated and experienced in taking responsibility and being on point for both departmental and business projects.

Key Responsibilities:
Design, model and maintain data sets to support reporting analytics and exploratory analysis
Can understand and contribute to the technical solution from design through to code level
Contribute to technical design and ongoing development of our custom ETL solutions and analytics platforms, and help improve overall design and delivery standards
Work with big data developers to build scalable and supportable infrastructure
Employ a variety of languages and tools (e.g. scripting languages) to marry systems together
Recommend and support the implementation available and latest big data technologies
Participate in reviews and meetings
Recommend ways to improve data, efficiency and quality
Work with data architects, modelers and IT team members on project goals
Contribute to post implementation reviews demonstrating success
Work on multiple projects involving the implementation of new and existing systems, solutions and processes
Desired Experience:
We are looking for a candidate with 5+ years of experience in a Data Engineer role, who has attained a Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field.
Should also have experience using the following software/tools:
Experience with big data tools including: Hadoop, HDFS, Hive, Spark, Storm and Impala
Experience with relational query authoring (SQL) and NoSQL databases, including Postgres and Cassandra.
Experience with data pipeline and workflow management tools such as Airflow
Experience with AWS cloud services: ECS, EKS, EMR, RDS, ELB, and Docker
Experience with Snowflake
Experience with object-oriented/object function scripting languages: Python, C#, SQL, NoSql and SnowSQL
Working knowledge of message queuing, stream processing, and scalable big data data stores
Experience working with unstructured datasets
Experience performing root cause analysis on all data and processes to answer specific fiscal questions while identifying opportunities for improvement
Experience in the physical and logical design of database architecture for relational databases, data warehouses and data lakes.
Experience with database optimization, data replication, database recovery and performance tuning.
Excellent personal organization
EA is an equal opportunity employer. All employment decisions are made without regard to race, color, national origin, ancestry, sex, gender, gender identity or expression, sexual orientation, age, genetic information, religion, disability, medical condition, pregnancy, marital status, family status, veteran status, or any other characteristic protected by law. EA also makes workplace accommodations for qualified individuals with disabilities as required by applicable law.",3.9,Electronic Arts,Vancouver,"Redwood City, CA",5001 to 10000 employees,1982,Company - Public,Video Games,Media,$2 to $5 billion (CAD),"Riot Games, Google, Activision Blizzard",101.0,38,data engineer,senior,0,1,0,0,0,1,1,1,0,0,0,0,0,0,1,3429,3
357,"About Pinterest:

Millions of people across the world come to Pinterest to find new ideas every day. Its where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. As a Pinterest employee, youll be challenged to take on work that upholds this mission and pushes Pinterest forward. Youll grow as a person and leader in your field, all the while helping users make their lives better in the positive corner of the internet.

Within the Content Signals team, youll be responsible for building machine learning signals from NLP and CV components to productionizing the end product in batch and real-time setting at Pinterest scale. Our systems offer rich semantics to the recommendation platform and enable the product engineers to build deeper experiences to further engage Pinners. In understanding structured and unstructured content, we leverage embeddings, supervised and semi-supervised learning and LSH. To scale our systems we leverage Spark, Flink and low-latency model serving infrastructure.

What youll do:
Apply machine learning approached to build rich signals that enable ranking and product engineers to build deeper experiences to further engage Pinners
Own, improve, and scale signals over both structured and unstructured content that bring tens of millions of rich content to Pinterest each day
Drive the roadmap for next generation content signals that improve content ecosystem at Pinterest
Work in a fast-paced environment with a quick cadence of research, experimentation, and product launches
What were looking for:
5+ years of relevant industry experience
Deep expertise in content modeling at consumer Internet scale
Strong ability to work cross functionally and with partner engineering teams
Expert in Java, Scala or Python
#LI-EA2",4.0,Pinterest,Toronto,"San Francisco, CA",1001 to 5000 employees,2010,Company - Public,Internet,Information Technology,$100 to $500 million (CAD),-1,101.0,10,machine learning engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,1875,0
358,"Join SADA as a Sr. Data Engineer!

Your Mission

As a Sr. Data Engineer at SADA, you will work collaboratively with architects and other engineers to recommend, prototype, build and debug data infrastructures on Google Cloud Platform (GCP). You will have an opportunity to work on real-world data problems facing our customers today. Engagements vary from being purely consultative to requiring heavy hands-on work and cover a diverse array of domain areas, such as data migrations, data archival and disaster recovery, and big data analytics solutions requiring batch or streaming data pipelines, data lakes and data warehouses.

You will be expected to run point on whole projects, end-to-end, and to mentor less experienced Data Engineers. You will be recognized as an expert within the team and will build a reputation with Google and our customers. You will demonstrate repeated delivery of project architectures and critical components that other engineers demur to you for lack of expertise. You will also participate in early-stage opportunity qualification calls, as well as lead client-facing technical discussions for established projects.

Pathway to Success

#BeOneStepAhead: At SADA we are in the business of change. We are focused on leading-edge technology that is ever-evolving. We embrace change enthusiastically and encourage agility. This means that not only do our engineers know that change is inevitable, but they embrace this change to continuously expand their skills, preparing for future customer needs.

Your success starts by positively impacting the direction of a fast-growing practice with vision and passion. You will be measured quarterly by the breadth, magnitude, and quality of your contributions, your ability to estimate accurately, customer feedback at the close of projects, how well you collaborate with your peers, and the consultative polish you bring to customer interactions.

As you continue to execute successfully, we will build a customized development plan together that leads you through the engineering or management growth tracks.

Expectations

Required Travel - 30% travel to customer sites, conferences, and other related events. Due to the COVID-19 pandemic, travel has been temporarily restricted.

Customer Facing - You will interact with customers on a regular basis, sometimes daily, other times weekly/bi-weekly. Common touchpoints occur when qualifying potential opportunities, at project kickoff, throughout the engagement as progress is communicated, and at project close. You can expect to interact with a range of customer stakeholders, including engineers, technical project managers, and executives.

Training - Ongoing with first-week orientation at HQ followed by a 90-day onboarding schedule. Details of the timeline can be shared.

Job Requirements

Required Credentials:
Google Professional Data Engineer Certified or able to complete within the first 45 days of employment
Required Qualifications:
Mastery in at least one of the following domain areas:
Data warehouse modernization: building complete data warehouse solutions, including technical architectures, star/snowflake schema designs, infrastructure components, ETL/ELT pipelines, and reporting/analytic tools. Must have hands-on experience working with batch or streaming data processing software (such as Beam, Airflow, Hadoop, Spark, Hive).
Data migration: migrating data stores to reliable and scalable cloud-based stores, including strategies for near zero-downtime.
Backup, restore & disaster recovery: building production-grade data backup and restore, and disaster recovery solutions. Up to petabytes in scale.
Experience writing software in one or more languages such as Python, Java, Scala, or Go
Experience building production-grade data solutions (relational and NoSQL)
Experience with systems monitoring/alerting, capacity planning and performance tuning
Experience in technical consulting or customer-facing role
Useful Qualifications:
Experience working with Google Cloud data products (CloudSQL, Spanner, Cloud Storage, Pub/Sub, Dataflow, Dataproc, Bigtable, BigQuery, Dataprep, Composer, etc)
Experience with IoT architectures and building real-time data streaming pipelines
Experience operationalizing machine learning models on large datasets
Demonstrated leadership and self-direction -- a willingness to teach others and learn new techniques
Demonstrated skills in selecting the right statistical tools given a data analysis problem
About SADA

Values: We built our core values on themes that internally compel us to deliver our best to our partners, our customers and to each other. Ensuring a diverse and inclusive workplace where we learn from each other is core to SADA's values. We welcome people of different backgrounds, experiences, abilities and perspectives. We are an equal opportunity employer.
Make them rave
Be data driven
Be one step ahead
Be a change agent
Do the right thing
Work with the best: SADA has been the largest partner in North America for GCP since 2016 and has been named the 2019 and 2018 Google Cloud Global Partner of the Year. SADA has also been awarded Best Place to Work by Inc. as well as LA Business Journal!

Benefits: Unlimited PTO, competitive and attractive compensation, performance-based bonuses, paid holidays, rich medical, dental, vision plans, life, short and long-term disability insurance, 401K with match, professional development reimbursement program as well as Google Certified training programs.

Business Performance: SADA has been named to the INC 5000 Fastest-Growing Private Companies list for 12 years in a row garnering Honoree status. CRN has also named SADA on the Top 500 Global Solutions Providers for the past 5 years. The overall culture continues to evolve with engineering at its core:3200+ projects completed, 3000+ customers served, 10K+ workloads and 25M+ users migrated to the cloud.",4.7,SADA,Toronto,"North Hollywood, CA",51 to 200 employees,2000,Company - Private,IT Services,Information Technology,$100 to $500 million (CAD),-1,101.0,20,data engineer,senior,0,1,0,0,0,1,1,0,0,1,0,0,1,0,0,5910,0
359,"Company Profile

TTT Studios is a digital innovation studio working for a global client list in multiple industries. Over the past eight years, we have built multiple applications and patented a portfolio of technologies. This experience puts us in a strong position to cater to larger accounts and launch our own products.

We are a family. We have fun. Design means everything to us and we have the technical chops to deliver what lesser programmers might describe as spooky magic. We expect amazing things from every TTT family member and drive each other to achieve greatness.

Role Summary - Big Data Engineer (Contractor)

We are looking for a talented and experienced big data engineer who is meticulous with designing and then developing data platforms for TTT Studios' client projects. The ideal candidate should have a deep understanding of best practices when it comes to building data pipelines and applications to stream and process datasets at low latencies.

Job Specifics
Big data platform architecture design.
Large dataset processing and migration.
Writing clean, readable, and testable code.
Ensuring the best performance and user experience of the application.
Seeing through a project from conception to finished product.
Work closely with the engineering team.
Documenting architecture and technical specs for a backend application.
Directly conversing with clients and stakeholders.
Skills and Qualifications
3+ years of experience in big data analytics platform.
Expertise in Spark, Akka, Kafka/Pulsar, AWS EKS
Experience in Cassandra database and Snowflake platform.
Proficient in Scala/Java programming language.
Experience writing technical documentation and software architecture.
Understanding of REST APIs, OOP, and related best practices.
Nice to have: Python, Ruby on Rails
Nice to have: Experience building CI/CD pipelines.
Hiring Process
Complete this application and include your resume or CV.
If your profile matches what we are looking for, we'll contact a you and setup a short phone call.
We will also setup an interview at our offices or via Zoom. We'll talk about your experience, what do you think about patterns, architecture, and some common situations while developing an app.
We will send you a challenge your way! You will be working with the team solving a specific task regarding an API and a backend service.
After finishing the code challenge, we'll come to a decision.
A Day at TTT Studios

The work culture at TTT is second to none. On arrival, head to the kitchen for your daily caffeine fix before joining the team in our open-plan office space. Once you've settled in, our engineering team will onboard you with our development processes and technical standards. Equipped with the tools you need, get ready to jump into action. Working from home is always an option.

Our clients operate across a wide range of industries that span from tourism to communications. For every project you take on, you’ll encounter intellectually stimulating and impactful technical challenges that keep you on your toes. For an idea of some of the projects we’ve taken on in the past, check out our case studies here.

As you work, keep your eyes peeled for our office dogs who will trot by and welcome you to the TTT family. To help combat work stress, our perks include work flexibility, monthly happy hours, weekly lunch & learns, yoga lessons twice a week, and a cozy massage chair overlooking Vancouver’s scenic waterfront. The team at TTT is passionate about creating software that impacts lives, and management does everything it can to plant the seeds that will propel you to greater heights.

More from Us

TTT Studios is an award winning digital innovation studio focused on empowering businesses through technology. #1 ranked Canadian custom software and mobile app developer. Our values are integrity, passion and excellence. We’re obsessed with delivering quality work. That’s why our team consists of designers and engineers of the highest calibre. We also strongly believe in empowering the community by being heavily involved in local and international events as speakers, educators, and sponsors. Whether you’re a developer, designer, management or co-op student, every single person here contributes to who we are as a company.",4.6,TTT Studios,Vancouver,"Vancouver, Canada",1 to 50 employees,2010,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Atimi Software, Dynamic Leap, Finger Food Advanced Technology Group",101.0,10,data engineer,na,0,1,0,0,0,0,1,1,0,0,0,1,0,0,0,4282,3
360,"Using our industry-leading game engine, we are creating a whole new line of products and services centered around running massively scaled simulations in the cloud. What we create will impact multiple industries such as Robotics and Autonomous Vehicles, and contribute to the advancement of the field of Artificial Intelligence.

The visual machine learning team in AI@Unity is focused on building robust tools to train, test, and validate autonomous systems using simulated environments. This requires visual content understanding, content generation, flexible yet accurate simulated sensors including LIDARs, cameras, and radars, and self-supervised learning.

We are looking for an exceptional Senior Machine Learning Engineer to push the boundaries of what is possible in the world of cloud-based simulations. If you're passionate about using synthetic data for computer vision, creating better autonomous vehicles and robots, and launching products from the ground-up, then we want to talk with you!

Responsibilities
Research and implement state of the art algorithms for domain adaptation and self-supervised learning
Implement state of the art models for a range of standard Computer Vision tasks to drive user engagement with the Unity simulation platform
Lead junior machine learning engineers with technical decisions to deploy models to the cloud and integrate them with new or existing services
Keep up to date with the latest in simulations, perception, and computer vision research
Requirements
B.Sc. in Data Science, Machine Learning, Statistics, Computer Science, Applied Math, or an experience in equivalent highly technical field
Hands-on experience in Computer Vision, Computer Graphics, or Machine Learning projects
Hands-on experience building production models with TensorFlow, PyTorch, or equivalent deep learning framework
Proven ability to ship quality software products and services
Bonus Points
Ph.D. in Data Science, Machine Learning, Statistics, Computer Science, Applied Math, or an equivalent technical field
Significant contributions to open-source software
Published research in areas of Machine Learning at major conferences and/or journals
Experience with Unity Engine, 3D simulators, game development and graphics
Excellent communication skills with the ability to build relationships across the company
About Unity Technologies

Unity is the world's leading platform for creating and operating real-time 3D (RT3D) content. Creators, ranging from game developers to artists, architects, automotive designers, filmmakers, and others, use Unity to make their imaginations come to life. Unity's platform provides a comprehensive set of software solutions to create, run and monetize interactive, real-time 2D and 3D content for mobile phones, tablets, PCs, consoles, and augmented and virtual reality devices.

The company's 1,400+ person research and development team keeps Unity at the forefront of development by working alongside partners to ensure optimized support for the latest releases and platforms. Apps developed by Unity creators were downloaded more than three billion times per month in 2019 on more than two billion unique devices. For more information, please visit www.unity.com.

Unity is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. Therefore, we provide employment opportunities without regard to age, race, color, ancestry, national origin, religion, disability, sex, gender identity or expression, sexual orientation, or any other protected status in accordance with applicable law. If there are preparations we can make to help ensure you have a comfortable and positive interview experience, please let us know.

Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Unity does not accept unsolicited headhunter and agency resumes. Unity will not pay fees to any third-party agency or company that does not have a signed agreement with Unity.

#LI-MH1 #SEN",4.9,Unity Technologies,Vancouver,"San Francisco, CA",1001 to 5000 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Epic Games, Electronic Arts, Zynga",101.0,15,machine learning engineer,senior,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,4042,3
361,"Autodata Solutions is currently looking for an Artificial Intelligence Machine Learning Engineer to join their growing team!

Position Overview:

The AI Machine Learning Engineer will work among our AI R&D team to streamline and reinvent the current data processes within the enterprise. This role will also collaborate with data science and software engineering teams in the US, China and other geographies to develop and deliver best-in-class data engineering solutions to support our market research and data science product and services offerings.

Key Responsibilities:
Lead the engineering and the management of our data assets, which are the core foundation of our new and existing product offerings;
Understand data assets that empower our products and services;
Identify inefficiencies in our current data ecosystem by working closely with our database administrators, data scientists, and software engineers;
Develop and deploy a scalable and robust cloud-based data ecosystem working closely with our Cloud Architect;
Migrate our current data assets to the new data system seamlessly and support the current product/service offerings on the new system;
Help expedite the development of new product/service offerings on the new system in close collaboration with data science and software engineering teams;
Maintain the new system to ensure on-time delivery of products and services;
Develop comprehensive and automated Q/A and Q/C tools for products;
Utilize knowledge of event based or asynchronous programming architecture, micro server architecture, or server less environment
Qualifications:
7-10+ years of demonstrated experience in end-to-end development of machine learning and artificial intelligence (A.I.) products and services
Masters or Ph.D. out of the following disciplines: Math: statistics, probability, predictions, calculus, algebra, Bayesian algorithms and logic, Sciences: physics, mechanics, cognitive learning theory, language processing ; Computer Science: data structures, programming, logic and efficiency
Prior experience of managing the creation and deployment of Machine Learning solutions for the retail space
Hands-on software development experience with object oriented and/or functional programming
Strong experience in predictive analytics, machine learning, optimization, and agile product development
Demonstrated knowledge of common frameworks and libraries in AI such as: TensorFlow /Torch, PyTorch/PyText/FastText, scikit-learn, Theano, Caffe, Keras, Microsoft Cognitive Toolkit
Experience in designing a production environment on Cloud, creating model scoring pipelines, and deploying AI/ML models through REST API
Deep experience in SQL, NoSQL databases, Python, Flask, R, Java, C++/C#, AWS and/or other Cloud products and services
For more information about Autodata Solutions, check out our website at www.autodatasolutions.com

When you work for an Autodata Solutions company, you join a team of dedicated professionals who are always looking for new ways to raise the bar. It takes talent, ambition and forward thinking to meet the challenges of our exciting and rapidly evolving market.

Autodata Solutions is the industry leader of technology, merchandising and sales solutions for the automotive industry. We have set the industry standard by providing the most up-to-date and innovative data, content, and platform capabilities all the essentials to create and manage engaging digital experiences for consumers and end users. We are committed to transforming the customer journey through a better vehicle consideration, purchase, and ownership experience.

We thank all applicants for their interest, however, only those selected for an interview will be notified. Autodata Solutions is an equal opportunity employer. We are compliant with AODA legislation; if you require work-related accommodations, please specify.

Powered by JazzHR",2.5,Autodata Solutions,London,"London, Canada",501 to 1000 employees,1990,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (CAD),-1,101.0,30,machine learning engineer,na,0,1,0,0,0,1,0,1,0,0,0,0,1,0,1,3896,0
362,"@SYNNEX, we believe everyone has a story to tell. If you have a passion for advancing technology solutions, always putting customers first and want to become part of a team that embraces differences and creates trends, build your career story with us. We strive to create a work environment that is fun and inclusive with a sense of work-life balance and charitable giving.

Our recruiting experience is digital!

Technology is at the core of our business – we don’t just sell technology, we use it. The power of digital interviewing allows you the flexibility of using your computer or mobile device to record your interview on your own schedule in the comfort of your home. Our recruiting process allows you to tell your story in a stress-free way that is interactive and fun, so if you receive a link to Share your Story with us, we hope you have an awesome digital experience.

Business Systems Analyst (Data Analyst)


You will be the data analyst of SYNNEX IT, working with IT leadership, ERP business system analysts and the technical data management team utilizing report writing resources to help compile IT data relating to initiatives and strategies.

Get Inspired by the Work You’ll Do
Active member of our SYNNEX IT Digital Transformation task force
You will be working with SYNNEX global IT teams which includes US, Canada, China, Japan and LATAM
Responsible for data modeling and analytics using statistical techniques and provide ongoing reports
Identify, analyze, and interpret trends or patterns in complex data sets
Know how to analyze data, data modeling and data presentation
Locate and define new process improvement opportunities
Manage projects and resources (not a people manager)
Your passion is sparked by:
Bachelor of Science (BS or equivalent) in Mathematics, Economics, Computer Science, Information Management or Statistics coupled with 4-5 years of industry experience
Strong Power BI and related experience
Technical expertise regarding data modeling, mining and segmentation techniques
Proven working experience as a Data Analyst or Business Data Analyst
Experience of industrial data analysis. Supply chain industry experience is a plus
Strong analytical skill with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
Demonstration of logical thinking, problem solving capability
Business Intelligence experience
Big Data experience – such as Vector or equivalent
SQL or equivalent experience
Project management experience
AI/ML knowledge or experience is a plus
We have Great Perks • 3-weeks’ vacation • Every day is Casual Day • Comprehensive Group Health Insurance plan • Profit Sharing Opportunity • Employee Referral Award program • Employee Purchase Plan/ Company Discounts • Out of Country travel assistance • Health/ Wellness initiatives • Paid Sick Days • Employee Assistance Program • Education Reimbursement • Milestone Service Awards • Community Involvement activities in partnership with Kids Help Phone • Employee of the Quarter awards • Group RRSP with Company Matching • Training Opportunities • Huang Leadership Development Scholarship • Bi-annual President’s Club • Annual Founders Award

Be Inspired In Your Career.


@ SYNNEX Corporation, we believe employees are our greatest asset and we empower them to make a difference in our business. Diversity and inclusion makes us all better. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, age, disability, protected veteran status, and all other protected statuses.

@ SYNNEX Canada Limited, we are committed to supporting accommodation and inclusivity for persons with disabilities throughout the recruitment process and employment lifecycle. If you require accommodation during the recruitment and selection process, please let us know; we will work with you to meet your needs.

Note: The preceding job description has been designed to indicate the general nature and level of work performed by employees with this classification. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications required of employees assigned to this job.",3.3,SYNNEX,Toronto,"Fremont, CA",10000+ employees,1980,Company - Public,Enterprise Software & Network Solutions,Information Technology,$10+ billion (CAD),"Ingram Micro, Tech Data",101.0,40,data analyst,na,0,0,1,0,0,1,1,0,0,0,0,0,0,0,1,4301,2
363,"Role and Responsibilities

(English follows)

Lorsque vous prenez l’avion, peu importe la destination, il y a de fortes chances que le pilote ait été formé par CAE. Le point focal étant les clients, l’équipe Accélérateur numérique s’engage à rehausser l’expérience de formation afin de s’assurer que les pilotes soient les meilleurs possible.

Voici quelques raisons pour lesquelles les employés aiment travailler à CAE!
Travail significatif qui favorise le perfectionnement professionnel
Possibilité de travailler dans l’industrie technologique et de s’y épanouir
Environnement de travail axé sur la collaboration
Faire partie d’une équipe à haut rendement

Votre mission

À titre d’ingénieur des données, votre mission est d’améliorer l’expérience client en faisant la transformation des données dans un format pouvant être utilisées à des fins de prédiction. Cela sera accompli principalement par l’élaboration, l’entretien et la mise à l’essai d’infrastructures destinés à la production de données. Vous jouerez un rôle important dans la promotion de solutions d’architecture pour des projets de science des données et de modélisation avancée.

Votre rôle et responsabilités principales

Être le leader de la stratégie d’intelligence artificielle
Créer et maintenir une architecture de pipeline de données optimale et évolutive.
Assembler des ensembles de données complexes qui respectent les exigences opérationnelles fonctionnelles et non fonctionnelles.
Concevoir l’infrastructure requise pour l’extraction, la transformation et le chargement de données optimaux à partir d’une grande variété de sources de données et de technologies de « données massives ».
Définir, concevoir et mettre en œuvre des améliorations de processus internes : l’automatisation des processus manuels, l’optimisation de la transmission de données, la nouvelle conception de l’infrastructure pour une plus grande évolutivité, etc.
Mettre au point des outils d’analyse qui utilisent le pipeline de données pour fournir des perspectives applicables en matière d’acquisition de clients, d’efficacité opérationnelle et d’autres mesures clés du rendement opérationnel.
Maintenir les données séparées et en sécurité à travers les frontières nationales par l’entremise de plusieurs centres de données.
Travailler avec des experts en données et en analyse pour parvenir à une meilleure fonctionnalité de nos systèmes de données.
Être un contributeur-clé dans la transformation de l’entreprise
Travailler avec des intervenants, y compris les équipes de la direction, de l’expérience client et de la conception pour les assister dans la résolution de questions techniques liées aux données et le soutien de leurs besoins en infrastructure.
Être un collègue inspirant et motivant
Partager des connaissances avec les membres de l’équipe et prendre des initiatives de partage de connaissances hors de l’équipe de science des données
Être un agent de changement et un promoteur de la mentalité agile
Contribuer au milieu de travail collaboratif et stimulant
Être actif dans la communauté d'intelligence artificielle de Montréal et d'ailleurs pour trouver de nouvelles possibilités de collaboration et pour amener de nouvelles idées

Vos qualifications
Volonté de participer à tous les niveaux de l’exécution des travaux liés à un projet.
Excellentes aptitudes pour la communication verbale et écrite, en français et en anglais.
Compétences techniques
Baccalauréat en informatique, en ingénierie ou un domaine connexe.
Au moins trois (3) ans d’expérience dans l’industrie en matière de travail avec des données, de code, de création de scripts (Python/Java/Scala/SQL/JS/Bash), de conception, et de mise à l’essai.
Au moins trois (3) ans d’expérience en matière d’élaboration et d’administration de gros systèmes de données.
Solides connaissances des principes fondamentaux du soutien à la clientèle en matière d’algorithmes et de structures de données.
Expérience en soutien et en travail avec des équipes interfonctionnelles dans un environnement dynamique Expérience en utilisation d’outils de traitement de données massives : Hadoop, Spark, Kafka.
Expérience en utilisation de bases de données relationnelles SQL et NoSQL, y compris Serveur SQL et CosmosDb.
Expérience en utilisation de pipelines de données automatisées et d’outils de gestion du flux de travail : DevOps, ARM, Data Factory, Airflow.
Expérience en utilisation de services infonuagiques Microsoft : Azure, Databrick.
Expérience en utilisation de systèmes de traitement de flux : Storm, Spark-Streaming.
Ce que nous avons à offrir
Avantages sociaux : entièrement flexibles pour que vous puissiez choisir ce qui est important
Retraite : Régime de retraite à prestations déterminées et régime enregistré d’épargne-retraite (REER) collectif
Avantages financiers : Régime d’actionnariat et nombreux rabais d’entreprise
Programmes personnels et familiaux : Plan de bien-être physique et prestations de maternité complémentaires
Équilibre travail-vie personnelle : Horaires flexibles et « vendredis californiens » toute l’année
Plaisir au travail : Activités sociales et communautaires tout au long de l’année!

À CAE, il est très important de créer des liens avec les gens. Si vous avez des questions au sujet de cette possibilité de carrière, n’hésitez pas à communiquer avec Nadine Dubois, spécialiste, acquisition de talents (nadine.dubois1@cae.com), Marc-André Proulx, Spécialiste technique (marc-andre.proulx@cae.com) ou Sofiane Hocine, gestionnaire de produits numériques (sofiane.hocine@cae.com).

Joignez-vous au moteur de changement à CAE - notre prochain horizon de croissance passe avant tout par l’innovation numérique afin d’appuyer la réussite de nos clients.
***************************

If you’ve taken a plane to any destination in the world, chances are, your pilot was trained by CAE. With its strong customer focus, the Digital Accelerator team is dedicated to elevating the training experience to make pilots the best they can be.

Here are few reasons why folks love working at CAE!
Meaningful work that drives professional development
Ability to enter and grow within the technology industry
Work in a collaborative environment
Be part of a high-performance team

Your Mission

As a member of the Data Science team, your mission is to transform data into a format that can be consuming for other analytics stakeholders by developing, maintaining and testing infrastructure for data generation. You will also play an instrumental role enabling architecture solutions for Data Science and advance modelling projects.

Your Role & Main Responsibilities

Be a key contributor to the AI & Data Science Strategies
Create and maintain optimal and scalable data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources and ‘big data’ technologies.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Keep data separated and secure across national boundaries through multiple data centers.
Be an active member of the business transformation
Work with stakeholders including the Executive, CX and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Be an inspirational and motivational colleague
Be an inspirational and motivational colleague
Share knowledge with team members & participate in various learning-sharing activities
Contribute to the collaborative and stimulating work environment
Be a change agent & Agile mindset promoter
Be connected to the industry to know tendencies and suggest innovative ideas
Your Qualifications

Softskills
Willingness to participate in all levels of project work when necessary.
Excellent English and French written and verbal communication skills.
Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.
Technical skills
Bachelor's degree in Computer Science, Engineering, or related field.
A minimum of 3 years industry experience working with data, coding and scripting (Python/Java/Scala/SQL/JS/Bash), design and testing.
A minimum of 3 years experience developing and administering large data systems.
Solid knowledge of CS fundamentals in algorithms and data structures.
Experience supporting and working with cross-functional teams in a dynamic environment. Experience with big data tools: Hadoop, Spark, Kafka.
Experience with relational SQL and NoSQL databases, including SQL Server and CosmosDb.
Experience with automated data pipeline and workflow management tools: DevOps, ARM, Data Factory, Airflow.
Experience with Microsoft cloud services: Azure, Databrick.
Experience with stream-processing systems: Storm, Spark-Streaming.
What we have to offer
Benefits: fully flexible for you to choose what is important
Retirement: Defined Benefits Retirement Plan & Group Registered Retirement Savings Plan (RRSP)
Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts
Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan
Work-Life Balance: Flextime & California Fridays all year
Fun at work: social and community events all-year round!

At CAE, connecting with people is very important. If you have any questions on this career opportunity, please do not hesitate to contact Nadine Dubois, Talent Acquisition Specialist (nadine.dubois1@cae.com), Marc-André Proulx, Technical Lead (marc-andre.proulx@cae.com) or Sofiane Hocine, Digital Product Manager (sofiane.hocine@cae.com).

Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.
Position Type

Regular

CAE thanks all applicants for their interest. However, only those whose background and experience match the requirements of the role will be contacted.

Equal Employment Opportunity

At CAE, everyone is welcome to contribute to our success. With no exception.

As captured in our overarching value ""One CAE"", we’re proud to work as one passionate, boundaryless and inclusive team.

At CAE, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age.

The masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.",3.9,CAE,Montreal,"Montreal, Canada",10000+ employees,1947,Company - Public,Aerospace & Defence,Aerospace & Defence,$2 to $5 billion (CAD),"Pratt & Whitney, Lockheed Martin",101.0,73,data engineer,na,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,10808,2
364,"StackAdapt is the no. 1 performing native advertising platform helping brands accelerate customer engagement and acquisition. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience.

Ranking the highest in customer satisfaction and performance by G2 Crowd in the DSP category for the fourth time, we're one of the fastest growing companies in Canada and ranks 6th in Deloitte's Technology Fast 50 ranking and 23rd in Fast 500 in North America.

We're looking to add a Data Engineer to our data team! This team works on solving complex problems for StackAdapt's digital advertising platform. You'll be working directly with our data scientists, data engineers, Director of Engineering and CTO on building pipelines and ad optimization models. With access to over 500,000 data sets per second, there's no shortage of data and problems to tackle.

Learn more about our engineering culture here: https://www.stackadapt.com/artificial-intelligence-in-advertising

Watch our talk at Amazon Tech Talks: https://www.youtube.com/watch?v=lRqu-a4gPuU
We'll be responding to applicants that have:
Proven experience architecting scalable ETL / machine learning pipelines (advertising technology experience preferred but not required)
Strong experience with Apache Spark
Strong programming skills in Scala (Golang and Python is a plus)
Experience in NoSQL databases such as HBase and Aerospike
Experience with data warehouse technologies such as Amazon Redshift, Hive
Experience with AWS, ElasticMapReduce, S3 and EC2 in particular
Experience working with small to mid-size teams, and a rapid development process
Experience with Airflow or other job scheduling libraries is a plus
Understanding of machine learning algorithms

StackAdapters enjoy:

Highly competitive salary
Full benefits from League on day one of employment
Coverage and support of personal development initiatives (conferences, courses, etc)
Fully stocked kitchen with healthy (and some not so healthy) snacks
Monthly presentations from global business leaders and innovators
An awesome parental leave policy
A weekly $15 lunch credit via Ritual
Our weekly Friday social events (sometimes on our 4000sq. ft. outdoor patio)
Quarterly team events like escape rooms, bubble soccer, obstacle courses, indoor skydiving, boat cruises, the list goes on…
About StackAdapt

StackAdapt is a self-serve programmatic advertising platform used by North America’s most exceptional digital marketers. This state-of-the-art platform is where some of the most progressive work in machine learning meets cutting-edge user experience. Ad buyers plan, execute, and manage data-driven digital advertising campaigns across all devices, inventory and publisher partners. Ranking a high performer by G2 Crowd in the DSP category for four consecutive years, StackAdapt is also recognized as a LinkedIn Top Startup in 2019.

Our office is located at King and Sherbourne near Toronto's historic Distillery District and the St. Lawrence Market. Our Walk, Bike and Transit Score are all over 90.

We've been recognized for our high performing campaign conversion rates, award winning customer service, and innovation by numerous industry publications including:

6th Fastest on Deloitte Technology's Fast 50 In Canada
StackAdapt’s New Chrome Extension Tackles Recruitment Bias
G2 Crowd's Highest Performing Demand Side Platform
The Globe and Mail 2019 Canada’s Top Growing Companies
Startup 50: The Complete Ranking of Canada’s Top New Growth Companies

StackAdapt is a diverse and inclusive team of collaborative, hardworking individuals trying to make a dent in the universe. We are an equal opportunity employer and we are happy to work with applicants requesting accommodation at any stage of the hiring process. We welcome and encourage anyone and everyone to apply.",4.1,StackAdapt,Toronto,"Toronto, Canada",51 to 200 employees,2013,Company - Private,Advertising & Marketing,Business Services,Unknown / Non-Applicable,-1,101.0,7,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,3871,0
365,"Why We’re Rad (about us):
Rad Power Bikes is a leading consumer direct ebike manufacturer specializing in high quality yet affordable electric bikes for weekend warriors, hardcore commuters, and family cyclists.

Madly growing and located in Seattle, WA we are seeking a gifted Data Engineer to join our Vancouver team to help us design, build, and maintain the data-foundation that powers our warehouse and technologies that are central to Rad’s day-to-day operation, providing critical business value every day.

Our Data Engineer will be responsible for managing the interchange of data between systems, servers, employees and our Rad Riding customers. We are looking for someone who can architect, design and implement data processes that are crucial to Rad’s data-driven decisions. This role reports into our Director of Business Operations and Technology and is part of a cross-functional Technology department.
Why You’re Rad (about you):
5+ years of experience in a data engineering role, working with big datasets
Knowledge of professional software engineering practices & best practices for full software development life cycle, including coding standards, code reviews, source control management, continuous integration/deployments, testing and operations
Strong desire to work in a team environment
Ability to think and solve complex data engineering problems in a maintainable and scalable fashion
Desire to find new and better ways of doing things, generating original and imaginative ideas, products, and/or solutions
Desire to embrace documentation creation & maintenance
Ability to work independently and collaboratively with both local & non-local teammates
Strong problem solving and organizational skills
Impeccable written & oral communication skills with strong attention to detail
Additional Requirements:
Bachelor’s degree in Computer Science, Mathematics, Electrical Engineering or equivalent work experience
Expert knowledge and proficiency with SQL and no-SQL databases.
Familiarity with Big Data tools such as Google’s BigQuery
Experience with Visualization tools and libraries such as Power BI or Google’s Data Studio
Strong understanding of Dev Ops practices with a good understanding of AWS and Google Cloud infrastructure
You get bonus points for:
Experience working with Shopify’s systems and API
Experience with cloud-based ERPs and Warehouse Management Systems
Experience with NetSuite
Experience with GraphQL, BigQuery and Postgres
Open-source contributions or have personal projects you’ve shipped successfully
Project management experience
Had you been with us last month, you would have:
Developed business intelligence and reporting solutions
Utilized and built out the data warehouse foundation and set up the pipes for data sources
Managed the building of data and documentation across company wide systems
Worked cross functionally with all teams, including Supply Chain, Customer Experience, etc. to capture and report on inventory data
Evaluated the feasibility and effectiveness of proposed data solutions
Designed schemas, optimized data transformation, and managed deployments and maintenance of the data pipeline
Completed end-to-end administration and maintained tools, systems, pipelines and ETLs
Communicated designs, issues and trade-offs to stakeholders
Helped develop the foundational data stores that power our internal/external web apps and reporting systems
Dealt with 3rd party vendors, managing the relationships & troubleshooting high-level issues
Additional duties and overtime as required
Rad Power Bikes is proud to be an Equal Opportunity Employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.

If you need assistance or an accommodation due to a disability, you may contact us at 800-939-0310 or jobs@radpowerbikes.com.

Recruitment Agencies: Although we value the services you provide, at this time we are not leveraging external 3rd party recruitment resources for this search. Should those needs change, we will seek your assistance directly.",3.8,Rad Power Bikes,Vancouver,"Seattle, WA",201 to 500 employees,2007,Company - Private,Sports & Recreation,"Arts, Entertainment & Recreation",Unknown / Non-Applicable,-1,101.0,13,data engineer,na,0,0,1,0,0,1,0,1,0,1,0,0,0,0,0,4348,0
366,"Data Engineer/Analyst
We are looking for a Data Engineer/Analyst to join our growing technology team in the exciting space of financial services. Our technology integrates big data, analytics, data science and machine learning with distributed computing architectures to deliver a suite of data-driven web and mobile applications. This position is located in our Montreal office.
Role Description
This position focuses on the design, implementation, and operation of data management systems to meet our data-driven business needs. This includes designing how the data will be stored, consumed, integrated, and managed by different data entities and digital systems. You will work together with developers and business stakeholders to determine, create, and implement systems to gain insights, support decisions, and prescriptive analytics.

Collaborating with developers and architects, you will help plan, design, and optimize for data throughput and query performance issues. This requires constantly updating expertise in areas such as platform, network and storage technologies, bandwidth management, data bus implications, and design. You will play a key role in the selection of backend data technologies (databases, platforms, processing technologies, etc.), their configuration and utilization, and the optimization of the infrastructure for a data platform to support real-time and batch processes, pipelines for predictive and prescriptive analytics to support the intended kinds of queries and analysis to match expected responsiveness.
Duties & Responsibilities
Create and maintain optimal data pipeline architecture.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the executive, product, development and design teams to assist with data-related technical issues and support their data infrastructure needs.
Requirements & Characteristics
Five or more years of experience and/or equivalent post-graduate and academic experience in a data engineering or similar role. Experience using the following software/tools:
Experience with big data tools: Hadoop, Spark, Hive, etc.
Experience with relational SQL and NoSQL databases: MySQL, PostgreSQL, MongoDB, Cassandra, etc.
Experience with data pipeline and ETL tools: Kafka, Airflow, Jaspersoft, etc.
Experience with ML data flow tools: SciKit Learn, TensorFlow, Watson, etc.
Experience with AWS cloud services: EC2, EMR, RDS, Redshift
Experience with stream-processing systems: Storm, Spark-Streaming, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured and disconnected datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Experience supporting and working with cross-functional teams in a dynamic environment.
Please provide Resume/CV in English

Job Types: Full-time, Permanent

Benefits:
Casual Dress
Dental Care
Extended Health Care
Life Insurance
On-site Parking
Paid Time Off
Vision Care
Schedule:
Monday to Friday
Experience:
data analytics: 3 years (Required)
Location:
Montréal, QC (Required)
Work remotely:
Temporarily due to COVID-19",-1.0,RCN Call Center Servi,Montreal,-1,-1,-1,-1,-1,-1,-1,-1,90.5,-1,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,1,0,0,4097,0
367,"About the Opportunity:

As part of the Data Hub team at AIR MILES, you will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flows and collection for cross functional teams. The pipeline needs to be scalable, repeatable, and secure. You will work with some of the largest and most varied data sets (both batch and real-time) in Canada. You will expand and develop the AIR MILES Cloud analytical platform that enables business users, data analysts and data scientists to make data driven decisions, build innovative data products and roll out advanced analytics.

What will you bring?
Ability and desire to work in our collaborative environment: open team room, pair programming and fluid interactions with all products and operations teams.
Focusing on building solutions utilizing an agile approach: close relationships with Product Managers, communicating and digesting real time feedback, and working smartly to build story cards on daily basis.
Passionate about Big Data and the latest trends and developments. We strongly believe in and encourage continuous learning.
You are self-driven, need minimal supervision and comfortable pushing your own projects and getting things done.
Experience with Python, Spark, and SQL
Experience building ‘big data’ pipelines, architectures, and datasets
Experience with Amazon AWS and other cloud platforms
Experience with Databricks
Experience with Agile methodologies as well as familiar with CI/CD tools (Jenkins, Travis, github)
Experience in ETL and Data Modeling preferred
Experience in designing and implementing streaming applications is preferred
Fully understand standard architecture methodologies, processes and best practices
About AIR MILES

Today, there are more ways than ever to engage shoppers. At AIR MILES, we believe that understanding the people behind the purchase is key to winning their hearts – and their wallets. For over two decades and from more than fifty locations around the globe, we have paired expertise in shopper behavior with advanced analytics to uncover the data-driven insights that drive successful loyalty, marketing and merchandising solutions. At AIR MILES, we know that in coming together we are at our strongest – and that together we can help shape the future for our clients, their shoppers and our communities. AIR MILES is an Alliance Data company. For more information, visit www.loyalty.com

About ADS

Alliance Data® (NYSE: ADS) is a leading global provider of data-driven marketing and loyalty solutions serving large, consumer-based industries. The Company creates and deploys customized solutions, enhancing the critical customer marketing experience; the result is measurably changing consumer behavior while driving business growth and profitability for some of today's most recognizable brands. Alliance Data helps its clients create and increase customer loyalty through solutions that engage millions of customers each day across multiple touch points using traditional, digital, mobile and emerging technologies. An S&P 500 and Fortune 500 company headquartered in Plano, Texas, Alliance Data consists of three businesses that together employ more than 16,000 associates at approximately 100 locations worldwide. For more information, visit www.alliancedata.com

Alliance Data is an Equal Employment Opportunity employer. Accordingly, we will make reasonable accommodations to respond to the needs of people with disabilities in accordance with legislation.

Alliance Data participates in E-Verify.

Check us out – AIR MILES on Stack Overflow | LinkedIn | Glassdoor | Facebook |Twitter | Blog | Instagram

Company: AIR MILES",-1.0,AIR MI,Toronto,"Toronto, Canada",501 to 1000 employees,1992,Company - Private,Advertising & Marketing,Business Services,$2 to $5 billion (CAD),-1,90.5,28,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,3691,0
368,"About Skillz:

Skillz is driving the future of entertainment by accelerating the convergence of sports, video games and media for an exploding mobile-first audience worldwide. The company's platform empowers mobile game developers and players with democratized access to fun, fair and skill-based competition for real prizes, shifting the paradigm to make eSports accessible to anyone, anywhere with a mobile device.

Skillz helps developers build multi-million dollar game franchises by turning content into competitive social gaming properties for the world's 2.6 billion gamers. The company has already worked with 13,000 game developers, leveraging its patented technology to host over 800 million tournaments for 18 million players worldwide.

This year, Skillz was recognized as one of Fast Company's Most Innovative Companies and CNBC Disruptor 50 (for the second time). In 2018, Skillz was listed as one of Forbes' Next Billion-Dollar Startups and Entrepreneur Magazine's 100 Brilliant Companies. In 2017, Inc. Magazine ranked Skillz the No. 1 fastest-growing private company in America.

The company is backed by leading venture capitalists, media companies, and professional sports luminaries, ranging from Liberty Global, Accomplice, Wildcat Capital, Telstra Ventures, and a founder of Great Hill Partners to the owners of the New England Patriots, Milwaukee Bucks, New York Mets, and Sacramento Kings.

Who we're looking for:

You're ready to take the next step in your Data Engineering career - to a fast-moving, successful company building out their next-generation streaming analytics infrastructure! You love data consistency and integrity. You consider yourself scrappy and a technologist, passionate about data infrastructure... with your attention to detail and insistence on doing things correctly, you know you can make a big impact on a small team! You're an excellent communicator and know that you grow faster from being able to mentor others.

What You'll Do:
Build new systems to provide real-time streaming analytics and event processing pipeline based on fast data architecture
Build enterprise grade data lake to support both business analytical needs and next generation data infrastructure
Building data integration toolkit for backend services
Support our data science team in deploying new algorithms for matchmaking, fraud and cheat detection
Find better ways to move massive amounts of data from a variety of sources to formats consumable by reporting systems and people
Improve monitoring and alarms that impact data integrity replication lag
Support our product development team in creating new events to measure/track
Your Skillz:

Basic Qualifications:
At least 4-5 years of experience in Scala/Java or Python programming
AWS data products (Data pipelines, Athena, Pinpoint, S3, etc)
Experience deploying data infrastructure
Experience with recognized industry patterns, methodologies, and techniques
Bonus:
Familiarity with Agile engineering practices
2+ years experience on Kubernete, Helm chart
4+ years of experience with Spark, Scala and/or Akka
4+ years of experience with Spark Streaming, Storm, Flink, or other Stream Processing technologies
2+ years of experience working with Kafka or similar data pipeline backbone
4+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python
3+ years' experience with NoSQL implementation (ElasticSearch, Cassandra, etc. a plus)
At least 4-5 years of experience with Unix/Linux systems with scripting experience
Familiarity with Alooma, Snowflakes
Familiarity with Kinesis, Lamda
Prior experience in gaming
Prior experience in finance
Skillz embraces diversity and is proud to be an equal opportunity employer. As part of our commitment to diversifying our workforce, we do not discriminate on the basis of age, race, sex, gender, gender identity, color, religion, national origin, sexual orientation, marital status, citizenship, veteran status, or disability status.",4.2,Skillz Inc.,Vancouver,"San Francisco, CA",201 to 500 employees,2012,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,90.5,8,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,3989,0
369,"Nokia is a global leader in the technologies that connect people and things. With state-of-the-art software, hardware and services for any type of network, Nokia is uniquely positioned to help communication service providers, governments, and large enterprises deliver on the promise of 5G, the Cloud and the Internet of Things. Serving customers in over 100 countries, our research scientists and engineers continue to invent and accelerate new technologies that will increasingly transform the way people and things communicate and connect.

Discovering the possibilities that shape the human experience are at the heart of everything we do. Our researchers are continually massively scaling the capabilities of networks from the data center to the end device, to change the way we live and work, by inventing breakthrough technologies to make networks and systems faster, smarter and greener.

At Nokia, employment decisions are made regardless of race, color, national or ethnic origin, religion, gender, sexual orientation, gender identity or expression, age, marital status, disability, protected veteran status or other characteristics protected by law.

Job Description:

We are looking for Interested candidates for Data Engineer to not only help us build data pipelines to efficiently and reliably move data across systems but also to build the next generation of data tools to enable us to take full advantage of this data. In this role, you will learn and work with the company's products, data consumers and analysts.

Key Responsibilities / Functions:
Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Working experience with Tableau, QlikView, Mode, Matplotlib, Jupyter, or similar data visualization tools
Extensive experience analyzing data using SQL
Required Minimum Qualifications: (Education, Technical Skills/Knowledge)
2+ years of Python or Java development experience
2+ years of SQL experience (NoSQL experience is a plus)
3+ years of experience with schema design and dimensional data modeling
Ability in managing and communicating data warehouse plans to internal clients
3+ years of relevant experience such as implementing statistical analysis, developing cloud-based data lakes / data warehouses, managing data science projects, developing APIs, developing machine learning models, creating advanced data visualizations.
Good communication and writing skills to facilitate productive collaboration with other team members and business units;
Strong knowledge of project management principles and concepts;
Experience solving problems with an emphasis on product development
Experience with predictive modeling and dissemination of research results;

Apply now.",4.2,Nokia,Ottawa,"Nokia, Finland",10000+ employees,1865,Company - Public,Telecommunications Services,Telecommunications,$10+ billion (CAD),"Ericsson-Worldwide, Huawei Technologies, Microsoft",90.5,155,data engineer,na,0,1,0,1,0,1,0,0,0,0,0,1,1,0,0,2785,3
370,"Role and Responsibilities

Analyste des données

(English follows)

Lorsque vous prenez l’avion, peu importe la destination, il y a de fortes chances que le pilote ait été formé par CAE. Le point focal étant les clients, l’équipe Accélérateur numérique s’engage à rehausser l’expérience de formation afin de s’assurer que les pilotes soient les meilleurs possible.

Voici quelques raisons pour lesquelles les employés aiment travailler à CAE!
Travail significatif qui favorise le perfectionnement professionnel
Possibilité de travailler dans l’industrie technologique et de s’y épanouir
Environnement de travail axé sur la collaboration
Faire partie d’une équipe à haut rendement
Votre mission

À titre d’analyste des données, votre mission consiste à soutenir et à promouvoir la stratégie d'IA et à mettre en œuvre des pratiques exemplaires en matière d'analyse des données.

Votre rôle et responsabilités principales

Être un.e contributeur.trice de la stratégie d’intelligence artificielle
Effectuer des analyses sur de grands ensembles de données, extraire des informations et communiquer avec divers intervenants dans le but d'améliorer le rendement global de l'entreprise.
Développer des outils de gestion de données pour appuyer la prise de décision de la haute direction.
Créer des outils et des tableaux de bord pour faciliter la communication d'informations avec des indicateurs de rendement clés pertinents pour différents intervenants.
Exploiter l'IA, les statistiques avancées et les techniques d'exploration de données pour trouver des données commerciales clés.
Établir des partenariats avec des scientifiques des données et des stratèges en IA pour améliorer les modèles de science des données.
Collaborer avec les chefs de produits numériques pour explorer de nouvelles idées ou améliorations de produits.
Établir des rapports pour mesurer les progrès des principales initiatives.
Effectuer des validations et détecter les problèmes d'intégrité des données.
Améliorer le cadre de gouvernance des données.
Être un collègue inspirant et motivant
Partager vos connaissances avec l’équipe et initier des activités de partage des connaissances
Être un agent de changement et un promoteur de la mentalité agile
Contribuer au milieu de travail collaboratif et stimulant
Communiquer avec la communauté d'intelligence artificielle de Montréal et d'ailleurs pour trouver de nouvelles possibilités de collaboration et pour injecter de nouvelles idées dans notre pipeline
Vos qualifications
Niveau élevé d'exactitude, souci du détail et capacité à apprendre de nouveaux outils et technologies rapidement
Aptitude manifeste à intervenir sur des idées et des possibilités avant qu'on ne vous le demande ou d'y être contraint par des événements.
Aptitude à exercer une souplesse et à fonctionner de façon indépendante dans un environnement agile.
Aptitude à formuler des problèmes et des concepts complexes pour un public de gens d'affaires.
Grand sens de l'organisation et capacité à travailler sous pression.
Attitude positive envers l'acceptation de défis et de mandats additionnels.
Expérience de conceptualisation et de mise en œuvre d'entrepôts de données avec un accent sur la préparation de données.
Excellentes aptitudes en communication verbale et écrite en anglais. Le français est un atout.
Compétences techniques
Excellentes compétences techniques et analytiques avec un minimum de trois ans d'expérience en tant qu'analyste d'entreprise ou des données.
Baccalauréat en informatique ou en systèmes d'information de gestion, ou expérience équivalente.
Aptitude à créer des requêtes SQL, à utiliser Jira, PowerBI, Confluence et Sharepoint.
Être capable de nettoyer et d'analyser de grands ensembles de données avec les technologies de données appropriées (p. ex., Python, SAS, R).
Avoir acquis une solide expérience en prise de décisions fondées sur des données analytiques et opérationnelles, en analyse de données, et en statistiques.
Excellent sens de l'analyse avec la capacité de découvrir des tendances dans les données et de comprendre des relations de données particulières.
Expérience du développement de solutions d'expérience client (tableaux de bord, indicateurs de rendement clés, carte de pointage).
Ce que nous avons à offrir
Avantages sociaux : entièrement flexibles pour que vous puissiez choisir ce qui est important
Retraite : Régime de retraite à prestations déterminées et régime enregistré d’épargne-retraite (REER) collectif
Avantages financiers : Régime d’actionnariat et nombreux rabais d’entreprise
Programmes personnels et familiaux : Plan de bien-être physique et prestations de maternité complémentaires
Équilibre travail-vie personnelle : Horaires flexibles et « vendredis californiens » toute l’année
Plaisir au travail : Activités sociales et communautaires tout au long de l’année!
À CAE, il est très important de créer des liens avec les gens. Si vous avez des questions au sujet de cette possibilité de carrière, n’hésitez pas à communiquer avec Sawsan Ghamraoui, spécialiste en acquisition de talents (sawsan.ghamraoui@cae.com) ou Arnaud Van de Voorde, vice-président, accélérateur numérique (arnaud.vdv@cae.com).

Joignez-vous au moteur de changement à CAE - notre prochain horizon de croissance passe avant tout par l’innovation numérique afin d’appuyer la réussite de nos clients.

**********************************************************************************

Data Analyst

If you’ve taken a plane to any destination in the world, chances are, your pilot was trained by CAE. With its strong customer focus, the Digital Accelerator team is dedicated to elevating the training experience to make pilots the best they can be.

Here are few reasons why folks love working at CAE!
Meaningful work that drives professional development
Ability to enter and grow within the technology industry
Work in a collaborative environment
Be part of a high-performance team
Your Mission

As a member of the Data Science team, your mission is to support and promote de AI strategy and implement best practices in data analysis.

Your Role & Main Responsibilities

Be a contributor to the AI Strategy
Perform analysis on large data set, extract insights and communicate various stakeholders with the objective of improving the overall business performance.
Develop data management tools to support data-driven decision from Senior Management.
Create tools and build dashboards to facilitate reporting with relevant KPIs for different stakeholders.
Leverage AI, advanced statistics and Data Mining techniques to find key business insights
Partner with Data Scientists and AI Strategists to improve Data Science models
Collaborate with Digital Product Managers to explore new product ideas or enhancements
Build reporting to measure progress in key initiatives
Perform validation and detect data integrity issues.
Enhance the data governance framework.
Be an inspirational and motivational colleague

Be an inspirational and motivational colleague
Share knowledge with team members & participate in various learning-sharing activities
Contribute to the collaborative and stimulating work environment
Be a change agent & Agile mindset promoter
Be connected to the industry to know tendencies and suggest innovative ideas
Your Qualifications

Softskills
High level of accuracy, attention to detail and ability to learn new technologies and tools quickly
Demonstrated strength in taking action on ideas and opportunities before being asked or forced to by events
Ability to exercise flexibility and operate independently in an agile environment
Ability to articulate complex problems and concepts to a business audience
Strong organizational skills and able to work under pressure
Positive attitude towards accepting additional challenges and assignments
Experience in data warehouse design and implementation with an emphasis on data preparation
Excellent English written and verbal communication skills. French an asset.
Technical skills
Excellent technical and analytical skills with a minimum of 3 years’ experience as a business and/or data analyst
Bachelor's degree in Computer Science, Management Information Systems or equivalent experience
Proficiency creating SQL queries, Use of Jira, PowerBI, Confluence, SharePoint
Comfort cleaning and analyzing large data sets with appropriate data technologies (e.g., Python, SAS, R)
Strong experience in analytical business decision-making, data analytics, and statistics
Strong analytical skills with the ability to discover patterns in data and figure out puzzling data relationships
Experience in developing customer experience solutions (dashboards, KPI, scorecard)
What we have to offer
Benefits: fully flexible for you to choose what is important
Retirement: Defined Benefits Retirement Plan & Group Registered Retirement Savings Plan (RRSP)
Financial Perks: Employee Stock Purchase Plan & numerous corporate discounts
Personal and Family Programs: Physical Wellness Plan & Supplementary Maternity Plan
Work-Life Balance: Flextime & California Fridays all year
Fun at work: social and community events all-year round!
At CAE, connecting with people is very important. If you have any questions on this career opportunity, please do not hesitate to contact Sawsan Ghamraoui, Talent Acquisition Specialist (sawsan.ghamraoui@cae.com) or Arnaud Van de Voorde, Vice-President, Digital Accelerator (arnaud.vdv@cae.com).

Join the engine that is changing CAE, pointing towards the next horizon of growth through digital innovations to support our customers in their success.

Position Type

Regular

CAE thanks all applicants for their interest. However, only those whose background and experience match the requirements of the role will be contacted.

Equal Employment Opportunity

At CAE, everyone is welcome to contribute to our success. With no exception.

As captured in our overarching value ""One CAE"", we’re proud to work as one passionate, boundaryless and inclusive team.

At CAE, all employees are welcome regardless of race, nationality, colour, religion, sex, gender identity or expression, sexual orientation, disability or age.

The masculine form may be used in this job description solely for ease of reading, but refers to men, women and the gender diverse.",3.9,CAE,Montreal,"Montreal, Canada",10000+ employees,1947,Company - Public,Aerospace & Defence,Aerospace & Defence,$2 to $5 billion (CAD),"Pratt & Whitney, Lockheed Martin",90.5,73,data analyst,na,0,1,1,1,0,1,0,0,0,0,0,0,0,0,1,10257,2
371,"IT/IQ Tech Recruiters is seeking a Data Scientist to join our client in Victoria, BC.

Why work with our client?
Centrally located
Transit accessible
Competitive compensation
Responsibilities
Collaborates with team members, other IT teams, and customers to understand the organization’s business objectives, decisions and data in order to build the most effective analytical models
Uses statistical and mathematical techniques to undertake analysis including forecasting, segmentation and predictive modelling
Applies current and emerging techniques in deep learning, natural language processing and other machine learning areas
Designs, develops and conducts data science experiments and communicates the results to foster data and analytics literacy and adoption
Designs, develops and implements cloud-based AI and machine learning production pipelines
Ensures AI and machine learning production pipelines are scalable, repeatable and secure
Integrates structured and unstructured data from multiple sources for use in models and products
Collects, cleans, manages, analyzes and visualizes large sets of data using multiple data platforms, tools and techniques
Leads other internal resources on ad-hoc data and analytics requests, investigations, pilot studies, proofs of concept, and projects
Enhances data collection procedures to include information that is relevant to building advanced analytical models and provides input to other internal resources on the applications, databases and systems used to assess data quality
Communicates data science complexities in plain language to technical and non-technical audiences and develops reports and presentations
Keeps up to date with the latest technology trends and methods by staying abreast of state-of-the-art literature in the fields of deep learning, operations research, machine learning, statistical modeling, statistical process control and mathematical optimization
Identifies issues and risks, develops action plans, and takes corrective actions as needed
Undertakes special projects or assignments as required
Performs other related duties as required
Top Skills Required
Master’s Degree in Data Science, Statistics, Mathematics, Computer Science or a related discipline
A minimum of 5 years of experience as a Data Scientist or Data Analytics professional
Coding skills and deep proficiency with SQL, Python, R etc.
Competence at manipulating and analyzing complex, high-volume, high-dimensional data from varying sources
A flexible analytic approach that allows for results at varying levels of precision
Experience with version control systems (i.e. Git)
Demonstrated statistical, machine learning and other data science skills and capability for delivering effective modeling and analytics results
Must have excellent listening, communication, collaboration and problem-solving skills
Ability to understand business problems and bridge the gap between data analysis results and meaningful business insights
Must be legally eligible to work in Canada
Why work with us?
Build a long-term relationship with an experienced recruitment expert
Access to the ‘hidden’ job market – opportunities across Canada that aren’t posted on job boards
Get a high-level understanding of market dynamics affecting your industry
Gain insight into the culture of the company you’re applying for before submitting your profile
About Us

IT/IQ Tech Recruiters provides contract and permanent IT recruitment services to employers across Canada. We have a specialized approach to recruiting, segmenting our recruitment teams into specialty practice areas focusing on Development, PMO, Infrastructure and BI/CRM/ERP skill sets.

This approach enables our recruiters to become specialists; they know the market and work hard to understand each candidates’ capabilities, goals, career ambitions and quickly present them with the best possible opportunities. We are committed to helping candidates develop their careers and to helping our clients grow their business and complete important projects successfully.

We create opportunities for IT Professionals to empower business.",2.8,IT IQ TECH RECRUITERS LTD,Vancouver,"Vancouver, Canada",1 to 50 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (CAD),"Randstad, TEKsystems, TEEMA Solutions Group",90.5,18,data scientist,senior,1,1,0,0,0,1,0,0,0,0,0,0,1,1,1,4120,3
372,"(Senior) Principal Data Scientist

As a senior principal data scientist within our Personalized Health Care function you will work with partners throughout the global organization to use meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access. You would have the primary responsibility to design and implement analyses using a variety of data sources such as electronic medical records, insurance claims, patient registries, clinical trials, genomics, imaging and patient reported data (surveys, digital etc.). You will drive methodology development for use of real-world data for regulatory grade evidence generation and will partner with cross-functional teams and external organizations with considerable independence. This will require a deep understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical data science expertise.

Responsibilities
Drive methodology development for use of real-world data for regulatory purposes including but not limited to external controls, hybrid controls etc
Identify evidence needs & recommend data solutions: Ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.
Dive into data: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.
Produce high quality analyses: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to maximize impact and interpretability; implement and/or handle the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.
Collaborate & craft: Collaborate and contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaborations, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.
Minimum Qualifications:
MSc, PhD or similar qualification in a quantitative data science discipline (e.g., statistics/ biostatistics, epidemiology) with strong methodology focus
Consistent track record of developing and execution of data science research projects, patient-level data analyses (e.g., real world data, insurance claims, clinical trials, registries, surveys and digital health) with publications and presentations
Demonstrated experience with leading project scope and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges
Demonstrated strong collaboration skills and excellent communication skills; ambitious mindset and self-direction, ability to teach others and willingness to learn new techniques
Proficiency in English, both written and verbal
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Roche is an equal opportunity employer.

Research & Development, Research & Development > Biometrics",4.1,Roche,Welwyn,"Basel, Switzerland",10000+ employees,1896,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (CAD),"Novartis, AstraZeneca, Siemens Healthineers",90.5,124,data scientist,senior,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,3723,3
373,"What is Bold Commerce?
Named one of Canada’s fastest-growing tech companies by Deloitte, Bold Commerce is a software company specializing in innovative ecommerce apps and solutions for businesses of all sizes. We empower merchants both big and small by providing them with tools to make their ecommerce stores truly awesome.

Staples Canada, V-Dog and KONG Box are among the 90,000+ brands in over 170 countries around the world that trust Bold’s suite of ecommerce tools to power their online stores every day.

We're made up of more than 350 professionals (and growing) who live and breathe ecommerce, and truly give a shit about what we do. We call ourselves Builders. Here at Bold, we live by the BUILDERS Code, our shared set of practices, beliefs and values that help to shape this amazing company. We believe in challenging each other to create the best products and to constantly improve, all to ensure we deliver the best results to our merchants at all times.

Why work at Bold?
Our founders have worked to create and maintain a place that our employees look forward to coming to every day. A place where you can learn and grow, where your ideas are valued and where you can do cool things, all while contributing to the larger success of the company. At Bold we embrace and cultivate a culture of creativity, innovation, and collaboration in order to allow everyone to do their best work every day.

The Bold team is looking for a Senior Data Engineer to join the Data Analytics Team. This role will involve building out our cloud data warehouse to suit the needs of multiple business lines. In addition to building data pipelines, this role also includes building a clear data model, and documenting it in dbt. Additionally, the Senior Data Engineer will develop best practices for building data pipelines into Big Query that aggregate data from our applications for analytics purposes. The ideal candidate will have previously built a data warehouse (preferably Cloud) and will be able to confidently speak to best practices around warehouse design and data modeling. This person will also have the ability to communicate complex concepts to non-technical audiences.
Other key responsibilities include:
Designing, implementing, and maintaining large-scale batch and real-time scalable data pipelines with complex data transformations
Performing data wrangling to transform and map data from raw data forms into formats more appropriate and valuable for analytics
Writing and optimizing complex queries on large data sets
Assemble large, complex data sets that meet functional / non-functional business requirements
Developing workflows and tools that automate data loading processes and help ensure data quality and integrity
Evaluating new technologies and guiding the team through adoption
Providing feedback on projects owned by other members of the team
Contributing to a data-savvy culture
Here's what we need from you
Desire to get shit done
Belief in our core values
Bachelor’s Degree or higher in Computer Science or related discipline
5+ years of experience building data ingestion infrastructure
Expertise in designing, deploying, and automating data infrastructure frameworks in Python and SQL
Have taken a leading role in delivering complex software systems all the way from design to production
Experience working closely with business users and data analysts
Experience managing an entire data flow, ingesting data from a variety of sources including SQL, NoSQL, streams, and external APIs
Mastery of SQL and Python
Experience with cloud service providers, ideally GCP
Google Cloud Certified Data Engineer, a huge plus
Excellent verbal and written communication skills
Other skills that will get you far
Familiarity with Apache Kafka & Airflow
Experience with Salesforce
Being a generally awesome human being. We want someone cool to work with. It makes the office a better place for everyone. Impress us with anything else you can do! ­ Juggle knives, make a killer mixtape, or bake delicious pastries
At Bold, we work hard and we play hard! If you are a potential Builder and think you've got what it takes to be Bold, we encourage you to apply. We promise it will be a career like no other!

We get a lot of applicants, so we encourage you to do something that stands out. Go above and beyond when you apply so you don’t get lost in the mix. Talk about a cool project you’ve done, drop us a link to your github or portfolio if applicable, or just impress us with your personality.

Show us that you have what it takes to be Bold!",4.1,Bold Commerce,Winnipeg,"Winnipeg, Canada",201 to 500 employees,2012,Company - Private,Enterprise Software & Network Solutions,Information Technology,Unknown / Non-Applicable,"Ubisoft, SkipTheDishes, BigCommerce",90.5,8,data engineer,senior,0,1,0,0,0,1,0,0,0,1,0,0,0,0,0,4559,3
374,"You are a sharp, disciplined individual who has a passion for mobile games. Your experience helps to demonstrate your superior quantitative analytical skill and a scientific thought process. Your expertise paves the way for working with our game team to optimize every facet of player retention and monetization to ensure the continued success of our games. Large data sets are your playground and you can’t wait to join the fun!

Sound like a match? Kabam Vancouver is looking for a Senior Data Analyst to join us! We don’t just make games, we play and love them too.
You will contribute by:
Providing support to cross-functional teams across the organization to understand overall business goals, improve reporting, and assist with larger scale projects as needed
Finding answers to business questions via hands-on exploration of data sets using SQL, dashboards, statistical analysis, and data visualizations
Generating and maintaining a suite of dashboards and reports for teams throughout the organization
Creating and managing multiple A/B tests to gain valuable insights on KPIs including retention, acquisition, and monetization
Measuring the success of product features after release and optimize their performance through rapid, data-driven iteration
Aiding in task prioritization and general project management within the data team
Your background includes:
4+ years of industry data analysis experience, with solid knowledge of statistical methods
Bachelor’s Degree
Expert SQL skills and experience querying very large data sets
Proven ability to thrive using multiple mixed, varied, and inconsistent data sources
Fundamental knowledge of project management methodologies
Regular communication with stakeholders from other departments and drive actionable items for continuous improvement
It would be nice to have:
Experience with Google BigQuery, Tableau, JIRA and/or other project management software
Experience working for a social or mobile game developer
Understanding of game design concepts and principles
MBA or Master’s Degree
Together, we can create and support some of the best games ever made.

About Kabam
Kabam is a world leader of developing entertaining, immersive, and highly social multiplayer games for mobile devices. They merge consumer behaviour with the art of game design to create experiences that are enjoyed by millions of players across the globe. Each game has raised the benchmark in mobile gaming, bringing high-quality graphics, next-generation technology and revolutionary gameplay to the console in every player’s pocket.
Kabam has partnered with leading entertainment brands like Disney, Hasbro and Universal to create mobile games based on some of the world’s most iconic franchises.

Kabam’s games have generated hundreds of millions of downloads including Fast & Furious 6: The Game, Fast & Furious: Legacy, Marvel Contest of Champions, Transformers: Forged to Fight, Shop Titans and Mini Guns. These games have also received multiple awards such as Apple’s Editor’s Choice and Google Play’s Best Game of the Year.

Founded in 2006, Kabam has studios and offices in Vancouver, Montreal, Charlottetown, San Francisco and Austin. Kabam is a wholly-owned subsidiary of Netmarble Games.",4.1,Kabam,Vancouver,"Vancouver, Canada",501 to 1000 employees,2006,Company - Private,Video Games,Media,Unknown / Non-Applicable,"GREE, Electronic Arts, Glu Mobile",90.5,14,data analyst,senior,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,3231,3
375,"Location: Mississauga, Ontario
Req ID: 201139WD

The Big Data Engineer 5 role is responsible for developing solutions to acquire, curate and make available enterprise data assets to be used in advanced analytic processes. The incumbent must have an advanced understanding of business domain data and how to effectively connect business data to enable advanced analytics. This person will also work closely with the Big Data Architect to perform R&D of new analytical processes and will mentor a team of data engineers to mature overall analytics and engineering capabilities.
Works closely with business teams and various data domains to understand how to design connected data solutions to enable advanced analytics. Designs, develops and implements complex Big Data projects and technical solutions in support of maturing business intelligence and analytic capabilities. Translates business requirements into innovative technical solutions.
Heavy emphasis on automation, continuous process improvement, reusability and streamlining data ingestion/curation processes.
Mentor and guide team members to develop their technical competency and work with business partners to enable self service capabilities to speed business insights.
Provide ongoing operations and support for production systems to meet defined SLAs
Research modern technologies to solve unique challenges. Defines standards and best practices for end to end development lifecycle.
Basic Qualifications:

Education and Experience: Bachelors and 5 years or HS/GED and 9 years
2+ years of experience in supporting and developing data ingestion solutions using StreamSets
5+ years of experience in supporting and developing data pipelines using Spark (pySpark)
3+ years of experience with Python
4+ years of experience with SQL Hive, Impala, Kudu
Sponsorship is not available for this position. Candidates must be able to work without the need of sponsorship now or anytime in the future in order to be considered.
Preferred Qualification:

Education: Bachelors in Computer Science or Data Analytics

Experience: 6 years of IT Engineering and Analytics
8+ years of experience in any programming language to include education and professional experience
6+ years of experience with Python
1+ years of experience with Cloudera
4+ years of experience in supporting and developing data ingestion solutions using StreamSets
2+ years of experience with Kafka
https://www.youtube.com/embed/UGXTiKuQaTU

AODA:Deluxe Corporation and Deluxe companies will provide reasonable accommodation for qualified individuals with disabilities. If you need assistance with any part of the application or hiring process, please contact us at DeluxeCareers@deluxe.com.

Department: IT Architecture & Engineering
Time Type: Full time",3.0,Deluxe Corporation,Mississauga,"Shoreview, MN",1001 to 5000 employees,1915,Company - Public,Business Service Centres & Copy Shops,Business Services,$2 to $5 billion (CAD),"R.R. Donnelley, MDC Partners, Harland Clarke",90.5,105,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,2772,3
376,"As a (Senior) Principal Data Scientist within our Personalized HealthCare function you will work with meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access.

You will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions. The data will be varied in type -- patient-level clinical data, supplemented with deep patient data such as omics (e.g. genomics, proteomic), imaging, digital health, etc. Source data will be diverse -- real-world data, including patient registries, electronic medical records, claims, biobanks, and clinical trials. The evidence and insights will be used to inform the research and development of our molecules, and support healthcare decisions by patients, physicians, health authorities, payers, and policy-makers. You will also contribute to functional, cross-functional, enterprise-wide or external initiatives that shape our business and healthcare environments. This will require a good understanding of molecule and disease area strategies, healthcare environments, as well as strong scientific and technical expertise in observational research. You will need strong strategic, collaboration and communication skills, as well as an entrepreneurial mindset, to transform the way we use data and analytics to develop and deliver medicines for our patients.

As (Senior) Principal Data Scientist you will typically be expected to contribute to the molecule/disease area for multiple or complex projects with minimal supervision. You will contribute to the development of new concepts, techniques, and standards using your expertise in epidemiology. We will look to you as a positive role model for peers and you will coach colleagues to improve in their role with both technical and interpersonal skills.

RESPONSIBILITIES
IDENTIFY EVIDENCE NEEDS & RECOMMEND DATA SOLUTIONS: Ask the right scientific questions, understand the evidence needs for research and development, regulatory and market access, and ideate and make recommendations on fit-for-purpose data and analytics solutions.
DEVELOP DATA STRATEGY & GAIN ACCESS TO DATA: Develop strategic plans to access fit-for-purpose data sources to support evidence generation, and gain access to data through collaboration or data generation.
DIVE INTO DATA: Develop a comprehensive and deep understanding of the data we work with and foster learning with colleagues using analytical tools and applications to broaden data accessibility and advance our proficiency/efficiency in understanding and using the data appropriately.
BE AN EXPERT IN APPLYING METHODS: Stay current with and adopt emergent analytical methodologies, tools and applications to ensure fit-for-purpose and impactful approaches.
PRODUCE HIGH QUALITY ANALYSES: Apply rigor in study design and analytical methods; plan for data processing; design a fit-for-purpose analysis plan, assess effective ways of presenting and delivering the results to maximize impact and interpretability; implement and/or oversee the study, including its reporting; ensure compliance with applicable pharma industry regulations and standards.
INTERPRET AND SHARE RESULTS: Communicate findings to internal stakeholders, regulatory, health technology assessment (HTA) bodies and scientific communities; publish results; participate in external meetings and forums to present your insights (e.g. congress/conference).
COLLABORATE & SHAPE: Collaborate and contribute to functional, cross-functional, enterprise-wide or external data science communities, networks, collaborations, initiatives or goals on knowledge-sharing, methodologies, innovations, technology, IT infrastructure, policy-shaping, processes, etc. to enable broader and more effective use of data and analytics to support business.
MINIMUM QUALIFICATIONS

We are looking for a professional with MSc or PhD in epidemiology, pharmacoepidemiology or biostatistics/public health (with focus on epidemiology/observational research) and minimum of 2 years working in a relevant department in pharmaceutical development. You will bring:
Demonstrated track record of developing and executing epidemiological or outcomes research projects, with publications and presentations
Demonstrated experience with managing project scope and driving delivery in an evolving environment requiring proactivity and effective problem-solving and prioritization when faced with challenges
Demonstrated strong collaboration skills and excellent communication skills
Demonstrated entrepreneurial mindset and self-direction, ability to teach others and willingness to learn new techniques
Proficiency in English, both written and verbal
Track record of effectively working in a matrix environment with global, international team members coming from scientific, business and operational backgrounds, using influence without authority
PREFERRED/ADDITIONAL QUALIFICATIONS
PhD degree as listed in Minimum Qualifications
Relevant work experience especially with managing internal and external stakeholder collaborations
Proven ability to translate and communicate complex study design and findings to diverse audiences
Roche is an equal opportunity employer.

Research & Development, Research & Development > Modelling & Simulation",4.1,Roche,Welwyn,"Basel, Switzerland",10000+ employees,1896,Company - Public,Biotech & Pharmaceuticals,Biotech & Pharmaceuticals,$10+ billion (CAD),"Novartis, AstraZeneca, Siemens Healthineers",76.5,124,data scientist,senior,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,5539,3
377,"BenchSci exponentially increases the speed and quality of life-saving research by empowering scientists with the world’s most advanced biomedical artificial intelligence to run more successful experiments. Backed by F-Prime and Google’s AI fund, Gradient Ventures, BenchSci uses machine learning to diagnose pharmaceutical R&D health from hidden patterns in procurement data. A turnkey application of AI with immediate, quantifiable impact, BenchSci now optimizes reagent procurement and experimental success in 15 of the top 20 pharmaceutical companies and over 4,300 leading academic centers globally.

We are currently seeking a Senior Data Engineer to join our Data Team. As part of the job, you will work on evolving our data models in several styles of datastores, improve internal tooling to allow data self-service, and operationalize production-grade data pipelines.
What you’ll do:
Scale data pipelines to allow data to go from research to platform as fast as possible
Develop data access mechanisms for downstream applications consumption
Manage sources which contain both semi-structured as well as unstructured data
Develop and apply suitable frameworks to detect data drift, and then calibrate and redeploy them to production seamlessly
Collaborate closely with other engineers to solve interesting and challenging data problems
Who we’re looking for:
5+ years working as a professional developer
Experience with SQL
Experience with cloud reference architectures and developing specialized stacks on cloud services
Expertise in Spark 2.x, Dataset/DataFrame API and performance tuning
Experience with Pandas
You have strong cross-team communication and collaboration skills
A team player who strives to see teammates succeed together
Bonus points for:
Background in Life Science
Experience in Python
Experience with Airflow or other workflow management systems in a distributed setup
Experience with graph data modeling and scaling graph databases
Experience with Kubernetes in production
Experience with technical design and applying architectural patterns
What’s in it for you:
Competitive salary with company benefits from day one
Dedicated learning and development budget (conferences, courses, etc.)
An opportunity to help transform and improve scientific research with a fun, energetic, and supportive team
Quarterly team events, annual retreats, and regular lunch and learns
Fully stocked kitchen with healthy snacks
Onsite gym and showering facilities
Casual dress code in a creative office environment (we have our own botanist!)
Office located in the heart of downtown Toronto (College/Bathurst)


Here at BenchSci, these are our core values:
Focused: We focus on what will drive the greatest impact at all times.
Advancement: We believe in continuous growth, and discovering new ways to do things better. This applies to our product and business, but also to ourselves.
Speed: We recognize that without a sense of urgency, our team, our product and our mission lose their value.
Tenacity: What we’re trying to do isn’t easy, but we hire the best people, and give them the autonomy, tools, and resources to succeed. The hard work is up to them.
Transparency: We believe that sharing diverse ideas and information creates strong teams. Our success stems from research, collaboration, feedback, and trust.
BenchSci is an equal opportunity employer. We value diversity and are committed to fostering an inclusive environment. All four of our cofounders are immigrants to Canada, as are many of our employees. We welcome your fresh perspectives and ideas.",5.0,BenchSci,Toronto,"Toronto, Canada",51 to 200 employees,2015,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,76.5,5,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,1,1,0,0,3574,0
378,"Guavus is a young and fast-growing company whose mission is to provide Communication Service Providers (CSPs) with a competitive advantage in the ability to accurately understand their mobile subscribers’ behaviors and extract value from this knowledge.

We are at pivotal point in our history where big data innovation can impact businesses and individuals in new and unforeseen ways, but we need exceptionally smart people to join our team who are:
Passionate  about getting the job done,
Relentless  about flawless execution,
Committed  to solving problems creatively, and
Believe  in the collective intelligence to design, build and engineer extraordinary products and solutions that are useful to all.
If this sounds like you, please reach out we’d love to hear from you.

Your Role


Guavus is looking for a highly motivated and talented Sr. Data Engineer to participate in the development of the most advanced solutions in the Big Data space by using agile methodologies. The developer will actively participate and collaborate with data team to design and implement data pipelines integrating advanced AI/ML models.

Responsibilities
Develop and maintain batch and streaming data pipelines with big data technologies such as Spark, Kafka, Hive, HDFS, HBase, Phoenix, Impala etc.
Work closely with data scientists to produce ML/AI pipelines.
Analyze and implement proof of concepts related to big data technologies
Analyze new technologies (DB, Storage, Compute Engines)
Produce quality code that is well documented
Qualifications and Experience
Four (4) years of experience in a data engineer position
Holder of a Degree in Computer Science or Engineering
Experience in Cloud and non-Cloud based Hadoop ecosystem
Experience in data warehousing and ETL development
Fluent in Java & with some Scala knowledge.
Fluent in SQL
Experience in performant and highly scalable applications
Experience in distributed framework and technologies e.g. Columnar Database, NoSQL and Hadoop
Experience in Linux and shell scripting.
Basic knowledge or interest in Python
Fluency in English, both written and spoken
Speaking French is an asset

Working conditions


This opportunity consists of full-time job and is located in the Mile Ex area of Montreal, Canada.",2.7,Guavus,Montreal,"San Jose, CA",201 to 500 employees,2006,Subsidiary or Business Segment,Enterprise Software & Network Solutions,Information Technology,$50 to $100 million (CAD),-1,76.5,14,data engineer,na,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,2253,0
379,"With thousands of beautiful spaces built for travel and living, Sonder is transforming the future of hospitality. Each Sonder is purposefully selected, designed and maintained - customized to reflect the vibe of its neighborhood. Whether your stay is two days, two months or two years, in a studio or a six-bedroom, Sonder ensures a unique, yet consistent experience. And with 24/7 contactless service, professional cleanings that exceed PHAC recommendations, and over 200 other quality standards, we're taking stay further for guests all around the world.

Sonder started in 2014, and now has thousands of spaces in cities across the globe.

The Data Engineering team is mainly focused on building and operating our data infrastructure, data warehouse, data and ETL pipelines, ML platform, and performing data modeling for analytics purposes. The team also partners with product engineering and data science teams to deliver data products to the business.

AT SONDER YOU WILL:
Build and operate our data infrastructure by building and maintaining the data platform, data pipelines, and the tools that ingest, process, transform and serve data
Build software libraries that standardize the acquisition, ingestion and integration of external data sources critical for real-time competitive intelligence and pricing
Use your expert SQL and data modeling skills to build the data warehouse base layer data models that will power Sonder's reporting dashboards
Establish and maintain the company's data lake/data warehousing strategy, define the appropriate data architecture, implement the best technical solution, and continue to meet the growing needs of the business;
Work with product and business analytics teams to ensure availability and accessibility of relevant business data and business metrics for product analytics and business performance reporting.
Understand Sonder's business intimately and model data that will be the source of truth for Sonder's business KPIs and metrics
Design and develop scalable platforms and processes for feature extraction, model training, and simulation
Own tools, processes and controls to help the team grow at scale.
WHAT WE LOOK FOR:
5+ years of experience working as a Data Engineer at a progressive company
Expert Python coding skills
Expert SQL and data modeling skills
Knowledge of data warehouse principles and methodologies
Experience in writing ETL jobs, performance tuning and query optimization
Strong communication skills and ability to gather requirements and translate them to specs and design
Experience with AWS cloud services and data warehouse stores like Redshift or Snowflake
Background in real estate or hotel industry is desirable
Self-driven, highly motivated and able to learn quickly
We offer great benefits to make your life easier so you can focus on what you're best at:
Competitive salary
Generous stock option plan
Medical, dental and vision insurance
Discretionary vacation/ Paid vacation and sick time
Annual free credits and discounts to stay in Sonders
Monthly culture budget: join your fellow colleagues for a monthly get together
A company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work-with colleagues!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Avec des milliers de beaux espaces construits pour le voyage et la vie, Sonder transforme l'avenir de l'hospitalité. Chaque Sonder est sélectionné, conçu et entretenu de manière ciblée, et personnalisé pour refléter l'ambiance de son quartier. Que votre séjour soit de deux jours, deux mois ou deux ans, dans un studio ou un appartement de six chambres, Sonder vous garantit une expérience unique, mais cohérente. Et grâce un service sans contact 24 heures sur 24, 7 jours sur 7, des nettoyages professionnels qui dépassent les recommandations de l'ASPC et plus de 200 autres normes de qualité, nous allons encore plus loin pour nos clients du monde entier.

Sonder a débuté en 2014, et compte aujourd'hui des milliers de chambres dans des villes du monde entier.

L'équipe d'ingénierie des données se concentre principalement sur la construction et l'exploitation de notre infrastructure de données, de notre entrepôt de données, de nos pipelines de données et d'ETL, de notre plateforme ML et sur la modélisation des données des fins d'analyse. L'équipe s'associe également des équipes d'ingénierie de produits et de science des données pour fournir des produits de données l'entreprise.

À SONDER VOUS LE FEREZ :
Construire et exploiter notre infrastructure de données en construisant et en entretenant la plate-forme de données, les pipelines de données et les outils qui ingèrent, traitent, transforment et servent les données
Créer des bibliothèques de logiciels qui normalisent l'acquisition, l'ingestion et l'intégration de sources de données externes essentielles pour la veille concurrentielle et la tarification en temps réel
Utilisez vos compétences en matière de SQL et de modélisation des données pour construire les modèles de données de la couche de base de l'entrepôt de données qui alimenteront les tableaux de bord de Sonder
Établir et maintenir la stratégie de l'entreprise en matière de lac de données/entreposage de données, définir l'architecture de données appropriée, mettre en œuvre la meilleure solution technique et continuer répondre aux besoins croissants de l'entreprise ;
Travailler avec les équipes d'analyse des produits et des activités pour garantir la disponibilité et l'accessibilité des données commerciales pertinentes et des mesures commerciales pour l'analyse des produits et les rapports sur les performances commerciales.
Comprendre intimement l'activité de Sonder et modéliser les données qui seront la source de vérité pour les KPI et les métriques de l'activité de Sonder
Concevoir et développer des plates-formes et des processus évolutifs pour l'extraction de caractéristiques, la formation de modèles et la simulation
Des outils, des processus et des contrôles propres pour aider l'équipe se développer l'échelle.
CE QUE NOUS RECHERCHONS :
5+ ans d'expérience en tant qu'ingénieur de données dans une entreprise progressiste
Compétences d'expert en codage Python
Compétences d'expert en SQL et en modélisation de données
Connaissance des principes et des méthodologies de l'entrepôt de données
Expérience dans la rédaction de travaux ETL, l'optimisation des performances et des requêtes
Solides compétences en matière de communication et capacité rassembler les exigences et les traduire en spécifications et en conception
Expérience avec les services de cloud computing AWS et les entrepôts de données comme Redshift ou Snowflake
Une formation dans l'immobilier ou l'hôtellerie est souhaitable
Autonome, très motivé et capable d'apprendre rapidement
Nous vous offrons de grands avantages pour vous faciliter la vie afin que vous puissiez vous concentrer sur ce que vous faites de mieux :
Un salaire compétitif
Un plan d'options d'achat d'actions généreux
Assurance médicale, dentaire et visuelle
Vacances discrétionnaires/ Vacances payées et congés de maladie
Crédits annuels gratuits et réductions pour séjourner Sonders
Budget mensuel de la culture : rejoignez vos collègues pour une réunion mensuelle
Une entreprise qui a une grande vision, un environnement de travail dynamique et une équipe de collègues intelligents, ambitieux et agréables travailler!
Nous sommes un employeur souscrivant au principe de l'égalité des chances et valorisons la diversité au sein de notre entreprise. Nous ne faisons aucune discrimination fondée sur la race, la religion, la couleur, l'origine nationale, le sexe, l'orientation sexuelle, l'âge, l'état civil, le statut d'ancien combattant ou le handicap.",3.0,Sonder,Montreal,"San Francisco, CA",1001 to 5000 employees,2014,Company - Private,Hotel & Resorts,Travel & Tourism,$100 to $500 million (CAD),-1,76.5,6,data engineer,senior,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,7912,0
380,"Senior Data Engineer

Nomis is looking for an outstanding data expert to join our team. The Data Engineer will collaborate closely with our client services team to process critical data while working to power advanced analytics and enable the integration of data science across the company. You are ready to be flexible and nimble in your work, from constructing ETL pipelines for customer delivery to participating in exploratory data analysis with our Analytics team.

Who We Are & What We Build

We partner with Banks and FinTechs on their journey to best-in-class pricing technology and analytics so that they deliver more value to their customers, employees and shareholders. Our top-notch people, proven technology, and innovative analytics are tackling big data challenges at banks and lenders every day. We deliver market-leading cloud-based Pricing & Profitability Management solutions and insights for the Banking & Financial Services industry leveraging cutting-edge behavioral data science. We are a Blue Chip venture-backed company with the vision to transform the consumer banking landscape.

Responsibilities
Establish and maintain big data processing platform
Build data management applications and microservices on AWS
Design and implement Hive/Greenplum/RedShift distributed data warehouses and standard schemas
Design, develop, maintain cross-platform ETL processes and MapReduce/Hive/Spark data processing workflows
Manage and maintain reference data securely on S3 and other storage systems
Support client services teams by:
Manage, customize, and automate cloud-based (AWS) data processing supporting multiple clients
Administration of relational databases, capacity plans, infrastructure and storage design
Oversee and execute data migration from existing data stores
Application/implementation of custom analytics applications and datasets
Develop code standards, guidelines, and automated test suites to ensure highest data quality and integrity
Desired Skills and Requirement
Experience with building distributed systems, query processing, and the Hadoop ecosystem
Understanding of Data warehousing - architect and design data warehouse
Expertise with data schema - logical and physical data modeling
Knowledge of ETL processes and tools
Experience with AWS or a major cloud platform such as GCP
Proficiency in: Python, SQL, Java
Strong pluses:
Experience of Business Intelligence tooling such as Tableau
Experience with data mining techniques and analytics functions
Predictive analytics experience is a PLUS
Experience with Spark 2, Apache Airflow and other modern data engineering tooling a strong plus
Experience with streaming architectures and MPP databases such as Greenplum a strong plus
Up-to-date with the open-source community w.r.t. data engineering
Experience with the following services in AWS a strong plus: EMR, Lambda, Kinesis, Firehose, S3",3.8,Nomis Solutions,Toronto,"San Bruno, CA",51 to 200 employees,2004,Company - Private,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (CAD),-1,76.5,16,data engineer,senior,0,1,0,1,0,1,1,1,0,0,0,0,0,0,0,2883,0
381,"Are you looking for an opportunity to apply your skills and talent to spark both innovation and positive social change? Symend is a rapidly growing fintech company that combines behavioral science with advanced AI, data, and analytics capabilities to enable companies to engage at-risk customers more effectively and humanely. By creating better ways to approach individuals with empathy and dignity at the time when they need it most, Symend’s employees are helping to transform the debt recovery industry and improve lives in North America and around the world.
This role is a good fit for you if:
You want to get into a fast-paced organization that is growing incredibly fast. Sales is outrunning our data engineering team and we need your help to catch up!
You’re the kind of person that likes a good challenge, is ready to roll up your sleeves and dig into the problem and can pump out some code that makes data dance for you.
You take pride in the readable code you write, add comments to make sure others can follow it and you’re ready to step up to help when it goes sideways.
You’re cool with inheriting code that you didn’t write. You empathize that someone in the history of this code had to balance their own constraints; it is what it is and you’re here to help make it better.
You appreciate the weekly mix of building solutions towards a roadmap alongside root cause analysis of problems as they arise.
You have a pod, so you don’t go it alone and you make sure your pod lead and your manager are aware of the issues that are cropping up and the approach you’re using to solve it.
You have a very collaborative attitude and you want to learn as you go!
What you’ll be doing
Build data ingest and propagation pipelines, including the SQL procs and Azure functions for transformations;
Write unit tests and develop code that will pass the tests and can be understood by others;
Perform code reviews and be comfortable with your code being reviewed by others;
Adhere to the design standards that exist, and apply new design standards as they are produced;
Perpetually look for areas of improvement with a focus on throughput speeds and automations;
Perform root cause analyses on bugs and on long-running queries and stages in the data pipelines;
Perform data mapping activities to describe source data, target data and the high-level or detailed transformations that need to occur;

Treat the product team as partners, and support them by:
only accepting work that is achievable in the sprint;
informing them when an urgent request disrupts the sprint;

Treat the QA team as partners, and support them by:
Rigorously testing your own code;
Identifying opportunities for test automation;
Making yourself available to the QA team during release testing;

Treat the Ops team as partners, and support them by:
Providing high-level workflows on how a pipeline is meant to run;
Using descriptive naming conventions that make it easy to follow the code;

Treat the client-facing teams as your data customers, and support them by:
Working with your team lead and manager to understand the challenges that they face;

Realize that it’s okay to make mistakes, if:
We learn from them, and
We flag them and inform our team leads when they happen
What you need
2 years of experience in Azure cloud platform, Azure data factory and Azure data functions;
2 years of experience with agile sprints;
5 years of experience as an integration developer in a SQL Server environment with Visual Studio and git branching patterns;
Experience with data modelling patterns (eg. ODS, Kimball, 3NF, DataVault, data virtualization);
Experienced in database development, data modelling and administration skills with SQL Server;
Experience in cloud data warehouse technologies (eg. Snowflake, Synapse) would be an asset;
Experience with SSAS and Power BI would be an asset;
Experience in python-based data development would be an asset;
BSc/BA in Computer Science, Engineering or relevant field would be an asset.
All positions require background screening. This will include criminal and education checks to comply with regulations.
Why Symend?
We could tell you all about our competitive compensation, flexible work environment, beer Fridays, and awesome team events, but working at Symend is so much more than that.
Working at Symend means being part of a driven and collaborative team that values trust, accountability and continuous learning. We work hard, but always make time for fun!
You get the chance to do work that matters on a product that truly changes lives
You get unique opportunities to serve leading global businesses including Tier-1 telecom providers, major utility companies and Fortune 500 financial institutions
You get to make history as we disrupt the debt recovery industry for the good and change the way companies engage with their clients
Ready to do something big?
Send us your resume and tell us why you’d be a fit for Symend.
About Symend
Symend is transforming the debt recovery industry by treating individuals with empathy and dignity at the time when they need it most. Combining behavioral science with advanced AI, data, and analytics capabilities, Symend’s customer engagement platform enables service providers and financial institutions to develop positive, individualized treatment programs for their at-risk customers. By approaching past-due customers with both evidence-based insight and compassion, Symend’s clients experience higher cure rates and reduced costs while building long-term relationships with customers and lifelong value for their companies and brands. Symend: The science of engagement.™",3.5,Symend,Calgary,"Calgary, Canada",51 to 200 employees,2016,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,-1,76.5,4,data engineer,na,0,1,1,0,0,1,1,0,1,0,0,0,0,0,0,5633,0
382,"Reference #: 5912
Location: Ottawa
Type: Sub-contract

Donna Cona Inc. is currently seeking a Business Analyst (Data Analyst/Data Quality Analyst), Level 3, for one of our key government clients.

Candidate MUST have the following:
A valid Secret security clearance;
Over 10+ years of experience in a Business Analyst role; and
Experience in each of the following technologies:
AWS (RDS, Redshift, Kinesis, Lambda, Firehose, EMR, DynamoDB, Glue. QuickSight, or Sagemaker);
IBM InfoSphere Information Analyzer;
InforSphere Business Glossary Anywhere;
IBM InfoSphere Information Governance Catalog; and
SQL.
The following demonstrated experience in the following Technologies:
Aginity Workbench;
Azure (SQL Data Warehouse, Databricks, HDInsight, Event Hubs, PowerBI, SQL Server, Data Factory, Stream Analytics, or CosmosDB);
IBM InfoSphere Data Architect;
IBM InfoSphere Information Server for Data Quality;
IBM InfoSphere suite;
IIBM SPSS Modeler v14+;
Power BI;
Python;
R;
SQL; and
Tableau.",5.0,Donna Cona,Ottawa,"NEPEAN, Canada",1 to 50 employees,1996,Company - Private,Consulting,Business Services,$5 to $10 million (CAD),-1,76.5,24,data analyst,na,0,1,1,1,0,1,0,0,1,0,0,0,0,0,0,990,0
383,"Are you a Data Engineer guru? Do you have strong managerial and leadership skills? If so, we want to meet you!

This position manages a Data Engineering team and has primary responsibility of building and maintaining an Analytics Platform with high quality, clean data that can be used to power the analytics team and other verticals to make informed decisions with data. This position is responsible for defining best practices around enterprise class data platforms and developing core data engineering capabilities including, but not limited to, data quality processes, data pipelines, data aging and change management systems as well as containerization and model automation. The role manages a team of Data engineers responsible for building solutions which are flexible, performant and scalable. Incumbents must have in-depth knowledge of analytic platforms.

Our client has been around for over 15 years and has remained a well reputed company in Canada.

Position Responsibility:
Manages a team of Data Engineers and is responsible for the delivery of a next gen Data Platform
Work Closely with existing IT team across the company to develop optimal data pipelines for ingesting data from various sources.
Identify and work with data scientist and analysts to understand their daily workloads and suggest techniques and tools for optimization.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using AWS tools like glue, step functions, lambda and others.
Develop relationships with IT config, security and other teams across the company to understand and develop data science development lifecycle.
Develop code in python to write serverless functions to automate the data flow as per existing architecture.
Develop code in python for data quality for pipelines to reduce time spent on data cleaning.
Being able to initiate and coordinate discussion with vendors and engage the required participants leading to delivery.
Develop integration patterns with third party and internal systems of data like salesforce, mobile and others.
Develop partnerships with data, IT security, Cloud infrastructure and other teams at the company to ensure timely execution of responsibilities for data science projects.
Responsible for timely execution of data engineering projects in fast paced environment with a team of data engineers.
Develop change management and data quality processes to ensure users of data are able to focus on insights.
Strong understanding of basic data science principles.
Qualifications:
Minimum of a Bachelor’s degree in Computer Science, engineering or related degree and seven (7) years of relevant experience including management or leadership experience or an equivalent combination of education, training and experience.
Strong leadership skills to move the organization through change and drive to succeed and identify and solve potential obstacles.
Advanced working knowledge of ETL processes and databases including but not limited to redshift.
Working knowledge of serverless ecosystem on AWS and its advantages and disadvantages.
Good understanding of IT security processes around data.
Experience with data pipeline and workflow management tools like AWS Step functions, Airflow.
Experience integrating and maintaining data bricks or like solutions.
Pushing machine learning models to and from mobile application.
Experience with AWS cloud services: Redshift, Lambda, Glue (ETL tooling).
Experience with data optimization and compression techniques like parquet, Avro, gzip, snappy.
Strong project management and organizational skills.
Experience with big data tools: Spark, Hadoop, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Contact Details


Don't miss out on this great opportunity! Apply Today!

Qualified candidates please submit resume to saudn@fuzehr.com for consideration. Contact Saud at (905) 361 - 3987 ext: 126",3.6,Fuze HR Solutions,Woodbridge,"Montreal, Canada",51 to 200 employees,2006,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,"Robert Half, Randstad, Adecco",73.5,14,data engineer,na,0,1,0,0,0,0,1,1,0,0,0,0,1,0,0,3998,3
384,"Description:
Skip, as a division of Just Eat- Takeaway, is searching for a Senior Data Engineer to join the Data Systems team. Youll have the opportunity to work with big data technologies, building scalable and reliable solutions to support real-time analytics, advanced data science and critical operational projects powered by data.

What We Do

The Data Systems teams role is to build a transformational data platform in order to democratize data in Just Eat. Our team is built on the following ideals:
Open Data: We ingest all data produced across Just Eat using batch and real-time pipelines and make it available to every employee in Just Eat. This data is then used to drive analytics, business intelligence, data science and critical business operations.
Self Service: We build tools, frameworks and processes to support self-service modelling and activation of data. Our goal is to empower our users to find, process and consume our data without barriers.
Single Truth: We build services that host all metadata about Just Eats data in a single store and promote governance, data culture and Single Source of Truth.
Intelligent Personalisation: We build and maintain a machine learning platform that supports data scientists in developing and deploying ML models at production scale. This allows us to deliver insights, personalization and predictions to our customers at scale.
How We Do It

Our team is built on the following tenets:
Innovate: We are always learning, growing, inquisitive and keen on new technologies and open source tooling. We love like-minded engineers with a passion to keep our code-base and infrastructure best in class.
Build for Scale: All our tools and components are built for scale and we use Kubernetes and other tools to help us scale automatically.
Cloud-based: We use serverless technologies where possible to simplify our estate, technologies like BigQuery, PubSub, Dataflow and Cloud functions allow us to move quickly. In addition, we run a Kubernetes cluster on GKE with many workloads including instances of Apache Airflow.
DevOps culture: Everyone in the team contributes to infrastructure, we have a CI/CD pipeline and we define our infrastructure as code. Our stack includes Terraform, Jenkins and Helm. Teams monitor their applications using Prometheus, Grafana and alert manager.
Collaboration & Ownership: All code is owned by the team and we have multiple avenues for collaboration - rotation, pairing and technical showcases. We also encourage team members to own their own code and promote self-governance.
Were looking for an enthusiastic engineer to join the Self Service Tools team within Data Systems

Self Service Tools

Our mission is to enable all employees to be self-sufficient with data so that data-driven decisions can be made quickly and easily. We build and maintain all of Just Eats data-centric tools.

We use engineering to simplify tasks, reducing the technical barrier of entry to navigate, explore and consume our data. Our tools use Airflow to unlock the tasks of transformation and egress of data, making these simple functions that can be undertaken by anyone.

We support over 200 active users across the business, building Airflow backed tools that run thousands of DAGs in multiple timezones. We manage and run our own Airflow clusters on Kubernetes. We work together as a team in three countries to produce innovative products and keep data flowing.

You should apply if
You love writing well tested, readable and performant code, capable of processing large volumes of data. You have mastery in Scala and/or Python.
You love working with Cloud technologies and have experience in working with AWS, Azure or Google Cloud. We use Google Cloud with a mix of services - Kubernetes, Dataflow, PubSub etc.
You can contribute to architecture discussions and influence peers and stakeholders to make better decisions.
You have the inclination to collaborate and the ability to communicate technical ideas clearly.
You understand the entire product development lifecycle, from coding to deployments, to monitoring, alerting etc... Our teams maintain all aspects of our product lifecycle, but we dont expect everyone to be an expert in all of it.
You understand the fundamentals of computing and distributed systems.
What Its Like To Work At Skip:

Picture this: you, dressed in your fave casual attire, amongst a team of friendly and passionate colleagues. You feel pride knowing your input and uniqueness is not only embraced, but makes an impact on a major Canadian company, and its satisfied customers. As the company grows, so do youyou meet and surpass new challenges every day.

This is just a taste of what its like to work at one of Canadas leading tech companies. If youre hungry for opportunity, growth, and something meaningful in a dynamic yet casual environment, wed love to hear from you.

Note: All employees will be asked to sign a Consent for Disclosure of Personal Information in order to complete a background check. Job offers will be conditional upon results that the Company determines to be satisfactory.",3.3,SkipTheDishes,Winnipeg,"Winnipeg, Canada",201 to 500 employees,2013,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,73.5,7,data engineer,senior,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0,5103,0
385,"Are you passionate about building tools that have an immediate impact on your customers?

Do you want to help build some of the most sophisticated data-driven products in the eCommerce industry?

Do you want to help collect, store and manage TBs of data per day?

Do you thrive when you're contributing to a high-performing, humble team?

Amazing, then youre the type of person were looking for!

At Jungle Scout, we are on a mission to empower entrepreneurs to be successful Amazon sellers. We work hard, keep it real and do it all for our customers by providing industry-leading tools, education and content.

Were growing and we are looking to add a Senior Data Engineer to our fast-paced and customer-oriented team.

Where would this person be located? Great question! We have hubs in Vancouver, BC, Austin, TX and Shenzhen, CN. So if youre located in one of these cities - you're welcome to work in our offices! Jungle Scout started remotely and we want to stick to our roots, so we are open to hiring the right candidate remotely as well.

Interested in learning more? Lets get into the details:

What you will be doing:
Architect and build. You will help collect, manage and transform data for our engineering teams to enable the development of cutting edge, data-driven features in the Amazon space
Build and Maintain tools. You will help build and maintain various internal tools and dashboards that allow us to continually deliver high quality data to our customers
Eye for Detail. Youll use your eye for details to QA the data flowing in from our various apps to ensure accuracy and completeness. You know how to design effective monitoring for high-performance systems so we can proactively tweak our applications.
Make recommendations. You will play an active role in the way we make decisions around technologies to be used for new applications and improvements on existing applications
Scale, maintain, and improve. As we continue to grow, youll anticipate challenges before they happen by maintaining existing codebases and system infrastructures, as well as enhancing the development, staging and production environments of our applications.
Participate and contribute. Youll have an active hand in code reviews, as well as in project planning and management. Youll also provide input for ongoing improvement of engineering practices and procedures.
Passionate mentor. We are firm believers in knowledge sharing and supporting team development. You will coach other developers on programming and infrastructure best practices.
If you are thinking heck yeah!, please read on.

Who you are:
Done this before. We believe experience is best measured in results and intensity (not years), but you need to have been in this software development game a while. You also need to have experience with some subset of our primary tech stack: Ruby on Rails, Node, Python, Postgres, DynamoDB, Elasticsearch and Redshift.
Big Data Wizard. You have real-world experience using some of the following big-data tools: Hadoop, Spark, Flink, Storm, and Kafka
Heavy toolbelt. You know your way around working with SQL, know when to import a library or write code yourself for that Node project. You understand how your tools work in detail, and can show your team a thing or two.
AWS Cloud master. Youre an expert with AWS services, you can deep dive on any of the following tools: EC2, RDS, DynamoDB, Elasticsearch, ElasticBeanstalk, Lambda, Cloudwatch, SQS and SNS
Who we are:

Jungle Scout is the leading all-in-one tool for selling on Amazon, with the mission of providing powerful data and insights to help entrepreneurs and brands grow successful Amazon businesses.

The Jungle Scout team is a group of smart, motivated, and fun-loving professionals working hard to help our customers achieve success. We have a remote-first culture with employees across the world as well as in our hub offices in Austin TX, Vancouver BC and Shenzhen China. We believe team members should have the opportunity to choose the work environment that works best for them. Team members have the option of working from home, at one of our hub offices, or from a co-working space.

We offer workplace flexibility, competitive compensation packages, 401K/RRSP matching, generous vacation, and professional development to help you thrive in your career. The entire Jungle Scout team also gathers for annual all-expenses-paid retreats past locations have included Bali, Bangkok, Vietnam, Budapest, Mexico, Colombia, and Costa Rica. Check us out!

Powered by JazzHR",4.1,Jungle Scout,Vancouver,"Austin, TX",51 to 200 employees,2016,Company - Private,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,-1,73.5,4,data engineer,senior,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,4538,0
386,"Data Engineer
LOCATION: TORONTO

Capco – The Future. Now.

Capco is a distinctly and positively different place to work. Much more than consultants, we are active participants in the global financial services industry. Our passionate business and technology professionals enjoy a unique environment where they are actively encouraged to apply intellect, innovation, experience and teamwork. We are dedicated to fully supporting our world class clients as they respond to challenges and opportunities in: Banking, Capital Markets, Finance Risk & Compliance, Insurance, and Wealth and Investment Management. Experience Capco for yourself at capco.com

Let's Talk About You

You want to Own Your Career. You're serious about rising as far and as fast as your work and achievements can take you. And you're ready to write the next chapter of your career story: a challenging and rewarding role as a Capco Data Engineer.

Let's Get Down To Business

Capco is looking for talented, innovative, and creative people to join our development team to work on a number of projects and applications with a Data focus within the Digital practice.

Fitting that description, you will also need to be personally motivated to work in a team where clients become colleagues too.

Responsibilities
Produces high quality complex, deliverables with minimal input from stakeholders
Manage full software lifecycle for medium complexity projects from requirements, to design, to implementation, to testing
Develop and maintain back end solutions using cutting edge technologies and products
Work with Scrum Masters and product owners to priorities and deliver solutions using an Agile environment
Build reusable code and libraries for future use and follow emerging technologies
Mentor and train junior developers
Education/Experience
Bachelor's degree (preference given to Computer Science, Engineering, Gaming and STEM-based majors) or equivalent experience
Five (5) or more years of experience as a Full-stack Data Engineer/developer on Data driven projects
Strong understanding of the full development lifecycle including requirements, architecture, design, development and testing
Strong development experience with Scala/Spark
Experience working with REST APIs/Springboot.
Familiarity working with Java and Hive.
Ability to balance competing priorities in a very dynamic and fast-paced environment
Excellent detail-oriented, problem solving skills and the ability to quickly learn and apply new concepts, principles and solutions
Must have excellent communication skills (verbal and written)
Show Us What You've Got

It will be very useful if you have some or all of the following skills:
Understanding of big data and distributed programming concepts
Experience working with ASW, GCloud, Docker, Kubernetes
Experience working with Microservices, CQRS, EventSourcing
Experience working with Spring, Akka, Spark
Experience working with Reactive Streams (Rx, Akka, Reactor)
Strong organizational and communication skills
Experience working in an Agile environment
Experience working with code versioning tools
Experience working with build, packaging and continuous integration tools and frameworks
Professional experience is important. But it's paramount you share our belief in disruptive innovation that puts clients ahead in a tough market. From day one, your key skill will be to perceive new and better ways of doing things to give your clients an unfair advantage.

Now Take the Next Step

If you're looking forward to progressing your career with us, then we're looking forward to receiving your application.

Capco is well known for its thought leadership and client-centric model that distinguishes it from other consulting firms. Capco's strong technology and digital knowledge base, it's global experience of the Financial Service enables us to deliver projects from strategy through to delivery. We are committed to providing new areas of expertise from which our clients will greatly benefit. We have:
Access to industry-focused talent globally
Ability to leverage best-of-breed, innovative products and solutions for complex architecture and large-scale transformation
Extended global geographic market reach
Ability to capitalize on our client footprint and deep domain expertise within financial services
For more information about Capco, visit www.Capco.com.

Capco is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics.",3.9,Capco,Toronto,"London, United Kingdom",5001 to 10000 employees,1998,Company - Public,Consulting,Business Services,$1 to $2 billion (CAD),"Deloitte, EY, Accenture",73.5,22,data engineer,na,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,4632,3
387,"Ultimate Software is looking for a Senior Data Engineer to join our analytics experts within the Business Intelligence and Data Warehousing product development Organization. The individual will be responsible for optimizing our data pipelines and helping to design our next generation analytics environment. The ideal candidate is experienced in data pipeline builder who enjoys building new solutions and optimizing existing solutions. Must be self-directed and comfortable supporting the data needs of multiple teams, systems and products. And be excited by the prospect of optimizing or even re-designing our company’s data architecture to support our next generation of products and data initiatives.

The role will support our database architects, business analysts, product owners, and the data scientists on complex data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. You will do so by partnering with stakeholders/teams and building scalable solutions that provide business critical insights and metrics, while ensuring the best uptime and responsiveness.

Here at Ultimate Software, we truly put our people first. We strongly believe in teamwork, and we encourage and trust our people to reach higher, learn more, and live up to their potential. Ultimate is ranked #1 on Fortune's Best Places to Work in Technology for 2020 and #2 on the 100 Best Companies to Work For list in 2020. Ultimate is also ranked #2 on Fortune’s 75 Best Workplaces for Women and #9 on its Best Workplaces for Diversity list. Learn more about US here:www.ultimatesoftware.com/careers

Primary/Essential Duties and Key Responsibilities:
Assemble large, complex data sets that meet functional / non-functional business use cases.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability.
Build software required for optimal extraction, transformation, and loading of data from a wide variety of data sources using numerous technologies.
Build analytics data pipelines to provide actionable insights into customer behavior, operational efficiency and other key business performance metrics.
Work with key personnel to assist with data-related technical issues and product support.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with product teams to strive for greater functionality in our products.
Required Qualifications:
2+ Public Cloud Development Experience
3+ years of experience with Spark, Flink, Samza, Kafka Streams, Akka Streams, and/or Storm for .
5+ years of experience in a Data Engineering role
5+ years of experience with object-oriented/object function scripting languages: Python, Java, Scala, etc.
5 years of experience with SQL and NoSQL databases
7+ Experience building and optimizing data pipelines, architectures and data sets.
Experience supporting and working with cross-functional teams in a dynamic environment.
Working knowledge of DevOps methodology and Site Reliability Engineering
Experience with Business Intelligence tools and platforms.
Education:

Bachelor’s degree in Computer Science, Statistics, Informatics, Information Systems, another quantitative field or relevant work experience.

Preferred Qualifications:
Experience working with Google Cloud Platform.
Experience with deployment/CI/CD tools like: Teamcity, Maven, Jenkins, etc
Advanced working SQL knowledge and experience working with numerous large- scale SQL and NoSQL databases.
Experience with data pipeline and workflow management tools: Azkaban, Luigi, Airflow, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with structured and unstructured datasets.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Strong project management and organizational skills.


Travel Requirements:
25%
This job description has been written to provide an accurate reflection of the current job and to include the general nature of work performed. It is not designed to contain a comprehensive detailed inventory of all duties, responsibilities, and qualifications required of the employees assigned to the job. Management reserves the right to revise the job or require that other or different tasks be performed when circumstances change.

Ultimate Software will reasonably accommodate employees with disabilities as defined by the Rehabilitation Act of 1973, the Americans with Disabilities Act (ADA) and other appropriate statutes. If you are an applicant and need a reasonable accommodation when applying for job opportunities within the Company or request a reasonable accommodation to utilize the Company’s online employment application, please contactaccessibility@ultimatesoftware.com.

Beware of phishing or suspicious messages that appear to come from a trusted or known source and that asks for personal information, account information or requests that you send money to cover expenses associated with a job or otherwise. Ultimate Software does not ask for this information from our job applicants or candidates and never asks for any applicant or candidate to send money.

It has come to our attention that some people have been contacted online by persons impersonating job recruiters for Ultimate Software. These fraudulent“recruiters” have used Gmail accounts to contact, and have requested personal information, such as depositing a check to purchase work-related supplies. These are not legitimate recruiters or job offers, and do not represent Ultimate Software. To safely apply for and view open positions at Ultimate Software, please click“Apply"" and follow the instructions. Note that our recruiter emails always come from an official ultimatesoftware.com email address.

If you suspect you have been the victim of this or a related fraud, immediately contact your financial institution, and then file a complaint with the FBI’s Internet Crime Complaint Center at www.ic3.gov. If you shared other personal or sensitive information, you may need to take additional actions relative to what was shared. Your local law enforcement department may also be able to assist. For any general security related questions regarding Ultimate, feel free to email security@ultimatesoftware.com.",4.5,Ultimate Software,Toronto,"Weston, FL",5001 to 10000 employees,1990,Company - Private,Enterprise Software & Network Solutions,Information Technology,$2 to $5 billion (CAD),"ADP, Workday",73.5,30,data engineer,senior,0,1,0,0,0,1,1,0,0,1,0,0,0,0,1,6581,2
388,"ICBC is committed to delivering consistently high quality customer service to all British Columbians. If you are interested in receiving a competitive salary, doing meaningful work, contributing to an inclusive and respectful workplace and are a responsible and reliable team member, we invite you to apply to join us at ICBC. Drive your career with us.
ICBC is committed to being an inclusive employer, one that reflects the diversity of the people and communities of British Columbia.
Position Highlights
The Senior Data Engineer will join the Information Management team and focus on the development of big data reporting and analytics solutions, working closely with business partners and stakeholders to meet their decision-support requirements.
As the consolidation point for all business intelligence and business analytics functions across ICBC, the Information Management team's goal is to empower the organization to drive efficiencies and savings across all facets of the business. This is accomplished by providing internal and external customers with precision reporting, query and analysis, statistical, descriptive analysis, and performance measurement (dashboards, scorecards and indicators).
Accountabilities will include:
Working in collaboration with customers across the organization (Claims, Insurance, Finance etc.) to plan, scope, execute and sustain data-based solutions
Responding to internal and external ad hoc requests, review and clarify data requirements, ensuring report content is acceptable within policy and privacy protocols
Providing subject matter expertise within the department and to clients on data sources, reporting workflows, business process, and the appropriate tools with which to analyze their data
Participate with corporate data user teams, developing data validation and test plans, performing user acceptance testing, and providing feedback to development and sustainment teams
Conducting analysis for moderate to complex requests, defining data fields and determining data availability, developing information layout, format and interactivity.
Presenting findings and providing clarification.
Position Requirements
To make an immediate contribution, the Senior Data Engineer will bring the following:
Advanced skill in programming languages such as Scala or Java
Working experience with Big Data platforms, with exposure to Hadoop ecosystem (HDFS, Hive, Spark, Kafka)
Advanced working SQL knowledge and experience working with relational databases and SQL
Strong analytic skills related to working with unstructured datasets.
Demonstrated ability to work with large and complex datasets, while managing priorities and responding to time pressures
Detail-oriented with demonstrated ability to meet deadlines, manage multiple priorities and work effectively under pressure
Strong data quality management process understanding, data analysis and data profiling
Ability to apply critical thinking skills to troubleshoot and perform root cause analysis on technical problems and solution design
Providing technical advice and guidance to staff in resolving complex data ingestion and transformation issues
Experience with performance tuning and code optimization
Design, develop and enforce best practices and standards around data engineering
Ability to work effectively with a team or independently, as well as lead small teams as needed
Understanding of Agile Methodologies
Excellent interpersonal, verbal and written communication skills to work with Managers, Directors & Executive level stakeholders
•Experience with reporting and visualization tools, such as Tableau, user interface design, and iterative customer-driven design processes would be an asset.
Please include with your resume, a cover letter that describes your experience with Big Data platforms, SQL and projects that closely relate to this position. Also include other related experience you feel will be an asset to this role.
Only candidates legally entitled to work in Canada at present will be considered for this position.",3.7,ICBC (Canada),North Vancouver,"North Vancouver, Canada",5001 to 10000 employees,1973,Government,Insurance Operators,Insurance,$2 to $5 billion (CAD),-1,73.5,47,data engineer,senior,0,0,0,1,0,1,1,0,0,0,0,0,0,0,0,4048,0
389,"SENIOR DATA ENGINEER

As a Senior Data Engineer you will report to the Director Data Science at our new mobile technology studio and will help develop and maintain the ETL solutions necessary to provide the data that powers our game analysis and reporting.

We are looking for a senior data engineer to join our efforts in data science, machine learning, and R&D. Youll be part of a central studio data science team, working with our data scientists and analysts to architect data pipelines, support machine learning research, and build feature prototypes.

Responsibilities
Design, model, develop and maintain data sets to support reporting analytics and exploratory analysis
You will contribute to the technical solution from design through code level
Contribute to technical design and ongoing development of our custom ETL solutions and analytics platforms, and help improve our design and delivery standards
Work with big data developers to build scalable and supportable infrastructure
Employ a variety of languages and tools (e.g. scripting languages) to marry systems together
Assess and support the implementation available and latest big data technologies
Help build a machine learning platform for data scientists to develop and execute models.
Participate in reviews and meetings
Recommend ways that we can improve data reliability, efficiency and quality
Qualifications:
Bachelors or Masters degree in computer science or software engineering
Advanced working SQL experience working with relational databases, query authoring (SQL) and working familiarity with a variety of databases
6+ years of experience building and optimizing big data data pipelines, architectures and data sets
Strong analytical skills related to working with unstructured datasets
Experience performing root cause analysis on our data and processes to answer specific questions and identify opportunities for improvement
Experience working with big data technologies including BigQuery, Apache Beam, Apache Airflow
Experience working with ML technologies including Scikit, TensorFlow, and KubeFlow.
Experience developing software using Python, Java, SQL
You are expert in researching troubleshooting techniques and best practices and use of new technologies",3.9,Electronic Arts,Vancouver,"Redwood City, CA",5001 to 10000 employees,1982,Company - Public,Video Games,Media,$2 to $5 billion (CAD),"Riot Games, Google, Activision Blizzard",73.5,38,data engineer,senior,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,2244,3
390,"At Kinaxis, who we are is grounded in our common belief that people matter. Each one of us plays an important part in accomplishing our work, building our culture and making a global impact.

Every day, we're empowered to work together to help our customers make fast, confident planning decisions. This is how we create a better planet for each other, for our customers and for generations to come. Our cloud-based platform RapidResponse ensures that the products we need everything from medicine and cars, to day-to-day items like toothpaste make it to market and into our hands when we need them with minimal ecological footprint.

We make the world better, and you can too.

Senior Machine Learning Engineer


Job location: our office in Toronto, Canada

Who We Are Looking For


All aspects of the software development life cycle are familiar to you. You are passionate about shipping large-scale software systems in a fast-paced environment but are able to balance longer term issues such as maintainability, scalability and quality. You have a strong interest and experience in machine learning having worked with machine learning and data analysis libraries such as pandas, scikit-Learn, XGBoost, lightGBM and Tensorflow but realize building a machine learning system is much more than just calling a few APIs.

You treat data as a first class citizen whether that the data comes from a data warehouse, object storage or output of a model. You're fluent in Python and SQL and have hands-on experience with big data technologies such as Spark and Hadoop. You love learning about new technologies whether they be in the ML or data space but are pragmatic and discerning about which technologies you adopt in your system.

You are a team player, a quick starter and an implementer who is equally comfortable talking requirements with technical product managers or getting in the zone pair programming with data scientists. Your primary focus is on shipping large-scale machine learning software systems that drive customer value by building robust and scalable computational and data-intensive workflows and web services.

Requirements
Bachelor's degree or equivalent in Computer Science or a related field with focus in machine learning.
Strong software engineering skills and understanding of the ML lifecycle with a minimum of 3 years experience in ML and 5 years in software development.
Proficiency in Python.
Fluent in processing data with pandas and PySpark (e.g. querying, transforming, joining, cleaning, etc.) including experience debugging logic and performance issues.
Strong understanding of machine learning algorithms with experience writing, debugging and optimizing ML data structures, pipelines and transformations.
Ability to work in Linux environments with containerization technologies (Docker, Kubernetes, Argo) and major cloud services (AWS, GCP, Azure).
Nice to have
Retail and CPG business background.
SaaS, multi-tenant and MLaaS development experience (microservice frameworks, queuing systems, event-based processing and web services).
Machine learning dev-ops experience with major cloud providers (e.g. Kubernetes, Terraform).
What we have to offer
Challenging Work - We love solving highly complex problems. And as the global leaders in our industry, we never stop innovatingour work is never ""done. That's because across our teams and in all roles, every employee is empowered to bring their best ideas forward and to jump in and solve the problems they're passionate about.
Great People - We take our work seriously, but we don't take ourselves too seriously! It's in our DNA to celebrate, laugh, and have fun. We are stronger, together, when we are open, honest, and above all, real. Every person is valued here and plays an important role in our shared success.
Global Impact - As a global team spanning continents, boundaries, and cultures, every day we are inspired by the impact our work has on our colleagues, our customers, our communities, and the world at large.
For more information, visit the Kinaxis web site at www.kinaxis.com or the company's blog at http://blog.kinaxis.com/.

Kinaxis invites candidates to apply to its welcoming community. Accommodations are available upon request for applications in all aspects of the recruitment process. If you require accommodation, please contact Human Resources at accommodation@kinaxis.com",4.7,Kinaxis,Toronto,"Kanata, Canada",501 to 1000 employees,1984,Company - Public,Enterprise Software & Network Solutions,Information Technology,$100 to $500 million (CAD),-1,73.5,36,machine learning engineer,senior,0,1,0,0,0,1,1,0,1,0,0,0,1,0,0,4385,0
391,"Job Type: Permanent
Primary Location: Vancouver, British Columbia, Canada
All Available Locations: Calgary; Montreal; Toronto; Vancouver

Be encouraged to deepen your technical skills…whatever those may be.

Be expected to share your ideas and to make them a reality.

Be part of a firm where you are valued for your unique strengths and where everyone feels a sense of belonging.
Do you dream about data? Do you speak SQL as well as your mother language? Are you motivated by solving complex problems by leveraging best-in-class data pipelines? We want to hear from you!
What will your typical day look like?
Everyday you will work with our clients to solve their toughest problems in data engineering, data acquisition, and data standardization. You will do so by leveraging leading technology to accomplish large-scale implementations. You will facilitate design sessions with business stakeholders to define key data definitions, consolidate findings, and work with technology teams to develop appropriate data models. Everyday, you will design and implement optimal data pipeline architecture that is auditable, redundant, scalable and high-performing. Since we know you are a great self-starter, you willm also build the cloud infrastructure and pipeline required for optimal extraction, transformation, and loading of data from a wide variety of data sources (structured and un-structured, streaming and batch).
About the team
Omnia AI, Deloitte's Artificial Intelligence practice is comprised of specialized experts with hands-on experience, and cutting-edge information assets that facilitate successful Artificial Intelligence (AI) transformations. We develop AI-enabled solutions to address all aspects of a client’s transformative journey with disciplined focus on business outcomes.

As a member of our Data & Analytics Modernization team within our Omnia AI practice, you will help our clients design and implement the data platform architectures – be it in the cloud or on-premises – required to enable cutting-edge AI solutions. You will be part of a practice to deliver a breadth of solutions to solve our clients most challenging business problems, with a focus on Big Data, BI/DW, Data Integration, Data Governance, Master Data and Analytics applications. Each of these applications leverages a different mix of traditional and innovative technologies to achieve business outcomes.
Enough about us, let’s talk about you
With hands-on Microsoft Azure data ingestion experience, with at least 2 projects (minimum of 3 month each)
Who has leveraged at least 3 out of these 2 components: Azure Data Factory, Azure Event Hub, Databricks
With 1+ years of hands-on experience with data ingestion on Azure
With 3+ years of relevant technology consulting or industry experience in data & analytics delivery
With 2+ years of experience designing and developing data pipelines, data cleansing routines utilizing typical data quality functions involving standardization, transformation, rationalization, linking and matching
With Azure Data Engineer Certification

Why Deloitte?

Launch your career with The One Firm where you can make an impact that matters in a way that you never thought possible. With endless opportunities at every turn, and a culture built to support and develop our people to be the very best they can be, Deloitte is The One Firm for you to learn, grow, create, connect, and lead. We do this by making three commitments to you:
You will lead at every level: We grow the world’s best leaders so you can achieve the impact you seek, faster.
You can work your way: We give you the means to be flexible in how you need and want to work, and we have innovative spaces, arrangements and the mindset to help you be wildly successful.
You will feel included and inspired: We create a deep sense of belonging where you can bring your whole self to work.
The next step is yours

Sound like The One Firm. For You?

At Deloitte we are all about doing business inclusively – that starts with having diverse colleagues of all abilities! We encourage you to connect with us at accessiblecareers@deloitte.ca if you require an accommodation in the recruitment process, or need this job posting in an alternative format. We’d love to hear from you!

By applying to this job you will be assessed against the Deloitte Global Talent Standards. We’ve designed these standards to provide our clients with a consistent and exceptional Deloitte experience globally.",3.9,Deloitte,Vancouver,"New York, NY",10000+ employees,1850,Company - Private,Accounting,Accounting & Legal,$10+ billion (CAD),"Amazon, PwC, McKinsey & Company",49.0,170,data engineer,senior,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,4472,3
392,"Req Id: 244472

At Bell, we do more than build world-class networks, develop innovative services and create original multiplatform media content – we’re revolutionizing how Canadians communicate.

If you’re ready to bring game-changing ideas to life and join a community that values bold ideas, professional growth and employee wellness, we want you on the Bell team.

Bell’s forward-thinking Customer Operations team is creating the ultimate service experience for our residential, wireless and small business consumers. We lead strategic development and execution of day-to-day operations, develop tools and processes to drive service enhancements, manage customer loyalty and retention, and leverage big data and artificial intelligence to create intellectual property.

We have been building our Business Intelligence team and have made tremendous strides in creating the BEST BI environment this industry has seen! As a result, we've been able to provide strategic guidance and intelligence that has contributed to Bell's success. If you want to work with the latest & greatest BI tools like, Best in Class Teradata, SAS and Hadoop all within an Agile Methodology environment, then this may be the role for you!

Our people are empowered to make big things happen and are supported by growth, training and personal development opportunities.

About the Role

The Hadoop\Linux Administrator will be a key member of the Bell Business Intelligence Big Data Team and support the Hadoop platform. The Hadoop Administrator will work closely with Hadoop Developers, Data Scientists, and IT. This position will be responsible for, but not limited to:
Diagnose, assess, troubleshoot and fix issues within the Hadoop ecosystem.
Performance tuning, troubleshooting, resource and capacity management of users and scheduled jobs.
Enforce OS/app security compliance and BI governance rules.
Documentation of all environmental settings and configurations.
Planning and upgrading of the environment, both hardware and software (where applicable).
Provide front line support to teams using Hadoop, Openshift and environments.
Ensure availability and stability of the systems in production.
Interface with various stakeholders and lead technical discussions\recommendations.
Along with the rest of the team, actively research and share learning/advancements in the Hadoop space, especially related to administration.
Essential Skills

The following skills would be considered assets:
Degree in Computer Science or related discipline.
Aptitude for self-learning and a drive to learn new skills
Experience using and troubleshooting Open Source technologies. (3+ years)
Strong RHEL Linux skills. Experience automating routine tasks and writing bash scripts (3+ years)
Knowledge of Hadoop components and familiarity with the Hadoop tool set such as Spark, Sqoop, Hive, Impala, Yarn, etc. (1+ years)
Knowledge of Hadoop architecture and the evolving role of Hadoop in the Enterprise environment
Knowledge of Hadoop related coding languages (Spark, Python) and SQL for Performance tuning reasons.
Experience with any of the above responsibilities or Cloudera specific tools is preferred
Experience working with Kerberos in a LDAP environment
Comfortable with SSL\TLS security concepts and certificates.
Knowledge of Containers and its concepts. Familiarity with Docker\Kubernetes\Openshift
Postgresql or RDBMS administration experience
And must be a team player and fit well with the Bell Business Intelligence culture!
#MR

#LI-ML1

Bilingualism is an asset (English and French); adequate knowledge of French is required for positions in Quebec.

Additional Information:

Position Type: Management
Job Status: Regular - Full Time
Job Location: Canada : Ontario : Don Mills
Application Deadline: 07/31/2020

Please apply directly online to be considered for this role. Applications through email will not be accepted.

At Bell, we don’t just accept difference - we celebrate it. We’re committed to fostering an inclusive, equitable, and accessible workplace where every team member feels valued, respected, and supported, and has the opportunity to reach their full potential. We welcome and encourage applications from people with disabilities.

Accommodations are available on request for candidates taking part in all aspects of the selection process. For a confidential inquiry, simply email your recruiter directly or recruitment@bell.ca to make arrangements. If you have questions regarding accessible employment at Bell please email our Diversity & Inclusion Team at inclusion@bell.ca.

Created: Canada, ON, Toronto

Read more about why Bell is considered one of Canda's Top 100 Employers.",3.6,Bell Canada,Toronto,"Montreal, Canada",10000+ employees,1880,Company - Public,"Cable, Internet & Telephone Providers",Telecommunications,$10+ billion (CAD),"Rogers Communications, TELUS, IBM",49.0,140,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,4677,3
393,"// ENGLISH VERSION WILL FOLLOW ...//

Poste: Analyste de données

Relève de: BI Manager

Fonctions:
Déterminer les besoins de l’équipe de jeu au niveau analytique;
Définir les spécifications de la collecte d’information;
Apporter du support aux programmeurs lors de l’implémentation du système de collecte de données;
Participer au processus de vérification de qualité des données en collaboration avec l’équipe QA;
Créer des modèles analytiques et tableaux de bord personnalisés;
Générer des rapports d’analyse personnalisés;
Présenter, sous forme de story telling, les insights générés au travers des analyses, à tout type d’audience;
Fournir des recommandations opérationnelles en termes de design et de monétisation;
Participer à l’amélioration continue des processus décisionnels au sein de l’équipe de production;

Expérience et qualifications:
3 ans d’expérience pertinente ou équivalente dans le domaine du jeu mobile ou connexe.
Expérience de production d’une application mobile est un atout majeur.
Expérience avancée avec des plateformes analytiques tel que deltaDNA ou Amplitude.
Expérience pertinente avec des outils de reporting tel que Looker, PowerBI ou Tableau.
Compétent au niveau statistique et data mining.
Capacité de générer des connaissances poussées à partir de jeu de données multidimensionnel.
Bonne compréhension des concepts de Game Design, Economic Game Design et monétisation pour un jeu mobile.
Expérience en programmation SQL : un atout important.
Connaître d’autres langages de programmation tels que R et Python sont des plus.

Qualités interpersonnelles:
Grandes habiletés pour expliquer des phénomènes complexes et interreliés de façon claire et concise à tout type d’audience (anglais et français).
Axé sur l’impact opérationnel, débrouillard et capable de prendre de l’initiative.
Excellentes compétences relationnelles, capable de collaborer avec différents intervenants qui ont des objectifs différents et potentiellement contradictoires.
Faire preuve de pragmatisme et de rigueur dans les approches méthodologiques.
Être capable de s’adapter dans un environnement où les priorités peuvent changer régulièrement.
Être capable de faire preuve d’humilité et d’aider à faire progresser l’équipe

Motivation et intérêts:
De l’ambition et de la passion pour les jeux vidéo sont essentiels!
Title: Data Analyst
Reports to: BI Manager

Duties:
Determine the development team’s needs at an analytical level;
Define the specializations of the information collected;
Provide support to the developer when implementing the data collection system;
Participate in the verification process of the data quality in collaboration with the QA team;
Create analytical models and personalized dashboards;
Generate personalized analytical reports;
Present in a story telling format the insights generated through analyzes, to all types of audiences;
Provide operational recommendations in terms of design and monetization;
Participate in the continuous improvement of decision-making processes within the production team.

Experience and qualifications:
3 years of pertinent experience or equivalent in the mobile game field or related;
Production experience of a mobile application is a major asset;
Advanced experience with analytical platforms such as deltaDNA or Amplitude;
Pertinent experience with reporting tools such as Looker, PowerBI or Tableau;
Competent at a statistical and data mining level;
Capacity to generate advanced knowledge from multidimensional game data;
Good understanding of Game design concepts, Economic Game design and monetization for a mobile game;
Experience in SQL programming: an important asset;
Knowledge of other programming languages such as R and Python are a plus.

Interpersonal qualities:
Strong ability to explain complex and interrelate phenomena in a clear and concise manner to any type of audience (English and French);
Focused on the operational impact, resourceful and able to take initiative;
Excellent interpersonal skills, able to collaborate with different stakeholders that have different objectives and that are potentially contradictory;
Demonstrate pragmatism and rigor in methodological approaches;
Able to adapt in an environment where priorities can regularly change;
Able to be humble and help the team to move forward.

Motivation and interests:
Passion and ambition for video games are essential!",-1.0,Square Enix Montr,Montreal,-1,-1,-1,-1,-1,-1,-1,-1,49.0,-1,data analyst,na,1,1,1,1,0,1,0,0,0,0,0,0,0,0,0,4378,0
394,"3+ years of professional experience in analytics, business analysis or comparable analytics position, including handling large/complex data sets, developing metrics, and developing trusting customer relationship, data manipulation tools and presentation tools (e.g. Quicksight, AWS, etc.).
Proficiency in Python, SQL, and Excel
Excellent written communication and presentation skills
Bachelor's degree in a quantitative field or similar.
Language required for job: English
#0000

Job Location: 510 W Georgia St, Vancouver, BC V6B 0M3, Canada

Terms of employment: Full time, permanent

Job Description
Do you feel passionate about data? Are you excited about figuring out ways slice, dice, and send data to multiple sources? Woot.com, the innovative company who invented the deal-of-the-day business model, is looking for a talented, self-motivated Business Intelligence Engineer with broad technical skills to dive deep into large amounts of data, have a great business sense, curiosity and a proven ability to deal with ambiguity, and the desire to influence key strategic decisions with data-driven analysis and insights.

Woot specializes in daily deals across multiple categories and offers our customers unique content giving them many reasons to visit our website and mobile apps frequently. Via integration into the development process, Data Pipeline programs influence course-corrections in product roadmaps that yield future benefits to customers while lowering the dependency on manual reporting.

As a Business Intelligence Engineer, you will help answer key questions such as “How do Website, Mobile App redesign initiatives help customers discover products in a more efficient manner? How will our customers react to changes in prices, product selection, delivery times, return/replacement policies etc.? Which customer would like this deal the best? What is the best marketing channel to promote a particular deal to our customer base? How can we improve our customer service? How can we improve our delivery experience? etc” These are among the most important questions at Woot today.

You will have an opportunity to shape the long-term outlook for Woot’s business intelligence and shape strategic decisions by working directly with the leadership team and key cross functional stakeholders. The ideal candidate will be able to formalize problem definitions from ambiguous requirements, extract insights from big data and develop cutting-edge solutions for non-standard problems. You are an individual with outstanding analytical abilities, excellent communication skills, and are comfortable working with technical teams and systems. You will draw upon advanced analytical, critical thinking, problem solving skills, software development experience, and a passion for creating maintainable, highly reliable, systems which operate 24/7. You will work with analytic tools, can write excellent SQL scripts, can partner with customers to answer key business questions, and you are an advocate for your customers.

Key Expectations:
Work closely with business stakeholders to understand business issues and develop the data driven insights to drive the business’ direction.
Work closely with internal Amazon teams to develop data ingestion models from varying customer and application touchpoint sources (such as survey data, application metrics, APMQ messages, customer service contacts among others) for text mining analysis.
Audit the tagging process (manual or automated) to make sure data is complete and accurately represented in the systems.
Understand that ad-hoc analysis is part of the landscape and be prepared to structure relevant analysis and demonstrate a sense of urgency in delivering insights to the leadership team.
Dive deep into data by leveraging SQL, MS Access, Excel, and other data manipulation tools and presentation tools (e.g. Quicksight, AWS, etc.). .
Develop and propose new metrics, recommend strategies to stakeholders to improve business results, and work across our organization to make actionable intelligence available to business stakeholders.
Contribute to the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards, etc. to drive key business decisions.
Interact with software and business groups to develop an understanding of their business requirements and operational processes.
Salary Range: $88,200 to $147,300/yr, commensurate with experience #0000

All candidates must meet all qualifications above.

Benefits: Amazon provides a full range of benefits for our global employees and their eligible family members. Eligible employees may also receive signing bonuses and Amazon Restricted Stock Units. This position is eligible for further pay increases and bonuses at the company's discretion. While they might vary from location to location, Amazon benefits for Canada may include:
Health Care
Savings Plans
Income Protection
Paid Time Off
Signing Bonuses
Employee Stock
#0000",-1.0,"AMZN CAN Fulfillment Svcs, ",Vancouver,-1,-1,-1,-1,-1,-1,-1,-1,49.0,-1,data engineer,na,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,4967,0
395,"Perpetua's mission is to give superpowers to anyone that sells online. At the moment, we help media agencies, brands, and Amazon sellers win on Amazon by analyzing large amounts of data and using AI to develop smart optimization algorithms that drive transformational sales growth.

As a Senior Data Engineer, you will be responsible for maintaining and evolving our data infrastructure to support the massive scale of data that we process to power our customers' ad campaigns. This includes advancing our data capabilities to both cut costs and increase performance, while maintaining data integrity and consistency. You will build scalable infrastructure and data pipelines to deliver a platform unparalleled in the advertising space using Google BigQuery, Looker, Airflow and Python (Django, Pandas, SciPy Stack).
What You'll Do
Interact with internal stakeholders to figure out how to make it easier for them to leverage Petabyte-scale data
Accelerate data-informed decision making to transform our product & engineering strategy
Be responsible for developing, maintaining and evolving the Data Platform
Considering technical tradeoffs and advancing our data capabilities
Being responsible for data consistency and integrity both for our internal tools and client APIs
Owning data accessibility and discovery across all parts of the company
Increasing performance of our data pipeline
Evolving our use of available tools and optimising current tools to optimise infrastructure costs
Work in a fast-paced, scaling start-up building software that is truly impactful
What You'll Have
Experience with workflow management tools like Airflow for moving and transforming data
Experience with data mapping, schema design, data structures and algorithms, data quality and integrity
You'll deeply know your datawarehouse from your datalake from your transactional database
Experience designing infrastructure to facilitate both availability and approachability of data to all users (internal and external)
Ability to source requirements from stakeholders and develop a vision for a data-driven company
Ability to build and performance tune complex database queries
Ability to solve problems in new and innovative ways
Self starter who takes initiative; owning a project from start to finish
The ability to communicate complex technical issues in a clear and concise manner
Flexibility to adjust to changing priorities, requirements, and schedules
Experience working in a fast-paced, agile environment
Company Benefits
Impactful work that will help lay the foundation for future projects
Meaningful equity at an early stage company
Ground floor opportunity
Paid-for meals
Unlimited snacks and drinks
Full benefits plus a health spending account
Top of the line technology to help you build your own workspace
Flexible time off policy
At Perpetua, we are dedicated to pursuing and hiring a diverse workforce with varied experiences, perspectives and opinions. We believe diversity helps our team perform better and enables us to build an outstanding product for our customers. We are an equal opportunity employer and are committed to work with applicants requesting accommodation at any stage of the hiring process.",5.0,Perpetua,Toronto,"New York, NY",1 to 50 employees,-1,Company - Private,-1,-1,$1 to $5 million (CAD),-1,49.0,-1,data engineer,senior,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,3208,0
396,"Teranet is seeking a Big Data Engineer with experience configuring and administering public cloud (AWS/Azure) as well as on-prem Big Data analytics infrastructure. This individual’s primary role will be the setup and maintenance of Teranet’s Big Data analytics infrastructure as Teranet continues to expand its growing analytics program. Responsibilities include the creation and management of infrastructure orchestration scripts needed to manage the life-cycle of various components running in Teranet’s Analytics production, disaster recovery and test environments involving both on-prem as well as public cloud (AWS/Azure) compute and storage infrastructure. Additional responsibilities include the configuration and maintenance of Teranet’s in-house developed Change Data Capture (CDC) framework; third-party CDC tools (HVR); data access and security; visualization tools (Tableau); on-prem/cloud connectivity; as well as future AI and ML tools Teranet adopts to build upon existing analytics capabilities.

Key responsibilities include:
Support, maintain & monitor Teranet’s Cloudera Analytics & Data Warehouse platform infrastructure
Develop & Maintain Cloudera on-prem and public cloud infrastructure orchestration scripts
Monitor & Manage Cloudera infrastructure (service alerts, errors, end-user access issues)
Be the primary Cloudera Support interface for Cloudera infrastructure issues
Support component/software updates & patching
Support environment patching & updates
Support DR environment and conduct regular DR Failover/Failback tests to verify capability to switch-over between Prod & DR environments
Support, maintain & monitor Teranet’s Change Data Capture (CDC) infrastructure:
Support software updates/patching (test software releases & coordinate production deployment)
Support CDC Infrastructure (manage HVR/Attunity and Oracle/Microsoft Staging DBs)
Monitor CDC production systems and investigate and address incidents
Support CDC DB refreshes as required
Support new DB CDC deployments (Config/Testing/Tuning/Change Management)
Tableau Server Infrastructure
Maintain & Monitor Tableau Server infrastructure
Manage upgrade of Tableau Server software (2-3 times per year)
Coordinate Server OS patching & upgrades (testing)
Coordinate Server infrastructure enhancements (memory, cpu, additional storage)
Work with Analytics Architect to implement Tableau Server High-Availability (cluster)
Work with Analytics Architect to design Tableau Server Business Continuity/DR environment.
Support VAS, Finance, CMS Analysts in creating and deploying Tableau Data Lake Data Source connections for Tableau Dashboards
Manage and investigate incidents related to Tableau Server infrastructure
Additional Responsibilities include:
Maintain and monitor Teranet’s data lake feeds
Assist with data views for downstream data lake consumers (e.g. Data Scientists and Analysts)
Optimization of Teranet’s Big Data environment, applications and data views
Design, build and test data queries for data views and feeds for downstream data lake consumers
Design, build and integrate additional data sources into the Teranet data lake
Design, build and test analysis/data models to support downstream data lake consumers
You are someone who:
Is curious, enjoys exploring, learning and experimenting with new technology
Continuously seeks to improve your knowledge of DevOps and Big Data best practices
Strives to understand business drivers and strategy in order to understand business requirements
Takes a collaborative approach to assignments and works well with others
Is a good communicator with strong written and oral communication skills
Clearly documents your work so that it can be readily understood by others
Takes ownership and accountability for your assignments and responsibilities
Takes pride in delivering detail-oriented, thoughtful, thorough, and quality results
Key qualifications:
Bachelor’s degree in Computer, a quantitative field, or equivalent practical experience
2-3 years of experience working with Unix/Linux, ideally with some Redhat Linux admin experience
AWS Certified Devops Engineer or a minimum of 1.5 years of equivalent experience developing cloud infrastructure orchestration scripts involving EC2/RDS templates, S3 policies, security setup and configuration including IAM, SAML, FreeIPA, DNS, TLS and networking configuration and setup (VPC/VPN).
A minimum of 1 years working with and administering Hadoop related technologies (HDFS, Hive, Spark, Kafka) and ideally 2-4 years of experience.
Familiarity with the Cloudera Hadoop environment and in particular experience with the Cloudera Management console. Ideally, some experience with Cloudera’s latest CDP Public Cloud release.
Software development experience with Scala, Java or Python languages as well as strong SQL development skills
Familiarity with visualization and statistical modeling tools, ideally with 1-2 years Tableau Server administration experience",3.4,Teranet,Toronto,"Toronto, Canada",501 to 1000 employees,1991,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (CAD),-1,49.0,29,data engineer,na,0,1,0,1,0,1,1,0,1,0,0,0,0,0,0,4955,0
397,"Are you looking for unlimited opportunities to develop and succeed? With work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations.

Job Description

Are you a go-getter who has a passion in building next gen data pipelines and provide Big data solution for business problems? Are you a big fan of simplification and automation?

Manulife is seeking an awesome Lead Data Engineer, with Big Data experience as well as strong understanding of data-ingestion, data curation and both Batch & Stream Data processing, to join our rapidly expanding IT Organization and assist us as we work to be a digital leader in our industries!

Skills and Experience

You will have the following skills and experience:
Lead development teams to define and build data pipelines
Expert in building and operationalizing BigData platforms in cloud using one of the public clouds, preferably MS Azure.
Hands on experience with Big Data streaming frameworks and tools (Spark Streaming, Storm, Kafka, etc.)
Expert in Hadoop ecosystem and toolset Sqoop, Nifi, Pig, Spark, HDFS, Hive, HBase, etc.
Expert in automating data pipelines in a Big Data ecosystem, DevOps and CICD.
Experience in developing Hadoop integrations (batch or streaming) for data ingestion, data mapping and data processing capabilities
Experience programming in both compiled languages (Java, Scala) and scripting languages (Python or R)
Expert in developing Big Data set processes for data modeling, mining and production
Experience in working with key partners including business and technology to establish definition of success, goals, key use cases and aligning dev team on strategic priorities.
Excellent communication and interpersonal skills
Excellent analytics, problem solving and solutioning skills
A capacity for constant learning from both success and failure, remaining open to change and continuous improvement

Good to Haves
Experience in Exploratory data analysis; Query and process Big Data, provide reports, summarize and visualize the data
Experience in Canary deployments, 0-downtime, 0-dataloss, hot-hot DR
Experience in designing solutions for Big Data warehouses
Experience with Hadoop security frameworks like Knox, Ranger.
Experience with Hadoop metadata frameworks and security policies such as Ranger, Atlas
Experience in data profiling and analysis
Exposure to and an understanding of Agile scrum methodologies and experience of working in an Agile team
Experience in Big Data performance analysis, tuning and capacity planning
Experience in designing business intelligence systems, dashboard reporting, and analytical reporting is a plus
Experience with the Hortonworks Data Platform (version 2.5)
Experience in using Git flow.
Basic understanding of following will be useful but not required:
Exposure to and basic understanding of collaboration tools like Slack, Skype, Teams, and JIRA

What about Perks?

Manulife has lots of perks including, but not limited to:
Competitive compensation
Retirement Savings Accounts including a RPP (Pension Plan), RRSP (Retirement Savings Plan), and TFSA (Tax Free Savings account)
Manulife Share Ownership Program with employer matching
Customizable Benefits Package including Health, Dental, Vision, and 100% of Mental Health expenses
Financial support for ongoing training, learning, and education
Monthly Innovation Days (Hackathons)
Wearing jeans to work every day
An abundance of career paths and opportunities to advance
A flexible work environment with flex hours, work from home arrangements, distributed teams, and condensed work week arrangements.
This is a full time permanent role and the team is located in Kitchener/Waterloo, Ontario. There is opportunity for Toronto based people to work in this role, however there would be travel to Kitchener / Waterloo twice per week.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

About Manulife

Manulife Financial Corporation is a leading international financial services group that helps people achieve their dreams and aspirations by putting customers' needs first and providing the right advice and solutions. We operate primarily as John Hancock in the United States and Manulife elsewhere. We provide financial advice, insurance, as well as wealth and asset management solutions for individuals, groups and institutions. At the end of 2017, we had approximately 34,000 employees, 73,000 agents, and thousands of distribution partners, serving more than 26 million customers. As of December 31, 2017, we had over $1.04 trillion (US$829.4 billion) in assets under management and administration, and in the previous 12 months we made $26.7 billion in payments to our customers. Our principal operations are in Asia, Canada and the United States where we have served customers for more than 100 years. With our global headquarters in Toronto, Canada, we trade as 'MFC' on the Toronto, New York, and the Philippine stock exchanges and under '945' in Hong Kong

If you are ready to unleash your potential, its time to start your career with Manulife/John Hancock.


About Manulife

Manulife Financial Corporation is a leading international financial services group that helps people make their decisions easier and lives better. We operate primarily as John Hancock in the United States and Manulife elsewhere. We provide financial advice, insurance, as well as wealth and asset management solutions for individuals, groups and institutions. At the end of 2018, we had more than 34,000 employees, over 82,000 agents, and thousands of distribution partners, serving almost 28 million customers. As of December 31, 2018, we had over $1.1 trillion (US$794 billion) in assets under management and administration, and in the previous 12 months we made $29.0 billion in payments to our customers.

Our principal operations in Asia, Canada and the United States are where we have served customers for more than 100 years. With our global headquarters in Toronto, Canada, we trade as 'MFC' on the Toronto, New York, and the Philippine stock exchanges and under '945' in Hong Kong.

Manulife is committed to supporting a culture of diversity and accessibility across the organization. It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will consult with applicants contacted to participate at any stage of the recruitment process who request an accommodation. Information received regarding the accommodation needs of applicants will be addressed confidentially.",3.7,Manulife,Toronto,"Toronto, Canada",10000+ employees,1887,Company - Public,Investment Banking & Asset Management,Finance,$50 to $100 million (CAD),"MetLife, ING, Sun Life",49.0,133,data engineer,senior,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,6767,3
398,"Start Date: Immediately

Location: Downtown Vancouver

Startup -Consumer Packaged Goods - Skin care

Requirements:
3+ years experience in Data Analysis
Well versed in using Tableau + queries, report writing and presenting findings
Experienced in using statistical packages for analyzing datasets

Education:
Computer Science ,Mathematics, Economics, Information Management or Statistics

Scope of work:
Work with management to prioritize business and information needs
Conduct full lifecycle analysis to include requirements, activities and design
Interpret data, analyze results using statistical techniques and provide ongoing reports
Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Acquire data from primary or secondary data sources and maintain databases/data systems
Identify improvements by monitoring performance and quality control plans
Identify, analyze and interpret trends or patterns in complex data sets and filter and clean data
Locate and define new process improvement opportunities
Interviews are happening now, for a confidential chat, send all inquiries to Shiva@aceit.work",-1.0,AceIt Strategi,Vancouver,"Vancouver, Canada",1 to 50 employees,2015,Unknown,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,49.0,5,data analyst,na,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1189,0
399,"Why Fiix?
Fiix has a big goal – to create a more sustainable world. Sounds lofty right? Our mission is to make every maintenance team successful by enabling the adoption of a CMMS and we’re off to a great start. Teams that are part of the world’s most well known brands (like Toyota, Siemens, and Sara Lee) manage their maintenance activities and achieve greater results with Fiix. But we’re not stopping there. Our team is growing by leaps and bounds and we’re conquering new challenges every day. We’re looking for big thinkers with small egos to join us on our journey to create a more sustainable world.

Why we do it?
We’re a team of market disrupting, like-minded individuals. We all do things our own way, but we come together each and every day to create and deliver the long awaited answer to an antiquated industry – and we have a lot of fun while we’re at it.

We’re looking for a Data Engineer to help take Fiix’s explosive growth to a whole new level. We are looking for an experienced Data Engineer to build our data layer to support the delivery of machine learning-driven products. This is a unique opportunity to join a team of creative and passionate individuals committed to bringing AI to the predictive maintenance world.

What You Will Do:
Work with software engineering to design, build, maintain and optimize our data management and analytics pipeline
Perform data analysis, quality assessments, cleaning, imputation and data aggregation tasks
Perform feature engineering and selection to support machine learning activities
Build data processing pipelines and automate data pipelines in production environments
Work with engineers and data scientists to deploy analytics capabilities and machine learning models in production
Work with engineering and data teams to ingest and structure high throughput IoT data
Develop processes and frameworks to ensure data and model quality
Perform code reviews and testing to ensure software quality is high and requirements are met
Diagnose and repair data issues and assist customers with technical problems
What We're Looking for:
3+ years experience in a high growth software development environment developing data-driven products
Experience working on ETL, data warehousing, data modeling, data architecting, data analysis
Experience with at least some of: 1) Data streaming with Kinesis, Kafka or similar 2) ETL orchestration frameworks such as Airflow, Luigi or similar 3) Data warehouses such as Snowflake or similar
Development skills in Python, MySQL and other relational databases, NoSQL databases such as DynamoDB, Redis or similar
Experience with AWS or other cloud provider
*Education background:
Bachelor’s Degree or higher in Computer Science or a related field
At Fiix, we recognize that people come with a wealth of experience and talent beyond just the technical requirements of a job. If your experience is close to what you see listed here, please still consider applying. Diversity of experience and skills combined with passion is a key to innovation and excellence. Therefore, we encourage people from all backgrounds to apply to our positions. Please let us know if you require accommodations during the interview process.",4.1,Fiix Software,Toronto,"Toronto, Canada",51 to 200 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,$10 to $25 million (CAD),-1,49.0,12,data engineer,na,0,1,0,0,0,1,0,1,0,0,0,0,1,0,0,3211,0
400,"*This is a remote position within Canada

SSENSE is looking for a Senior Data Engineer to join our rapidly growing technology team. The Senior Data Engineer will take complex features of the product roadmap, break them down into their required technical components, and develop them independently. They own at least one component of the SSENSE technical stack and hold accountability for its SLAs. The ideal candidate will actively contribute to knowledge dissemination within the organization, participate in the recruiting and onboarding of new employees, and mentor Junior Developers on the team.

RESPONSIBILITIES
Product delivery
Build, test and operate stable, scalable data pipelines that cleanse, structure and integrate disparate data sets into a readable and accessible format for end-user facing reports, data sciences and ad-hoc analyses
Develop a deep understanding of the product roadmap for the squad, including future features to be developed
Contribute to high-level estimation and participate in laying out the development sequences, challenging the product roadmap and identifying areas where technical debt can be reduced or avoided
Complete independently complex development tasks and actively contribute to pushing code to production
Write testable, efficient, and reusable code suitable for continuous integration and deployment, respecting best practices and SSENSE development standards
Review Unified Modeling Language (UML) diagrams and technical documentation

Ownership and accountability
Be accountable for code quality by conducting adequate testing
Be accountable for performance, reliability, scalability and resilience of at least one technical component owned by the squad through SLAs and monitoring
Solve complex technical problems and mentor/support other technical staff on data modeling and ETL related issues
Contribute to cross-squad initiatives, acting as a change agent amongst peers to foster adoption of new processes or technical solutions

Knowledge sharing and coaching
Review Pull Requests with the objective to guide and upskill other Data Engineers on various technical topics
Actively contribute to SSENSE University (the internal peer learning platform) to promote continuous learning
Participate in the onboarding of new Data Engineers

Architecture
Contribute to solution designs, challenging other members on technical decisions and explaining the technical design to junior developers so they can write documentation for the rest of the team

Recruiting
Participate in HR recruiting events, helping to identify and recruit top developers

REQUIREMENTS
Bachelor’s degree in Computer Science, Engineering, or a related technical field, Master’s degree an asset
A minimum of 5 years of Functional Programming and/or Object Oriented Programming (OOP) experience
A minimum of 3 years experience writing and optimizing SQL queries
A minimum of 3 years experience with Apache Spark for big data processing
Extensive knowledge of Python programming language and its data manipulation libraries (Pandas and Numpy)
Expertise in data modeling and an advanced understanding of data architecture
Expertise with RDBMS and NoSQL databases at scale
Experience with Apache Airflow or other similar data pipelining and workflow scheduling framework (Luigi, Azkaban)
Ability to use containers, orchestration frameworks, and other DevOps tools (Kubernetes, Terraform, Giant Swarm, etc.)
Proficiency with cloud resources (AWS/Google Cloud/Azure) with the ability to operate them for the components owned, Certification is an asset.
Knowledge of the AWS services (Redshift, Glue, Athena, S3, etc.) an asset
Knowledge of big data technology (Databricks, Hadoop, Hive, Pig, Presto) an asset
Familiarity with continuous integration and automated pipeline tools (Jenkins, Travis, etc.)
Proficiency in Git
Strong written and verbal communication skills in both English and French

SKILLS
Highly analytical and detail oriented
Ability to coach and mentor junior employees to achieve personal and professional goals
Team player with a high sense of accountability and ownership
Ability to influence and drive change
Solution-oriented mindset and can-do attitude to overcome challenges
Ability to thrive in a fast-paced environment and master frequently changing technologies and techniques

----------

*Poste en télétravail au Canada

SSENSE est à la recherche d’un ingénieur de données principal pour joindre son équipe technique en pleine croissance. La personne détentrice du poste analysera les fonctionnalités complexes de la stratégie produit pour déterminer les composantes techniques requises et les développer de façon indépendante. L’ingénieur de données principal est responsable d’au moins une composante de la pile technique SSENSE ainsi que des niveaux de service associés. Il participera activement au partage de connaissances au sein de l’entreprise ainsi qu’au recrutement et à l’intégration de nouveaux employés, en plus d’agir à titre de mentor auprès des ingénieurs de données.

RESPONSABILITÉS
Livraison produit
Construire, tester et mettre en opération des pipelines de données stables et adaptables pour épurer, structurer et intégrer des ensembles de données hétérogènes dans un format compréhensible pour les rapports destinés aux utilisateurs finaux, à la science des données et aux analyses ad hoc
Comprendre en profondeur la stratégie produit de l’équipe ainsi que les fonctionnalités à développer
Contribuer à l’estimation et à l’élaboration de séquences de développement, par la remise en question de la stratégie produit et l’identification des dettes techniques
Effectuer des activités complexes de développement de manière autonome et soutenir activement l’intégration du code dans la production
Mettre au point des solutions de code testables, efficaces et réutilisables, applicables à l’intégration et au déploiement continus, en phase avec les meilleures pratiques et les standards de développement SSENSE
Réviser les diagrammes de langage de modélisation unifié (UML) et la documentation technique correspondante

Engagement et responsabilité
Assumer la responsabilité de la qualité du code en réalisant les tests adéquats
Assumer la responsabilité du rendement, de la fiabilité, de l’évolutivité et de la résilience d’au moins une des composantes techniques complexes de l’équipe, au moyen de supervision et d’ententes de niveau de service
Résoudre des problèmes techniques complexes et mentorer d’autres membres du personnel technique quant à la modélisation de données et aux enjeux relatifs à l’extracto-chargeur (ETL)
Contribuer aux projets interéquipes par la promotion du changement et de l’adoption des nouveaux processus ou solutions techniques

Coaching et partage de connaissances
Réviser les Pull Requests afin d’orienter le perfectionnement des ingénieurs de données sur divers sujets techniques
Contribuer activement à SSENSE University, une plateforme d’apprentissage destinée aux employés, afin de promouvoir l’apprentissage continu
Participer à l’intégration de nouveaux ingénieurs de données

Architecture
Participer à la conception de solutions, questionner l’équipe quant à ses décisions techniques et expliquer le design technique aux développeurs afin qu’ils rédigent de la documentation pour le reste de l’équipe

Recrutement
Participer aux activités de recrutement des ressources humaines et soutenir la recherche et l’identification des meilleurs développeurs

EXIGENCES
Baccalauréat en informatique, ingénierie ou un dans un domaine technique connexe; maîtrise, un atout
Un minimum de cinq ans d’expérience en programmation orientée objet et/ou en programmation fonctionnelle
Un minimum de trois ans d’expérience en rédaction et optimisation de langage de requête structurée (SQL)
Un minimum de trois ans d’expérience avec Apache Spark pour le traitement de mégadonnées
Notions avancées du langage de programmation Python et des bibliothèques de manipulation de données (Pandas et Numpy)
Expertise en modélisation de données et connaissances approfondies en architecture de données
Maîtrise à grande échelle des bases de données relationnelles (SGBDR) et des systèmes de gestion de bases de données (NoSQL)
Expérience avec Apache Airflow et avec d’autres outils de pipelines de données et de gestion de flux de travail (Luigi, Azkaban)
Capacité à utiliser les conteneurs et les logiciels d’orchestration intégrés ainsi que d’autres outils de DevOps (Kubernetes, Terraform, Giant Swarm, etc.)
Maîtrise des ressources infonuagiques (AWS, Google Cloud, Azure) et habileté à les employer pour les composantes possédées; la détention d’une certification dans le domaine est un atout
Connaissance des services AWS (Glue, Athena, S3, Spark, etc.), un atout
Connaissance des technologies de mégadonnées (Databricks, Hadoop, Hive, Pig, Presto), un atout
Familiarité avec les outils d’intégration continue et de pipelines automatisés (Jenkins, Travis, etc.)
Maîtrise de Git
Excellentes habiletés en communication écrite et verbale tant en français qu’en anglais

COMPÉTENCES
Sens de l’analyse et souci du détail
Aptitudes en coaching des employés pour l’atteinte de leurs objectifs individuels et professionnels
Esprit d’équipe et fort sens de la responsabilité
Force d’influence et de changement
Esprit déterminé, positif et orienté vers la recherche de solutions pour surmonter les obstacles
Habileté à s’épanouir dans un environnement à rythme accéléré et à maîtriser les technologies web en évolution fréquente

Note: le masculin est employé dans le seul but d’alléger le texte et inclut par défaut tous les genres.",3.9,SSENSE,Montreal,"Montreal, Canada",501 to 1000 employees,2003,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1,49.0,17,data engineer,senior,0,1,0,0,0,1,1,1,1,1,0,0,0,0,0,9602,0
401,"If you are looking to join one of Canadas fastest growing companies, goeasy Ltd. is the place for you! Recognized as one of Canadas Most Admired Corporate Cultures in 2018, one of Canadas Top 50 Fintechs and one of North Americas Most Engaged Workplaces, we want the best and brightest to join our team.

We are a publicly traded company on the TSX with over 4000% shareholder return since 2001, goeasy operates two main business units. easyfinancial is our consumer lending business that offers secured and unsecured installment loans of up to $35,000 and easyhome is Canadas largest merchandise lease-to-own company. It is our mission to provide everyday Canadians the chance for a better tomorrow, today by giving them access to the credit they need and by offering them a second chance when they have been turned down by banks and traditional lenders. With a retail network of nearly 400 locations across Canada and over 1900 employees, we are able to build lasting relationships with our customers as we help them rebuild their credit and graduate towards prime rates and a brighter financial future.

We are seeking a Data Analyst reporting directly to the Director, IT Audit & Analytics. You will be responsible for maintaining and enhancing the data analysis capabilities of the Internal Audit department.

Responsibilities:
Work as part of the Internal Audit team to mitigate risk and detect/prevent fraudulent activities
Actively participate in identifying technical or procedural solutions to high risk issues
Extract and Analyze data to assist the Internal Audit and Branch Audit teams in identifying exceptions and anomalies, as well as building and maintain a continuous monitoring program.
Proactively identify issues or areas requiring additional analysis
Create and maintain Branch Audit specific reports
Perform ad hoc analysis to assist in investigations and audits
Create dashboards to track store/branch performance metrics
Handle ad-hoc projects and management requests as necessary
Requirements:
Minimum 3 years of experience in a data analyst or forensic analyst role
Experience working in a banking or financial services company considered an asset
Superior technical skills utilizing SQL, SAS or ACL required
Advanced Excel skills including macros and visual basic
Advanced PowerBI skills
Ability to quickly understand operational and system processes and how it relates to the data
Strong time management and organization skills; ability to prioritize and multi-task in a time sensitive, fast-paced and often demanding environment
Excellent communication and interpersonal skills
Exceptional problem-solving skills
Excellent attention to detail
Professional attitude with an ability to handle sensitive situations and confidential information
Inclusion and Equal Opportunity Employment

goeasy is an equal opportunity employer. In addition, goeasy is committed to providing accommodations for applicants upon request at any stage of the recruitment process in accordance with all legislative requirements throughout Canada. Please let us know if you require an accommodation due to a disability during any aspect of the recruitment process and we will work with you to address your needs.

Additional Information:

All candidates considered for hire must successfully pass a criminal background check, credit check, and validation of their work experience to qualify for hire.

We thank all interested applicants, however we will only be contacting those for interview who possess the skills and qualifications outlined above.

Why should you work for goeasy?

To learn more about our great company please click the links below:",4.4,goeasy,Mississauga,"Mississauga, Canada",1001 to 5000 employees,1990,Company - Public,Lending,Finance,$1 to $2 billion (CAD),"Fairstone, Mogo (Canada), Money Mart Financial Services",49.0,30,data analyst,na,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,3655,3
402,"This is a 6-month contract for a client located in the GTA.The work will be done remote and all appropriate social distancing practices will be observed.

Our Client is a global management and technology consultancy dedicated to the financial services and energy industries. They help their clients successfully innovate, increase revenue, manage risk and regulatory change, reduce costs, and enhance controls. They serve their clients from offices in leading financial centers across the Americas, Europe, and Asia Pacific.

Full Stack Developer/Data Engineer

Responsibilities:

Produces high quality complex, deliverables with minimal input from stakeholders
Manage full software lifecycle for medium complexity projects from requirements, to design, to implementation, to testing

Develop and maintain back end solutions using cutting edge technologies and products

Work with Scrum Masters and product owners to priorities and deliver solutions using an Agile environment

Build reusable code and libraries for future use and follow emerging technologies

Mentor and train junior developers

Education/Experience

Bachelor’s degree (preference given to Computer Science, Engineering, Gaming and STEM-based majors) or equivalent experience

Three (3) or more years of experience as a Full-stack Data Engineer/developer on Data driven projects

Strong understanding of the full development lifecycle including requirements, architecture, design, development and testing

Working knowledge of JavaScript (ES6+), ReactJS, Redux

Development experience with Core Java / Scala

Experience working with Multithreading, Websockets, REST

Familiarity working MongoDB, SQL

Experience working with JUnit, Mockito

Ability to balance competing priorities in a very dynamic and fast-paced environment

Bonus Skills that would be desirable:

Understanding of big data and distributed programming concepts

Experience working with ASW, GCloud, Docker, Kubernetes

Experience working with Microservices, CQRS, EventSourcing

Experience working with Spring, Akka, Spark

Experience working with Reactive Streams (Rx, Akka, Reactor)

Experience working in an Agile environment

Experience working with code versioning tools

Experience working with build, packaging and continuous integration tools and frameworks",4.7,TalentVault,Toronto,"Vancouver, Canada",1 to 50 employees,2016,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,49.0,4,data engineer,na,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,2301,0
403,"ABOUT US
CI Investments Inc. is one of the country’s largest investment fund companies. CI is known for its innovation and ability to adapt quickly to the changing needs of Canadian investors. It provides employees with a fast-paced and challenging work environment with opportunities for advancement. CI is part of CI Financial, a diverse group of financial services firms.

POSITION: Fund Data Analyst, Security Master and Pricing
LOCATION: Toronto, ON (M5C 3G7)
STATUS:Contract (12 Months)

JOB OVERVIEW
We are currently seeking a Fund Data Analyst to join our Portfolio Operations team. In this role, the successful candidate is expected to support the oversight of CI’s order management and investment book of record system and to assist in maintaining accurate and complete data used for on-going trading, performance and risk reporting requirements.

WHAT YOU WILL DO
Supporting day-to-day Data operational activities for the Portfolio Managers, Traders, Performance/Attribution and Risk reporting teams
Providing operational and subject matter expertise across multiple data elements including Fixed Income, Equity and Derivatives
The Analyst is responsible for the security master file, reference data, pricing and market data; consolidating multiple external data sources, comparing them and then creating a single version of master and reference data
Handle all data challenge process, including vendor prices, custodian prices and reference data
Monitor changes or additions to fund list and coordinate corresponding updates to the Investment System
Ensure all internal and custodian compliance procedures are adhered to
Identify opportunities for process improvement and collaborate with IT on testing and implementation efforts
Document changes in process/new process and provide team members with respective training
Assist in generating additional supporting documentation where required to provide data support for POS (Prospectus information and Fund Fact Sheets), Web updates, and client and financial reporting requirements
WHAT YOU WILL BRING
Bachelors’ degree related to finance/business/mathematics
2-3 years of security master/pricing experience, or front office trade support experience
Advanced knowledge and experience with Charles River Order Management system and Bloomberg
Experience with BarraOne or FactSet would be an asset
Good understanding of Exchange and OTC derivative valuation in one or more asset classes
Excellent communication and listening skills to understand business needs and translate those needs into workable solutions
Strong attention to detail and ability to work in a fast-paced, dynamic environment
Strong logic and analytical skills to clearly identify key issues
Effective time-management and ability learn, prioritize, and execute quickly
Advanced in using Microsoft Excel and other Microsoft Office applications
Proficient in programming and data management; Python, SQL, VBA
WHAT YOU CAN EXPECT FROM US
Our dedication to the Employee Experience at CI is aimed at supporting, empowering and inspiring our talented team through:
Recognition& Compensation
Training& Development
Health& Well-being
Communication& Feedback
If you are a passionate, committed and dynamic individual, please submit your resume in confidence by clicking “Apply”.

Only qualified candidates selected for an interview will be contacted.

CI Financial Corp. and all of our affiliates (“CI”) are committed to fair and accessible employment practices and we are committed to providing accommodations for persons with disabilities. If you require accommodations in order to apply for any job opportunities, or require this posting in an additional format, please contact us at accessible.recruitment@ci.com, or call 416-364-1145 ext. 4747. If you are contacted by CI regarding a job opportunity or testing and require accommodation in any stage of the recruitment process, please use the above contact information. We will work with all applicants to determine appropriate accommodation for individual accessibility needs.",3.3,CI Financial,Toronto,"Toronto, Canada",1001 to 5000 employees,1965,Company - Public,Investment Banking & Asset Management,Finance,$2 to $5 billion (CAD),-1,49.0,55,data analyst,na,0,1,0,0,1,1,0,0,0,0,0,0,0,0,0,4051,0
404,"The recruitment team at Myticas Consulting is looking for an experienced Data Engineer who would be interested in a remote contract opportunity within the Ottawa, Toronto and Montreal regions.

Duties:
Defining and reviewing security design requirements for cloud infrastructure and application components.
Evaluating architecture patterns from security perspective.
Building and implementing security controls to enable enforcement of compliance with Cloud Control Objectives, using custom Azure policies and integrated controls in DevOps processes
Qualifications:
Strong Data Engineer w/ DevOps expertise + Azure Cloud Experience
Must know how to code and stand up scripts.
Experience with Data Digestions
Experience writing scripts to automate (infrastructure)
ARM Templating Expertise
Azure Synapse Expertise
Support developing automated DevOps processes and procedures for the following Azure components:
Azure Synapse (Azure DW) & Studio (private preview)
Azure Data Catalog Gen 2 (Babylon – private preview)
Azure Data Lake Storage Gen 2
Azure ML
ML Flow
Azure SQL Analysis Service
Azure Databricks
ADF data pipelines for data loading to AzSQL/Synapse
ADF data pipelines for connecting to on-prem data sources for data
Job is also known as: Data Engineer, DevOps Engineer, Azure Cloud Engineer, Azure Engineer, Cloud Engineer",5.0,Myticas Consulting,Ottawa,"Ottawa, Canada",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Modis, excelHR, Robert Half",74.0,-1,data engineer,na,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,1332,3
405,"With thousands of beautiful spaces built for travel and living, Sonder is transforming the future of hospitality. Each Sonder is purposefully selected, designed and maintained - customized to reflect the vibe of its neighborhood. Whether your stay is two days, two months or two years, in a studio or a six-bedroom, Sonder ensures a unique, yet consistent experience. And with 24/7 contactless service, professional cleanings that exceed CDC recommendations, and over 200 other quality standards, we're taking stay further for guests all around the world.

Sonder started in 2014, and now has thousands of spaces in cities across the globe.

The Data Engineering team is mainly focused on building and operating our data infrastructure, data warehouse, data and ETL pipelines, ML platform, and performing data modeling for analytics purposes. The team also partners with product engineering and data science teams to deliver data products to the business.

AT SONDER YOU WILL:
Build and operate our data infrastructure by building and maintaining the data platform, data pipelines, and the tools that ingest, process, transform and serve data
Build software libraries that standardize the acquisition, ingestion and integration of external data sources critical for real-time competitive intelligence and pricing
Use your expert SQL and data modeling skills to build the data warehouse base layer data models that will power Sonder's reporting dashboards
Establish and maintain the company's data lake/data warehousing strategy, define the appropriate data architecture, implement the best technical solution, and continue to meet the growing needs of the business;
Work with product and business analytics teams to ensure availability and accessibility of relevant business data and business metrics for product analytics and business performance reporting.
Understand Sonder's business intimately and model data that will be the source of truth for Sonder's business KPIs and metrics
Design and develop scalable platforms and processes for feature extraction, model training, and simulation
Own tools, processes and controls to help the team grow at scale.
WHAT WE LOOK FOR:
5+ years of experience working as a Data Engineer at a progressive company
Expert Python coding skills
Expert SQL and data modeling skills
Knowledge of data warehouse principles and methodologies
Experience in writing ETL jobs, performance tuning and query optimization
Strong communication skills and ability to gather requirements and translate them to specs and design
Experience with AWS cloud services and data warehouse stores like Redshift or Snowflake
Background in real estate or hotel industry is desirable
Self-driven, highly motivated and able to learn quickly
We offer great benefits to make your life easier so you can focus on what you're best at:
Competitive salary
Generous stock option plan
Medical, dental and vision insurance
Discretionary vacation/ Paid vacation and sick time
Annual free credits and discounts to stay in Sonders
Monthly culture budget: join your fellow colleagues for a monthly get together
A company with a huge vision, a dynamic work environment, and a team of smart, ambitious and fun to work-with colleagues!
We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",3.0,Sonder,Toronto,"San Francisco, CA",1001 to 5000 employees,2014,Company - Private,Hotel & Resorts,Travel & Tourism,$100 to $500 million (CAD),-1,74.0,6,data engineer,senior,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,3467,0
406,"At Bond we design creative and innovative solutions for our clients, all with the goal of helping them build ever-stronger loyalty to their brands. That can take us in some pretty amazing directions, and as a Data Engineering Lead you’ll have your hands on the wheel as we drive the future of loyalty.

A typical day in this role might include:
Build, test and operate scalable data pipelines that ingest structure and clean data into a performant and acceptable format for down stream reporting, machine learning and ad hoc analysis.
Work cross functionally with data scientists, infrastructure engineers and client facing analysts to deliver data solutions
Write testable, efficient, and reusable code suitable for continuous integration and deployment. Review Pull Requests and guide development of standards and practices
Lead and mentor junior data engineers to ensure best practices integrated into data pipelines.
Understand the high-level product roadmap and immediate features to be developed, contributing to high-level estimation and layout of the development sequences
Constantly and actively contribute to pushing code to production with the objective of becoming a main contributor
Do these statements describe you?
Bachelor’s degree in Computer Science, Engineering, or a related technical field
5 years of relevant experience; 1-2 years leading a technical team.
Demonstrated Experience using big data technologies (Delta lake, Hive, Spark, EMR, Databricks, Snowflake etc.) ideally in the azure ecosystem
Good understanding of data warehouse/data lake design patterns and best practices
Systematic problem-solving approach, with effective communication skills and a sense of drive
Hands-on experience with building data lake solutions, streaming analytics solutions and code development across environments (i.e. DevOps)
Comfortable working directly with data analytics to bridge business requirements with data engineering
Experience in software engineering best practices such as code reviews, testing frameworks, maintainability and readability
Experience deploying applications into production environments e.g. code packaging, integration testing, monitoring, release management
Strong understanding of Information Security principles to ensure compliant handling and management of client data
Why Join Us?

Bond Brand Loyalty is proud to be recognized as one of Canada’s Best Managed Companies.

We’re 400(ish) people working tirelessly together to make the world a more loyal place. You’ll be joining a hyper-talented team with a galaxy of skillsets ranging from research to creative to digital and beyond. You’ll have an excellent opportunity to grow, learn and make an impact as we tackle some of our client’s biggest business challenges.

If you’re looking to build your career, build your skills and build bonds apply today!

Bond Brand Loyalty welcomes and encourages applications from people with disabilities. Accommodations are available on request for candidates taking part in all aspects of the selection process.",3.2,Bond Brand Loyalty,Mississauga,"Mississauga, Canada",201 to 500 employees,1980,Company - Private,Advertising & Marketing,Business Services,$100 to $500 million (CAD),"LoyaltyOne, Aimia",74.0,40,data engineer,senior,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0,3047,2
407,"Who We are

Founded in 2014, Enthusiast Gaming is the largest gaming network in North America with over 100 websites and 900 Youtube communities of gaming and esports fans which collectively reach over 160 million visitors monthly. Together with its owned digital media properties, esports teams and influencers and live events, it reaches over 200 million gamers monthly with unique, curated content and user-generated posts. Enthusiast Gaming also owns and operates Canada’s largest gaming expo, Enthusiast Gaming Live Expo (EGLX).

We are currently seeking a Senior Data Engineer to join our Analytics team who will be responsible for designing and building Enthusiast Gaming's next generation real time monitoring systems and data pipelines in GCP and AWS. We are looking for someone who cares deeply about system scalability and performance and is excited to process massive volumes of data as we begin collecting first party data from hundreds of millions of pageviews per month.

What You Will Do:
Be a technology visionary; Explore and champion available technologies and design solutions to continuously improve our data quality, workflow reliability and scalability
Build a testing and measurement system; You will be a critical senior member of our Analytics team, building out a sophisticated testing and measurement system in GCP or AWS, which captures revenue, engagement, and page speed metrics in real time, for hundreds of millions of monthly page views. This is a critical system required by the development team to be able to understand the impact of ad code and page optimization improvements made. The ability for the development team to make speedy and empirically-driven progress hinges upon the successful rollout of this system.
Build data pipelines; You will build out and maintain data pipelines which capture millions of dollars of revenue data from more than a dozen different data sources, which feed into various executive and operational level reports and dashboards, informing practically every single business decision made by the Monetization department of the company. Data reliability, data accuracy, and systems resiliency are all critical factors which you will be helping improve.
Ad-hoc querying and analysis; You will be called upon to leverage your SQL, Python and R skills to query the data warehouse for ad-hoc requests, creating timely reports required for making pressing business and technology decisions
Who You Are
You are a problem solver; you can make your way into the abyss and then find your way out again. You know how to make good decisions with limited information, and correct your course as needed.
You are comfortable with the unknown; we are well-funded and organized, yet still have many exciting characteristics of a startup charting new paths. You need to be comfortable working in an environment that will continue to evolve.
You are a self-starter; you relish the opportunity to identify needs and take action, without being explicitly told to.
You are a person of integrity; honesty, trust and ethical decision-making are at the core of who we are. These values are important to you and you model them in your decision making and in your interactions with colleagues, customers, and stakeholders.
You have a growth mindset; you are continually honing your craft, and keeping up with the best tools for the job.
You are a great communicator; you shine when you are able to pass on knowledge and gather requirements from stakeholders. You are able to articulate your thoughts very clearly, with various audiences such as managers, peers, and clients.
Requirements
At least 5 years of experience as a Data Engineer (or equivalent), including at least 2 years in a role working on a system processing billions of daily events
At least 2 years of experience designing and architecting real-time data gathering systems in AWS (Redshift, Kinesis) or GCP (BigQuery, Dataflow)
Expert SQL skills
Expert skills in Python or R
Understanding of ad serving platforms and online advertising systems is a major asset
What We Offer

This is your opportunity to join our collaborative team in our newly renovated office at Yonge & Eglinton, just steps away from the Subway and surrounded by diverse restaurants, cafes, pubs, and beautiful parks. We offer access to group health & dental benefits, and a Goodlife gym membership (conveniently located next door!) We anticipate continued growth over the coming years, which will provide tremendous opportunity for you to grow with us.

For more information about us, please visit www.enthusiastgaming.com.

Enthusiast Gaming is an equal opportunity employer. We welcome and encourage applications from people with disabilities. If you require an accommodation, please notify us and we will work with you to meet your needs.

Benefits:
Flexible working hours
Work from home opportunities
Life insurance
Extended health care
Dental care
Casual dress
Reference ID: 3

Job Types: Full-time, Permanent

Experience:
Python or R: 3 years (Required)
SQL: 3 years (Required)
AWS (Redshift, Kinesis) or GCP (BigQuery, Dataflow): 2 years (Required)",2.7,Enthusiast Gaming Inc.,Toronto,"Toronto, Canada",1 to 50 employees,2014,Company - Public,Internet,Information Technology,Unknown / Non-Applicable,-1,74.0,6,data engineer,senior,1,1,0,0,0,1,0,1,0,0,0,0,0,0,0,5134,0
408,"IT/IQ Tech Recruiters is seeking a Data Engineer to join our client in Toronto, ON.

Why work with our client?
Certified Great Place to Work
Weekly delivery of groceries and all types of snacks to the office
Competitive compensation
Responsibilities
You will be working on writing frameworks building for real time and batch pipelines to ingest and transform events (108 scale) from 100’s of applications every day
Our ML and Software engineers consume these for building data products like personalization and fraud detection.
You will also help optimize the feature pipelines for fast execution and work with software engineers to build event driven microservices
You will get to put cutting edge tech in production and freedom to experiment with new frameworks, try new ways to optimize and resources to build next big thing in fintech using data
Top Skills Required
You have previously worked on building serious data pipelines ingesting and transforming > 10 ^6 events per minute and terabytes of data per day.
You are passionate about producing clean, maintainable and testable code part of real-time data pipeline.
You understand how microservices work and are familiar with concepts of data modelling.
You can connect different services and processes together even if you have not worked with them before and follow the flow of data through various pipelines to debug data issues.
You have worked with Spark and Kafka before and have experimented or heard about Flink/Druid/Ignite/Presto/Athena and understand when to use one over the other.
On a bad day maintaining zookeeper and bringing up cluster doesn’t bother you.
You may not be a networking expert but you understand issues with ingesting data from applications in multiple data centres across geographies, on-premise and cloud and will find a way to solve them.
Proficient in Java/Scala/Python/Spark
Must be legally eligible to work in Canada
Why work with us?
Build a long-term relationship with an experienced recruitment expert
Access to the ‘hidden’ job market – opportunities across Canada that aren’t posted on job boards
Get a high-level understanding of market dynamics affecting your industry
Gain insight into the culture of the company you’re applying for before submitting your profile
About Us

IT/IQ Tech Recruiters provides contract and permanent IT recruitment services to employers across Canada. We have a specialized approach to recruiting, segmenting our recruitment teams into specialty practice areas focusing on Development, PMO, Infrastructure and BI/CRM/ERP skill sets.

This approach enables our recruiters to become specialists; they know the market and work hard to understand each candidates’ capabilities, goals, career ambitions and quickly present them with the best possible opportunities. We are committed to helping candidates develop their careers and to helping our clients grow their business and complete important projects successfully.

We create opportunities for IT Professionals to empower business.",2.8,IT IQ TECH RECRUITERS LTD,Vancouver,"Vancouver, Canada",1 to 50 employees,2002,Company - Private,Staffing & Outsourcing,Business Services,$50 to $100 million (CAD),"Randstad, TEKsystems, TEEMA Solutions Group",74.0,18,data engineer,na,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,3010,3
409,"SSENSE is looking for a Data Engineer to join our rapidly growing technology team. The level 3 Data Engineer will join a squad and deepen their knowledge of software development and data pipelines. They will break down, with minimal guidance, large tasks into smaller, manageable steps to deliver complex tasks required for well-defined features of the Product roadmap. The ideal candidate will contribute to knowledge dissemination within the organization and participate in the recruiting and onboarding of new employees.

RESPONSIBILITIES
Product Delivery
Build, test and operate stable, scalable data pipelines that cleanse, structure and integrate disparate data sets into a readable and accessible format for end-user facing reports, data sciences and ad-hoc analyses
Understand the high-level product roadmap and immediate features to be developed, contributing to high-level estimation and layout of the development sequences
Complete complex development tasks with minimal guidance
Constantly and actively contribute to pushing code to production with the objective of becoming a main contributor
Review Pull Requests
Write testable, efficient, and reusable code suitable for continuous integration and deployment, that respect best practices and SSENSE development standards
Review Unified Modeling Language (UML) diagrams and technical documentation, ensuring its quality
Ownership and accountability
Be accountable for code quality and conduct adequate testing
Review and contribute to technical documentation
Knowledge sharing and coaching
Join SSENSE University (the internal peer learning platform) sessions to ramp up on various technologies and host at least two sessions per year
Lead the onboarding of new data engineers
Architecture
Contribute actively to the design of the solution, challenging other members on technical decisions
Help more junior Data Engineers understand the technical design so they can write documentation for the rest of the team
Recruiting
Participate in HR recruiting events, helping to identify and recruit top tech talent

REQUIREMENTS
Bachelor’s degree in Computer Science, Engineering, or a related technical field
A minimum of 3 years of Object Oriented Programming (OOP) and/or functional programming experience
Knowledge of Apache Spark for big data processing
Knowledge of Python programming language
Knowledge of the data modelling concepts and ability to define the architecture with minimal guidance to develop a complex microservice
Familiar with various database systems and able to write complex queries independently
Knowledge of cloud concepts and the ability to follow instructions to use them with minimal guidance
Knowledge of the AWS services (Glue, Athena, S3, Databricks, etc.) and Apache Airflow, an asset
Proficiency in Git
Strong English written and verbal communication skills, French is an asset

SKILLS
Fast learner and detail oriented
Solution-oriented mindset and can-do attitude to overcome challenges
Team player with a high sense of accountability and ownership
Ability to thrive in a fast-paced environment and master frequently changing technologies and techniques

----------

SSENSE est à la recherche d’un Ingénieur de données qui se joindra à notre équipe technique en pleine croissance. L’ingénieur de données de niveau 3 rejoindra une équipe et approfondira les connaissances de cette dernière en développement de logiciels et en pipelines de données. Il/Elle divisera avec un minimum d’assistance les tâches importantes en étapes plus petites et aisément gérables afin de compléter les travaux complexes nécessaires au lancement de nouvelles fonctionnalités de la feuille de route Produit. La personne détentrice du poste contribuera à la dissémination des connaissances au sein de l’entreprise et participera au recrutement et à l’intégration de nouveaux employés.

RESPONSABILITÉS
Livraison de produit
Construire, tester et utiliser des pipelines de données stables et évolutives permettant de trier, de structurer et d’intégrer des ensembles de données disparates, créant ainsi un format lisible et accessible pour les rapports consacrés à l’utilisation par l’utilisateur finale, pour les sciences des données et pour les analyses ad hoc
Comprendre la feuille de route produit de haut niveau ainsi que les fonctions à développer immédiatement, contribuant à l’estimation de haut niveau et à l’élaboration des séquences de développement
Remplir des tâches de développement complexes avec un minimum d’assistance
Participer constamment et activement à pousser du code en production en vue de devenir un contributeur principal
Revoir les Pull Requests
Écrire des programmes testables, efficaces et réutilisables, qui se prêtent à l’intégration et au déploiement continus et qui respectent les meilleures pratiques et les standards de développement SSENSE
Revoir les diagrammes UML et les documents techniques pour garantir leur qualité
Appropriation de l'exécution et responsabilisation
Être responsable de la qualité du code et effectuer les tests adéquats
Réviser la documentation technique et y contribuer
Partage des connaissances et coaching
Participer activement à SSENSE University (notre plateforme d’apprentissage entre pairs) afin d’accroître sa connaissance de différentes technologies et donner au moins deux cours par an
Gérer l’intégration des nouveaux ingénieurs de données
Architecture
Contribuer de manière active à l’élaboration de solutions, en questionnant positivement les choix techniques des autres participants
Aider les développeurs junior à comprendre le design technique afin qu’ils soient en mesure de rédiger des documents pour le reste de l’équipe
Recrutement
Participer aux événements de recrutement organisés par les Ressources humaines afin d’aider à identifier et recruter les meilleurs talents en technologie


EXIGENCES
Baccalauréat en informatique, ingénierie ou un domaine connexe
Un minimum de 3 années d’expérience en Programmation orientée objet et/ou programmation fonctionnelle
Connaissance d’Apache Spark pour le traitement de mégadonnées
Connaissance du langage de programmation Python
Connaissance des concepts de modélisation de données et capacité à définir l’architecture avec un minimum d’assistance afin de développer un microservice complexe
Familiarité avec des systèmes de bases de données variés et capacité à formuler des requêtes complexes de façon autonome
Connaissances des concepts d’infonuagique (cloud) et capacité à suivre des instructions afin de les appliquer avec un minimum d’assistance
Connaissance des services AWS (Glue, Athena, S3, Databricks, etc.) et de la plateforme Apache Airflow, un atout
Connaissance de Git
Excellente maîtrise de l’anglais, tant à l’écrit qu’à l’oral, français un atout

COMPÉTENCES
Souci du détail et capacité à apprendre rapidement
Mentalité positive axée sur la recherche de solutions pour surmonter les obstacles
Esprit d’équipe et grand sens de la responsabilité
Habileté à prospérer dans un milieu au rythme rapide et à maîtriser les technologies et les techniques en évolution fréquente",3.9,SSENSE,Montreal,"Montreal, Canada",501 to 1000 employees,2003,Company - Private,"Department, Clothing, & Shoe Shops",Retail,Unknown / Non-Applicable,-1,74.0,17,data engineer,na,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,7077,0
410,"Job Summary

Reporting to the Senior Manager of Investment Data Management, the Business Data Analyst will support two mission critical functions (data operations and data governance) ensuring the timely availability of accurate investment data for HOOPP.

Data operations ensures investment applications have complete information for business users daily. This includes but is not limited to: monitoring the daily cycle of events, ensure data integrity and availability within investment applications, data reconciliation, pricing integrity, security master, integrity of reference and market data straight-through trade capture, and first level support for vendor-based trading applications. The Business Data Analyst will assist in the design and implementation of data quality best practices. Data governance practices ensures the integrity, usability and transparency of investment data. Business Data Analyst will be involved in maintaining the investment data dictionary, reviewing data governance processes and practices keeping up-to-date on industry standards in data governance space. The Business Data Analyst will assist in the design and implementation of the governance process and its systems.

The position requires strong analytical skills coupled with investment operations knowledge, data loading and scheduling, managing reference and market data, and systems testing experience. This position requires the individual to be available at 7:00 a.m. to support the data management functions. Occasionally when supporting other team members, the individual may be required to stay as late as 6:00 p.m. or until all daily tasks are completed. There may also be the occasional weekend work for system testing or implementations.

Roles and Responsibilities
Ensure completeness of overnight data jobs. Work with IT in repairing failed jobs, re-running processes as required and optimizing scheduling.
Resolve data integrity issues on a timely basis, escalate as needed and contribute to finding resolutions and for improving controls and efficiency.
Review data integrity checks to assess potential data issues resident in the various investment applications. Create, develop, implement and test data quality checks, processes and procedures to manage data, content quality and reconciliation requirements.
For Production systems (SimCorp Dimension, SAP HANA, SAP Data Services, Eagle PACE, Bloomberg, SS&CNet, Vendor Based Trading applications) the Business Data Analyst is responsible for setting up new Security Masters, reference data, maintaining tables and data translations. The controls must be executed for static data, pricing, market data and automated trade capture on an ongoing basis.
For vendor-based trading applications (E.g. Bloomberg AIM) the Business Data Analyst will provide first level support and work with vendors to address issues.
Where custom application function or report requirement is identified, the Business Data Analyst is responsible to work with IT by assisting in the preparation of specifications, providing test cases, testing finished product and signing off.
Document operational processes, data flows, test cases and results.
Develop effective working relationships with HOOPP’s investment management teams, operational teams, custodians, auditors, system vendors and others within the industry.
Develop a detailed understanding of HOOPP’s investment business and the various systems and operation processes used to support it; to respond quickly and accurately to questions and problems that arise in the availability, integrity or completeness of Investment Data.
Primary back up and support for Senior Analysts and Senior Associate as required.
The Business Data Analyst will work with the IT Specialists to ensure that the security reference manager, market data, pricing data feeds meet or exceed HOOPP Data Standards.
Actively monitor and execute data governance controls, this includes the ongoing maintenance of HOOPP’s investment data dictionary. Contribute to the development of best practices and data governance standards.
Proactively validates data using exception handling tools and procedures. Contributes to the development of the Data Quality checks and identify opportunities to leverage new business tools to meet business requirements.
Work cross functionally as a contributing team player to ensure Investment applications have complete information for business users daily.
Other duties as assigned.
Qualifications
Knowledge of investment management principles and practices with exposure to marketable securities, derivatives, private placements, infrastructure and real estate.
Highly analytical with strong consulting and problem-solving skills.
Proactive and results oriented with good time management skills and the ability to work well under pressure and focus on multiple tasks concurrently.
Post-secondary training in finance or equivalent experience. Completion of Canadian Securities Course. Enrolment or completion of relation professional training (e.g. CFA) – is not required though may be an asset.
Minimum experience: 5 years in investment and financial systems administration, implementation and reporting.
A team player with excellent interpersonal and communication (written and verbal) skills are essential to deal with all levels of staff and outside contacts.
Comprehensive understanding of middle and back office processes and technical applications.
Competence with database report writers and Windows based software with a strong proficiency in Excel.
An understanding of the accounting and performance reporting requirements will be an asset to this position.
Develop a strong proficiency with systems being utilized for the Investment business (SAP HANA, Eagle PACE, SimCorp Dimension, Bloomberg, SS&CNet)
This position requires an above average, technically inclined individual who is a self-starter and highly motivated to manage financial data/systems in an integrated environment.
Good understanding of databases and report development concepts. Knowledge of MS SQL Server Tools, SQL language and/or Transact-SQL language is a definite asset.
Experience with Business Intelligence software and ETL tools a definite asset.",3.6,HOOPP,Toronto,"Toronto, Canada",501 to 1000 employees,1960,Non-profit Organisation,Investment Banking & Asset Management,Finance,Unknown / Non-Applicable,-1,74.0,60,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,6230,0
411,"This position will join our growing
team of data and analytics experts for Cox Automotive Canada. You will be
responsible for expanding and optimizing our data pipeline architecture, as
well as optimizing data flow and collection for cross functional teams. You
will support our data initiatives and will ensure optimal data delivery
consistent throughout ongoing projects.

As a Senior Data Engineer,
you will be responsible for leading Data Engineering projects throughout their
entire lifecycle, that being: initial investigation and stakeholder engagement,
solution design, application development, testing and sign-off, release and
maintenance

The ideal candidate is an experienced data pipeline builder and
data wrangler who enjoys optimizing data systems and building them from the
ground up. They must be self-directed and comfortable supporting the data needs
of Cox Automotive Canada. The right candidate will be excited by the prospect
of optimizing or even re-designing our companys data architecture to support
our next generation of products and data initiatives, enabling the evolution of our Data Science and Business Intelligence
Responsibilities:
Assemble large, complex data sets that
meet functional / non-functional business requirements.
Recommend different ways to constantly improve
data reliability and quality
Identify, design, and implement internal
process improvements: automating manual processes, optimizing data delivery,
re-designing infrastructure for greater scalability, etc.
Improve upon the data ingestion
pipelines, ETL jobs, and alarms to maintain data integrity and data
availability.
Build analytics tools that utilize the
data pipeline to provide actionable insights into customer acquisition,
operational efficiency and other key business performance metrics
Performs other job-related duties as
assigned or apparent and Stay up-to-date with advances in data persistence and
big data technologies
Prototype and design new data integration
solutions that balance security, scalability, fault-tolerance, performance as
well as cost effectiveness
Define, document and champion best practice architectural
patterns and work with wider technology development teams to proactively seek
out new opportunities to utilise Data Solutions technology and data assets
Be responsible for leading the delivery of multiple Data
Engineering development projects at a time. Project delivery responsibility
extends from design, development, testing, release and maintenance
Be responsible for leading the delivery of multiple Data
Engineering development projects at a time. Project delivery responsibility
extends from design, development, testing, release and maintenance
Qualifications
3+ years technical experience working in Big Data, designing
solutions to complex data ingestion problems
Graduate degree in Computer Science, Computer Engineering or
a related field
Big Data Certification and AWS certification would be an
asset
Must have strong Data Orchestration experience using tools
such has AWS Step Functions, Lambda, AWS Data Pipeline, Apache Nifi.
Advance Python Skills to develop efficient, decouple Data
pipeline
In-depth knowledge of AWS Big Data Services
Must possess in-depth knowledge and hands on development
experience in building Distributed Big Data Solutions including ingestion,
caching, processing, consumption, logging & monitoring)
Must have a strong understanding and experience with Cloud
Storage infrastructure and operationalizing AWS based storage services &
solutions prefer S3 or related specific business questions and identify
opportunities for improvement
Experience in building processes supporting data
transformation, data structures, metadata, dependency and workload management
A successful history of manipulating, processing and
extracting value from large disconnected datasets
Working knowledge of message queuing, stream processing, and
highly scalable data stores
Advanced working SQL knowledge and experience working with
relational databases, query authoring (SQL) as well as working familiarity with
a variety of databases
Experience supporting and working with cross-functional
teams in a dynamic environment
Experience deploying data pipelines with CI/CD
Experience with Snowflake Data Warehouse is plus

Who We Are

About Cox Automotive

Theres nothing ordinary about Cox Automotive. We are people of every background driven by our passion for mobility, innovation, client success and community outreach. We make buying, selling and owning (or simply using) cars easier for everyone. Touching more than 40,000 clients across five continents, we bring together the best brands and the best teams to propel the automotive industry forward. Some of those team members work for our iconic consumer brands like Autotrader and Kelley Blue Book, while others are creating the future of automotive at industry-facing brands like Dealer.com, Manheim and vAuto.

About Cox

We are the Cox family of businesses. Weve been making our mark since 1898 by building and evolving world-class businesses, staying true to our values, and encouraging top talent to always look for growth and impact while building a career with us. Our primary divisions Cox Communications and Cox Automotive are driving a new wave of innovation, powering smart cities with powerhouse broadband communications and pioneering greener, more progressive transportation alternatives for individuals and fleet operators. Were also expanding into new spaces like cleantech and healthcare to rev up our momentum toward building a better future for the next generation. Were looking for the talent today who will be our leaders tomorrow. Sound intriguing? Learn more about where we are today, where we hope youll be going with us, and the common purpose that unites us at coxenterprises.com.

Cox is an Equal Employment Opportunity employer - All qualified applicants/employees will receive consideration for employment without regard to that individuals age, race, color, religion or creed, national origin or ancestry, sex (including pregnancy), sexual orientation, gender, gender identity, physical or mental disability, veteran status, genetic information, ethnicity, citizenship, or any other characteristic protected by law.

Statement to ALL Third-Party Agencies and Similar Organizations: Cox accepts resumes only from agencies with which we formally engage their services. Please do not forward resumes to our applicant tracking system, Cox employees, Cox hiring manager, or send to any Cox facility. Cox is not responsible for any fees or charges associated with unsolicited resumes.",3.6,Cox Automotive,Mississauga,"Atlanta, GA",10000+ employees,2014,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"CarGurus, Carvana, CarMax",74.0,6,data engineer,senior,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,6631,3
412,"Are you looking for unlimited opportunities to develop and succeed? With work that challenges and makes a difference, within a flexible and supportive environment, we can help our customers achieve their dreams and aspirations.

Job Description

Are you looking for unlimited opportunities to develop and succeed? With work that challenges and makes a difference and a flexible and supportive environment, we can help our customers achieve their dreams and aspirations. We are currently seeking a Data Engineer to join one of our fast growing teams.

A day to day breakdown of the role would be as follows: 60% Hands On Development and Analysis, 20% Business partner interaction, 20% Agile Team Collaboration.

Additional responsibilities include:
Designs and implements data architectures in production environments
You will develop solutions that process data real-time from a variety of sources and make data available to multiple partners ranging from other IT applications to business teams to end customers.
You will work jointly with the Front-End team to ensure the definition of API endpoints is well understood and their requirements are supported
Translates business needs into data architecture solutions
Develops data landscape modernization architectures and roadmaps
Review and analyze the effectiveness and efficiency of existing systems and develop strategies for improving or further utilizing these systems.
Creates, reviews, updates and presents systems models, specifications, diagrams and charts to provide direction to system programmers and manages third party vendor (managed services) relationships.
Develops standards and processes for coding, deployment, testing, and governance.
You would be a good for this this role if:
You work jointly with the Front-End team to ensure the definition of API endpoints is well understood and their requirements are supported
You value collaborative development, this can be read in the quality and readability of your code and in your thorough code reviews
You are obsessed with accurate, reliable customer data
You think about QA and testability before you implement anything
You are mindful your work doesn’t stop when something works on your local computer: you work collaboratively with DevOps, think about migration, deployment, test coverage and documentation
You are promoting a culture of self-serve data analytics by minimizing technical barriers to data access and understanding
Qualifications for this role include:
BSc in Computer Science, Statistics, Informatics, Information System, Mathematics or equivalent quantitative field preferred
Well versed in software development methodologies, testing, release management, and maintenance. take pride in optimizing and cleaning code, and leave a program in a better shape than you found it
Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL). A SQL veteran,
Good understanding of Master Data Management and IBM InfoSphere.
Good knowledge of DevOps and CI practices, ability to spec and setup the right environments and deployment procedures, proficiency with Docker and Jenkins.
Excellent troubleshooting skills. Experience performing root cause analysis on internal and external data and processes to answer specific business questions and find opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
Understanding of relational and warehousing database technology working with at least one of the major databases platforms, preferably DB2, SQL Server
Practical experience with big data processing frameworks and techniques such as Azure, Hortonworks, Spark, Hive, PCF,
Solid working knowledge of data processing tools using SQL, Spark, Python or similar open source and commercial technologies
Knowledge of Java/Scala especially in relation to big data open source software preferred.
ETL experience is a requirement.
Agile project methodologies
Collaborative attitude, willingness to work with team members; able to coach, participate in code reviews, share skills and methods
Constantly learns from both success and failure
Good organizational and problem-solving abilities that enable you to manage through creative abrasion
Good verbal and written communication; effectively articulates technical vision, possibilities, and outcomes
Experiments with emerging technologies and understanding how they will impact what comes next.
What about Perks?

Manulife has lots of perks including, but not limited to:
Competitive compensation
Retirement Savings Accounts including a RPP (Pension Plan), RRSP (Retirement Savings Plan), and TFSA (Tax Free Savings account)
Manulife Share Ownership Program with employer matching
Customizable Benefits Package including Health, Dental, Vision, and 100% of Mental Health expenses
Financial support for ongoing training, learning, and education
Monthly Innovation Days (Hackathons)
Wearing jeans to work every day
An abundance of career paths and opportunities to advance
This is a full-time permanent role located in Toronto, Ontario.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status

If you are ready to unleash your potential it’s time to start your career with Manulife/John Hancock.

About Manulife

Manulife Financial Corporation is a leading international financial services group that helps people make their decisions easier and lives better. With our global headquarters in Toronto, Canada, we operate as Manulife across our offices in Canada, Asia, and Europe, and primarily as John Hancock in the United States. We provide financial advice, insurance, and wealth and asset management solutions for individuals, groups and institutions. At the end of 2019, we had more than 35,000 employees, over 98,000 agents, and thousands of distribution partners, serving almost 30 million customers. As of March 31, 2020, we had $1.2 trillion (US$0.8 trillion) in assets under management and administration, and in the previous 12 months we made $30.4 billion in payments to our customers. Our principal operations are in Asia, Canada and the United States where we have served customers for more than 155 years. We trade as 'MFC' on the Toronto, New York, and the Philippine stock exchanges and under '945' in Hong Kong.

Manulife is an equal opportunity employer. We strive to attract, develop and retain a workforce that is as diverse as the customers we serve and to foster an inclusive work environment that embraces the strength of cultures and individuals. We are committed to fair recruitment, retention and advancement and we administer all of our practices and programs based on qualification and performance and without discrimination on any protected ground.

It is our priority to remove barriers to provide equal access to employment. A Human Resources representative will consult with applicants contacted to participate at any stage of the recruitment process who request any accommodation. Information received regarding the accommodation needs of applicants will be addressed confidentially.",3.7,Manulife,Toronto,"Toronto, Canada",10000+ employees,1887,Company - Public,Investment Banking & Asset Management,Finance,$50 to $100 million (CAD),"MetLife, ING, Sun Life",74.0,133,data engineer,na,0,1,0,0,0,1,1,0,1,0,0,1,0,0,1,7257,3
413,"The Tech360 Data Platform team's vision is to help customers handle the full life cycle of data at all levels of granularity, simplify data collection, integration, and aggregation of AWS data assets, and provide services (compute, storage, security) to access datasets at scale. We collect and process billions of usage and billing transactions every single day and relate it to the largest data feed supported by Salesforce.com. We transform this raw data into actionable information in the Data Lake and make it available to our internal service owners to analyze their business and service our external customers.
We are truly leading the way to disrupt the big data industry. We are accomplishing this vision by bringing to bear Big Data technologies like Elastic Map Reduce (EMR) in addition to data warehouse technologies like Spectrum to build a data platform capable of scaling with the ever-increasing volume of data produced by AWS services. You will have the ability to craft and build Tech360's data lake platform and supporting systems for years to come.
You should have deep expertise in the design, creation, management, and business use of large datasets, across a variety of data platforms. You should have excellent business and interpersonal skills to be able to work with business owners to understand data requirements, and to build ETL to ingest the data into the data lake. You should be an authority at crafting, implementing, and operating stable, scalable, low cost solutions to flow data from production systems into the data lake. Above all you should be passionate about working with huge data sets and someone who loves to bring datasets together to answer business questions and drive growth.


Basic Qualifications

· This position requires a Bachelor's Degree in Computer Science or a related technical field, and 5+ years of meaningful employment experience.
· 5+ years of work experience with ETL, Data Modeling, and Data Architecture.
· Expert-level skills in writing and optimizing SQL.
· Experience with Big Data technologies such as Hive/Spark.
· Proficiency in one of the scripting languages - python, ruby, linux or similar.
· Experience operating very large data warehouses or data lakes.

Preferred Qualifications

· Authoritative in ETL optimization, designing, coding, and tuning big data processes using Apache Spark or similar technologies.
· Experience with building data pipelines and applications to stream and process datasets at low latencies.
· Demonstrate efficiency in handling data - tracking data lineage, ensuring data quality, and improving discoverability of data.
· Sound knowledge of distributed systems and data architecture (lambda)- design and implement batch and stream data processing pipelines, knows how to optimize the distribution, partitioning, and MPP of high-level data structures.
· Knowledge of Engineering and Operational Excellence using standard methodologies.
Amazon.com is an Equal Opportunity Employer Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation.",3.9,Amazon,Vancouver,"Seattle, WA",10000+ employees,1994,Company - Public,Internet,Information Technology,$10+ billion (CAD),"Google, Microsoft, Walmart",74.0,26,data engineer,na,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,3064,3
414,"Job Description: AWS Data engineer with 3-5 years work experience using Python, PySpark, AWS EMR and Airflow. The desired candidate should have strong development skills and experience on datalake implementation including data extraction and building data pipeline.

Job Type: Full-time

Pay: $94,832.00-$120,000.00 per year

Schedule:
Monday to Friday
Experience:
AWS Data: 3 years (Preferred)",-1.0,SmartTechlink Sollutions I,Toronto,"Rolling Meadows, IL",Unknown,-1,Company - Public,-1,-1,Unknown / Non-Applicable,-1,74.0,-1,data engineer,na,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0,394,0
415,"Are you interested in being part of a small team tasked to build the next-generation industry-leading platform for healthcare markets? We are looking for smart, passionate, and a highly skilled Principal Data Engineer with data steward skillsto join the effort to define and build the future of MacroHealth. You will be joining a team that's developing the data platform for advanced analytics. The work youll do directly impacts the experience of our customers.

About us:

The U.S. health sector is complex and dynamic - a vast and diverse network of entities that impacts the population and economy like no other industry. At USD$3.3 Trillion, healthcare spending represents nearly 18% of U.S. GDP. It is complex and inefficient, with estimates of fraud and waste ranging up to 30% of total spending. Health service buying, selling, and settlements have seen little change in the past decade despite clear changes in available information, technology, regulation, and market consolidation.

Enter MacroHealth. MacroHealth is a mission driven company. We are building the most advanced and trusted market platform for health service payers and providers. The companys vision is to create Intelligent Health Markets by building technology, knowledge and relationships that enable payers and providers to optimize the buying and selling of health services.

We are expanding our team of passionate thought leaders as we pursue our goal of disrupting the U.S. health sector with our vision and technology. We are committed to developing leading edge solutions in a supportive environment focused on customer success and employee fulfillment.

What youll do:
Develop, manage, and maintain an up to date map of all the data sources at MH,
Create, implement, and enforce data management policies, procedures, and standards,
Monitor data health, data quality, and compliancy according to MH's data policy,
Design, build, and launch efficient and reliable data pipelines to move and transform data,
Develop additional tools and refine processes to help with analytics at MH,
Collaborate with the customer engineers, data analysts/scientists, and business owners
Fit in a people-first culture of teamwork and respect,
What youll need:
3-5 years of experience of working in start-ups and larger companies in a high-tempo, dynamic environments,
Excellent documentation skills,
Experience with at least one scripting programming language, such as Python or Go,
Knowledge of at least one backend programming language, such as Java or Scala,
Experience with MS Azure stack. Work experience with ADF would be an asset
Strives to stay up to date with the best practices of data management,
Has worked in the healthcare market before, an asset",-1.0,MacroHea,Vancouver,"Kirkland, WA",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,74.0,-1,data engineer,senior,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,2728,0
416,"Job description:

Job Responsibilities:
Develops and maintains scalable data pipelines and builds out new API integrations to support continuing increases in data volume and complexity.
Collaborates with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.
Implements processes and systems to monitor data quality, ensuring production data is always accurate and available for key stakeholders and business processes that depend on it.
Writes unit/integration tests, contributes to engineering wiki, and documents work.
Performs data analysis required to troubleshoot data related issues and assist in the resolution of data issues.
Works closely with a team of frontend and backend engineers, product managers, and analysts.
Defines company data assets (data models), spark, sparkSQL, and hiveSQL jobs to populate data models.
Designs data integrations and data quality framework.
Designs and evaluates open source and vendor tools for data lineage.
Works closely with all business units and engineering teams to develop strategy for long term data platform architecture.
Data Engineer Qualifications / Skills:
Knowledge of best practices and IT operations in an always-up, always-available service
Experience with or knowledge of Agile Software Development methodologies
Excellent problem solving and troubleshooting skills
Process oriented with great documentation skills
Excellent oral and written communication skills with a keen sense of customer service
Education, Experience, and Licensing Requirements:
BS or MS degree in Computer Science or a related technical field
4+ years of Python development experience
4+ years of SQL experience (No-SQL experience is a plus)
4+ years of experience with schema design and dimensional data modeling
Experience in PySpark
Experience in designing end to end solution
Familiar with Design patterns and best practices in designing system
Familiar with orchestration tools such as Airflow
Experience designing, building, and maintaining data processing systems
Job #43489",3.6,Tundra,Toronto,"Toronto, Canada",201 to 500 employees,2004,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,126.5,16,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,1,0,0,0,2150,0
417,"Senior Data Engineer
Location


Markham

Region

CA-ON

Req #

200317

Apply Now


Job Field:
Information Technology

Job Type:
Full-time

Building Location:

Length of Assignment:

SUMMARY

The Senior Data Engineer is a deep technical expert in building complex data warehousing and business intelligence applications. At this level, the incumbent demonstrates a passion and in-depth knowledge of large, complex application development methodologies. They motivate themselves and the team to refine their skills and adopt best practices for developing pragmatic software solutions for the organization. Leading the charge, they continue to raise the bar on mastery of business intelligence application development within the team and the organization.

KEY DUTIES & RESPONSIBILITIES

Programming
Uses in-depth knowledge of advanced programming techniques, design patterns and hardware/software interfaces to develop business intelligence and data warehouse applications.
Designs, tests and integrates data warehouse and BI modules and resolves programming errors using various debugging tools and techniques.
Provides guidance/mentors on programming practices and techniques to individuals and cross-functional teams.
Provides support, guidance and production assurance for very complex or urgent problems.
Performs work with minimum supervision, and work is assigned in terms of technical objectives.
Prepares technical documentation (e.g., user guides, technical specifications).
Assists in the design of business solutions.
Analysis
Conducts impact analysis for proposed changes to or problems across the system.
Leads team discussions in the analysis and collaboration to clarify and improve specifications or to identify alternative programming solutions.
Continuous Improvement
Makes recommendations or decisions on architecture, application design, standards and process improvements.
Enforces team and organizational standards and practices (e.g. at walkthroughs and peer code reviews).
Engages in continuous learning by developing and executing on a learning plan.
Takes responsibility for individual and the team's results.
Advocates for quality in all aspects of development efforts based on the team's definition of quality.
Risk Management
Estimates and prioritizes work to maximize value while taking into account risk, effort and dependencies.
Raises impediments, risks, and issues as early as possible and work with the team to mitigate as needed.
KNOWLEDGE & SKILLS
University graduation and minimum 5-10 years of relevant experience
Demonstrates in-depth knowledge of Microsoft BI architecture, established data warehouse development methodologies, multi-dimensional data modelling, OLAP, metadata management, data security, predictive analysis and big data processing. Extensive experience in one of these cloud data warehouses (Snowflake, bigtable, Redshift), Data Vault 2.0 methodology, steaming data processing, BI components in SQL Server 2016+, TSQL, and DAX, Power BI.
A good working knowledge of application security, C#, python, PowerShell, metadata management, NoSQL, and data security.
Experience in programming and debugging complex data warehouse and BI applications as part of a multi-disciplinary team environment (following an agile framework such as SCRUM preferred) based on Microsoft Team Foundation Server and git.
Experience in writing unit tests to support production code using a unit test framework.
Experience with database management (i.e. database design, schema creation, concurrency and performance considerations).
Takes ownership and initiative and collaborates well with a team of peers.
Demonstrates a commitment to continuous learning (e.g. user groups, blogs, conferences, community awareness, and next generation tooling).
Able to clearly communicate in both a verbal and written form within a predominantly English working environment.
Has a positive, passionate, idea generating attitude when faced with challenges.
Licenses and/or Professional Accreditation
Certification in Microsoft technologies preferred",3.8,BGIS,Markham,"Markham, Canada",5001 to 10000 employees,1992,Company - Public,Real Estate,Real Estate,$100 to $500 million (CAD),-1,126.5,28,data engineer,senior,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,4065,0
418,"At SoundHound Inc., we believe every brand should have a voice. As the leading innovator of conversational technologies, we're trusted by top brands around the globe. Houndify, our independent Voice AI platform, with 70,000+ users, allows brands to create custom voice assistants that deliver results with unprecedented speed and accuracy.

Our mission is to enable humans to interact with the things around them in the same way we interact with each other: by speaking naturally. We're making that a reality through our SoundHound music discovery app and Hound voice assistant and through our strategic partnerships with brands like Mercedes-Benz, Hyundai, Deutsche Telekom, and Pandora. Today, our customized voice AI solutions allow people to talk to phones, cars, smart speakers, mobile apps, coffee machines, and every other part of the emerging 'voice-first' world.

Our diverse team of engineers, UX/UI designers, writers, data scientists and linguists are all passionate about creating a world with more conversations. With more than 14 years of expertise in voice technology, we have hundreds of millions of end users, and a worldwide team in six countries building solutions for a voice-first world.

About the Role:
Innovate on state-of-the-art deep learning systems for speech recognition and speaker recognition
Apply deep learning techniques to improve acoustic models and keyword spotting
Requirements:


Understanding of modern machine learning techniques
Experience with Deep Learning / Neural Network frameworks such as Tensorflow, PyTorch, Caffe, Torch, MxNet, etc.
Strong programming skills on Linux using C++ and/or Python
Solid knowledge of algorithms and probability / statistics
MS / PhD in Computer Science or Electrical Engineering or Statistics or equivalent
5+ years of relevant industry experience
Nice to Haves:


Experience working with automatic speech recognition systems
Experience working with speaker recognition and keyword spotting, including wake-up phrase detection
Experience in computer vision and pattern recognition
Knowledge of DSP principles, noise reduction, echo cancelation",4.3,SoundHound Inc.,Toronto,"Santa Clara, CA",201 to 500 employees,2005,Company - Private,Computer Hardware & Software,Information Technology,$50 to $100 million (CAD),-1,126.5,15,machine learning engineer,senior,0,1,0,0,0,0,0,0,0,0,0,0,1,1,1,2122,0
419,"Lightspeed is growing quickly and we're looking for a passionate Data Engineer to join our Montreal-based Development team. The primary role for this position is to work on our cloud-based software, Lightspeed Retail.

If you have worked on large projects and your background is in Java or in any other object-oriented language, and you're a natural-born problem-solver and always game to develop products that solve real-world problems for customers around the globe, this might be the role for you.

What you'll be responsible for:
Design, build and develop ETL pipelines consolidating various data sources (streaming or batch) into application specific Data Warehouses
Design, build and develop Analytical and Business Intelligence solutions
Prototype and develop solutions using statistical methods; data mining, machine learning, AI, etc.
Work as part of a team to deliver product features and functionality
Translate requirements into conceptual and detailed designs with estimates
Develop clean, maintainable code in a continuous integration + continuous deployment environment
Assist QA and Support staff in troubleshooting software issues as well as implementing bug fixes
What you'll be bringing to the team:
Senior level experience developing reliable, highly available and scalable software
Fluent with Java and Python
Experience with cloud environments like GCP, AWS, as well as cloud solutions like Kubernetes, Docker, etc.
Experience with both relational (SQL) and non-relational (NoSQL) databases
Experience with real time messaging systems (Pub/Sub, Kafka, etc.)
Proven skills in server side resource profiling, optimization and debugging
Strong interest/experience in data mining, machine learning, statistical methods, AI, etc.
Strong proficiency in a UNIX/Linux environment
Excellent communication skills
Experience writing automated unit and functional tests
Experience working in an Agile development environment
BS/BA in Computer Science, or equivalent experience
Even better if you have, but not necessary:
Research or work experience in AI, automation and/or Data Engineering
Good understanding of Design Patterns
Experience in a continuous delivery model
Experience in building APIs
Experience with event based and messaging systems
DevOps background
Advanced degree Computer Science, Statistics or related fields
Who is Lightspeed?

Lightspeed (TSX: LSPD) powers small and medium-sized businesses with its cloud-based, omni-channel commerce platforms in over 100 countries around the world. With smart, scalable, and dependable point of sale systems, Lightspeed provides all-in-one solutions that help restaurants and retailers sell across channels, manage operations, engage with consumers, accept payments, and grow their business.

Headquartered in Montréal, Canada, Lightspeed is trusted by favourite local businesses, where the community goes to shop and dine. Lightspeed has offices in Canada, USA, Europe, and Australia.",3.9,Lightspeed ENG,Montreal,"Montreal, Canada",1001 to 5000 employees,2005,Company - Public,Computer Hardware & Software,Information Technology,Unknown / Non-Applicable,"Shopify, Revel Systems, ShopKeep",126.5,15,data engineer,senior,0,1,0,0,0,1,0,0,0,0,0,0,1,0,1,2954,3
420,"Sr. Data Engineer

Toronto, ON

6+ Months
Senior Data Engineer

8+ years of hands-on development experience in multiple projects, with progressively increasing responsibility
5+ years of hands-on experience working with data warehousing like applications and big data.
Experience leveraging big data technologies (One or more of Hadoop, Python, Spark) is required.
Exposure to Microsoft Azure (or other cloud) platforms is preferred
Experience working with various data exchange formats (JSON, CSV, XML etc.)
Solid understanding of relational and dimensional database design and knowledge of logical and physical data models is preferred
Experience with SDLC and/or Agile methodologies for project development, and participation in all phases of project development, is required
Excellent knowledge of SQL and Linux shell scripting
Experience in deploying and managing SQL and NoSQL databases is preferred
Experience with job scheduling (TIDAL, CAWLA, Oozie) and file transfer (e.g. SFTP)
Excellent diagnostic, analytical and problem-solving skills are preferred
Experience with continuous delivery tools (Jenkins, Bamboo, Circle CI), and an understanding of the principles and pragmatics for build pipelines, artefact repositories, zero-downtime deployment, etc. is preferred
Experience building real-time data pipelines using Kafka or spark streaming is preferred",-1.0,Atlantis IT gr,Toronto,-1,-1,-1,-1,-1,-1,-1,-1,126.5,-1,data engineer,senior,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,1365,0
421,"Data Engineer/Architect

This is an opportunity within the advanced analytics team in the Global Asset Management division. As part of this group, the successful candidate will support GAM’s business leaders leveraging advanced analytics to support decisions in investment management, new product development, and sales/marketing opportunities. The candidate will have the opportunity to build data driven products and insights, tackle challenging data-related problems using RBC's internal datasets & value-added external data.

What you will do:

Create the overall data architecture vision and ensure specific components are appropriately designed and leveraged, while contributing to the holistic vision of Enterprise Architecture at GAM.
Create reference architecture frameworks and patterns.
Promote adoption of industry best practices and ensures development adheres to RBC-GAM framework, tools, standards, and guidelines
Design systems using PL-SQL, S3/HDFS, Presto, Hive, GraphQL etc. using cloud services to design for high availability, security, and auto scalability.
Use SLAs and user requirements to determine capacity requirements and incorporate them into architecture
What you need:

A Bachelor’s degree in Information Technology or related field (preferred) or equivalent experience.
Experience in architecture/design/development in Data Warehousing/ETL.
3+ years of architecture experience, utilizing S3, Presto, Hive, Spark, GraphQL or similar technologies in a Hybrid cloud environment.
Ability to design pub-sub methods, master-transaction data structures, complex data mappings with multiple systems in accordance with data requirements.
Experience and understanding of data in Global Asset Management function.
Nice to have:

Knowledgeable about containers & orchestration (Docker, Kubernetes, Mesos).
Continuously learning mindset and enjoy working on open-ended problems.
An outstanding ability to communicate, both verbally and in writing and ability to cultivate strong working relationships.",3.4,CoreHR Solutions Inc.,Toronto,"Toronto, Canada",1 to 50 employees,-1,Company - Private,Staffing & Outsourcing,Business Services,Unknown / Non-Applicable,-1,126.5,-1,data engineer,na,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,2020,0
422,"Role Purpose and Key Accountabilities:

The primary role of a Lead Data Engineer is to support development of various data engineering components of Prevalent’s Security Insight Platform (SIP) across data collection, transport, transformation, ingestion and analytics. SIP is based on open source big data technologies designed to ingest, process and analyse peta byte scale data on a distributed architecture.

The ideal candidate would be a self-motivated individual with strong technology skills, commitment to quality and positive work ethic, who can
Participate in design, development, and deployment of SIP data management modules.
Develop data ingestion, parsing, scheduling, processing and other data management components based on agile development practices.
Work in a fast-paced agile development environment.
Conduct unit, system and integration testing of developed modules.
Select and integrate any Big Data tools and frameworks required to provide requested capabilities.
Collaborate with client and partner teams to ensure high quality data solutions are delivered.
Troubleshoot operational escalations and resolve client implementation issues in a timely manner with strong collaboration and care for business priorities.
Develop an understanding of industry trends and best practices related to Data Engineering and Open Source Big Data technologies.
Create and follow personal education plan in the technology stack and solution architecture.
Collaborate and contribute to agile teamwork.
Build processes supporting data transformation, data structures, metadata, dependency and workload management.
Skills & Experience
Significant experience in data engineering on open source big data technologies.
Experience with big data tools: Hadoop, Spark, Kafka, etc. and NoSQL databases like Postgres, Mongo DB, Elastic.
Experience with data pipeline and workflow management tools: Airflow, etc.
Experience with AWS cloud services: EC2, EMR, RDS.
Experience with stream-processing systems: Spark-Streaming, etc.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
Great verbal and written communication skills.
Self-motivated individual with an analytical mind-set capable of working in a fast-paced environment.
Strong project management and organizational skills.
Knowledge:
Good knowledge of object-oriented/object function scripting languages: Python, Java, Scala.
Good understanding of Data lake concepts such as data ingestion and transformation.
Understanding of Hadoop Framework including MapReduce concepts and parallel processing.
In depth understanding of Spark Framework.
Good understanding of Agile methodology.
Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
Great verbal and written communication skills.
Self-motivated individual with an analytical mind-set capable of working in a fast-paced environment.
Strong project management and organizational skills.
Education:

Masters/Bachelor’s Degree in Computer Science Engineering",-1.0,Prevalent,Cochin,"Kochi, India",Unknown,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,126.5,-1,data engineer,senior,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,3136,0
423,"Senior Panel Data Analyst - COnsumer Packaged Goods

Who is Plastk?

Plastk Financial & Rewards is a Canadian FinTech company. Our secure credit card and rewards brand was created to help members (cardholders) achieve financial independence by enabling them to establish or rebuild their credit scores. Plastk offers the only premium rewards program for a secure credit card in Canada, focusing on providing rewards for your everyday purchases. Critical to our business model is our unique advertising platform that connects brand managers directly to their customers in order to build brand loyalty.

By joining Plastk, you’ll become part of a forward-thinking company that is transforming financial services by embracing technology to build innovative win-win rewards programs, credit tools, and more.

Summary:

As an energetic Sr Panel Data Analyst professional, who can embrace the entrepreneurial spirit of a FinTech Startup, the right candidate will play an integral part in creating and implementing Plastk’s Platform. In this role, you will be tasked with leading data discovery and visualization across channels with a focus on driving growth of our portfolio data set.

You will own and analyze large internal and external datasets from different sources. The successful candidate should have extended business knowledge as well as technical skillsets. You should be able to translate business requirements into data requirements then develop ETL pipelines to generate final data sets and accompanying visualization. Also, You have experience in designing, developing, and executing large scale of data pipelines in cloud environment.

Required Experience
5+ years of experience SQL / T-SQL / Stored Procedures / SQL User Defined Functions
5+ years of experience in Database Architecture, Data Modeling, Data Management
5+ years of experience in OLTP Relational Model design
5+ years of experience in OLAP Dimensional Modeling
5+ years of experience with ETL Processes / Data Integration between databases;
5+ years of experience with database warehouse and decision support tools and techniques
5+ years of advanced SQL query techniques and designing and developing data solutions for reporting
Bachelor’s Degree (required) or Master’s Degree (preferred) with 3+ years relevant experience
Management Consulting or CPG experience in Brand Marketing, Market Research, Category Management and/or Shopper & Consumer Insights roles or experience, and/or as a service provider to these functions
Experience in consulting, product, sales support, and/or service delivery function in relevant software industry (e.g. Nielsen, IRI, etc.) is ideal
Working knowledge of enterprise software applications and services designed for the retail and consumer goods industries is highly valued (e.g., Nielsen, IRI, Dunnhumby)
Experience as a power user of Microsoft Excel and Business Intelligence software such as Microstrategy, Tableau, QlikView, Business Objects, etc.
Duties:
Works with digital product manager, brand product teams and business customers to develop requirements for designing the data architecture and associated reporting;
Creates and Implements Database design, development and configuration for the storage and maintenance of data;
Reviews and Evaluates Business Requirements and translates to technical design specifications for development;
Support the design, development and automation of data pipelines to support routine BI reports and analytical workstreams
Support ad-hoc data requests from clients or analytics teams
Thorough documentation of database tables, fields, and records;
Documents test cases, performs unit and system testing, and debugs data;
Advises team regarding data administration, data modeling, and data mapping ETL processes;
Participate in team discussions about problem solving, planning and architecture;
Hands-on SQL programming and database management of existing databases;
Ensure IT related policies & procedures reflect current best practices and governance.
Identify, analyze, and interpret trends or patterns relating to key performance indicators in complex data sets;
Evaluate internal/external datasets for efficiency, problems, and inaccuracies, developing and maintaining protocols for handling, processing, and cleaning data;
Develop, modify, maintain and support custom reports for both ad-hoc and ongoing needs
Interpret data and analyze results;
Create and maintain technical documentation for various systems, services and business processes including databases and reporting procedures;
Assist with the review, consolidation and reduction of data discrepancies;
Locate and define new process improvement opportunities
Interface directly with consumer insights, shopper insights, category management, brand management, and field teams, supporting their most pressing business questions and challenges
Regularly leverage third party panel data to deliver analytic insights and data-driven stories that address strategic customers goal improved marketing effectiveness
Work with clients and Plastk’s product team in developing, prototyping and piloting new solutions and enhanced capabilities. Bring the voice of customers back to the greater our organization through data to help drive the growth of the business
Support sales efforts by participating throughout sales cycles and presentations as a subject matter expert and Plastk Platform solutions guru, including occasional product demonstrations
Generate thought leadership content for our clients, from webinars, and training materials, to blog posts and industry presentations
Travel, as required, to support the above responsibilities
Job Types: Full-time, Permanent

Experience:
Panal Data Analyst: 5 years (Preferred)
Location:
Calgary, AB (Preferred)
Work remotely:
Temporarily due to COVID-19",-1.0,Pla,Calgary,-1,-1,-1,-1,-1,-1,-1,-1,82.0,-1,data analyst,senior,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,5819,0
424,"The recruitment team at Myticas Consulting is looking for experienced Business Analyst who would be interested in a long-term contract opportunity within the Ottawa, Ontario region.

Duties:
Analyze functional requirements to identify information, procedures and decision flows.
Evaluate existing procedures and methods, identify and document items such as database content, structure, application subsystems.
Define and document various user support artifacts.
Develop and document statements of requirements for considered alternatives.
Elicit Business Requirements.
Coach and mentor teams members and users on best practices and provide knowledge transfer.
Support in defining input / output sources, including detailed plan for technical design phase, and obtain approval of the system proposal.
Qualifications:
8+ years of experience with the following:
AWS
IBM InfoSphere Information Analyzer
InforSphere Business Glossary Anywhere
IBM InfoSphere Information Governance Catalog
SQL
Aginity Workbench experience would also be required
Candidates looking to apply for this role are to send us an updated version of their resume in confidence. Our team will be sure to review all applicants and follow up accordingly at the conclusion of the review process.

Job is also known as: Business Analyst, Data Analyst, Quality Analyst

GDMY",5.0,Myticas Consulting,Ottawa,"Ottawa, Canada",1 to 50 employees,-1,Company - Private,IT Services,Information Technology,Unknown / Non-Applicable,"Modis, excelHR, Robert Half",82.0,-1,data analyst,na,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1337,3
425,"At Veeva, we build enterprise cloud technology that powers the biggest names in the pharmaceutical, biotech, consumer goods, chemical & cosmetics industries. Our customers make vaccines, life-saving medicines, and life-enhancing products that make a difference in everyday lives. Our technology has transformed these industries; enabling them to get critical products and services to market faster. Our core values, Do the Right Thing, Customer Success, Employee Success, and Speed, guide us as we make our customers more efficient and effective in everything they do.

The Role

Veeva Systems is looking for experienced data engineers to build a cloud-based data analytics solution for the life science industry. If you are passionate about data and are eager to design and build data platforms from the ground up this is the role for you. The data analytics platform will provide data ingestion, data storage and rich data analytics capabilities with elegant visualization dashboards.
What You'll Do
Design and implement AWS based ETL processes to onboard data into our data lake from a variety of internal and external sources for our new data analytics platform.
Design data models and data services for optimal storage and retrieval.
Implement scalable data lake interfaces, microservices, and rest based API for querying and storing structured data.
Integrate new technologies to support advanced analytic use cases.
Requirements
5+ years’ experience in Python or Java, preferably at an enterprise cloud software company
Proven ability to write clean, testable, readable code in a team environment
Hands-on experience with building data pipelines in a programming language like Java or Python
3+ years of experience in relational databases with a mastery of SQL
Experience in data modelling, ETL development (pref. Apache Spark), and Data warehousing
Nice to Have
AWS Services (S3, Redshift, Elastic Search)
Experience with large scale big data pipeline – ETL / Kafka / Spark / MapReduce / Hadoop
Familiarity with Open API Specifications and Swagger
Experience working in an agile environment
Experience working in a startup
Perks & Benefits

· Conveniently located in downtown Toronto
· Snacks, beverages, and weekly lunches from local restaurants
· Team events and rec league sports teams
· Allocations for continuous learning & development
· Health & wellness programs
· Weekly yoga classes
· Ping pong and other games



Veeva’s headquarters is located in the San Francisco Bay Area with offices in more than 15 countries around the world.

Veeva Systems is an equal opportunity employer. Accordingly, we are committed to fair and accessible employment practices. Veeva Systems welcomes and encourages applications from people with disabilities. Accommodations are available upon request for candidates taking part in all aspects of the selection process.",3.5,Veeva Systems,Toronto,"Pleasanton, CA",1001 to 5000 employees,2007,Company - Public,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (CAD),-1,82.0,13,data engineer,senior,0,1,0,0,0,1,1,1,0,0,0,1,0,0,0,2865,0
426,"StackPros Inc is seeking a candidate for a full-time role within our Data Systems Team in Toronto, Ontario.

The Cloud Data Engineer will play a key role at StackPros, required to help create and maintain industry-leading quality and efficiency of service and software delivery.

StackPros will rely on the Data Engineer to support the Data Systems team, in both data engineering and data science-related workflows. The Data Engineer will be expected to meet and exceed StackPros' quality standards, while helping the organization rapidly expand complex Machine Learning and related applications.

Key Responsibilities:

Data Engineering-Specific Responsibilities
Participate in continuous delivery pipeline to fully automate deployment of the highly available cloud platform that supports multiple projects
Design and develop ETL workflows and datasets to be used in data visualization tools
Write complex SQL queries with multiple joins to automate and manipulate data extracts
Perform end to end Data Validation to maintain accuracy of data sets
Build tools for deployment, monitoring and operations
Troubleshoot and resolve issues in the development, test and production environments
Develop re-useable processes that can be leveraged and standardized for multiple instances
Prepare technical specifications and documentation for projects
Stay up-to-date on relevant technologies, plug into user groups, understand trends and opportunities to ensure we are using the best possible techniques and tools
Understand, implement, and automate security controls, governance processes, and compliance validation
Design, manage, and maintain tools to automate operational processes
Data Science-Specific Responsibilities
Perform exploratory data analysis to identify patterns from historical data, generate and test hypotheses, and provide product owners with actionable insights
Design experiments for product initiatives and perform statistical analysis of the results with recommendations for next steps and future experiments
Create and design dashboards by using different data visualization tools to present reports and insights, and support business decision making
Help the StackPros Data Systems team adopt and evolve Predictive Modeling, Machine Learning and Deep Learning processes to deliver to clients in the future
Company-Wide Responsibilities:
Maintain and exceed client satisfaction with StackPros Inc.s deliverables, day-to-day work and overall value as a partner
Cultivate opportunities for company growth, always seek areas where StackPros Inc.s role could be expanded
Adapt to ever-changing client needs and expectations
Maintain dedication toward achieving excellence in StackPros Inc.s delivery against client needs, and overall success as an organization
Be an enthusiastic, positive and generally awesome team mate, mentor & constantly curious learner
Qualifications:
4+ years experience in Data Engineering
Understanding of digital ecosystems including online data collection, cloud systems and analytics tools (Google Stack, Facebook, AWS, Salesforce, Adobe Suite etc.) a strong asset
Strong technical understanding of a range of marketing concepts such as cookie-based data collection, setting and leveraging audience segments, attribution modelling, AB/N & multivariate
Excellent written & verbal communication skills are essential; candidate should be comfortable presenting and participating in group discussions of concepts with internal and external stakeholders
Candidate must exhibit an analytical, detail-oriented approach to problem solving
Experience with Jira / Atlassian project management tools is an asset
WHATS IN IT FOR YOU?
100% employer-paid benefits package
Monthly yoga and meditation classes onsite
Regular Lunch and Learns from your Team Mates
Standing desks
Entertainment and Games area, including pool table
Fully-loaded kitchen: snacks/fruit/drinks/beer
Fun Employee Events and Activities
Participation in Community Engagement",-1.0,StackPros and DRVN Intellige,Toronto,-1,-1,-1,-1,-1,-1,-1,-1,82.0,-1,data engineer,na,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,3975,0
427,"Senior Data Engineering Developer

As part of the Data Engineering team you will develop and support implementation of data pipeline and data aggregation processes. We are looking for an experienced Senior Data Engineering Developer who is enthusiastic about developing code and providing data manipulation solutions by using Java and Python languages as well as Spark framework.

You will:
Design, develop, implement and monitor a highly scalable system to ingest and process terabytes of data per day
Work with other developers, engineers, data scientists and business stakeholders to continuously explore new capabilities and technologies to drive innovation
Work with different teams to translate business and analytics requirements into a data strategy for the engagement including ETL, data models, aggregations and reports for analysis
Develop standards for data processes and automate routine tasks
Support data transformation testing and production implementation as required
Youre great at
Developing, monitoring, maintaining, and supporting data analytics, data management and ETL solutions including availability, scalability, performance, data quality and data aggregation
Implementing new components using various emerging Big Data technologies
Executing ingestion of new data sources into the analytics platform including but not limited to ETL code development, data persistence design and processing logic
Assistance with design, implementation and POC of any components related to the Analytical Environment
Building large-scale real-time and batch data processing and analytics pipelines using the latest technologies
Implementing conceptual, logical and physical data models for the data analytics platform
Suggesting scheduling/timing of automatic jobs to avoid conflict with application processes
Translating business requirements into functional and technical specifications
Developing tools and utilities as needed
Supporting the data operations group for problem analysis and resolution.
Participating in rotating on-call support.
Who are you?
You have a University Degree in Computer Science Engineering or an equivalent combination of education and experience
You have 3-5 years experience in a similar role and have hands on development experience with Hadoop environment, Spark framework and Java and Python languages
You have strong knowledge of RDBMS and NoSQL databases
You have solid experience with ETL processes and data integration patterns
You have an experience with CI/CD practices within big data development
You like to develop in one or few of the languages like JAVA, Python and PL/SQL
You have exposure to Big Data technologies including the development, performance tuning, and operational activities involved
You have experience with data warehousing, operational data stores and large-scale implementations as well as a lot of experience with ETL processing
Your knowledge related to DevOps, Cloud engineering, AWS experience, Oracle, Cloudera and Talend is an asset
You know that security is one of the most important and critical parts in any data related projects.
You have the ability to apply technology when solving business problems and are able to communicate with both technical and non-technical audiences
Youre great at coaching other members of the Data Engineering team
Youre a strategic thinker who understands business requirements and ensures that the overall application architecture and solutions meet our business requirements with specific attention to future demands and functional growth
How we Work

We know that exceptional people have great ideas and are passionate about their work. Our culture encourages excellence and actively rewards contributions with:

Connection: Youre surrounded by talented people every day who are driven by their passion of a common goal.

Core Values: They define us. Living them helps us be the best at what we do.

Compensation & Benefits: Pay is driven by individual and corporate performance and we provide a multitude of benefits and perks.

Education: To ensure you are the best at what you do we invest in you

About Interac

Interac Corp. operates an economical, world-class debit payments system with broad-based acceptance, reliability, security, and efficiency. The organization is one of Canada's leading payments brands and is chosen an average of 16 million times daily to pay and exchange money. For more than 30 years, Interac Corp. and its predecessors, Interac Association and Acxsys Corporation, have facilitated secure financial transactions through the development of innovative and convenient debit and money transfer solutions. A leader in the prevention and detection of fraud, the organization has one of the lowest rates of fraud globally. Visit interac.ca or follow @INTERAC on Twitter. Interac Corp. has a diverse group of shareholders that includes banks, credit unions, caisses populaires, payment processors and merchants.

Interac Corp. believes in providing an inclusive workplace where all individuals have the opportunity to succeed. We are committed to doing so by providing accessible employment practices. Contact a member of the Human Resources department if you need accommodation at any point in the application process or want more information about our Accessibility Policy, which is also available online here.

Powered by JazzHR",3.6,Interac,Toronto,"Toronto, Canada",201 to 500 employees,1984,Company - Private,Financial Transaction Processing,Finance,Unknown / Non-Applicable,-1,82.0,36,data engineer,senior,0,1,0,0,0,1,1,1,0,0,0,0,0,0,0,5375,0
428,"Infoblox is the global leader in providing actionable network intelligence through network services, security, and threat intelligence. We give companies total control and visibility of their network, allowing them to operate more efficiently and intelligently.

We are looking for a Senior Big Data Engineer to join our SaaS Next Generation Platform Team in Burnaby, BC. In this role, you will be responsible for developing, maintaining, evaluating, and testing big data technologies. Our organization is extremely data-driven where technical innovations happen and you will have an opportunity to use cutting edge technology across all stages of the development lifecycle and be part of our exciting and innovative initiatives.

Responsibilities:
Join an agile SaaS team to design, develop and maintain features and iteratively deploy services using Infoblox’s cloud-based architecture
Design and implement components of our Next Generation Platform
Recommend ways to improve data reliability, efficiency and quality
Expand and grow data platform capabilities to solve new data problems and challenges
Build large-scale data processing systems using cloud computing technologies
Build high-performance algorithms, prototypes, and proof of concepts
Apply complex big data concepts with a focus on collecting, parsing, managing, and analyzing large sets of data to turn information into insights
Work closely with various cross-functional product teams
Stay current on key trends especially in the area of technologies and frameworks like Mesos/Marathon, Kubernetes, Docker, etc.
Requirements:
6+ years experience, 2+ in Big Data Engineering
Proficient in Java, Scala, Golang, or Python
Good understanding of Microservices architecture
Expertise in BigData - MapReduce, HIVE, HBase, Spark Streaming, Apache Flink, Storm, Kafka, In-memory Database, JMS
Experience with NoSQL databases such as Cassandra/DynamoDB
Good exposure in application performance tuning, memory management, scalability
Ability to design highly scalable distributed systems, using different open source technologies
Experience building high-performance algorithms
Education
Bachelor’s degree in CS, CE or EE is required
Masters in CS, CE, or EE is preferred
Perks:
Work with a world-class Engineering team in a rapidly growing company
A career path with opportunities to grow
Boutique office space with state of the art amenities, located in the heart of Metro Vancouver area; steps from SkyTrain and Metrotown Mall
Cross-functional break room stocked with snacks and beverages
And many, many more perks!
It’s an exciting time to be at Infoblox. We are the market leader in technology for network control. Our success depends on bright, energetic, talented people who share a passion for excellence in building the next generation of networking technologies—and having fun along the way. Infoblox offers a fast-paced, action-oriented environment. We promote a culture that embraces innovation, change, teamwork, and strong partnerships. Join the winning Infoblox team—our future looks bright, and so will yours. To check out what it’s like to be a Bloxer click here.

#LI-AB1",4.2,Infoblox,Burnaby,"Santa Clara, CA",1001 to 5000 employees,1999,Company - Private,Enterprise Software & Network Solutions,Information Technology,$1 to $2 billion (CAD),-1,82.0,21,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,3146,0
429,"Senior Hands-on Spark and Hadoop framework and Utilities Developer who will take the overall responsibility for end to end software development, continuous integration and continuous deployment, meeting a high level of code quality working within established timelines and Engineering Excellence best practices. The ideal candidate will be a resourceful software professional who can comfortably work in a large development team in a globally distributed, dynamic work environment that fosters diversity, teamwork and collaboration. Qualifications: Bachelors degree (in Science, Computers, Information Technology or Engineering) At least 8+ years overall IT experience with 3+ years in a technical lead role with experience on large & complex projects Technical / Functional Proficiency: Hadoop Spark using Scala/Java minimum 3 years of experience. 3-4 years of core Java experience with Spring and ORM frameworks such as Hibernate. 3 years of Cloudera Hadoop 5.x / 6.x. Experience with real time messaging and ingestion including Kafka. Experience with developing frameworks and utility services including logging/monitoring using ELK or similar Working experience with Big Data (HBase/Impala/Hive) No-SQL databases. Hands on experience with open source software platforms Linux. Experience with Oracle and/or MYSQL database application development. Agile build and deploy DevOps experience preferred. Cloud experience with Google Cloud (DataProc or BigQuery) or AWS EMR/Cloudera on EC2 is a plus Leadership Skills: Proven ability in working with the development team members and other partners, with minimal supervision Strong verbal and written communications skills, excellent interpersonal skills with ability to communicate well at all levels Team Player, self-starter and thorough who is willing to take on any assigned job/responsibilities Ability to learn new skills quickly with little supervision and ensuring the detail is of high priority Efficiently and effectively manages work, time, and resources. Ability to work under high-pressure situations and effectively prioritize in a highly dynamic work environment that includes a global focus. This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - CA ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,Citi,Mississauga,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,$10+ billion (CAD),-1,82.0,208,data engineer,senior,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,3608,0
430,"Data Innovation and Architecture technology group has responsibility for key technologies and capabilities on behalf of the Treasury and Trade Services (TTS) organisation at Citi. TTS provides transaction and banking services to Citis Institutional Clients, and is truly a global organisation, having a presence in over 100 countries. TTS is one of the strongest businesses at Citi, delivering consistent quarter-on-quarter profitability and growth. This is a Sr. Machine Learning Engineer role within the Big Data Analytics team to develop and operationalize AI/Machine Learning models. The candidate will work on existing applications and frameworks for data delivery and will also be responsible for developing new models and frameworks, and delivering on business use cases. The role is within a technology group, but involves engagement with business and understanding of operating environments. Responsibilities: Design, develop, and implement machine learning software to analyze large amounts of structured and unstructured data; Use statistics and machine learning techniques to develop algorithms to extract information from data; Test and enhance algorithms to measure the accuracy of software Develop and run machine learning tests and experiments Develop frameworks to Train and retrain systems when necessary Extend existing ML libraries and frameworks Liaising with partner teams and distributed groups to secure rapid engagement, support and problem solving as needed Analysis and documentation of data from variety of sources and formats Developing mappings and code for integration of data sets from disparate domains Quality assurance and testing of analytical routines and data frameworks Effective problem solving and issue identification in the event of outages and failures Remain up to date on industry research and new techniques in machine learning Understanding technology industry trends, how they impact our future solutions and provide strategic direction for the development community. Qualifications & Competencies: Strong background in Algorithms, Data Structures, Machine Learning, Deep Learning and Natural Language Processing. Experience must include text analytics such as Named Entity Recognition (NER), Topic Modelling, Sentiment Classification etc., Extensive hand-coding expertise in programming language such as Python and Core Java Experience in building and managing REST APIs. Experience in systems integration, web services, batch processing Experience with distributed systems such as Hadoop/MapReduce, Spark, streaming data processing, cloud architecture. Familiarity with machine learning frameworks and libraries (like scikit-learn, SparkML, tensorflow, pytorch etc.,) Experience of visualisation tools such as Qlikview, Tableau, MicroStrategy Candidate should have strong analytical and numeric capability, a background in analytics and knowledge of analytical tools / data science tools and techniques. Candidate should be a strong communicator and a disciplined worker, who is capable of self-motivation and effective problem-solving PhD, Masters in computer science, applied mathematics or/computational discipline. Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - CA ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.7,Citi,Mississauga,"New York, NY",10000+ employees,1812,Company - Public,Investment Banking & Asset Management,Finance,$10+ billion (CAD),-1,82.0,208,machine learning engineer,senior,0,1,0,1,0,0,1,0,0,0,0,0,1,1,1,4486,0
431,"The Data Engineering practice at Gore Mutual Insurance is going through an exciting transformation to modernize technologies and approaches, and to better enable a data driven future for the company. As such, the Data Engineering team is looking for a new member to assist with several new and ongoing data migration, acquisition, and development projects, with the goal of expediting their delivery.

We are on a new path called NEXT HORIZON

The insurance industry is changing at an exponential pace, driven by changing customer experience, climate change and technology. In response Gore Mutual is making bold moves to reposition our company as a purpose driven, digitally led national insurer. Next Horizon is our 10-year vision and strategy that sets a new path for our company.

Come and make your mark on our Next Horizon!

What will you do?
• Design, develop, and document new data solutions, including data pipelines and data storage systems
• Collect and analyze requirements to help inform development activities and objectives
• Identify new opportunities for data acquisition and help with utilization of new data assets
• Maintain and improve existing data solutions on an ongoing basis
• Mentor and assist team members with solution implementation and technology adoption

What will you need to succeed?
• Undergraduate degree in a technical field such as Computer Science, Software Engineering, etc.
• Proficiency with and in-depth understanding of development best practices in Python and SQL
• Extensive experience developing Object Oriented and Functional programs, applications, and APIs
• Extensive knowledge and experience with data pipeline development using PySpark preferably within Databricks
• Experience working with and analyzing structured, semi-structured, and unstructured datasets, and identification and extraction of key metrics from large and disparate data sources
• Experience modelling data storage systems using modern approaches and best practices
• Experience with the Azure platform, including core data services such as Data Factory, Event Hubs, Databricks, Azure Synapse, Kubernetes, etc.

Nice to Have
• Graduate degree in a technical field with specialization in Analytics, Data Science, or a related subject
• Azure certification

Gore Mutual Insurance is committed to providing accommodations for people with disabilities during all phases of the recruiting process, including the application process. If you require accommodation because of a disability, we will work with you to meet your needs. If you are selected for an interview and require accommodation, please advise the HR representative who will consult with you to determine an appropriate accommodation.",3.6,Gore Mutual Insurance Company,Cambridge,"Cambridge, Canada",201 to 500 employees,1839,Company - Private,Insurance Operators,Insurance,$100 to $500 million (CAD),-1,82.0,181,data engineer,senior,0,1,0,0,0,1,1,0,1,0,0,0,0,0,0,2715,0
432,"Located in the heart of downtown Montreal, AdGear is an advertising technology startup that is now part of Samsung Electronics. We work on complex technical challenges at an increasingly impressive scale, addressing hundreds of millions of devices across the world. Being part of an international company and doing business around the world means that we get to work on big, complex projects with stakeholders and teams in Silicon Valley, Korea and Europe.

As our infrastructure and business continue to grow, we are looking to expand our Engineering team.

What youll do

As a Machine Learning Engineer, you will be responsible for designing, building, deploying, and maintaining ML pipelines. You will collaborate closely with our backend and data teams to build scalable ML solutions that can be leveraged by our bidding stack (high-performance, low-latency system). With the help of our SRE team you will productionize these solutions and help with monitoring their health (not on call). As a consequence, there will be opportunities to contribute to open source, conduct research and development, review code, and share knowledge.

You will work with some incredibly talented and passionate developers within an engineering team with a strong technological background building the next generation of AdGear's administrative interfaces, ad decisioning, delivery, data processing and analytics systems.

This is us: https://github.com/adgear/team

In this position, the chosen candidate is expected to have a hands-on, problem-solving approach and a friendly human-facing side to communicate and manage expectations.

REQUIRED SKILLS AND/OR EXPERIENCE
BS degree with 5 years experience or MS in Computer Science with 2 years experience.
Knowledge in linear algebra, calculus, statistics, and optimization.
Experience with statistical machine learning algorithms or deep learning algorithms.
Experience with data collecting and cleaning (Kafka, Spark).
Experience with a deep learning framework: TensorFlow or Torch or Keras.
Experience with shipping real-world production systems
Passionate about driving the performance of machine learning algorithms towards the state of the art, and in challenging us to continually improve what is possible.
You have a track record of making things better and leading solutions that remove technical pain points and facilitate growth
You enjoy working with others who are smart and passionate about building useful, reliable, performant products
You can balance moving fast with breaking things, and you make sure you know how to fix them when they do break
GENERAL SKILLS
Good communication skills and capacity/willingness to work in a multi-teams environment.
Be resourceful, inventive and passionate about technologies.
You are eager to challenge the status quo and willing to learn new programming languages
Demonstrated ability to prioritize tasks and resolve problems in a timely manner;
Ability to work autonomously, multi-task and work in a fast-paced and stressful environment;
Be proactive, addressing potential problems before they occur;
Strong attention to detail;
Excellent communication skills in English; French is an asset.
WHATS IN IT FOR YOU?
Competitive compensation package
Great choice of snacks and drinks in the office available daily
Board games and Ping-Pong
Company outings, roasts, and many more interesting things
Yoga in the office once a week
Referral bonus
Great rebates, coupons and promotions through Perkopolis
Amazing discounts through Samsung Employee Discounts website
100% Company-paid comprehensive extended health & dental coverage
Travel, Life, and Short/Long term disability Insurance
Group RRSP Matching Program up to 5%
Group TFSA Program
Powered by JazzHR",4.3,AdGear,Montreal,"Montreal, Canada",51 to 200 employees,2008,Company - Private,Computer Hardware & Software,Information Technology,$100 to $500 million (CAD),"Index Exchange, district m",82.0,12,machine learning engineer,senior,0,0,0,0,0,0,1,0,0,0,0,0,1,1,1,3742,2
433,"Senior Data Engineer

Nomis is looking for an outstanding data expert to join our team. The Data Engineer will collaborate closely with our client services team to process critical data while working to power advanced analytics and enable the integration of data science across the company. You are ready to be flexible and nimble in your work, from constructing ETL pipelines for customer delivery to participating in exploratory data analysis with our Analytics team.

Who We Are & What We Build

We partner with Banks and FinTechs on their journey to best-in-class pricing technology and analytics so that they deliver more value to their customers, employees and shareholders. Our top-notch people, proven technology, and innovative analytics are tackling big data challenges at banks and lenders every day. We deliver market-leading cloud-based Pricing & Profitability Management solutions and insights for the Banking & Financial Services industry leveraging cutting-edge behavioral data science. We are a Blue Chip venture-backed company with the vision to transform the consumer banking landscape.

Responsibilities
Establish and maintain big data processing platform
Build data management applications and microservices on AWS
Design and implement Hive/Greenplum/RedShift distributed data warehouses and standard schemas
Design, develop, maintain cross-platform ETL processes and MapReduce/Hive/Spark data processing workflows
Manage and maintain reference data securely on S3 and other storage systems
Support client services teams by
Manage, customize, and automate cloud-based (AWS) data processing supporting multiple clients
Administration of relational databases, capacity plans, infrastructure and storage design
Oversee and execute data migration from existing data stores
Application/implementation of custom analytics applications and datasets
Develop code standards, guidelines, and automated test suites to ensure highest data quality and integrity
Desired Skills and Requirement
Experience with building distributed systems, query processing, and the Hadoop ecosystem
Understanding of Data warehousing - architect and design data warehouse
Expertise with data schema - logical and physical data modeling
Knowledge of ETL processes and tools
Experience with AWS or a major cloud platform such as GCP
Proficiency in: Python, SQL, Java
Strong pluses:
Experience of Business Intelligence tooling such as Tableau
Experience with data mining techniques and analytics functions
Predictive analytics experience is a PLUS
Experience with Spark 2, Apache Airflow and other modern data engineering tooling a strong plus
Experience with streaming architectures and MPP databases such as Greenplum a strong plus
Up-to-date with the open-source community w.r.t. data engineering
Experience with the following services in AWS a strong plus: EMR, Lambda, Kinesis, Firehose, S3
Powered by JazzHR",4.5,Nomis,Toronto,"Toronto, Canada",1 to 50 employees,-1,Company - Private,-1,-1,Unknown / Non-Applicable,-1,82.0,-1,data engineer,senior,0,1,0,1,0,1,1,1,0,0,0,0,0,0,0,2900,0
434,"OVERVIEW

We're looking for experienced Data Engineers to join our fast moving team. We work on a range of interesting and challenging problems, from supporting thousands of concurrent shoppers and processing millions of data points in real time, to building enterprise grade solutions for our retailer partners to help them understand their customers better. Our platform is complex, rapidly scaling and processing millions of transactions in real-time all the time. There is a tremendous amount of opportunity in front of us, and joining now gives you a chance to grow your career and interests as we succeed.

ABOUT THE JOB
Be part of a small team, with a large amount of ownership and responsibility for managing things directly.
Ship high-quality solutions with a sense of urgency and speed.
Architect, develop, test and maintain big data pipelines and processing systems
Collaborate with Data Scientists, Machine Learning Engineers and Software Engineers and provide recommendations and actionable strategies for performance enhancements and development of best practices
Own a large part of the process to enforce data governance and privacy while improving data quality and reliability
Have the freedom to suggest and drive organization-wide initiatives
ABOUT YOU
5+ years of experience
Bachelor's degree in Computer Science, Computer Engineering, Electrical Engineering, or equivalent work experience
A blend of product, system and people knowledge that lets you jump into a fast paced environment and contribute from day one
Experience with big data tools and databases (Apache Spark, Apache Hive, Presto, Snowflake, PostgreSQL)
Experience with data pipeline and workflow management tools (Snowplow, Azkaban, Luigi, Airflow, etc)
Strong programming skills in Python and/or Go
Extensive experience working with large codebases and cross-functional teams
Experience with cloud native infrastructure (AWS, Docker, Kubernetes, etc)
Excellent written and verbal communication skills; able to effectively collaborate with diverse teams.
Ability to balance a sense of urgency with shipping high quality and pragmatic solutions
Experience in distributed systems and scale
Experience with AI/Machine Learning/Data Modeling",3.4,Instacart,Toronto,"San Francisco, CA",1001 to 5000 employees,2012,Company - Private,Internet,Information Technology,Unknown / Non-Applicable,-1,82.0,8,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,2223,0
435,"Address:

2000 Argentia Road, Plaza 1
Job Family Group:
Data Analytics & Reporting

The Reporting and Segmentation Analyst, North American Collections Analytics for data and analytics will assist with:
Sourcing and management of data sets to support strategy and segmentation function.
Segmentation, ad hoc analytics, and test design to support decisioning within collections and recovery.
Monthly performance reporting incorporating performance reads of different strategy changes and new initiatives
This role requires strong data and analytical capabilities to develop new analytics insight supporting a 500+ FTE operations center. The analyst will assist in the development of new collection and recovery strategies such as call center and digital campaigns for high risk customers, next best offer prioritization for collections offers and deals, outsourcing and legal campaigns on defaulting accounts, and debt sale break-even analysis using decision trees, logistic scorecards, and NPV modelling.
They will also support through interpretation of monthly performance results across collections portfolios including shifts in customer risk profile as well as strategy performance.
Change Management
New strategy development including data-driven analytics, test design, and rollout plan
Assist in development of segmentation and advanced analytics to drive different treatments and strategies
Drive profitability assessment of Collection and recovery strategies through risk / return analysis using financial modelling.
Work with internal and external operations teams to define specific treatments to be allocated by strategy
Review strategy changes from conceptual design to analytical sizing to test design to stakeholder buy-in to implementation to interpretation of results
Business Performance Management
Management of existing strategies including monitoring / measurement and communication to key stakeholders
Manage continuously measure of tests’ impact through implementation of dedicated reporting and ad hoc analysis. As required, amend / refine strategies through a defined change management process.
Monitor operations execution to ensure that strategies are executed as designed. Assist operations in the execution of strategy through standardized and ad hoc analysis including capacity planning, AHT analysis, etc.
Monitor profile and portfolio changes across countries, products, and delinquency levels
Manage monthly performance views across portfolios including operational execution, strategy performance, and changes to risk profile.
Qualifications

Knowledge and Experience:
Bachelor’s Degree in Mathematics, Statistics, Physics, Computer Science, Economics, Finance, or other quantitative fields. Master’s Degree preferred
3+ years of experience in analytics (ideally scorecard development / monitoring, customer segmentation, strategy development in Credit Risk, Marketing or Collection). Graduate Degree with 1+ years of experience will also be considered.
Working level statistical skills, including regression, time series, champion/challenger testing, and decision tree modeling.
Experiences with automated report production, preferably through SAS.
Strong data mining skills in SAS Enterprise Guide and Enterprise Miner, or in other programming software such as R and Python
Ability to access complex data sources, explore data resources, clean and compile data to provide analytical driven solutions to real business problems.
Knowledge of consumer credit products
Skills:
Excellent analytical thinking capability, skilled at translating business problems into analytical questions and summarizing data to reach conclusion.
Good communication skills. Strong ability to explain complicated ideas to broader audience.
Proactive problem solver and team player.
Good presentation skills, able to organize information and present analytical result in an efficient manner
We’re here to help

At BMO we are driven by a shared Purpose: Boldly Grow the Good in business and life. It calls on us to create lasting, positive change for our customers, our communities and our people. By working together, innovating and pushing boundaries, we transform lives and businesses, and power economic growth around the world.

As a member of the BMO team you are valued, respected and heard, and you have more ways to grow and make an impact. We strive to help you make an impact from day one – for yourself and our customers. We’ll support you with the tools and resources you need to reach new milestones, as you help our customers reach theirs. From in-depth training and coaching, to manager support and network-building opportunities, we’ll help you gain valuable experience, and broaden your skillset.

To find out more visit us at https://bmocareers.com.

BMO is committed to an inclusive, equitable and accessible workplace. By learning from each other’s differences, we gain strength through our people and our perspectives. Accommodations are available on request for candidates taking part in all aspects of the selection process. To request accommodation, please contact your recruiter.",3.7,BMO Financial Group,Mississauga,"Toronto, Canada",10000+ employees,1817,Company - Public,Banks & Building Societies,Finance,$10+ billion (CAD),"CIBC, RBC, TD",82.0,203,data analyst,senior,1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,5114,3
436,"Senior Hands-on Spark and Hadoop framework and Utilities Developer who will take the overall responsibility for end to end software development, continuous integration and continuous deployment, meeting a high level of code quality working within established timelines and Engineering Excellence best practices. The ideal candidate will be a resourceful software professional who can comfortably work in a large development team in a globally distributed, dynamic work environment that fosters diversity, teamwork and collaboration. Qualifications: Bachelors degree (in Science, Computers, Information Technology or Engineering) At least 8+ years overall IT experience with 3+ years in a technical lead role with experience on large & complex projects Technical / Functional Proficiency: Hadoop Spark using Scala/Java minimum 3 years of experience. 3-4 years of core Java experience with Spring and ORM frameworks such as Hibernate. 3 years of Cloudera Hadoop 5.x / 6.x. Experience with real time messaging and ingestion including Kafka. Experience with developing frameworks and utility services including logging/monitoring using ELK or similar Working experience with Big Data (HBase/Impala/Hive) No-SQL databases. Hands on experience with open source software platforms Linux. Experience with Oracle and/or MYSQL database application development. Agile build and deploy DevOps experience preferred. Cloud experience with Google Cloud (DataProc or BigQuery) or AWS EMR/Cloudera on EC2 is a plus Leadership Skills: Proven ability in working with the development team members and other partners, with minimal supervision Strong verbal and written communications skills, excellent interpersonal skills with ability to communicate well at all levels Team Player, self-starter and thorough who is willing to take on any assigned job/responsibilities Ability to learn new skills quickly with little supervision and ensuring the detail is of high priority Efficiently and effectively manages work, time, and resources. Ability to work under high-pressure situations and effectively prioritize in a highly dynamic work environment that includes a global focus. This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required. Citi Canada is an equal opportunity employer. Accordingly, we will make accommodations to respond to the needs of people with disabilities (including, without limitation, physical and mental health disabilities) during the recruitment process and otherwise in accordance with law. Individuals who view themselves as Aboriginals, members of visible minority or racialized communities, and people with disabilities are encouraged to apply. ------------------------------------------------- Grade :All Job Level - All Job FunctionsAll Job Level - All Job Functions - CA ------------------------------------------------------ Time Type :Full time ------------------------------------------------------ Citi is an equal opportunity and affirmative action employer. Minority/Female/Veteran/Individuals with Disabilities/Sexual Orientation/Gender Identity. Citigroup Inc. and its subsidiaries (""Citi) invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity CLICK HERE . To view the ""EEO is the Law"" poster CLICK HERE . To view the EEO is the Law Supplement CLICK HERE . To view the EEO Policy Statement CLICK HERE . To view the Pay Transparency Posting CLICK HERE .",3.5,Citibank,Mississauga,"Elk Grove Village, IL",5001 to 10000 employees,-1,Subsidiary or Business Segment,Lending,Finance,$50 to $100 million (CAD),-1,82.0,-1,data engineer,senior,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,3608,0
437,"As a Senior Big Data Engineer in the Analytics and Machine Learning group you will provide technical expertise over development of a new, large (100+TB) green field data project. The project is for storing and extracting value from the results of Data Science and natural language processing. This role involves working closely with the Technical Program Manager and the Development Lead to understand the business requirements and translate the requirements into a scalable data system. The data system will be used for a wide range of analytics and visualizations. One of the primary use goals is to surface the results of Machine Learning algorithms in innovative ways.
About You:
5+ years of experience with a high level programming language like Java or Python
Expertise with a Large-scale Graph database ~ JanusGraph, DGraph, OrientDB, Neo4j
Expertise with a Large-scale Timeseries database ~ InfluxDB, RiakTS, M3DB
Expertise in data processing using technologies like Spark Streaming, Spark SQL, or Map/Reduce.
Expertise in Hadoop related technologies such as HDFS, Azkaban, Oozie, Impala, Hive, and Pig.
Expertise in developing big data pipelines using technologies like Kafka, Flume, or Storm.
Experience working on systems with petabytes of data and millions of transactions per day
Experience developing, maintaining and scaling an ever growing big data pipeline
(Nice to have) Experience with microservices
(Nice to have) Experience with Kubernetes

Global Relay is the leading provider of cloud-based archiving, supervision, eDiscovery, and analytics for the global financial sector. We deliver services to 23,000 customers in 90 countries, including 22 of the top 25 global banks. Our market-leading archiving service supports email, instant messaging, Bloomberg®, Thomson Reuters, social media, mobile messaging, and more – with mobile, Outlook, and web access.
Our Global Operations & Development Center is located in Vancouver, BC, Canada. In addition, we have offices in eight other cities across the world, including major financial centers like New York, Chicago, and London.
Over the years, we have won several major awards, including:
Company of the Year from the BC Tech Association (2016)
Canada’s 50 Best Small and Medium Employers (2014, 2015)
Canada’s Top Employers for Young People (2014)
Canada’s Top 10 Most Admired Corporate Cultures (2013, 2016)
Canada’s Best Managed Companies (2013 - present)
Technology Fast 50 – Leadership (2014, 2018)
We provide fantastic opportunities to individuals passionate about business and technology. For those with international business aspirations, we offer invaluable opportunities for doing business with some of the world’s largest, most influential firms. Our company is also perfect for those who want to create cool technology using massively scalable, big-data architecture, with a strong focus on mobile.
To learn more about our business, culture, and community involvement, visit www.globalrelay.com.
Think you're a great fit for this job? Apply today with your cover letter and resume.",3.1,Global Relay,Vancouver,"Vancouver, Canada",201 to 500 employees,1999,Company - Private,Computer Hardware & Software,Information Technology,$25 to $50 million (CAD),"Smarsh, Proofpoint, Sonian",82.0,21,data engineer,senior,0,1,0,0,0,1,1,0,0,0,0,0,1,0,0,3061,3
